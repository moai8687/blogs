{"./":{"url":"./","title":"介绍","keywords":"","body":"Welcome to Lyon's blog! 🍀 由于博文技术层次较低,完整度不高,本博客将在后期断断续续重构~ 关于作者 🍀 Email : lyon.yang@qq.com GitHub : https://github.com/lyonyang QQ : 547903993 微信 : Happy547903993 博客说明 🍀 欢迎收藏交流 , 欢迎Issues ! 如需转载 , 请注明出处 : https://lyonyang.github.io/blogs 如果本博客对你有帮助,请顺手点个🍀star🍀吧! 文章使用Markdown格式编写 , 托管于Github , 主要使用工具 : GitBook , 构建本书 Travis-CI , 持续构建 Typora , 编写MarkDown 博客目录 : . ├── Python ├── Go ├── MySQL ├── Front-End │ └── Vue ├── Web-Framework │ ├── Django │ ├── Django-Rest-Framework │ └── Flask ├── Redis ├── DesignPattern ├── Algorithms ├── Linux │ └── Git └── Read 如果你也想和我一样 , 搭建一个这样的博客 , 点这里 : GitHub Pages&Gitbook&Travis CI持续构建博客 动态 🍀 《高性能MySQL》 ---- 2019年9月 "},"SUMMARY.html":{"url":"SUMMARY.html","title":"目录","keywords":"","body":"Summary 介绍 目录 Python Basis Python - 语言基础 Python - 数字类型 Python - 字符串 Python - 元组 Python - 列表 Python - 字典 Python - 集合 Python - 字符编码 Python - 文件操作 Advanced Python - 函数 Python - 函数进阶 Python - 匿名函数 Python - 内置函数 Python - 迭代器和生成器 Python - 递归 Modules Python - 模块初识 Python - 模块导入详解 Python - 包导入详解 Python - 时间和日期模块 Python - 正则表达式 Python - 序列化 Object-Oriented Python - 面向对象初识 Python - 面向对象之继承 Python - 面向对象之多态 Python - 面向对象之封装 Python - 属性方法-类方法-静态方法 Python - 特殊成员方法 Python - 反射 Python - 异常处理 Python - 特殊操作符 Network Python - 网络编程初识 Python - 网络编程之Socket Python - Socket实现QQ聊天 Python - Socket实现远程执行命令 Python - 网络编程之粘包 Python - Socketserver实现多并发 Concurrent Python - 进程与线程 Python - 并发编程之多线程 Python - 并发编程之多进程 Python - 多进程实例及回调函数 Python - 并发编程之协程 Python - 并发编程之IO多路复用 Python - 实现线程池 Standard-Library Python - 标准库之os Python - 标准库之random Python - 标准库之sys Python - 标准库之wsgiref Third-Library Python - 第三方库之PyMySQL Python - 第三方库之MySQLdb Python - 第三方库之SQlAlchemy In-Depth Python - 对象机制 Python - 对象的创建 Python - 整数对象 Python - 字符串对象 Python - List对象 Python - Dict对象 Python - Tuple对象 Python - 垃圾回收 Python - 元类 Go Golang - 语言基础 MySQL MySQL - 库操作 MySQL - 数据类型 MySQL - 存储引擎 MySQL - 表操作 MySQL - 数据操作 MySQL - 索引 MySQL - 视图 MySQL - 存储过程与函数 MySQL - 触发器与事务 MySQL - SQL注入 SQL优化 前端 Web开发 - HTML-head Web开发 - HTML-body Web开发 - CSS Web开发 - JavaScript Web开发 - BOM Web开发 - DOM Web开发 - jQuery Web开发 - Ajax Vue Vue - 介绍 Vue - 实例 Vue - 模板语法 Vue - 计算属性和侦听器 Vue - Class与Style 绑定 Vue - 条件渲染 Vue - 列表渲染 Vue - 事件处理 Vue - 组件基础 Vue - Vue-cli Web框架 HTTP基础 REST ORM简介 Django Web框架简介 Django - Django初识 Django - Settings Django - Urls Django - Views Django - Model Django - Model Fields Django - Model Field Options Django - Model QuerySet API Django - Model Making queries Django - Forms Django - Template Django - Template Language Django - Middleware Django - Sessions Django - Authentication System Django - 源码之startproject Django - 源码之runserver Django - 源码之middleware Django - 源码之url Django - 源码之admin Django - Django命令整理 Django-Rest-Framework Quickstart Tutorial 1 Serialization Tutorial 2 Requests and Responses Tutorial 3 Class-based Views Tutorial 4 Authentication & Permissions Tutorial 5 Relationships & Hyperlinked APIs Tutorial 6 ViewSets & Routers Tutorial 7 Schemas & client libraries Flask Flask - 源码简要说明 Flask - 源码之开始 Flask - 源码之配置 Flask - 源码之路由 Flask - 源码之视图 Flask - 源码之蓝图 Flask - 源码之本地线程 Flask - 源码之上下文 Flask - 源码之信号 Flask - 扩展 DBUtils virtualenv基本使用 Tornado Redis Redis - 简介 Redis - 配置参数说明 Redis - 基础命令 Redis - 数据库 Redis - 事务 Redis - 主从复制 Redis - 集群 Redis - Sentinel Python操作MongoDB Python操作Redis 设计模式 六大原则 单例模式 算法 算法基础 排序算法 Linux Celery Docker Git Git&GitHub Git基础命令 GitHub Pages&Gitbook&Travis CI持续构建博客 Travis CI Linux基础命令 RabbitMQ vim Go入门指南 1 2 1 2 3 4 5 6 7 8 0 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 0 10 11 12 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 0 1 2 3 4 5 6 0 10 11 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 0 10 11 12 13 14 1 2 3 4 5 6 7 8 9 0 10 11 12 1 2 3 4 5 6 7 8 9 0 10 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 0 10 1 2 3 4 5 6 7 8 9 0 1 0 10 11 1 2 3 4 5 6 7 8 9 directory preface RabbitMQ Read "},"01-Python/":{"url":"01-Python/","title":"Python","keywords":"","body":"The road to Python 介绍 本目录下为Python之路系列文章 目录结构如下 : Python ├── Basis -- 基础篇 ├── Advanced -- 进阶篇 ├── Modules -- 模块篇 ├── Object-Oriented -- 面向对象篇 ├── Network -- 网络编程篇 ├── Concurrent -- 并发编程篇 ├── Standard-Library -- 标准库篇 ├── Third-Library -- 第三方库篇 └── In-Depth -- 深入篇 欢迎阅读 , 文章尚未整理完成 , 持续更新中 ... "},"01-Python/01-Basis/":{"url":"01-Python/01-Basis/","title":"Basis","keywords":"","body":"The road to Python - Basis 介绍 🍀 Python基础主要包括基础语句 , 基础数据类型 , 字符编码 , 文件操作等 基础语句 🍀 Hello World 变量 行和缩进 多行语句 注释 input print 数据运算 条件语句 for while 基础数据类型 🍀 数字 , Number 字符串 , String 元组 , Tuple 列表 , List 字典 , Dictionary 集合 , Set "},"01-Python/01-Basis/01-Python - 语言基础.html":{"url":"01-Python/01-Basis/01-Python - 语言基础.html","title":"Python - 语言基础","keywords":"","body":"Python - Python基础 Hello World 🍀 学一门语言基本都是从Hello World开始的 , 如下一个最简单的Hello World程序 Python 3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AMD64)] on win32 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print(\"Hello World\") Hello World >>> 此为Python 3.5.2版本 , 上述代码为在Windows环境命令行中执行 , 即以管理员身份运行 \"命令提示符\" # 已添加环境变量 C:\\Windows\\system32>python Python 2.7.x 版本的Hello World程序 Python 2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 20:53:40) [MSC v.1500 64 bit (AMD64)] on win32 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> print \"Hello World\" Hello World >>> 当然使用Python shell 仅仅适合处理一些非常简单的小程序 , 对于比较复杂 , 代码量稍微大一点的就不适合了 变量 🍀 变量用于存储在计算机程序中被引用和操作的信息 变量可能被明确为是能表示可变状态、具有存储空间的抽象(如在Java和Visual Basic中) , 变量的唯一目的是在内存中标记和存储数据 , 这些数据可以在整个程序中使用 声明变量 # 声明一个变量name,并绑定值\"Lyon\" name = \"Lyon\" # 同时为多个变量赋值 a = b = c = 1 Python变量定义的规则 : 变量名只能是 字母、数字或者下划线的任意组合 变量名的第一个字符不能是数字 以下关键字不能声明为变量名 , 属于Python中的保留字and and exec not assert finally or break for pass class from print continue global raise def if return del import try elif in while else is with except lambda yield 行和缩进 🍀 Python 与其他语言最大的区别就是 , Python 的代码块不使用大括号 {} 来控制类 , 函数以及其他逻辑判断 , Python 最具特色的就是用缩进来写模块 缩进的空白数量是可变的 , 但是所有代码块语句必须包含相同的缩进空白数量 , 这个必须严格执行 if True: print \"True\" else: print \"False\" ''' 执行会出现错误提醒: IndentationError: unexpected indent ''' IndentationError: unexpected indent 错误是Python编译器在告诉你 , 你的文件里格式有问题 , 可能是tab和空格没对齐的问题 还有IndentationError: unindent does not match any outer indentation level 错误表明 , 你使用的缩进方式不一致 , 有的是 tab 键缩进 , 有的是空格缩进 , 改为一致即可。 因此 , 在 Python 的代码块中必须使用相同数目的行首缩进空格数 建议你在每个缩进层次使用 单个制表符 或 两个空格 或 四个空格 , 切记不能混用 多行语句 🍀 Python语句中一般以新作为为语句的结束符 但是我们可以使用斜杠 \\ 将一行的语句分为多行显示 , 如下 : total = item_one + \\ item_two + \\ item_three 语句中包含 [], {} 或 () 括号就不需要使用多行连接符 , 如下实例 : days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'] 同一行使用多条语句 Python可以在同一行中使用多条语句 , 语句之间使用分号 ; 分割 , 如下 : #!/usr/bin/python import sys; x = 'runoob'; sys.stdout.write(x + '\\n') 字符串 🍀 Python 可以使用引号( ' )、双引号( \" )、三引号( ''' 或 \"\"\" ) 来表示字符串 , 引号的开始与结束必须的相同类型的 其中三引号可以由多行组成 , 编写多行文本的快捷语法 , 常用于文档字符串 , 在文件的特定地点 , 被当做注释 word = 'word' sentence = \"This is a sentence\" paragraph = \"\"\"This is a paragraph Contains multiple statements\"\"\" 注释 🍀 Python中单行注释采用 # 开头 # 第一个注释 print(\"Hello,Python\") # 第二个注释 Python中多行注释采用三个单引号 ''' 或三个双引号 \"\"\" ''' 这是多行注释，使用单引号。 这是多行注释，使用单引号。 这是多行注释，使用单引号。 ''' \"\"\" 这是多行注释，使用双引号。 这是多行注释，使用双引号。 这是多行注释，使用双引号。 \"\"\" 字符编码 🍀 Python解释器在加载 .py 文件中的代码时 , 会对内容进行编码 (默认ASCII) 然而ASCII是无法处理中文的 , 所以如果我们的代码中出现了中文 , 那么需要在代码的顶端加上一句声明 #!/usr/bin/env python # -*- coding:utf-8 -*- ''' 第一行,为脚本语言指定解释器 第二行,告诉Python解释器,用utf-8编码来进行编码 ''' 用户输入 🍀 当我们需要用户自己输入信息时 , 就可以使用input 语句 , 如下 : # 让用户进行输入,并用变量name接收用户输入的值 name = input(\"Please input your name:\") 上述代码 , 会一直等待用户输入 , 直到用户按回车键后才会退出 输出 🍀 当我们需要让控制台输出一些我们想要的信息时 , 可以使用print 语句 , 在Hello World里我们已经见到了 #!/usr/bin/python # -*- coding: UTF-8 -*- # Author:Lyon x = \"a\" y = \"b\" # 换行输出 print(x) print(y) print('---------') # 不换行输出 print(x,) print(y,) # 不换行输出 print(x, y) ''' 执行结果: a b --------- a b a b ''' 数据类型 🍀 我们知道在变量创建时 , 会在内存中开辟一个空间 , 用来存放变量的值 , 而这些变量的值可以是各种各样的类型 , 如 : 数字 , 字符串 , 列表 , 元组 , 字典 , 集合等等 数字类型 int (整型) 整数的大小范围由计算机字长确定 long (长整型) 跟C语言不同 , Python的长整数没有指定位宽 , 即 : Python没有限制长整数数值的大小 , 但实际上由于机器内存有限 , 我们使用的长整数数值不可能无限大 注意 , 自从Python 2.2 起 , 如果整数发生溢出 , Python会自动将整数数据转换为长整数 , 所以如今在长整数数据后面不加字母 L 也不会导致严重后果了 float (浮点型) 浮点数用来处理实数 , 即带有小数的数字 , 类似于C语言中的double类型 , 占8个字节(64位) , 其中52位表示底 , 11位表示指数 , 剩下的一位表示符号 complex (复数) 复数由实数部分和虚数部分组成，一般形式为x+yh，其中的x是复数的实数部分，y是复数的虚数部分，这里的x和y都是实数 注 : Python中存在整数小数字池 : -5~257 , 在此范围的整数数字共享 布尔值 即真或假 , 1或0 更多数据类型 , 后续文章中详细整理 数据运算 🍀 算术运算符 运算符 描述 实例 + 加 - 两个对象相加 a + b 输出结果 30 - 减 - 得到负数或是一个数减去另一个数 a - b 输出结果 -10 * 乘 - 两个数相乘或是返回一个被重复若干次的字符串 a * b 输出结果 200 / 除 - x除以y b / a 输出结果 2 % 取模 - 返回除法的余数 b % a 输出结果 0 ** 幂 - 返回x的y次幂 a**b 为10的20次方 , 输出结果 100000000000000000000 // 取整除 - 返回商的整数部分 9//2 输出结果 4 , 9.0//2.0 输出结果 4.0 比较运算符 运算符 描述 实例 == 等于 - 比较对象是否相等 (a == b) 返回 False != 不等于 - 比较两个对象是否不相等 (a != b) 返回 True <> 不等于 - 比较两个对象是否不相等 (a <> b) 返回 True这个运算符类似 != > 大于 - 返回x是否大于y (a > b) 返回 False 小于 - 返回x是否小于y , 所有比较运算符返回1表示真 , 返回0表示假这分别与特殊的变量True和False等价 , 注意 , 这些变量名的大写 (a >= 大于等于 - 返回x是否大于等于y。 (a >= b) 返回 False 小于等于 - 返回x是否小于等于y。 (a 赋值运算符 运算符 描述 实例 = 简单的赋值运算符 c = a + b 将 a + b 的运算结果赋值为 c += 加法赋值运算符 c += a 等效于 c = c + a -= 减法赋值运算符 c -= a 等效于 c = c - a *= 乘法赋值运算符 c = a 等效于 c = c a /= 除法赋值运算符 c /= a 等效于 c = c / a %= 取模赋值运算符 c %= a 等效于 c = c % a **= 幂赋值运算符 c **= a 等效于 c = c ** a //= 取整除赋值运算符 c //= a 等效于 c = c // a 位运算符 运算符 描述 实例 & 按位与运算符 : 参与运算的两个值 , 如果两个相应位都为1 , 则该位的结果为1 , 否则为0 (a & b) 输出结果 12 , 二进制解释 : 0000 1100 \\ 按位或运算符 : 只要对应的二个二进位有一个为1时 , 结果位就为1 (a 丨 b) 输出结果 61 , 二进制解释 : 0011 1101 ^ 按位异或运算符 : 当两对应的二进位相异时 , 结果为1 (a ^ b) 输出结果 49 , 二进制解释 : 0011 0001 ~ 按位取反运算符 : 对数据的每个二进制位取反 , 即把1变为0 , 把0变为1 , ~x 类似于 -x-1 (~a ) 输出结果 -61 , 二进制解释 : 1100 0011 , 在一个有符号二进制数的补码形式 左移动运算符 : 运算数的各二进位全部左移若干位 , 由 a >> 右移动运算符 : 把\">>\"左边的运算数的各二进位全部右移若干位 , >> 右边的数字指定了移动的位数 a >> 2 输出结果 15 , 二进制解释 : 0000 1111 逻辑运算符 运算符 逻辑表达式 描述 实例 and x and y 布尔\"与\" - 如果 x 为 False , x and y 返回 False , 否则它返回 y 的计算值 (a and b) 返回 20 or x or y 布尔\"或\" - 如果 x 是非 0 , 它返回 x 的值 , 否则它返回 y 的计算值 (a or b) 返回 10 not not x 布尔\"非\" - 如果 x 为 True , 返回 False , 如果 x 为 False , 它返回 True not(a and b) 返回 False 成员运算符 运算符 描述 实例 in 如果在指定的序列中找到值返回 True , 否则返回 False x 在 y 序列中 , 如果 x 在 y 序列中返回 True not in 如果在指定的序列中没有找到值返回 True , 否则返回 False x 不在 y 序列中 , 如果 x 不在 y 序列中返回 True 身份运算符 运算符 描述 实例 is is 是判断两个标识符是不是引用自一个对象 x is y , 类似 id(x) == id(y) , 如果引用的是同一个对象则返回 True , 否则返回 False is not is not 是判断两个标识符是不是引用自不同对象 x is not y , 类似 **id(a) != id(b) , 如果引用的不是同一个对象则返回结果 True , 否则返回 False 运算符优先级表 , 从上到下优先级依次增高 Operator Description lambda Lambda expression if – else Conditional expression or Boolean OR and Boolean AND not x Boolean NOT in, not in, is, is not, , , >, >=, !=, == Comparisons, including membership tests and identity tests 丨 Bitwise OR ^ Bitwise XOR & Bitwise AND , >> Shifts +, - Addition and subtraction *, @, /, //, % Multiplication, matrix multiplication, division, floor division, remainder [5] +x, -x, ~x Positive, negative, bitwise NOT ** Exponentiation [6] await x Await expression x[index], x[index:index], x(arguments...), x.attribute Subscription, slicing, call, attribute reference (expressions...), [expressions...], {key: value...}, {expressions...} Binding or tuple display, list display, dictionary display, set display if ... else 🍀 场景一 : 用户登录验证 # 导入getpass模块 import getpass # 等待用户输入 name = input(\"请输入用户名：\") # 等待用户输入密码,密码不可见 password = getpass.getpass(\"请输入密码：\") # 如果用户密码正确,执行如下 if name ==\"Lyon\" and password ==\"yang\": print(\"欢迎你!\") # 否则执行如下 else： print(\"用户名或密码错误\") 场景二 : 猜年龄游戏 # 定义一个年龄 age =21 # 用户输入 user_input = int(input(\"input your guess num:\")) if user_input == age: print(\"Congratulations, you got it !\") elif user_input for循环 🍀 循环10次 for i in range(10): print(\"loop:\", i ) ''' 执行结果: loop: 0 loop: 1 loop: 2 loop: 3 loop: 4 loop: 5 loop: 6 loop: 7 loop: 8 loop: 9 ''' 小于5就跳入下一次循环 for i in range(10): if i while循环 🍀 写一个死循环 count = 0 while True： print(\"你是风儿我是沙，缠缠绵绵走天涯\", count) count += 1 "},"01-Python/01-Basis/02-Python - 数字类型.html":{"url":"01-Python/01-Basis/02-Python - 数字类型.html","title":"Python - 数字类型","keywords":"","body":"Python - 数字类型 Int 🍀 在Python 2.7版本中 , Python把int和long是分开的 iint 类型的最大值是2147483647 , 超过了这个值就是long 类型了(长整数不过是大一些的数) ; 而在3.x中 , python把 int 和 long 整合到一起了 , 以int来表示 >>> num = 123 >>> type(num) Float 🍀 float有两种表现形式 , 一种是十进制数形式 , 它由数字和小数点组成 , 并且这里的小数点是不可或缺的 ; 另一种是指数形式 , 用e(大写也可以)来表示之后可以有正负号 , 来表示指数的符号 , e就是10的幂 , 指数必须是整数 >>> a = 10E2 >>> a 1000.0 >>> b = 10e2 >>> b 1000.0 >>> c = 1.1 >>> type(c) None 🍀 表示该值是一个空对象 , 空值是python里一个特殊的值 , 用None表示 None不能理解为0 , 因为0是有意义的 , 而None是一个特殊的空值 ; None有自己的数据类型NoneType , 它与其他的数据类型比较永远返回False , 你可以将None复制给任何变量 , 但是你不能创建其他NoneType对象 >>> type(None) >>> None == 0 False >>> None == True False >>> None == False False Bool 🍀 bool就是用来表征真假的一种方式 True为真 , False为假 ; Python中的值是自带bool值的 , 非0即真 , 为0即假 >>> False + False 0 >>> True + True 2 >>> True + False 1 Complex 🍀 复数有实数和虚数部分组成 , 一般形式为 x + yj , 其中的 x 是复数的实数部分 , y是复数的虚数部分 , 这里x和y都是实数 注意 , 虚数部分不区分大小写 >>> -.6545 + 0J (-0.6545+0j) >>> 4.53e1 - 7j (45.3-7j) >>> 45.j 45j >>> 3.14j 3.14j Data & Time 🍀 Python提供了一个 time 和 calendar 模块可以用于格式化如期和时间 , 时间间隔是以秒为单位的浮点数 , 每个时间戳都以自从1970年1月1日午夜 (历元) 经过了多长时间来表示 , 所以1970年之前的日期就不能用时间戳来表示了 , 太遥远的日期也是不行的 , UNIX和Windows只支持到2038年 时间戳是最适合用来做日期运算的 time 🍀 获取本地时间 # 导入time模块 import time # 获取当前时间戳，单位是秒 now_timestamp = time.time() # 打印now_timestamp print(now_timestamp) # 获取本地时间,默认是获取当前时间 localtime = time.localtime() # 打印localtime print(localtime) # 获取本地时间，传入时间戳 localtime = time.localtime(now_timestamp) # 打印locatime print(localtime) ''' 执行结果: 1499085481.4974537 time.struct_time(tm_year=2017, tm_mon=7, tm_mday=3, tm_hour=20, tm_min=38, tm_sec=1, tm_wday=0, tm_yday=184, tm_isdst=0) time.struct_time(tm_year=2017, tm_mon=7, tm_mday=3, tm_hour=20, tm_min=38, tm_sec=1, tm_wday=0, tm_yday=184, tm_isdst=0) ''' 时间元组struct_time 序号 属性 值 0 tm_year 2008 1 tm_mon 1 到 12 2 tm_mday 1 到 31 3 tm_hour 0 到 23 4 tm_min 0 到 59 5 tm_sec 0 到 61 (60或61 是闰秒) 6 tm_wday 0到6 (0是周一) 7 tm_yday 一年中的第几天，1 到 366 8 tm_isdst 是否为夏令时，值有：1(夏令时)、0(不是夏令时)、-1(未知)，默认 -1 time模块中的方法 : FUNCTIONS asctime(...) asctime([tuple]) -> string Convert a time tuple to a string, e.g. 'Sat Jun 06 16:26:11 1998'. When the time tuple is not present, current time as returned by localtime() is used. clock(...) clock() -> floating point number Return the CPU time or real time since the start of the process or since the first call to clock(). This has as much precision as the system records. ctime(...) ctime(seconds) -> string Convert a time in seconds since the Epoch to a string in local time. This is equivalent to asctime(localtime(seconds)). When the time tuple is not present, current time as returned by localtime() is used. get_clock_info(...) get_clock_info(name: str) -> dict Get information of the specified clock. gmtime(...) gmtime([seconds]) -> (tm_year, tm_mon, tm_mday, tm_hour, tm_min, tm_sec, tm_wday, tm_yday, tm_isdst) Convert seconds since the Epoch to a time tuple expressing UTC (a.k.a. GMT). When 'seconds' is not passed in, convert the current time instead. If the platform supports the tm_gmtoff and tm_zone, they are available as attributes only. localtime(...) localtime([seconds]) -> (tm_year,tm_mon,tm_mday,tm_hour,tm_min, tm_sec,tm_wday,tm_yday,tm_isdst) Convert seconds since the Epoch to a time tuple expressing local time. When 'seconds' is not passed in, convert the current time instead. mktime(...) mktime(tuple) -> floating point number Convert a time tuple in local time to seconds since the Epoch. Note that mktime(gmtime(0)) will not generally return zero for most time zones; instead the returned value will either be equal to that of the timezone or altzone attributes on the time module. monotonic(...) monotonic() -> float Monotonic clock, cannot go backward. perf_counter(...) perf_counter() -> float Performance counter for benchmarking. process_time(...) process_time() -> float Process time for profiling: sum of the kernel and user-space CPU time. sleep(...) sleep(seconds) Delay execution for a given number of seconds. The argument may be a floating point number for subsecond precision. strftime(...) strftime(format[, tuple]) -> string Convert a time tuple to a string according to a format specification. See the library reference manual for formatting codes. When the time tuple is not present, current time as returned by localtime() is used. Commonly used format codes: %Y Year with century as a decimal number. %m Month as a decimal number [01,12]. %d Day of the month as a decimal number [01,31]. %H Hour (24-hour clock) as a decimal number [00,23]. %M Minute as a decimal number [00,59]. %S Second as a decimal number [00,61]. %z Time zone offset from UTC. %a Locale's abbreviated weekday name. %A Locale's full weekday name. %b Locale's abbreviated month name. %B Locale's full month name. %c Locale's appropriate date and time representation. %I Hour (12-hour clock) as a decimal number [01,12]. %p Locale's equivalent of either AM or PM. Other codes may be available on your platform. See documentation for the C library strftime function. strptime(...) strptime(string, format) -> struct_time Parse a string to a time tuple according to a format specification. See the library reference manual for formatting codes (same as strftime()). Commonly used format codes: %Y Year with century as a decimal number. %m Month as a decimal number [01,12]. %d Day of the month as a decimal number [01,31]. %H Hour (24-hour clock) as a decimal number [00,23]. %M Minute as a decimal number [00,59]. %S Second as a decimal number [00,61]. %z Time zone offset from UTC. %a Locale's abbreviated weekday name. %A Locale's full weekday name. %b Locale's abbreviated month name. %B Locale's full month name. %c Locale's appropriate date and time representation. %I Hour (12-hour clock) as a decimal number [01,12]. %p Locale's equivalent of either AM or PM. Other codes may be available on your platform. See documentation for the C library strftime function. time(...) time() -> floating point number Return the current time in seconds since the Epoch. Fractions of a second may be present if the system clock provides them. calendar 🍀 打印某月日历 >>> import calendar >>> cal = calendar.month(2017,7) >>> print(cal) July 2017 Mo Tu We Th Fr Sa Su 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 calendar模块中的方法 : FUNCTIONS calendar = formatyear(theyear, w=2, l=1, c=6, m=3) method of TextCalendar instance Returns a year's calendar as a multi-line string. firstweekday = getfirstweekday() method of TextCalendar instance isleap(year) Return True for leap years, False for non-leap years. leapdays(y1, y2) Return number of leap years in range [y1, y2). Assume y1 Python中用于处理日期和时间的模块还有 : datetime pytz dateutil 类型转换即数学函数 🍀 数字类型转换 int(x [,base]) 将x转换为一个整数 float(x ) 将x转换到一个浮点数 complex(x) 将x转换为复数 str(x) 将对象x转换为字符串 ，通常无法用eval()求值 repr(x) 将对象x转换为表达式字符串 ，可以用eval()求值 eval(str) 用来计算在字符串中的有效Python表达式,并返回一个对象 tuple(s) 将序列s转换为一个元组 list(s) 将序列s转换为一个列表 chr(x) 将一个整数转换为一个字符 unichr(x) 将一个整数转换为Unicode字符 ord(x) 将一个字符转换为它的整数值 hex(x) 将一个整数转换为一个十六进制字符串 oct(x) 将一个整数转换为一个八进制字符串 数学函数 abs(x) 返回数字的绝对值，如abs(-10) 返回 10 ceil(x) 返回数字的上入整数，如math.ceil(4.1) 返回 5 cmp(x, y) 如果 x y 返回 1 exp(x) 返回e的x次幂(ex),如math.exp(1) 返回2.718281828459045 fabs(x) 返回数字的绝对值，如math.fabs(-10) 返回10.0 floor(x) 返回数字的下舍整数，如math.floor(4.9)返回 4 log(x) 如math.log(math.e)返回1.0,math.log(100,10)返回2.0 log10(x) 返回以10为基数的x的对数，如math.log10(100)返回 2.0 max(x1, x2,...) 返回给定参数的最大值，参数可以为序列 min(x1, x2,...) 返回给定参数的最小值，参数可以为序列 modf(x) 返回x的整数部分与小数部分，两部分的数值符号与x相同，整数部分以浮点型表示 pow(x, y) x**y 运算后的值。 round(x [,n]) 返回浮点数x的四舍五入值，如给出n值，则代表舍入到小数点后的位数 sqrt(x) 返回数字x的平方根，数字可以为负数，返回类型为实数，如math.sqrt(4)返回 2+0j "},"01-Python/01-Basis/03-Python - 字符串.html":{"url":"01-Python/01-Basis/03-Python - 字符串.html","title":"Python - 字符串","keywords":"","body":"Python - 字符串 介绍 🍀 字符串是Python中最基本的数据类型之一 字符串的使用需要用引号括起来 , 例如 : name = \"Lyon\" ; 这里name就是一个变量名 , 而引号里面的Lyon 则就是该变量绑定的值 , 该值的类型为 \" str\" 类型 , 我们可以利用type() 函数进行查看 : >>> name = \"Lyon\" >>> type(name) >>> 这就是字符串类型 , 当然如上使用的是双引号 , 这里其实还可以使用单引号'Lyon'以及三引号'''Lyon'''(或者是\"\"\"Lyon\"\"\" , 单引号双引号都可以) , 不过对于三引号 , 我们通常是表示多行字符串 , 这样我们就不需要利用 \" \\n \" （换行符）来进行每一行的换行了 对于嵌套引号的时候要注意 , 需要用不同的引号来避免歧义 , 比如 : 'I am \"Lyon\"' , 也可以 \"I am 'Lyon'\" 对于所有的基本数据类型 , 我们都应该熟悉其特性以及操作 字符串操作主要有 拷贝（复制）、拼接、查找、比较、统计、切片、测试、大小写等 在开始详细了解这些操作之前 , 我们需要记住一个特性 : 字符串是不可变的 , 既然是不可变的 , 那么我们对其进行的增删改查就都不是对本身进行操作的 , 而是创建了一个新的字符串 拷贝 🍀 >>> a = \"Lyon\" >>> b = a >>> print(a,b) Lyon Lyon 拼接 🍀 >>> a = \"Hello\" >>> b = \"Lyon\" >>> print(a+b) HelloLyon 注 : 这个方法要特别说明一下 , “+”是一个坑 , 因为使用加号连接2个字符串会调用静态函数string_concat(register PyStringObject *a,register PyObject *b) , 这个函数大致的作用 , 就是首先开辟一块a+b大小的内存的和的存储单元 , 然后把a和b都拷贝进去 ; 所以一旦我们的 \"+\" 操作过多将会造成大量内存的浪费 >>> a = \"Lyon\" >>> b = \"Hello\" >>> print(a.join(b)) HLyoneLyonlLyonlLyono #HLyon eLyon lLyon lLyon o 可以用join来将list中的元素进行拼接成字符串 : ''.join( list ) 即以空字符串连接列表中的每一个元素 查找 🍀 >>> name = \"Lyon\" # 返回L字符所在的下标,下标是从0开始的整数 >>> name.index('L') 0 # 如果不存在就会报错 >>> name.index('N') Traceback (most recent call last): File \"\", line 1, in ValueError: substring not found # 也可以用in,not in来进行判断 >>>'L' in name >>> 比较 🍀 本来Python 2中有个str.cmp()方法来比较两个对象 , 并根据结果返回一个整数。整数的正负就是数值的大小了 , 但是在Python 3中就没有这个方法了 , 官方文档如下 : ```The cmp() function should be treated as gone, and the cmp() special method is no longer supported. Use lt() for sorting, eq() with hash(), and other rich comparisons as needed. (If you really need the cmp() functionality, you could use the expression (a > b) - (a cmp() special method is no longer supported. Use lt() for sorting, eq() with hash(), and other rich comparisons as needed. (If you really need the cmp() functionality, you could use the expression (a > b) - (a 大致的意思就是cmp()函数已经走了 , 如果你真的需要cmp函数 , 你可以用表达式`(a>b)-(a>> a = \"100\" >>> b = \"50\" >>> cmp(a,b) # a>b 负数 -1 >>> cmp(b,a) # b统计 🍀 >>> name = \"Lyon\" # name中\"L\"的个数 >>> name.count(\"L\") 1 切片 🍀 >>> name = \"i like Lyon\" # 切取第7个到第9个字符,注意空格也是一个字符 >>> name[7:10] 'Lyo' >>> name = \"i like Lyon\" # 第7到第10各,顾头不顾尾 >>> name[7:11] 'Lyon' 检测 🍀 >>> name = \"Lyon\" # 检测\"L\"是否在name中,返回bool值 >>> \"L\" in name True >>> num = \"3412313\" # 检测num里面是否全都是整数 >>> num.isdigit() True >>> name = \"Lyon\" # 检测name是否可以被当作标标志符,即是否符合变量命名规则 >>> name.isidentifier() True　 # 检测name里面有没有\"L\",有就返回下标 >>> name.find('L') 0 # 检测name里面有没有\"N\",没有就返回-1 >>> name.find('N') -1 检测相关 str.startswith(prefix[,start[,end]]) # 是否以prefix开头 str.endswith(suffix[,start[,end]]) # 以suffix结尾 str.isalnum() # 是否全是字母和数字,并至少有一个字符 str.isalpha() # 是否全是字母,并至少有一个字符 str.isdigit() # 是否全是数字,并至少有一个字符 str.isspace() # 是否全是空白字符,并至少有一个字符 str.islower() # 是否全是小写 str.isupper() # 是否便是大写 str.istitle() # 是否是首字母大写的 注 : 结果全是bool值 大小写 🍀 >>> name = \"I am Lyon\" # 大小写互换 >>> name.swapcase() 'i AM lYON' # 首字母大写,其它都小写 >>> name.capitalize() 'I am lyon' # 转换为大写 >>> name.upper() 'I AM LYON' # 转换为小写 >>> name.lower() 'i am lyon' 更多 🍀 | capitalize(...) | S.capitalize() -> str | | Return a capitalized version of S, i.e. make the first character | have upper case and the rest lower case. | | casefold(...) | S.casefold() -> str | | Return a version of S suitable for caseless comparisons. | | center(...) | S.center(width[, fillchar]) -> str | | Return S centered in a string of length width. Padding is | done using the specified fill character (default is a space) | | count(...) | S.count(sub[, start[, end]]) -> int | | Return the number of non-overlapping occurrences of substring sub in | string S[start:end]. Optional arguments start and end are | interpreted as in slice notation. | | encode(...) | S.encode(encoding='utf-8', errors='strict') -> bytes | | Encode S using the codec registered for encoding. Default encoding | is 'utf-8'. errors may be given to set a different error | handling scheme. Default is 'strict' meaning that encoding errors raise | a UnicodeEncodeError. Other possible values are 'ignore', 'replace' and | 'xmlcharrefreplace' as well as any other name registered with | codecs.register_error that can handle UnicodeEncodeErrors. | | endswith(...) | S.endswith(suffix[, start[, end]]) -> bool | | Return True if S ends with the specified suffix, False otherwise. | With optional start, test S beginning at that position. | With optional end, stop comparing S at that position. | suffix can also be a tuple of strings to try. | | expandtabs(...) | S.expandtabs(tabsize=8) -> str | | Return a copy of S where all tab characters are expanded using spaces. | If tabsize is not given, a tab size of 8 characters is assumed. | | find(...) | S.find(sub[, start[, end]]) -> int | | Return the lowest index in S where substring sub is found, | such that sub is contained within S[start:end]. Optional | arguments start and end are interpreted as in slice notation. | | Return -1 on failure. | | format(...) | S.format(*args, **kwargs) -> str | | Return a formatted version of S, using substitutions from args and kwargs. | The substitutions are identified by braces ('{' and '}'). | | format_map(...) | S.format_map(mapping) -> str | | Return a formatted version of S, using substitutions from mapping. | The substitutions are identified by braces ('{' and '}'). | | index(...) | S.index(sub[, start[, end]]) -> int | | Like S.find() but raise ValueError when the substring is not found. | | isalnum(...) | S.isalnum() -> bool | | Return True if all characters in S are alphanumeric | and there is at least one character in S, False otherwise. | | isalpha(...) | S.isalpha() -> bool | | Return True if all characters in S are alphabetic | and there is at least one character in S, False otherwise. | | isdecimal(...) | S.isdecimal() -> bool | | Return True if there are only decimal characters in S, | False otherwise. | | isdigit(...) | S.isdigit() -> bool | | Return True if all characters in S are digits | and there is at least one character in S, False otherwise. | | isidentifier(...) | S.isidentifier() -> bool | | Return True if S is a valid identifier according | to the language definition. | | Use keyword.iskeyword() to test for reserved identifiers | such as \"def\" and \"class\". | | islower(...) | S.islower() -> bool | | Return True if all cased characters in S are lowercase and there is | at least one cased character in S, False otherwise. | | isnumeric(...) | S.isnumeric() -> bool | | Return True if there are only numeric characters in S, | False otherwise. | | isprintable(...) | S.isprintable() -> bool | | Return True if all characters in S are considered | printable in repr() or S is empty, False otherwise. | | isspace(...) | S.isspace() -> bool | | Return True if all characters in S are whitespace | and there is at least one character in S, False otherwise. | | istitle(...) | S.istitle() -> bool | | Return True if S is a titlecased string and there is at least one | character in S, i.e. upper- and titlecase characters may only | follow uncased characters and lowercase characters only cased ones. | Return False otherwise. | | isupper(...) | S.isupper() -> bool | | Return True if all cased characters in S are uppercase and there is | at least one cased character in S, False otherwise. | | join(...) | S.join(iterable) -> str | | Return a string which is the concatenation of the strings in the | iterable. The separator between elements is S. | | ljust(...) | S.ljust(width[, fillchar]) -> str | | Return S left-justified in a Unicode string of length width. Padding is | done using the specified fill character (default is a space). | | lower(...) | S.lower() -> str | | Return a copy of the string S converted to lowercase. | | lstrip(...) | S.lstrip([chars]) -> str | | Return a copy of the string S with leading whitespace removed. | If chars is given and not None, remove characters in chars instead. | | partition(...) | S.partition(sep) -> (head, sep, tail) | | Search for the separator sep in S, and return the part before it, | the separator itself, and the part after it. If the separator is not | found, return S and two empty strings. | | replace(...) | S.replace(old, new[, count]) -> str | | Return a copy of S with all occurrences of substring | old replaced by new. If the optional argument count is | given, only the first count occurrences are replaced. | | rfind(...) | S.rfind(sub[, start[, end]]) -> int | | Return the highest index in S where substring sub is found, | such that sub is contained within S[start:end]. Optional | arguments start and end are interpreted as in slice notation. | | Return -1 on failure. | | rindex(...) | S.rindex(sub[, start[, end]]) -> int | | Like S.rfind() but raise ValueError when the substring is not found. | | rjust(...) | S.rjust(width[, fillchar]) -> str | | Return S right-justified in a string of length width. Padding is | done using the specified fill character (default is a space). | | rpartition(...) | S.rpartition(sep) -> (head, sep, tail) | | Search for the separator sep in S, starting at the end of S, and return | the part before it, the separator itself, and the part after it. If the | separator is not found, return two empty strings and S. | | rsplit(...) | S.rsplit(sep=None, maxsplit=-1) -> list of strings | | Return a list of the words in S, using sep as the | delimiter string, starting at the end of the string and | working to the front. If maxsplit is given, at most maxsplit | splits are done. If sep is not specified, any whitespace string | is a separator. | | rstrip(...) | S.rstrip([chars]) -> str | | Return a copy of the string S with trailing whitespace removed. | If chars is given and not None, remove characters in chars instead. | | split(...) | S.split(sep=None, maxsplit=-1) -> list of strings | | Return a list of the words in S, using sep as the | delimiter string. If maxsplit is given, at most maxsplit | splits are done. If sep is not specified or is None, any | whitespace string is a separator and empty strings are | removed from the result. | | splitlines(...) | S.splitlines([keepends]) -> list of strings | | Return a list of the lines in S, breaking at line boundaries. | Line breaks are not included in the resulting list unless keepends | is given and true. | | startswith(...) | S.startswith(prefix[, start[, end]]) -> bool | | Return True if S starts with the specified prefix, False otherwise. | With optional start, test S beginning at that position. | With optional end, stop comparing S at that position. | prefix can also be a tuple of strings to try. | | strip(...) | S.strip([chars]) -> str | | Return a copy of the string S with leading and trailing | whitespace removed. | If chars is given and not None, remove characters in chars instead. | | swapcase(...) | S.swapcase() -> str | | Return a copy of S with uppercase characters converted to lowercase | and vice versa. | | title(...) | S.title() -> str | | Return a titlecased version of S, i.e. words start with title case | characters, all remaining cased characters have lower case. | | translate(...) | S.translate(table) -> str | | Return a copy of the string S in which each character has been mapped | through the given translation table. The table must implement | lookup/indexing via __getitem__, for instance a dictionary or list, | mapping Unicode ordinals to Unicode ordinals, strings, or None. If | this operation raises LookupError, the character is left untouched. | Characters mapped to None are deleted. | | upper(...) | S.upper() -> str | | Return a copy of S converted to uppercase. | | zfill(...) | S.zfill(width) -> str | | Pad a numeric string S with zeros on the left, to fill a field | of the specified width. The string S is never truncated. | | ---------------------------------------------------------------------- "},"01-Python/01-Basis/04-Python - 元组.html":{"url":"01-Python/01-Basis/04-Python - 元组.html","title":"Python - 元组","keywords":"","body":"Python - 元组 介绍 🍀 元组和字符串一样 , 元组也是不可修改的 , 元组使用小括号 元组的创建很简单 , 只需要在括号中添加元素 , 并使用逗号隔开即可 元组需要掌握的分别有创建、访问、修改、切片、删除、检测等 创建 🍀 # 创建一个带有元素的元组 mytuple = (\"Lyon\", \"Alex\", \"Leon\", 1, 2, 3) # 也可以不加括号,但是一定要加引号 mytuple = \"Lyon\", \"Alex\", \"Leon\", 1, 2, 3 # 创建一个空元组 mytuple = () # 当元组中只有一个元素,加逗号来消除歧义哟,这是一个好习惯,因为()既可以表示tuple又可以表示数学公式中的小括号 only_one = (\"Lyon\",) 访问 🍀 # 创建一个元组 names = (\"Lyon\", \"Alex\", \"Leon\", 1, 2, 3) # 访问元组中的第一个元素并打印结果,下标索也是从0开始 print(names[0]) # 访问元组中第一和第二个元素并打印结果 print(names[0:2]) ''' 打印结果: Lyon ('Lyon', 'Alex') ''' 注意 : 结果发现访问单个元素结果是字符串类型 , 而多个则是元组类型 字符串中每个字符就是一个元素 , 而元组中则是一个数字或者一个字符串就是一个元素 修改 🍀 # 创建一个元组 tuple_name = (\"Lyon\", \"Alex\", \"Leon\", 1, 2, 3) # 创建另一个元组 tuple_num = (1, 2, 3, 4, 5) # 生成一个新的元组 tuple_total = tuple_name + tuple_num # 打印tuple_total print(tuple_total) # 复制元组内元素一次 tuple_total = tuple_name * 2 # 打印tuple_total看结果 print(tuple_total) # 在列表中可以通过索引取值后进行修改,但是元组里面是非法的哦 tuple_name[0] = \"lyon\" # 这里直接就报错 ''' 打印结果: ('Lyon', 'Alex', 'Leon', 1, 2, 3, 1, 2, 3, 4, 5) ('Lyon', 'Alex', 'Leon', 1, 2, 3, 'Lyon', 'Alex', 'Leon', 1, 2, 3) ''' 注意 : 元组是不可变的 , 所以对于所有的修改操作 , 都是在根据原元组生成了一个新的元组 删除 🍀 #创建一个元组 names = (\"Lyon\", \"Alex\", \"Leon\", 1, 2, 3) # 删除元组names del names # TypeError: 'tuple' object doesn't support item deletion del names[0] 切片 🍀 names = (\"Lyon\", \"Kenneth\", \"Leon\", \"Charlie\") # 打印子集,第二个至第三个 print(names[1:2]) # 打印子集,倒数第三个(即第二个)至第三个 print(names[-3:3]) # 打印子集,第一个至第三个,隔一个取一个 print(names[0:2:1]) ''' 打印结果: ('Kenneth', 'Leon') ('Kenneth', 'Leon') ('Leon',) ''' 检测 🍀 # 创建一个元组 tuple_name = (\"Lyon\",\"Alex\",\"Leon\",1,2,3) # \"Lyon\"是否在tuple_name中，打印结果 print(\"Lyon\" in tuple_name) # 打印结果:True 更多 🍀 实例 # 创建一个元组 tuple_name = (\"Lyon\",\"Alex\",\"Leon\",1,2,3) # 计算元组长度 tuple_len = len(tuple_name) # 打印结果 print(tuple_len) # 创建一个元素全为数字的元组 tuple_num = (1,2,3,4,5) # 返回元组中的最大值 print(max(tuple_num)) # 返回元组中的最小值 print(min(tuple_num)) # 创建一个列表 list_name = [\"Lyon\",\"Alex\",\"Leon\"] # 将列表转换为元组 tuple_names = tuple(list_name) # 打印tuple_names print(tuple_names) ''' 打印结果: 6 5 1 ('Lyon', 'Alex', 'Leon') ''' 方法 | count(...) | T.count(value) -> integer -- return number of occurrences of value | | index(...) | T.index(value, [start, [stop]]) -> integer -- return first index of value. | Raises ValueError if the value is not present. "},"01-Python/01-Basis/05-Python - 列表.html":{"url":"01-Python/01-Basis/05-Python - 列表.html","title":"Python - 列表","keywords":"","body":"Python - 列表 介绍 🍀 列表是我们以后最常用的数据类型之一 , 通过列表可以对数据实现最方便的存储、修改等操作 列表是可变的、有序的 , 基本操作有 : 创建、访问、切片、追加、插入、修改、删除、扩展、拷贝、排序、翻转、等 列表相当于其他语言中的数组 创建 🍀 # 创建一个列表 names = [\"Alex\",\"Lyon\",\"Leon\"] # 创建一个空列表 names = [] # 也可通过list方法 names = list() 访问 🍀 # 创建一个列表 names = [\"Alex\",\"Lyon\",\"Leon\"] # 与字符串的索引一样,列表索引从0开始,访问列表中的第一个元素 fristname = names[0] # 打印结果 print(fristname) # 访问列表中第三个元素 threename = names[2] # 打印结果 print(threename) # 访问列表中最后一个元素 endname = names[-1] # 打印结果 print(endname) # 访问倒数第二个元素 penultimate = names[-2] # 打印结果 print(penultimate) ''' 执行结果: Alex Leon Leon Lyon ''' 获取下标 # 创建一个列表 names = ['Alex', 'Lyon', 'Leon', 'CTO','Lyon'] # 获取下标并打印 print(names.index('Lyon')) # 注:只返回找到的第一个下标 ''' 执行结果: 1 ''' 统计 # 创建一个列表 names = ['Alex', 'Lyon', 'Leon', 'CTO', 'BeiJing',\"IT\",21,\"man\"] # 统计 \"Lyon\" 的个数,并打印 print(names.count(\"Lyon\")) ''' 执行结果: 1 ''' 切片 🍀 # 创建一个列表 names = [\"Alex\",\"Lyon\",\"Leon\",\"CTO\",\"WuHan\"] # 取下标为1至下标3之间的值,包括1,不包括4 cutnames1 = names[1:3] # 打印cutnames1 print(cutnames1) # 取下标为1至-1的值,不包括-1（-1就是最后一个） cutnames2 = names[1:-1] # 打印cutnames2 print(cutnames2) # 从第一个到第三个 cutnames3 = names[0:3] # 从头开始取,0可以省略,跟上面的效果一样 cutnames4 = names[:3] # 打印cutnames3,cutnames4 print(cutnames3,cutnames4) # 想取最后一个,只能这样写,切片是不包含后一个参数的 cutnames5 = names[3:] # 后面的2是代表,每隔一个元素,就取一个 cutnames6 = names[0::2] # 或者这样 cutnames7 = names[::2] # 打印cutnames6,cutnames7 print(cutnames6,cutnames7) ''' 执行结果: ['Lyon', 'Leon'] ['Lyon', 'Leon', 'CTO'] ['Alex', 'Lyon', 'Leon'] ['Alex', 'Lyon', 'Leon'] ['Alex', 'Leon', 'WuHan'] ['Alex', 'Leon', 'WuHan'] ''' 追加 🍀 # 创建一个列表 names = [\"Alex\",\"Lyon\",\"Leon\",\"CTO\",\"WuHan\"] # 追加一个元素 names.append(\"New\") # 打印names print(names) # 注：append 方法只能追加到列表的最后一位 ''' 执行结果: ['Alex', 'Lyon', 'Leon', 'CTO', 'WuHan', 'New'] ''' 插入 🍀 # 创建一个列表 names = [\"Alex\",\"Lyon\",\"Leon\",\"CTO\",\"WuHan\",\"New\"] # 插入到下标1前面 names.insert(1,\"Insert\") # 打印names print(names) # 如果下标不存在就会插入到最后一个 names.insert(7,\"NoIndex\") # 打印names print(names) ''' 执行结果: ['Alex', 'Insert', 'Lyon', 'Leon', 'CTO', 'WuHan', 'New'] ['Alex', 'Insert', 'Lyon', 'Leon', 'CTO', 'WuHan', 'New', 'NoIndex'] ''' 修改 🍀 # 创建一个列表 names = ['Alex', 'Insert', 'Lyon', 'Leon', 'CTO', 'WuHan', 'New', 'NoIndex'] # 把 'WuHan' 改成 'BeiJing' names[5] = 'BeiJing' # 打印names print(names) # 注：就是通过下标直接改变list本身 ''' 执行结果: ['Alex', 'Insert', 'Lyon', 'Leon', 'CTO', 'BeiJing', 'New', 'NoIndex'] ''' 删除 🍀 # 创建一个列表 names = ['Alex', 'Insert', 'Lyon', 'Leon', 'CTO', 'BeiJing', 'New', 'NoIndex'] # 删除下标为7的元素 del names[7] #打印names print(names) # 删除 'Insert',remove删除指定元素 names.remove(\"Insert\") # 打印names print(names) # 删除最后一个元素 names.pop() # 打印names print(names) ''' 执行结果: ['Alex', 'Insert', 'Lyon', 'Leon', 'CTO', 'BeiJing', 'New'] ['Alex', 'Lyon', 'Leon', 'CTO', 'BeiJing', 'New'] ['Alex', 'Lyon', 'Leon', 'CTO', 'BeiJing'] ''' 扩展 🍀 # 创建一个列表 names = ['Alex', 'Lyon', 'Leon', 'CTO', 'BeiJing'] # 创建另一个列表 name = [\"IT\",21,\"man\"] # 将name扩展到names names.extend(name) # 打印names print(names) # 这里还有一个\"万恶的'+' \"也是可以的 print(names + name) ''' 执行结果: ['Alex', 'Lyon', 'Leon', 'CTO', 'BeiJing', 'IT', 21, 'man'] ['Alex', 'Lyon', 'Leon', 'CTO', 'BeiJing', 'IT', 21, 'man'] ''' 拷贝 🍀 # 创建一个列表 names = ['Alex', 'Lyon', 'Leon', 'CTO', 'BeiJing',\"IT\",21,\"man\"] # 拷贝names,这只是浅copy names_copy = names.copy() # 打印names_copy print(names_copy) ''' 执行结果: ['Alex', 'Lyon', 'Leon', 'CTO', 'BeiJing', 'IT', 21, 'man'] ''' 注意 : 在python2.7中列表的内置方法是没有copy这个方法的 , 这是在python3后加的 , 并且python3也只有有copy (浅copy) 这一个方法 , 用深copy需要我们导入copy模块 , 即 import copy 深浅copy会在后续文章中整理　 排序&翻转 🍀 # 创建一个列表 names = ['Alex', 'Lyon', 'Leon', 'CTO', 'BeiJing',\"IT\",21,\"man\"] # 在python3中不同的数据类型不能一起排序,换成str names[-2] = \"21\" # 排序,顺序为数字>大写>小写 names.sort() # 打印names print(names) # 翻转 names.reverse() # 打印names print(names) ''' 执行结果: ['21', 'Alex', 'BeiJing', 'CTO', 'IT', 'Leon', 'Lyon', 'man'] ['man', 'Lyon', 'Leon', 'IT', 'CTO', 'BeiJing', 'Alex', '21'] ''' 所有方法如下 : | append(...) | L.append(object) -> None -- append object to end | | clear(...) | L.clear() -> None -- remove all items from L | | copy(...) | L.copy() -> list -- a shallow copy of L | | count(...) | L.count(value) -> integer -- return number of occurrences of value | | extend(...) | L.extend(iterable) -> None -- extend list by appending elements from the iterable | | index(...) | L.index(value, [start, [stop]]) -> integer -- return first index of value. | Raises ValueError if the value is not present. | | insert(...) | L.insert(index, object) -- insert object before index | | pop(...) | L.pop([index]) -> item -- remove and return item at index (default last). | Raises IndexError if list is empty or index is out of range. | | remove(...) | L.remove(value) -> None -- remove first occurrence of value. | Raises ValueError if the value is not present. | | reverse(...) | L.reverse() -- reverse *IN PLACE* | | sort(...) | L.sort(key=None, reverse=False) -> None -- stable sort *IN PLACE* "},"01-Python/01-Basis/06-Python - 字典.html":{"url":"01-Python/01-Basis/06-Python - 字典.html","title":"Python - 字典","keywords":"","body":"Python - 字典 介绍 🍀 字典是一种key - value 的数据类型 , 用 冒号 (\" : \") 来分割 , 每个对象之间用逗号(\" , \")分割 , 整个字典包括在花括号(\"{ }\")中 字典中的键(key)是唯一的 , 但值(value)则不必 字典是可变的数据类型 , 并且是无序的 基本操作如下 : 创建、增加、修改、删除、查找、遍历、多级嵌套等 注意 : 字典中key是唯一的 , 如果出现多个相同的key被赋值 , 那么值为最后一个赋的值 ; key是不可变的 , 所以可变的数据类型是不能用的 , 如 : list , 对于不可变的数据类型则可以 , 如 : str、int、tuple 2）key是不可变的 , 所以可变的数据类型是不能用的 , 如 : list , 对于不可变的数据类型则可以 , 如 : str、int、tuple 创建 🍀 # 创建一个空字典 empty_info = {} # 创建一个字典 info = {\"name\":\"Lyon\",\"age\":21} # 也可调用dict()方法 info = dict() 增加 🍀 # 创建一个字典 info = {\"name\":\"Lyon\",\"age\":21} # 增加新的键/值对 info[\"school\"] = \"university\" # 打印info print(info) # 注:字典是无序的,所以打印结果也是随机打印 ''' 执行结果: {'school': 'university', 'age': 21, 'name': 'Lyon'} ''' 修改 🍀 # 创建一个字典 info = {\"name\":\"Lyon\",\"age\":21,\"school\":\"university\"} # 修改age info[\"age\"] = 18 # 打印info print(info) ''' 执行结果: {'age': 18, 'school': 'university', 'name': 'Lyon'} ''' 删除 🍀 # 创建一个字典 info = {\"name\":\"Lyon\",\"age\":21,\"school\":\"university\"} # 标准删除姿势 info.pop(\"school\") # 打印info print(info) # 换个姿势 del info[\"age\"] # 打印info print(info) # 随机删除 info.popitem() # 打印info print(info) ''' 执行结果: {'name': 'Lyon', 'age': 21} {'name': 'Lyon'} {} ''' 查找 🍀 # 创建一个字典 info = {\"name\":\"Lyon\",\"age\":21,\"school\":\"university\"} # 标准查找,判断name是否在字典info中 print(\"name\" in info) #打印：True # 获取值 print(info.get(\"name\")) #打印：Lyon # 换换姿势 print(info[\"name\"]) #打印：Lyon # 这种方式要注意如果key不存在就会报错,而get仅仅返回None print(info[\"home\"]) # 报错：KeyError: 'home' ''' 执行结果: True Lyon Lyon KeyError:'home' ''' 遍历 🍀 # 创建一个字典 info = {\"name\":\"Lyon\",\"age\":21,\"school\":\"university\"} # 方法1,推荐 for key in info: print(key,info[key]) # 方法2 for k,v in info.items(): print(k,v) ''' 执行结果: school university name Lyon age 21 school university name Lyon age 21 ''' 嵌套 🍀 # 创建一个多级嵌套字典 datas ={ '湖北省':{ \"武汉市\":{ \"武昌区\":[\"Hello\"], \"洪山区\":[\"Sorry\"], \"江夏区\":[\"Welcome\"], }, }, '湖南省':{ \"长沙市\":{ \"岳麓区\":{}, \"天心区\":{}, \"芙蓉区\":{}, }, }, '广东省':{ \"佛山市\":{ \"三水区\":{}, \"顺德区\":{}, \"男海区\":{}, }, }, } # 修改最里层的value datas[\"湖北省\"][\"武汉市\"][\"武昌区\"].append(\"Lyon\") # 打印结果 print(datas[\"湖北省\"][\"武汉市\"]) ''' 执行结果: {'洪山区': ['Sorry'], '武昌区': ['Hello', 'Lyon'], '江夏区': ['Welcome']} ''' 更多 🍀 len(dict) # 计算字典元素个数 dict.clear() # 清空词典所有条目 dict.fromkeys(seq, val)) # 创建一个新字典,以列表 seq 中元素做字典的键,val 为字典所有键对应的初始值 dict.has_key(key) # 如果键在字典dict里返回true,否则返回false dict.items() # 以列表返回可遍历的(键, 值) 元组数组 dict.keys() # 以列表返回一个字典所有的键 dict.values() # 以列表返回字典中的所有值 dict.setdefault(key, default=None) # 和get()类似, 但如果键不存在于字典中,将会添加键并将值设为default dict.update(dict2) # 把字典dict2的键/值对更新到dict里 方法合集 | clear(...) | D.clear() -> None. Remove all items from D. | | copy(...) | D.copy() -> a shallow copy of D | | fromkeys(iterable, value=None, /) from builtins.type | Returns a new dict with keys from iterable and values equal to value. | | get(...) | D.get(k[,d]) -> D[k] if k in D, else d. d defaults to None. | | items(...) | D.items() -> a set-like object providing a view on D's items | | keys(...) | D.keys() -> a set-like object providing a view on D's keys | | pop(...) | D.pop(k[,d]) -> v, remove specified key and return the corresponding value. | If key is not found, d is returned if given, otherwise KeyError is raised | | popitem(...) | D.popitem() -> (k, v), remove and return some (key, value) pair as a | 2-tuple; but raise KeyError if D is empty. | | setdefault(...) | D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D | | update(...) | D.update([E, ]**F) -> None. Update D from dict/iterable E and F. | If E is present and has a .keys() method, then does: for k in E: D[k] = E[k] | If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v | In either case, this is followed by: for k in F: D[k] = F[k] | | values(...) | D.values() -> an object providing a view on D's values "},"01-Python/01-Basis/07-Python - 集合.html":{"url":"01-Python/01-Basis/07-Python - 集合.html","title":"Python - 集合","keywords":"","body":"Python - 集合 介绍 🍀 集合是一个无序的 , 不重复的数据组合 , 它的主要作用如下 : 去重 , 把一个列表变成集合 , 就自动去重了 关系测试 , 测试两组数据之间的交集 , 差集 , 并集关系 在Python 2.7中集合表示如下 : set([1,2,3]) 在Python 3.x 中则是如下 : {1,2,3} 集合支持一系列标准操作 , 包括并集 , 交集 , 差集 , 对称差集 创建 🍀 与字符串等数据类型一样 , 集合支持如下方式创建 # 创建空集合只能用这种方式,参数为一个可迭代对象 s = set() # 注意集合是单个元素,字典是键值对 s = {1,2,3} 添加 🍀 为集合添加元素 # 定义集合 s = {'lyon','kenneth'} # 添加一项 s.add('geek') 注意 : 集合不支持 \"+\" 更新 🍀 # 定义集合 s = {'lyon','kenneth'} # 添加多项,参数为可迭代对象 s.update(['1','2','3']) 删除 🍀 # 定义集合 s = {'lyon','kenneth'} # 删除一项 s.remove('kenneth') # 清空集合 s.clear() 测试 🍀 a = {1,2,3,4,5} b = {1,2,3} # 测试是否b中的每一个元素都在a中,即 b=a ,返回bool值 b.issuperset(a) 集合操作 🍀 >>>a = {1,2,3} >>>b = {4,5,6} # 求并集 >>>a.union(b) # 同上,求并集 >>>a | b # 求交集 >>>a.intersection(b) # 同上,求交集 >>>a & b # 求差集 >>>a.difference(b) # 同上,求差集 >>>a - b # 求对称差集 >>>a.symmetric_difference(b) # 同上,求对称差集 >>>a ^ b 集合对象所有方法 | add(...) | Add an element to a set. | | This has no effect if the element is already present. | | clear(...) | Remove all elements from this set. | | copy(...) | Return a shallow copy of a set. | | difference(...) | Return the difference of two or more sets as a new set. | | (i.e. all elements that are in this set but not the others.) | | difference_update(...) | Remove all elements of another set from this set. | | discard(...) | Remove an element from a set if it is a member. | | If the element is not a member, do nothing. | | intersection(...) | Return the intersection of two sets as a new set. | | (i.e. all elements that are in both sets.) | | intersection_update(...) | Update a set with the intersection of itself and another. | | isdisjoint(...) | Return True if two sets have a null intersection. | | issubset(...) | Report whether another set contains this set. | | issuperset(...) | Report whether this set contains another set. | | pop(...) | Remove and return an arbitrary set element. | Raises KeyError if the set is empty. | | remove(...) | Remove an element from a set; it must be a member. | | If the element is not a member, raise a KeyError. | | symmetric_difference(...) | Return the symmetric difference of two sets as a new set. | | (i.e. all elements that are in exactly one of the sets.) | | symmetric_difference_update(...) | Update a set with the symmetric difference of itself and another. | | union(...) | Return the union of sets as a new set. | | (i.e. all elements that are in either set.) | | update(...) | Update a set with the union of itself and others. "},"01-Python/01-Basis/08-Python - 字符编码.html":{"url":"01-Python/01-Basis/08-Python - 字符编码.html","title":"Python - 字符编码","keywords":"","body":"Python - 字符编码 介绍 🍀 字符编码 字符编码 (Character encoding) 也称字集码 , 它是一套法则 , 使用该法则能够对自然语言的字符的一个集合 (如字母表或音节表) , 与其他东西的一个集合 (如号码或电脉冲) 进行配对 , 即在符号集合与数字系统之间建立对应关系 再简单一点说其实就是一张具有对应关系的表格 , 如下 +----+-----------+ | id | character | +----+-----------+ | 65 | A | | 66 | B | | 67 | C | +----+-----------+ 如上表所示 , 这就是一套法则 , 使我们用数字成功的表示了字符 为什么要一套这样的法则 ? 众所周知 , 计算机只认识机器码 , 也就是一堆0101之类的二进制数字 , 计算机并不认识我们的 \"A\" , \"B\" ,\"C\" , 我们为了使其友好的显示 , 就需要一套这样的法则 , 来完成这些转换 , 于是两个名词诞生了 编码 通俗的说 , 就是按照何种规则将字符存储在计算机中 . 比如 \"A\" 用65表示 , 也就是把字符\"A\"以二进制的方式存储在计算机中 解码 反之 , 将存储在计算机中的二进制数解析显示出来 , 这就是解码 在Python中 '''既然是对于字符,那么自然对应着Python中的字符串了''' '''Python中提供了两个函数来完成编码和解码''' # 编码函数encode() encode() character → byte # 解码函数decode() byte → character PS : 必须采用相对应的法则 , 否则就会出错 , 也就是我们常说的乱码 最后还有一个名词 , 字符集 字符集 是一个系统支持的所有抽象字符的集合 , 字符是各种文字和符号的总称 , 包括各国家文字、标点符号、图形符号、数字等 字符编码就是在字符集与数字系统之间建立的对应关系 ASCII 🍀 ASCII (American Standard Code for Information Interchange , 美国信息交换标准码) , 是基于拉丁字母的一套电脑编码系统 , 主要用于显示现代英语 ASCII字符集 : 主要包括控制字符 (回车键 , 退格 , 换行键等) , 可显示字符 (英文大小写字符 , 阿拉伯数字和西文符号) ASCII编码 : 将ASCII字符集转换为计算机可以接收的数字系统的数的规则 , 使用7位(Bit)表示一个字符 , 1 Byte = 8 Bit , 一共可以表示128(2的7次方)个字符 具体ASCII字符集映射到数字编码规则可以自行查询 ANSI 🍀 ANSI编码为在ASCII编码(7位)的基础上 , 将其最后一位也使用上 , 即使用8位 ANSI使使计算机支持更多语言 , 通常对于没超过128的即用ASCII编码 , 超过的即用扩展的ASCII编码ANSI 当然不同的国家和地区指定了不同的标准 , 由此产生了GB2312、GBK、GB18030、Big5、Shift_JIS 等各自的编码标准 在简体中文Windows操作系统中 , ANSI 编码代表 GBK 编码 ; 在繁体中文Windows操作系统中 , ANSI编码代表Big5 ; 在日文Windows操作系统中 , ANSI 编码代表 Shift_JIS 编码 GBXXX 🍀 GB2312编码 计算机发明之初及后面很长一段时间 , 只应用于美国及西方一些发达国家 , 于是到中国时 , 一个字节8位 , 256个字符是远远不能满足的 , 要想想中国有多少汉字 , 于是聪明的中国人这样规定 : 一个小于127的字符的意义与原来相同 , 但是两个大于127的字符连在一起时 , 就表示一个汉字 , 前面的一个字节称为高字节 , 后面的为低字节 , 这样就组合出了大约7000多个简体汉字了 , 这就是GB2312 ,全称 信息交换用汉字编码字符集 ▪ 基本集 GB18030 由于7000多个汉字还是不够用 , 于是继续改进 , 每个汉字可以由1个 , 2个或4个字节组成 , 于是庞大的编码空间形成了 , 最多可以定义161万个字符 , 这就是GB18030 , 全称 信息技术中文编码字符集 Unicode 🍀 各种各样的字符编码都出来了 , 大家各用各的 , 那么问题就来了 , 一旦出现在网络上 , 由于不兼容 , 互相访问就出现了乱码现象 , 为了解决这个问题 , Unicode编码系统应运而生 Unicode编码系统为表达任意语言的任意字符而设计 , 它使用2字节的数字来表达每个字母 , 符号 , 或者表意文字 , 每个数字代表唯一的至少在某种语言中使用的符号 (并不是所有的数字都用上了 , 但是总数已经超过了65535 所以2个字节的数字是不够用的) 总而言之 , Unicode是业界的一种标准 , 也叫做统一码 , 万国码 , 单一码 , 标准万国码 所以Unicode编码也成为了一个编码转换的基础 , 因为大家都支持他 , 从一种编码到另一中编码 , 只需要Unicode在中间搭桥就能简单的实现了 UTF - 8 对于Unicode来讲 , 任何字符都使用2个字节来存储 , 这明显是很浪费内存的 , 因为我们编写代码时 , 用到中文毕竟极少 , 所以为了节省内存 , 就有了UTF-8 , UTF - 8规定 , 英文只使用1个字节 , 中文使用3个字节 虽然说UTF - 8具有良好的国际兼容性 , 但中文需要比GBK/BIG5版本多占用50%的数据库存储空间 , 因此并不推荐使用 Python编码处理 🍀 在Python3中 , 源代码读取进行语法校验时 , 会将源代码中的字符串从声明的编码转换成Unicode类型 , 等到语法校验通过后 , 再将这些字符换回初始的编码 , 这也就是说 , Python3中 , 字符串默认编码就是Unicode , 这也是Python受欢迎的原因之一 查看默认编码 >>> import sys >>> sys.getdefaultencoding() PS : Windows下命令行的字符编码默认是GBK ; 并且Python2中 , 字符串是有两种类型的 , 这里不多说明 关于Python 2.x 与Python 3.x中乱码处理见后续文章 "},"01-Python/01-Basis/09-Python - 文件操作.html":{"url":"01-Python/01-Basis/09-Python - 文件操作.html","title":"Python - 文件操作","keywords":"","body":"Python - 文件操作 介绍 🍀 在磁盘上读写文件的功能都是由操作系统提供的 , 现代操作系统不允许普通的程序直接操作磁盘 , 所以 , 读写文件就是请求操作系统打开一个文件对象 (通常称为文件描述符) ; 然后 , 通过操作系统提供的接口从这个文件对象中读取数据 (读文件) , 或者把数据写入这个文件对象 (写文件) 在Python中我们进行文件操作需要首先利用open() 函数获取一个文件流来操作文件 这个流就是我们所使用的文件描述符 , 是一个I/O通道 open() 🍀 open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None): \"\"\" file:文件名 mode:模式 buffering:设置缓冲策略 encoding:指定使用编码 errors:指定处理编码和解码错误的方式 newline:控制通用换行模式的工作方式(只适用文本模式) closefd:如果为False并且给出了文件描述符而不是文件名,则文件关闭时,文件描述符将保持打开;如果给定文件名,则closefd必须为True,否则将抛出异常 opener:自定义开启器 \"\"\" 对于上述参数中 , 我们主要需要了解的就是file , mode , encoding 这三个 对于mode , 有以下模式 : Character Meaning 'r' open for reading (default) 'w' open for writing, truncating the file first 'x' open for exclusive creation, failing if the file already exists 'a' open for writing, appending to the end of the file if it exists 'b' binary mode 't' text mode (default) '+' open a disk file for updating (reading and writing) 'U' universal newlines mode (deprecated) 常使用的就是'r' , 'w' , 'a' , '+' , 'b' , 当然还可以组合使用 , 下面进行详细介绍 : r , 只读模式 , 文件必须已经存在 r+ , 可读可写模式 , 文件必须已经存在 w , 只写模式 , 会重新创建 , 意味着文件如果已存在会被空文件覆盖 w+ , 可写可读模式 , 同样会创建文件 a , 追写模式 , 文件不存在参考'w' a+ , 追写并可读模式 , 文件不存在参考'w' b , 以二进制的模式进行处理 (Linux可忽略 , Windows处理二进制文件时需标注) , 可以用该模式来读取图片 , 视频等等 rb , 同r wb , 同w ab , 同a 简单实例 file.txt A man is not old until his regrets take place of his dreams. Nothing can help us endure dark times better than our faith. No one but ourselves can degrade us. 实例 f = open('file.txt','r') contents = f.read print(contents) ''' 执行结果: A man is not old until his regrets take place of his dreams. Nothing can help us endure dark times better than our faith. No one but ourselves can degrade us. ''' file-like object 🍀 io模块提供了Python处理各种类型I/O的主要工具 , 有三种主要类型 , 即文本I/O , 二进 制I/O和原始I/O , 这些是通用类别 , 并且可以为它们中的每一个使用各种后备存储 三种主要类型详细见 : TextIOBase , BufferedIOBase , RawIOBase 属于这些类别中的任何一个的具体对象称为file-like object 创建这些类别的具体对象最简单的方法就是使用内置的open() 函数 , 其也被定义在io模块中 , 下面仅介绍一些这些类别对象常用的方法 : detach() ''' Separate the underlying binary buffer from the TextIOBase and return it. After the underlying buffer has been detached, the TextIOBase is in an unusable state. Some TextIOBase implementations, like StringIO, may not have the concept of an underlying buffer and calling this method will raise UnsupportedOperation. New in version 3.1. ''' read(size) ''' Read and return at most size characters from the stream as a single str. If size is negative or None, reads until EOF. ''' readline(size=-1) ''' Read until newline or EOF and return a single str. If the stream is already at EOF, an empty string is returned. If size is specified, at most size characters will be read. ''' readlines(hint=-1) ''' Read and return a list of lines from the stream. hint can be specified to control the number of lines read: no more lines will be read if the total size (in bytes/characters) of all lines so far exceeds hint. Note that it’s already possible to iterate on file objects using for line in file: ... without calling file.readlines(). ''' readable() ''' Return True if the stream can be read from. If False, read() will raise OSError. ''' write(s) ''' Write the string s to the stream and return the number of characters written. ''' writable() ''' Return True if the stream supports writing. If False, write() and truncate() will raise OSError. ''' writelines(lines) ''' Write a list of lines to the stream. Line separators are not added, so it is usual for each of the lines provided to have a line separator at the end. ''' seek(offset[, whence]) ''' Change the stream position to the given offset. Behaviour depends on the whence parameter. The default value for whence is SEEK_SET. SEEK_SET or 0: seek from the start of the stream (the default); offset must either be a number returned by TextIOBase.tell(), or zero. Any other offset value produces undefined behaviour. SEEK_CUR or 1: “seek” to the current position; offset must be zero, which is a no-operation (all other values are unsupported). SEEK_END or 2: seek to the end of the stream; offset must be zero (all other values are unsupported). Return the new absolute position as an opaque number. New in version 3.1: The SEEK_* constants. ''' tell() ''' Return the current stream position as an opaque number. The number does not usually represent a number of bytes in the underlying binary storage. ''' close() ''' Flush and close this stream. This method has no effect if the file is already closed. Once the file is closed, any operation on the file (e.g. reading or writing) will raise a ValueError. As a convenience, it is allowed to call this method more than once; only the first call, however, will have an effect. ''' fileno() ''' Return the underlying file descriptor (an integer) of the stream if it exists. An OSError is raised if the IO object does not use a file descriptor. ''' flush() ''' Flush the write buffers of the stream if applicable. This does nothing for read-only and non-blocking streams. ''' isatty() ''' Return True if the stream is interactive (i.e., connected to a terminal/tty device). ''' seek(offset[, whence]) ''' Change the stream position to the given byte offset. offset is interpreted relative to the position indicated by whence. The default value for whence is SEEK_SET. Values for whence are: SEEK_SET or 0 – start of the stream (the default); offset should be zero or positive SEEK_CUR or 1 – current stream position; offset may be negative SEEK_END or 2 – end of the stream; offset is usually negative Return the new absolute position. New in version 3.1: The SEEK_* constants. New in version 3.3: Some operating systems could support additional values, like os.SEEK_HOLE or os.SEEK_DATA. The valid values for a file could depend on it being open in text or binary mode. ''' seekable() ''' Return True if the stream supports random access. If False, seek(), tell() and truncate() will raise OSError. ''' truncate(size=None) ''' Resize the stream to the given size in bytes (or the current position if size is not specified). The current stream position isn’t changed. This resizing can extend or reduce the current file size. In case of extension, the contents of the new file area depend on the platform (on most systems, additional bytes are zero-filled). The new file size is returned. Changed in version 3.5: Windows will now zero-fill files when extending. ''' 注意 : 当使用完文件后一定要记得使用close() 方法将其关闭 ; 其次在进行文件操作时要注意文件描述符所在的位置 with 🍀 为了避免打开文件后忘记手动关闭 , 可以通过管理上下文 , 即使用with语句 , 如下 : with open('filepath','mode') as f: pass 在Python 2.7以上的版本 , 支持同时对多个文件同时进行上下文管理 , 如下 : with open('filepath1','mode') as f1,open('filepath2','mode') as f2: pass 更多文档资料 : https://docs.python.org/3.5/library/io.html?highlight=io#module-io "},"01-Python/02-Advanced/":{"url":"01-Python/02-Advanced/","title":"Advanced","keywords":"","body":"The road to Python - Advanced 介绍 🍀 该目录下为Python进阶篇 , 主要为面向函数编程 , 内容概述如下 函数 🍀 函数基础语法 嵌套函数 高阶函数 闭包 装饰器 递归 匿名函数 内置函数 迭代器、生成器 "},"01-Python/02-Advanced/01-Python - 函数.html":{"url":"01-Python/02-Advanced/01-Python - 函数.html","title":"Python - 函数","keywords":"","body":"Python - 函数 介绍 🍀 函数是组织好的 , 可重复使用的 , 用来实现单一 , 或相关联功能的代码段 函数能提高应用的模块性 , 和代码的重复利用率 , 比如我们一直使用的print() , input() 等等 , 都是函数 如下我们写了一个用户认证程序 ; 而现在我们又需要写一个用户管理系统 , 管理系统中有很多的功能 , 比如添加用户 , 删除用户 , 查询用户 , 修改用户 ; 但是这些功能必须先通过用户认证程序才能使用 , 明显我们不可能在每一个功能前加上一段用户认证代码 , 因为这将大大增加我们的重复代码 那么为了解决这个问题我们就可以将用户认证功能封装到一个函数之中 , 而后续我们如果需要使用这个函数仅需调用即可 , 着就是函数的魅力所在 , 当然更多的还是通过下面进一步了解函数 语法 🍀 # 自定义函数,function_name为函数名 def function_name(): \"\"\"注释\"\"\" ''' 功能代码块 ''' # 返回值,一般都具有返回值,当然也不可以不设定 return result 简单实例 def hello(): print(\"Hello Lyon!\") return None 注意 : 上述仅为定义函数 , 函数并不会执行 , 只有当函数被调用时 , 函数内部代码才会执行 函数调用 🍀 函数调用通过函数名后加() 进行调用 , 如下 : # 定义函数 def hello(): print(\"Hello Lyon!\") return None # 调用函数 hello() 既然函数调用是通过函数名后加括号 , 在这个固定语法之中前者函数名有是什么? 如下 : # 定义函数 def hello(): print(\"Hello Lyon!\") return None # 打印函数名 print(hello) ''' 执行结果: ''' 我们可以发现 , 函数名打印出来的是一个内存地址 , 由此不难理解 : 函数名相当于一个变量 , 而变量的值就是该函数本身所在的内存地址 ; 也就是说函数名实际上就是一个指针 , 它与函数本身存在一个映射关系 参数说明 🍀 形参 : 变量只有在被调用时才分配内存单元 , 在调用结束时 , 即刻释放所分配的内存单元 ; 因此 , 形参只在函数内部有效 , 函数调用结束返回主调用函数后则不能再使用该形参变量 实参 : 可以是常量、变量、表达式、函数等 , 无论实参是何种类型的量 , 在进行函数调用时 , 它们都必须有确定的值 , 以便把这些值传送给形参 ; 因此应预先用赋值 , 输入等办法使参数获得确定值 # 定义函数func def func(argument1,argument2): # argument1与argument2都为形参,形式参数 print(argument1,argument2) # 调用函数func func(\"Hello\", \"Lyon\") # Hello和Lyon都是实参,实际参数 ''' 执行结果: Hello Lyon ''' 位置参数 : 即参数必须以正确的顺序传入函数 , 传入的数量必须和声明的一样 , 不一样就报错 # 用户登录验证 def login(username,password): if username == \"Lyon\" and password == \"123456\": print(\"Login successfully!\") else: print(\"Login failed!\") # 进行调用 login(\"Lyon\",\"123456\") # 进行调用 login(\"Lyon\",\"78910JkQ\") ''' 执行结果: Login successfully! Login failed! ''' 默认参数 🍀 调用时不指定就以默认值传入 , 指定则按指定值传入 # 同时定义位置参数和默认参数 def add_userinfo(name,age,province=\"北京\"): return name,province # 位置参数必填,默认参数可选 add_userinfo(\"Lyon\",18) ''' 执行结果: ('Lyon', '北京') ''' 注：通过默认参数，我们就算不传参数也不会报错 , 即province 默认为\"北京\" 关键字参数 🍀 正常情况下 , 给函数传参数的时候要按照顺序传 , 如果不想按照顺序就可以使用关键参数 def add_userinfo(name,age,province=\"北京\"): return name,province add_userinfo(\"Lyon\",province=\"湖北\",age=18) # 注意关键参数不用按照顺序传入,但是关键参数必须写在位置参数后面 非固定参数 🍀 当我们想要传入多个参数 , 但是我们又不确定的时候就可以使用非固定参数 ; 非固定参数有两个 , 一个 *args (元组形式) 以及 **kwargs (字典形式) # 设定两个非固定参数 def main(*args,**kwargs): # 打印args,以及args的类型 print(args,type(args)) # 打印kwargs,以及kwargs的类型 print(kwargs,type(kwargs)) # 调用 main((1,2,3,4),{1:2,3:4}) 对于非固定参数 , 其主要在于* 号 , * 号的作用是进行打包与解包 : 一个* 号 , 则表示打包成元组或者将元组进行解包 , 过程如下 : def main(n,*args): return args # 传递参数,第一个参数被认为是位置参数n,余后参数*号将会对其进行打包成元组,但参数形式必须符合元组规范 result = main(1,2,3,4,5) print(result) ''' 执行结果: (2, 3, 4, 5) ''' ''' 额外说明: 传递参数时,*号将参数封装成一个元组,即元组args ''' 两个** 号 , 则表示打包成字典或者将字典进行解包 , 过程如下 : def main(**kwargs): return kwargs # 传递参数,**号将会对其进行打包成字典,但参数形式必须符合字典规范,即必须key-value result = main(n2=2,n3=3,n4=4) print(result) ''' 执行结果: {'n4': 4, 'n2': 2, 'n3': 3} ''' ''' 额外说明: 传递参数时,**号将参数封装成一个字典,即字典kwargs ''' 两者的解包如下 : # 进行打包 def main(*args,**kwargs): # 参数状态:(1,2,3,4,5){'n1':1,'n2':2,'n3'=3} # 进行解包 return (*args),{**kwargs} # 参数状态:1,2,3,4,5,n1=1,n2=2,n3=3 result = main(1,2,3,4,5,n1=1,n2=2,n3=3) print(result) ''' 执行结果: (1, 2, 3, 4, 5, {'n2': 2, 'n3': 3, 'n1': 1}) ''' # 解包补充 '''只要是可迭代对象我们都可以对其进行解包,如下''' mytuple = (1,2,3,4,5,6,7) # _为占位符,*c打包成列表 a,_,b,*c,d = mytuple print(a) print(b) print(c) print(d) ''' 执行结果: 1 3 [4, 5, 6] 7 ''' 参数顺序及组合 🍀 参数顺序 在函数头部 (定义参数) : 一般参数 → 默认参数 → 非固定参数*args → 非固定参数**kwargs 在函数调用中 (传递参数) : 位置参数 → 关键字参数 → 默认参数 → 非固定参数*args → 非固定参数**kwargs 参数组合 在我们使用过程中 , 如果没有非固定参数 , 那么我们的关键参数或者默认参数可以用关键字进行传递 ; 如果有非固定参数 , 必须按照位置参数的方式进行传递 默认参数和非固定参数*args位置可以进行调换 , 调换后默认参数传递需要加上关键字 全局与局部变量 🍀 局部变量：只在函数内部起作用的变量 全局变量：在整个程序中都起作用 # 全局变量name name = \"Lyon\" def func(name): print(name) # 局部变量name name = \"Kenneth\" print(name) # 调用函数 func(name) print(name) ''' 执行结果: Lyon Kenneth Lyon ''' 总结 : 全局变量作用域是整个程序 , 局部变量作用域是定义该变量的子程序 ; 当全局变量与局部变量同名时 : 在定义局部变量的子程序内 , 局部变量起作用 ; 在其他地方全局变量起作用 global语句 : 可以将局部变量变成全局变量 , 在函数内部变量前加上 global 即可如 : global name return语句 🍀 return 语句用于返回函数的执行结果 , 比如操作类函数一般都不需要返回值 , 当然可由我们的需要自己进行设定 不使用return 即返回None , 没有返回值 我们函数在执行过程中如果遇到return语句 , 就会结束并返回结果 def sum( arg1, arg2 ): # 返回2个参数的和 total = arg1 + arg2 print(\"两数之和:\",total) return total # 上一步函数就已经结束,不会往下执行 print(\"已经返回!\") # 调用sum函数 total = sum( 10, 20 ) ''' 执行结果: 两数之和: 30 ''' 如果我们返回函数名 def func(): print(\"I am Lyon\") # 返回func,函数名 → 内存地址 return func # result1接收返回值func函数名 result1 = func() # 返回一个函数对象 print(result1) # 可以继续调用 result2 = result1() print(result2) result2() ''' 执行结果: I am Lyon I am Lyon I am Lyon ''' 这是一处妙用 , 当然在单层函数中作用不明显 , 下一章的《Python之路 - 函数进阶》中的闭包可以让你体会魅力之所在 "},"01-Python/02-Advanced/02-Python - 函数进阶.html":{"url":"01-Python/02-Advanced/02-Python - 函数进阶.html","title":"Python - 函数进阶","keywords":"","body":"Python - 函数进阶 嵌套函数 🍀 嵌套函数即函数里面再套一个函数 , 如下 : # 全局变量name name = \"Lyon_1\" def func(): # 第一层局部变量name name = \"Lyon_2\" print(\"第1层打印\",name) #嵌套 def func2(): # 第二层局部变量name name = \"Lyon_3\" print(\"第2层打印\", name) # 嵌套 def func3(): # 第三层局部变量 name = \"Lyon_4\" print(\"第3层打印\", name) # 调用内层函数 func3() # 调用内层函数 func2() func() print(\"最外层打印\", name) ''' 执行结果: 第1层打印 Lyon_2 第2层打印 Lyon_3 第3层打印 Lyon_4 最外层打印 Lyon_1 ''' 嵌套函数不能越级调用 , 也就是说我们不能在func2 的外部去调用func3 , 当然反过来我们的代码就进入无限递归了 当然我们有时需要的就是在嵌套函数中 , 使用上一层的变量 , 那么我们可以使用nonlocal 语句 nonlocal 的作用就是改变变量的作用域 , 但是不会扩展到全局变量 , 即只能在函数内部改变 ; nonlocal声明之后 , 会从上层开始找并返回第一个变量 , 没找到则会报错 def func(arg): n = arg def func1(): n = 2 def func2(): nonlocal n # n = 2 n += 1 func2() print(n) # n = 3 func1() print(n) func(10) ''' 执行结果: 3 10 ''' 高阶函数 🍀 高阶函数就是将一个函数以参数的形式传入另一个函数 # 定义一个主函数,并设置一个参数func def main_func(func): # 返回func的值 return func # 定义一个函数作为参数传入主函数 def func(): # 返回\"Lyon\"给func() return \"Lyon\" # res接收main_func的返回值,将func()的返回值作为参数传入main_func函数 res = main_func(func()) print(res) ''' 执行结果: Lyon ''' 闭包 🍀 闭包必须是内部定义的函数 (嵌套函数) , 该函数包含对外部作用域而不是全局作用域名字的引用 def foo(): # 局部变量name name = 'Lyon' # 内部定义的函数 def bar(): # 引用了外部定义的变量name,即内部函数使用外部函数变量,这一行为就叫闭包 print(\"I am\",name) return \"In the bar\" # 调用bar并打印结果 print(bar()) return \"In the foo\" # 调用foo并打印结果 print(foo()) ''' 执行结果: I am Lyon In the bar In the foo ''' 在嵌套函数中 , 我们可以将函数作为参数 (高阶函数) 或者返回值进行传递 , 函数作为一个值可以赋给变量 , 如下 : def decorator(func): \"\"\"func变量在inner函数外部\"\"\" print(\"I am decorator\") def inner(): print(\"I am inner\") # 内部函数引用外部变量func,而func是一个函数对象,因此我们可以进行调用,此处闭包 func() # 内部调用inner函数 inner() # 返回inner,函数名 → 内存地址 return inner # decorator函数的参数函数 def decorator_arg(): print(\"I am decorator_arg\") # 返回decorator_arg,函数名 → 内存地址 return decorator_arg # result接收的是inner函数名 result = decorator(decorator_arg) print('-------------------') # 实际调用的是嵌套函数中内部的inner函数 result() ''' 执行结果: I am decorator I am inner I am decorator_arg ------------------- I am inner I am decorator_arg ''' \"\"\" 说明: 从本例子可以看出我们利用闭包, 打破了嵌套函数不能越级调用的规则, 实现了从外部调用内部函数 \"\"\" 所以利用闭包我们可以实现两种需求 : 在不修改源代码的情况下给函数增加功能 为某个函数的参数进行提前赋值 添加功能 🍀 如果我们以相同的变量名去覆盖函数名 , 修改上述代码 , 如下 : def decorator(func): def inner(): print(\"I am decorator\") func() # 此处删去inner调用 return inner def func(): print(\"I am func\") return func # func变量名覆盖了func()的函数名 func = decorator(func) # 实际调用inner() func() ''' 执行结果: I am decorator I am func ''' \"\"\" 说明: 通过对函数名进行覆盖,使我们的func变成了inner, 而原来的func已经成为了inner的一部分, \"\"\" 通过定义了变量decorator , 使其原来的函数decorator() 被覆盖 , 也就是说我们实现了在不修改func() 函数的情况下 , 为func() 函数新添加了一个功能 , 当然上述例子中的功能仅仅是打印一句 \"I am decorator\" 当然我们还可以这样 : def func(): print(\"I am func\") return def decorator(func): print(\"I am decorator\") func() return decorator func = decorator(func) ''' 执行结果: I am decorator I am func ''' # 此版本调用方式不同,所以一般不使用 闭包方式加参数版 : def decorator(func): # 此处将原始func参数进行打包 def inner(*args,**kwargs): print(\"I am decorator\") # 此处将原始func参数进行拆包返还 func(*args,**kwargs) return inner def func(*args,**kwargs): print(\"I am func\") print(args,kwargs) return func func = decorator(func) # inner(*args,**kwargs) func( ) 数据存储 🍀 def func(): name = \"Lyon\" def inner(): print(name) return inner func = func() # 调用之前name的值已经传入inner中 func() \"\"\" 为什么要数据存储? 因为如果我们将name定义到inner内部,那么只要inner一执行完毕,Python解释器就会把name释放 如果我们要执行一万次这样的操作,那么Python解释器就需要如此申请和释放一万次,会造成内存浪费 \"\"\" 一道面试题的翻译版本 def func(): l = [] for i in range(10): # inner函数并没有进行调用,但是for循环已经执行完毕,此时i=9 def inner(x): return i + x l.append(inner) return l res = func() print(res[0](10)) print(res[1](10)) print(res[2](10)) print(res[3](10)) ''' 执行结果: 19 19 19 19 ''' \"\"\" 说明: 这里虽然结果都为19,但是由for循环生成的10个函数却不是同一个函数, 在执行时,i的值通过绑定的方式进入每一个函数,直到for循环执行完毕, i的值固定在9,等你再调用时就全为9了 \"\"\" 面试题原版 # 知识点:列表生成式,匿名函数,闭包 s = [lambda x: x + i for i in range(10)] print(s[0](10)) print(s[1](10)) print(s[2](10)) print(s[3](10)) 对于闭包 , 我们可以使用__closure__ 属性查看闭包函数中引用变量的取值 , __closure__ 里包含了一个元组 , 这个元组中的每个元素是cell 类型的对象 , 默认为None def func(): name = \"Lyon\" def inner(): print(name) return inner # 内部inner print(func().__closure__) ''' 执行结果: (,) ''' 装饰器 🍀 装饰器即给原来的函数进行装饰的工具 装饰器由函数去生成 , 用于装饰某个函数或者方法 (类中的说法) , 它可以让这个函数在执行之前或者执行之后做某些操作 装饰器其实就是上一节闭包中的添加功能实现 , 不过使用闭包太过麻烦 , 所以Python就创造出一个语法糖来方便我们使用 语法糖 : 指那些没有给计算机语言添加新功能 , 而只是对人类来说更\"甜蜜\"的语法 , 语法糖主要是为程序员提供更实用的编码方式 , 提高代码的可读性 , 并有益于更好的编码风格 语法糖如下 : # 装饰器函数 def decorator(func): def inner(): func() return inner # 语法糖,@ 函数名 @decorator # 被装饰函数 def func(): pass 该语法糖只是将我们闭包中最后自己处理的部分进行处理了 , 如下 : @decorator ↓ 等价 func = decorator(func) 另一种一般不使用的方式 : # 装饰器函数 def decorator(func): return func() # 语法糖,@ 函数名 @decorator # 被装饰函数 def func(): pass 实例 def decorator(func): def inner(): print(\"I am decorator\") func() return inner @decorator # → func = decorator(func) def func(): print(\"I am func\") return func func() ''' 执行结果: I am decorator I am func ''' 多个装饰器装饰同一个函数 def decorator1(func): def inner(): return func() return inner def decorator2(func): def inner(): return func() return inner @decorator1 @decorator2 def func(): print(\"I am func\") func() 被装饰函数带有参数 def decorator(func): def inner(*args,**kwargs): return func(*args,**kwargs) return inner @decorator def func(name): print(\"my name is %s\" % name) func(\"Lyon\") 带参数的装饰器 F = False def outer(flag): def decorator(func): def inner(*args,**kwargs): if flag: print('before') ret = func(*args,**kwargs) print('after') else: ret = func(*args, **kwargs) return ret return inner return decorator @outer(F) # outer(F) = decorator(func) def func(): print('I am func') 我们利用装饰器虽然功能达到了 , 但是注意原函数的元信息却没有赋值到装饰器函数内部 , 比如函数的注释信息 , 如果我们需要将元信息也赋值到装饰器函数内部 , 可以使用functools模块中的wraps()方法 , 如下 : import functools def outer(func): @functools.wraps(func) def inner(*args, **kwargs): print(inner.__doc__) return func() return inner @outer def func(): \"\"\" I am func \"\"\" return None func() "},"01-Python/02-Advanced/03-Python - 匿名函数.html":{"url":"01-Python/02-Advanced/03-Python - 匿名函数.html","title":"Python - 匿名函数","keywords":"","body":"Python之路 - 匿名函数 匿名函数介绍 🍀 lambda是一个表达式 , 而并非语句 , 所以可以出现在def语句所不能出现的位置 , 并且不需要指定函数名; lambda表达式还可以提高代码的可读性 , 简化代码 lambda表达式主要用于写一些简单的方法 , 对于复杂的还是用函数写的好 示例: # 普通函数 def func(x): return x * x print(func(5)) ----------------------- # 匿名函数,自带return功能 func = lambda x : x * x print(func(5)) --------------------------------------------------- func = lambda arguments : expression using argument 使用匿名函数可以减少命名空间使用内存 , 因为没有函数名 可直接后面传递参数 >>> (lambda x,y : x if x > y else y)(1,2) 2 非固定参数 >>> (lambda *args : args)(1,2,3,4) (1, 2, 3, 4) PS : 匿名函数主要是与其他函数搭配使用 匿名函数运用 🍀 结合使用 map , 计算平方 # map后返回的对象为map对象,所以利用list方法进行强转 >>> list(map(lambda x : x * x, [1,2,3,4])) [1,4,9,16] filter , 筛选偶数 >>> list(filter(lambda x : x % 2 == 0,[1,2,3,4])) [2,4] reduce , 求和 # python3中已经没有reduce方法了,调用需要导入 >>> from functools import reduce # reduce(function, sequence, initial=None) >>> reduce(lambda x , y : x + y, [1,2,3,4,5],100) 115 嵌套使用 版本一 def func(x): return lambda x : x + y f = func(2) print(f(2)) # output: 4 版本二 func = lambda x : (lambda y: x + y) y = func(1) y(2) # output: 3 "},"01-Python/02-Advanced/04-Python - 内置函数.html":{"url":"01-Python/02-Advanced/04-Python - 内置函数.html","title":"Python - 内置函数","keywords":"","body":"Python - 内置函数 str类型代码的执行(3个) 🍀 exec(object[, globals[, locals]]) 👈 将字符串当做表达式去执行，没有返回值 # 流程语句用exec >>> exec(\"print('123')\") 123 >>> exec('1+2+3+4') 10 >>> res = exec('1+2+3+4') None eval(expression, globals=None, locals=None) 👈 将字符串当做表达式去执行，并返回执行结果 # 简单求值表达式用eval >>> res = eval('1+2+3+4') >>> res 10 compile(source, filename, mode, flags=0, dont_inherit=False, optimize=-1) 👈 把字符传编译成python可执行的代码，但是不会执行 filename : 默认sys.stout，即默认打印在控制台，打印到指定文件 mode : 指定compile后的对象的执行模式，注意有个single模式，当source带有变量赋值时，eval模式是解释不了的，所以需要用single模式或者exec模式 # 交互语句用single >>> code3 = 'name = input(\"please input your name:\")' >>> compile3 = compile(code3,'','single') # 执行前name变量不存在 >>> name # 报错说'name'变量没有定义 Traceback (most recent call last): File \"\", line 1, in name NameError: name 'name' is not defined >>> exec(compile3) # 执行时显示交互命令，提示输入 please input your name:'pythoner' # 执行后name变量有值 >>> name \"'pythoner'\" 数据类型相关(38) 🍀 数字相关 🍀 数据类型 🍀 bool([x]) 👈 查看一个元素的布尔值 int(x=0) / int(x, base=10) 👈 获取一个数的十进制或者进行进制转换 >>> int('1') 1 # 二进制转十进制 >>> int('0b11',base=2) 3 float([x]) 👈 将整数和字符串转换成浮点数 complex([real[, imag]]) 👈 创建一个值为real + imag * j的复数或者转化一个字符串或数为复数。如果第一个参数为字符串，则不需要指定第二个参数 >>> complex(1, 2) (1+2j) # 数字 >>> complex(1) (1+0j) # 当做字符串处理 >>> complex(\"1\") (1+0j) # 注意：这个地方在“+”号两边不能有空格，也就是不能写成\"1 + 2j\"，应该是\"1+2j\"，否则会报错 >>> complex(\"1+2j\") (1+2j) 进制转换 🍀 bin(x) 👈 将整数x转换为二进制字符串，如果x不为Python中int类型，x必须包含方法__index__()并且返回值为整数 # 返回一个整数的二进制 >>> bin(999) '0b1111100111' # 非整型的情况，必须包含__index__()方法且返回值为integer的类型 >>> class myType: ... def __index__(self): ... return 35 ... >>> myvar = myType() >>> bin(myvar) '0b100011' oct(x) 👈 转换为八进制 >>> oct(8) '0o10' hex(x) 👈 转换为十六进制 >>> oct(13) '0o15' 数学运算 🍀 abs(x) 👈 返回一个数的绝对值 >>> num = -1 >>> abs(num) 1 divmod(a, b) 👈 返回两个数的除,余 >>> divmod(5,2) # 第一个数为整除,第二个为取余 (2, 1) min(iterable, *[, key, default]) 👈 min(arg1, arg2, *args[, key]) 👈 返回最小值,如果多个参数最小值一样,则返回第一个 >>> min([1,2,3,4]) 1 # 返回第一个 >>> min([1,2,3],[4,5],[1,2]) [1,2,3] max(iterable, *[, key, default]) 👈 max(arg1 , arg2, *args[, key]) 👈 返回最大值,如果多个参数最大值,则返回第一个 >>> max([1,2,3,4]) 4 >>> max([2,3],[1,2,3]) [2, 3] sum(iterable[, start]) 👈 求和,参数为可迭代对象 >>> sum((1,2,3,4)) 10 round(number[, ndigits]) 👈 小数精确 # 保留两位小数,四舍五入 >>> round(1.235,2) 1.24 pow(x, y[, z]) 👈 幂运算 >>> pow(2,2) 4 # 参数z相当余 x**y % z >>> pow(2,2,2) 0 数据结构相关 🍀 序列 🍀 列表和元组 list([iterable]) 👈 将可迭代对象转换成list对象,实际上我们创建一个空list时,python解释器自动为我们调用了该方法 tuple([iterable]) 👈 将可迭代对象转换成tuple对象,与list类似 相关内置函数 reversed(seq) 👈 顺序翻转,与list中reverse的区别在于,该翻转为新生成了一个对象,而不是在原对象上操作 slice(stop) 👈 slice(start, stop[, step]) 👈 返回切片操作的三个参数 # 相当于[0:2:],注意最后一个参数不能为0而是None >>> op = slice(0,2,None) >>> l = [1,2,3,4] >>> l[op] [1,2,3] 字符串 str(object='') 👈 str(object=b'', encoding='utf-8', errors='strict') 👈 返回一个字符串对象,创建字符串时python解释器为我们调用了该方法进行创建 repr(object) 👈 返回一个可打印的字符串对象 >>> repr(123) format(value[, format_spec]) 👈 格式化字符串 bytes([source[, encoding[, errors]]]) 👈 将字符串转成bytes类型 >>> bytes('lyon',encoding='utf-8') b'lyon' bytearray([source[, encoding[, errors]]]) 👈 返回一个byte数组,Bytearray类型是一个可变的序列,并且序列中的元素的取值范围为[0,255] source : 如果source为整数,则返回一个长度为source的初始化数组; 如果source为字符串,则按照指定的encoding将字符串转换为字节序列; 如果source为可迭代类型,则元素必须为[0,255]中的整数; 如果source为与buffer接口一致的对象,则此对象也可以被用于初始化bytearray memoryview(obj) 👈 函数返回给定参数的内存查看对象(Momory view) 所谓内存查看对象，是指对支持缓冲区协议的数据进行包装，在不需要复制对象基础上允许Python代码访问 ord(c) 👈 把一个字符转换成ASCII表中对应的数字 >>> ord('a') 97 chr(i) 👈 返回一个数字在ASCII编码中对应的字符 >>> chr(66) 'B' ascii(object) 👈 在对象的类中寻找__repr__方法,获取返回值 >>> class Foo: ... def __repr_(self): ... return \"hello\" ... >>> obj = Foo() >>> r = ascii(obj) >>> print(r) # 返回的是一个可迭代的对象 数据集合 🍀 字典 dict(*\\kwarg*) dict(mapping, *\\kwarg*) dict(iterable, *\\kwarg*) 转换成字典类型,创建一个字典时python解释器会自动帮我们调用该方法 集合 set([iterable]) 👈 转换成集合类型,创建集合时,事实上就是通过该方法进行创建的 frozenset([iterable]) 👈 定义冻结集合,即不可变集合,存在hash值 好处是它可以作为字典的key，也可以作为其它集合的元素。缺点是一旦创建便不能更改，没有add，remove方法 相关内置函数 🍀 len(s) 👈 返回一个对象的长度 enumerate(iterable, start=0) 👈 为元素生成序号,可以定义序号的初始值,默认从0开始 >>> l = ['a','b','c'] >>> for i,k in enumerate(l,0): ... print(i,k) ... 0 a 1 b 2 c all(iterable) 👈 判断一个可迭代对象中的元素是否都为空,返回bool值 any(iterable) 👈 判断一个可迭代对象中是否有真元素,返回bool值 zip(*iterables) 👈 将两个长度相同的序列整合成键值对,返回一个zip对象可以用dict方法转换查看 >>> l1 = ['k1','k2','k3'] >>> l2 = ['v1','v2','v3'] >>> ret = zip(l1,l2) >>> dict(ret) {'k1':'v1','k2':'v2','k3':'v3'} filter(function, iterable) 👈 筛选过滤,把可迭代对象中的元素一一传入function中进行过滤 # 筛选出偶数 >>> def func(x): ... return x % 2 == 0 >>> f = filter(func,[1,2,3,4,5]) >>> ret = list(f) [2,4] map(function, iterable, ...) 👈 将可迭代对象中的元素一一传入function中执行并返回结果 >>> def func(s): ... return s + ' hello' >>> m = map(func,['alex','egon','lyon']) >>> m >>> ret = list(m) >>> ret ['alex hello', 'egon hello', 'lyon hello'] sorted(iterable, **, key=None, reverse=False*) 👈 为一个对象进行排序,在list中有个sort方法;区别:sort会改变原list,而sorted则不会改变原list >>> l = [3,4,5,1,2,9,8,7,6] >>> sorted(l) [1,2,3,4,5,6,7,8,9] >>> l 迭代器/生成器相关(3个) 🍀 range(stop) 👈 range(start, stop[, step]) 👈 返回一个序列,为一个可迭代对象,并可用下标取值 >>> from collections import Iterable >>> r = range(10) >>> r[0] 0 >>> isinstance(r,Iterable) True >>> list(r) [0,1,2,3,4,5,6,7,8,9] next(iterator[, default]) 👈 拿取迭代器中的元素,一次只拿一个 >>> Iter = iter([1,2,3,4]) >>> next(Iter) 1 >>> next(Iter) 2 >>> next(Iter) 3 >>> next(Iter) 4 # 没有元素就会进行报错 >>> next(Iter) Traceback (most recent call last): File \"\", line 1, in StopIteration iter(object[, sentinel]) 👈 创建一个迭代器 >>> obj = iter([1,2,3,4]) >>> obj 作用域相关(2个) 🍀 locals() 👈 打印函数局部命名空间 globals() 👈 打印函数的全局命名空间 面向对象相关(8个) 🍀 定义类方法 🍀 classmethod(function) 👈 返回一个函数的类方法 staticmethod(function) 👈 返回一个函数的属性方法 property(fget=None, fset=None, fdel=None, doc=None) 👈 返回一个静态属性 判断类之间的关系 🍀 isinstance(object, classinfo) 👈 判断对象的类型,返回bool值,主要用于判断类之间的关心,因为type无法判断类之间的关心 issubclass(class, classinfo) 👈 判断一个类是否为另一个类的子类,返回bool值 所有类的基类 🍀 classobject 👈 返回一个基类,不接收任何参数 类的继承 🍀 super([type[, object-or-type]]) 👈 用于继承父类 封装 🍀 vars([object]) 👈 返回一个对象中包含的属性 反射相关(4个) 🍀 hasattr(object, name) > vars([object]) 👈 参数是一个对象和一个字符串。如果字符串是对象的一个属性的名称，则结果为True,否则为False getattr(object, name[, default]) > vars([object]) 👈 返回对象的命名属性的值,name必须是字符串,如果字符串是对象属性之一的名称,则返回该属性的值 setattr(object, name, value) > vars([object]) 👈 为某个对象设置一个属性 delattr(object, name) > vars([object]) 👈 删除对象中的属性值 其他(10个) 🍀 input([prompt]) > vars([object]) 👈 交互式输入 print(*objects, sep=' ', end='\\n', file=sys.stdout, flush=False) > vars([object]) 👈 交互式输出 open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None) > vars([object]) 👈 打开文件 help([object]) > vars([object]) 👈 查找官方说明 hash(object) > vars([object]) 👈 返回一个hash地址 callable(object) > vars([object]) 👈 判断一个对象是否可以被调用执行 dir([object]) 👈 返回一个对象中的所有方法 id(object) 👈 返回一个对象的内存地址 type(object) type(name, bases, dict) 👈 查看一个对象的数据类型 __import__(name, globals=None, locals=None, fromlist=(), level=0) 👈 该函数是由import进行调用的,我们一般不用 "},"01-Python/02-Advanced/05-Python - 迭代器和生成器.html":{"url":"01-Python/02-Advanced/05-Python - 迭代器和生成器.html","title":"Python - 迭代器和生成器","keywords":"","body":"Python - 迭代器和生成器 可迭代对象 🍀 在Python中一切皆对象 迭代是重复反馈过程的活动 , 其目的通常是为了逼近所需目标或结果 可迭代对象 , 即可以按照迭代的方式进行存取数据的对象 , 在python中我们可以理解为可以用for循环遍历的对象就是可迭代对象 for循环做的那些事 : for循环是我们用来遍历一个数据集合的方法 , 其实就是根据一定的要求 (这个要求叫做'协议' ) 进行一次次的迭代的效果 . 当我们用for循环去遍历时 , 它做的第一件事就是判断对象是否是可迭代对象 , 如果是 , 那么它就会将该对象转换成一个迭代器 , 最后利用__next__()方法将迭代器中的内容一个接一个的取出来 可迭代对象的标志是 , 它具有__iter__()方法 判断对象是否为可迭代对象方法如下: # 导入模块 >>> from collections import Iterable >>> l = ['lyon','oldboy'] # 判断是否为Iterable , 即可迭代对象 >>> isinstance(l,Iterable) # 返回bool值 True 迭代器 🍀 通过上面的内容已经知道for循环有一个生成迭代器的过程 , 迭代器是啥 ? 迭代器是访问集合元素的一种方式 特点: 不依赖索引取值 , 访问者不需要关心迭代器内部的结构 , 仅需通过next()方法去访问 不能随机访问集合中的某个值 , 只能从头到尾依次访问 , 不可返回访问 惰性计算 , 只有在需要访问时才会生成值 , 节省内存 在python中有一个iter()方法 , 作用就是将可迭代对象变成一个迭代器 , 实质上iter()是去调用了__iter__()方法 , 看代码: >>> l = ['lyon'] >>> l.__iter__() # iterator即迭代器 可迭代对象与迭代器的区别: # 用dir方法查看对象中的所有方法 >>> dir_list = dir([1,2]) >>> dir_iter = dir([1,2].__iter__()) # 筛选出不同点 >>> set(dir_iter) - set(dir_list) {'__length_hint__', '__setstate__', '__next__'} 我们可以看出迭代器比可迭代对象多出了三个方法 , 所以我们可以根据这一点来判断一个对象到底是可迭代对象还是一个迭代器 # 创建一个迭代器 >>> i = iter([1,2,3,4]) # 查看迭代器中元素的长度 >>> i.__length_hint__() 4 # 根据索引指定迭代开始位置 >>> i.__setstate__(3) # 进行取值 >>> i.__next__() 4 判断方法: # 导入Iterable类 >>> from collections import Iterable # 导入Iterator类 >>> from collections import Iterator # 是否为可迭代对象 >>> isinstance(obj,Iterable) # 是否为迭代器 >>> isinstance(obj,Iterator) # 注意:迭代器也是可迭代对象 在迭代时 , 我们需要注意迭代器中是否有值的问题 , 即当我们一直调用__next__ 方法取值时 , 如果值都取完了 , 而此时我们再执行 __next__ 方法 , 解释器就会抛出 StopIteration , 因为已经没有值可以取了 生成器 🍀 自定义的一个能够实现迭代器功能的就是生成器 本质: 迭代器(所以自带了__iter__ 方法和__next__ 不需要我们去实现 特点: 惰性运算 , 开发者自定义 生成器函数 🍀 一个函数调用时返回一个迭代器 , 那么这个函数就叫做生成器函数 利用生成器做一个range( 2.x中的xrange ) 的功能 # 定义函数 >>> def range(n): ... start = 0 ... while start >> obj = range(5) >>> obj.__next__() >>> obj.__next__() >>> obj.__next__() >>> obj.__next__() >>> obj.__next__() yield的作用 : yield的作用是中断函数的执行并记录中断的位置 , 等下次重新调用这个函数时 , 就会接着上次继续执行 PS : 调用生成器函数时 , 仅仅会返回一个生成器 , 并不会执行函数的内容 , 生成器只能由next() 进行调用执行 , 实质上next()方法就是调用的__next__() 方法 yield from def func1(): for i in 'AB': yield i for j in range(3): yield j print(list(func())) def func2(): yield from 'AB' yield from range(3) print(list(func2())) 生成器应用 监听文件 import time def tail(filename): # 打开文件 f = open(filename,encoding='utf-8') # 从文件末尾算起 f.seek(0, 2) while True: # 读取文件中新的文本行 line = f.readline() if not line: time.sleep(0.1) continue yield line tail_g = tail('tmp') # 生成器也是可迭代对象 for line in tail_g: print(line) 计算动态平均值 def averager(): total = 0 count = 0 average = None while True: term = yield average total += term count += 1 average = total/count # 生成生成器 g_avg = averager() # 激活生成器,不激活无法send next(g_avg) # send相当于先传参,后调用next() print(g_avg.send(10)) print(g_avg.send(30)) print(g_avg.send(50)) 列表推导式和生成器表达式 🍀 # 列表解析 >>> num = [i for i in range(10)] >>> num [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] # 生成器表达式 >>> num_iter = (i for i in range(10)) >>> num_iter at 0x0000021C41003258> >>> next(num_iter) 0 >>> next(num_iter) 1 >>> next(num_iter) 2 >>> next(num_iter) 3 >>> next(num_iter) 4 >>> next(num_iter) 对于推导式会有另一篇专门来写 "},"01-Python/02-Advanced/06-Python - 递归.html":{"url":"01-Python/02-Advanced/06-Python - 递归.html","title":"Python - 递归","keywords":"","body":"Python - 递归 递归算法 🍀 递归算法是一种直接或者间接地调用自身算法的过程（递归函数就是一个体现）。在计算机编写程序中，递归算法对解决一大类问题是十分有效的，它往往使算法的描述简介而且易于理解。 特点：👈 递归就是再过程或函数里调用自身 再使用递归策略时，必须有一个明确的递归结束条件，称为递归出口。递归算法解题通常显得很简洁，但递归算法解题的运行效率低 在递归调用的过程当中系统为每一层的返回点、局部量等开辟了栈来存储。递归次数过多容易造成栈溢出等。所以一般不提倡用递归算法设计程序 要求：👈 每次调用在问题规模上都有所减少（通常是减半） 相邻两次重复之间有紧密的联系，前一次要为后一次做准备（通常前一次的输出就作为后一次的输入） 再问题的规模极小时必须要直接给出解答而不再进行递归调用，因而每次递归调用都是有条件的（以规模未达到直接解答的大小为条件），无条件递归条用将会称为死循环而不能正常结束 递归函数 🍀 面向函数编程中，利用递归思想来解决一些简单的问题是非常简单便洁的 递归函数就是函数内部通过调用自己本身来实现功能的函数。既然是调用自身,那么每次调用，需要解决的问题就应该有所减少，不然这个函数就没有尽头的执行下去。 打印10-0 def counter(num): # 打印num print(num) # 如果num小于等于0 if num 递归应用 🍀 用递归实现斐波那契数列 l = [] def fibonacci(n1,n2): # 大于1000后结束递归 if n1 > 2000: # 终止函数，并返回 \"不搞了\" return \"不搞了！\" # 追加进列表 l.append(n1) # 前两个数之和 n3 = n1 + n2 # 进行递归 fibonacci(n2, n3) # 从0开始 fibonacci(0, 1) print(l) 用递归实现三级菜单 menu = { '北京': { '海淀': { '五道口': { 'soho': {}, '网易': {}, 'google': {} }, '中关村': { '爱奇艺': {}, '汽车之家': {}, 'youku': {}, }, '上地': { '百度': {}, }, }, '昌平': { '沙河': { '老男孩': {}, '北航': {}, }, '天通苑': {}, '回龙观': {}, }, '朝阳': {}, '东城': {}, }, '上海': { '闵行': { \"人民广场\": { '炸鸡店': {} } }, '闸北': { '火车战': { '携程': {} } }, '浦东': {}, }, '山东': {}, } def threeLM(menu): while True: # 打印本级菜单内容 for key in menu: # 打印字典的key print(key) # 用户输入内容 chooice = input(\"请输入菜单>>\") if chooice == 'back': return elif chooice == 'quit': return 'q' if chooice in menu.keys(): # 将新字典作为参数进行递归调用 ret = threeLM(menu[chooice]) if ret == 'q':return 'q' threeLM(menu) "},"01-Python/03-Modules/":{"url":"01-Python/03-Modules/","title":"Modules","keywords":"","body":"The road to Python - Modules "},"01-Python/03-Modules/01-Python - 模块初识.html":{"url":"01-Python/03-Modules/01-Python - 模块初识.html","title":"Python - 模块初识","keywords":"","body":"Python - 模块初识 介绍 🍀 Python 模块 , 说白了就是一个 .py 文件 , 里面放了一坨函数和变量或者类 , 总而言之就是放了一堆代码 , 那么问题来了 , 我要它有什么用? 当我们写一个比较复杂的程序 , 程序里面定义了100个函数和200个变量 , 然后这些函数和变量要来回调用 , 于是我们就得到处找函数名 , 找变量名 ,找了一个小时终于找到了 , 好的 , 我们开始找下一个 ... 所以 , 这个时候我们就需要模块了 , 我们可以将一类作用的函数和变量放到一个 .py 文件中 , 这样分成好几个文件 , 我们就可以快速维护我们的代码了 模块的作用: 便于维护 模块导入方式: # 导入整个模块或者包 1. import moudle # 导入模块或者包中的所有内容 2. from moudle import * # 从模块或者包导入一部分内容 3. from moudle import part # 从模块或者包导入一部分内容并命名为m 4. from moudle import part as m collections模块 🍀 在内置数据类型(dict、list、set、tuple)的基础上 , conllections模块还提供了几个额外的数据类型 : Counter 、deque、defaultdict、namedtuple和OrderedDict等 namedtuple 🍀 生成可以使用名字来访问元素内容的tuple 从名字可以理解 , 带名字的元组 , 即我们可以通过key来取值 官方文档中解释 : 返回一个具有命名字段的元组的新子类 # 从collections模块中导入namedtuple >>> from collections import namedtuple # 设置属性 >>> Point = namedtuple('Point',['x','y']) # 传入参数 >>> p = Point(1,2) # 利用x进行取值 >>> p.x 1 # 利用y进行取值 >>> p.y 2 类似的 , 如果我们定义一个圆 >>> Circle = namedtuple('Circle',['x','y','r']) deque 🍀 双向队列 , 可以快速的从另外一侧追加和推出对象 使用list存储数据时 , 按索引访问元素很快 , 但是插入和删除元素就很慢了 , 因为list是线性存储 , 数据量大的时候 , 插入和删除效率很低 deque就是为了高校实现插入和删除操作的双向列表 , 适合用于队列和栈: # 从collections模块中导入deque >>> from collections import deque # 创建双向队列 >>> q = deque(['a','b','c']) # 从最后插入 >>> q.append('x') # 从头插入 >>> q.appendleft('y') >>> q deque(['y','a','b','c','x']) deque除了实现list的 append() 和 pop() 外, 还支持 appendleft() 和 popleft() , 这样就可以非常高效地往头部添加或删除元素 Counter 🍀 Counter类的目的是用来跟踪值出现的次数 , 它是一个无序的容器类型 , 以字典的键值对形式存储 , 其中元素作为key , 其计数作为value ; 计数值可以是任意interger(包括0和负数) , Counter类和其他语言的bags或multisets很相似 >>> c = Counter('abcdeabcdabcaba') >>> c Counter({'a': 5, 'b': 4, 'c': 3, 'd': 2, 'e': 1}) Counter详细用法 OrderedDict 🍀 创建有序字典 使用dict时 , key是无序的 ; 在对dict做迭代时 , 我们无法确定key的顺序 , 这时我们就可以利用OrderedDict来实现我们的目标 # 从collections模块中盗图OrderedDict >>> from collections import OrderedDict # 创建一个无序字典 >>> d = dict([('a',1),('b',2),('c',3)]) >>> d # dict的key是无序的 {'a':1,'c':3,'b':2} # 创建一个有序字典 >>> od = OrderedDict([('a',1),('b',2),('c',3)]) >>> od # OrderedDict的key是有序的 OrderedDict([('a',1),('b',2),('c',3)]) PS : OrderedDict的key会按照插入的顺序排序 , 不是key本身排序: >>> od = OrderedDict() # 插入一个键值对 >>> od['z'] = 1 >>> od['y'] = 2 >>> od['x'] = 3 >>> od.keys() # 按照插入的key的顺序返回 ['z','y','x'] defaultdict 🍀 带有默认值的字典 当我们使用dic时 , 如果引用的key不存在 , 就会抛出KeyError ; 如果希望key不存在时 , 返回一个默认值 , 就可以使用defaultdict # 从collections模块中导入defaultdict >>> from collections import defaultdict # 创建带默认值的字典 >>> dd = defaultdict(lambda:None) # 为创建的字典中添加键值对 >>> dd['key1'] = 'abc' abc # key2不存在,自动添加返回默认值 >>> dd['key2'] None # 查看最后结果 >>> dict(dd) {'key1': 'abc', 'key2': None} PS : 在dict类中的方法有一个 setdefault() 是用于创建的 ,而defaultdict是用来访问的 "},"01-Python/03-Modules/02-Python - 模块导入详解.html":{"url":"01-Python/03-Modules/02-Python - 模块导入详解.html","title":"Python - 模块导入详解","keywords":"","body":"Python - 模块导入详解 import 🍀 我们知道一个模块就是一个py文件 , 当我们执行py文件时 , python解释器会先加载内置命名空间 , 其次是加载全局命名空间( 学习函数就已知道 ) , 还有个局部命名空间就不说了 当python解释器遇到我们的import语句时 , import会将模块进行初始化 , 即会将模块中的内容执行一遍 , 既然执行 , 那么被import的模块的全局命名空间就创建成功了 , 并且会将这个创建成功的命名空间加载到使用import语句的本地的全局命名空间 . 于是我们就可以在本地使用被导入模块了 自定义模块my_module.py , 文件名my_module.py , 模块名my_module 在模块my_module.py下 ---------------文件内容---------------- | print('from the my_module.py') | | def read(): | | print('in the module.py read') | -------------------------------------- 在当前文件test.py下 ---------------文件内容---------------- | import my_module | | my_module.read() | -------------------------------------- # 执行test.py文件,打印结果 ''' # 执行了my_module.py的print语句 from the my_module.py # 成功调用my_module.py中的read函数 in the module.py read ''' import语句是可以在程序中的任意位置使用的 , 且针对同一个模块import多次时 , 为了防止你重复导入 , python进行了如下优化 : 第一次导入后就将模块名加载到内存了 , 后续的import语句仅是对已经加载大内存中的模块对象增加一次引用 , 不会重新执行模块内的语句 import多次同以模块 在模块my_module.py下 ---------------文件内容---------------- | print('from the my_module.py') | | def read(): | | print('in the module.py read') | -------------------------------------- 在当前test.py文件下 ---------------文件内容---------------- | import my_module | | import my_module | | import my_module | | my_module.read() | -------------------------------------- # 执行test.py文件,打印结果 ''' # 仅执行了一次my_module.py中的print语句 from the my_module.py # 成功调用my_module.py中的read函数 in the module.py read ''' 我们可以从sys.modules中找到当前已经加载的模块 , sys.modules是一个字典 , 内部包含模块名与模块对象的映射 ,该字典决定了导入模块时是否需要重新导入 每个模块的命名空间都是相互独立的 , 这样我们在编写自己的模块时 , 就不用担心我们定义在自己模块中全局变量在被导入时 , 与使用者的同名全局变量冲突 ps:模块中的内容使用 :模块名 .函数或者变量或者类来进行调用 总结 首次导入模块时python会做三件事 为源文件(如my_module模块) 创建新的命名空间 , 在my_module中定义的函数和方法若是使用到了globals() 时访问的就是这个命名空间 在新创建的命名空间执行模块中包含的代码 , 如上例中执行了模块中的print语句 , 并加载了函数 创建名字my_module 来引用该命名空间 , 使用my_module.名字的方式访问my_module.py文件中定义的名字 , 且名字与test.py文件中的名字来自两个完全不同的地方 import ... as ... 🍀 为模块取名 根据用户需求选择额不同的sql(数据库)功能 # 在mysql.py中 def sqlparse(): print('from mysql sqlparse') # 在oracle.py中 def sqlparse(): print('from oracle sqlparse') # 在test.py中 db_type = input('Please choice the database >>').strip() if db_type == 'mysql': import mysql as db elif db_type == 'oracle': import oracle as db 一行导入多个模块 import sys,os,re from ... import ... 🍀 相当于import , 同样会执行一遍my_module文件 , 同样也会创建命名空间 , 但是from .. . import ... 是将my_module中的名字直接导入到当前的命名空间 , 也就意味着可以直接调用 , 而不用像import那样 , 利用 my_module . 名字 来进行调用 两种方式对比 # import方式 import my_module # 模块名 + '.' + 函数名进行调用 my_module.read() # from...import...方式 from my_module import read # 直接用函数名调用 read() PS : 利用from...import...方式进行导入 , 一般用来指定导入模块中的某一部分 , 或者方便使用 , 还有一个特殊的导入 from ... import * (作用是导入模块中的所有内容 , 但是有弊端) as from my_module import read as r 多行 from my_module import (read1, read2, read3) from ... import * 🍀 from mymodule import * 会将my_module 中的所有的不是以下划线 ' ' 开头的名字都导入到当前位置 , 在大部分情况下我们python程序不应该使用这种导入方式 , 因为你无法知道 * 导入了什么名字 , 很有可能会覆盖掉你已经定义过的名字 , 而且可读性极其的差 在my_module.py中新增一行 # 这样在另外一个文件中用from my_module import * 就能导入列表中规定的两个名字 __all__ = ['money' , 'read1'] if __name__ == '__main__' 🍀 所有的模块都有一个内置属性 __name__ , 可以用来查看模块名 在当前文件执行时会返回' _main_ ', 如果不在当前文件执行那么就会返回所执行的模块名 # my_module.py中 print(__name__) # 执行my_module.py 执行结果: __main__ # test.py中 import my_modlue # 执行 test.py 执行结果: my_module 所以利用_name_ 属性 , 我们就可以实现 , 模块可以自己执行 , 也可以导入到别的模块中执行 , 并且他不会执行 两次 # my_module.py中 def main(): print('we are in %s' % __name__) # 如果在当前文件下就会执行 if __name__ == '__main__': main() # test.py中 , 执行test.py # 解释from语句时 , 并不会执行my_module中的main() from my_module import main # 执行main() main() 执行结果：we are in my_module # 结果显示只执行了一次main() "},"01-Python/03-Modules/03-Python - 包导入详解.html":{"url":"01-Python/03-Modules/03-Python - 包导入详解.html","title":"Python - 包导入详解","keywords":"","body":"Python - 包导入详解 介绍 🍀 为了帮助组织模块并提供命名层次结构 , Python有一个概念 : 包 包就相当于一个文件系统的目录 , 模块相当于目录中的文件 , 也就是说所有的包都时模块 , 但不是所有的模块都是包 包只是一种特殊的模块 , 具体来说 , 包含__path__ 属性的任何模块都被视为包 所有模块都有一个名称 , 子包名与他们的父包名由点隔开 , 类似于Python的标准属性访问语法 Python定义了两种类型的包 , 即 regular packages 和 namespace packages , 我们通常使用的就是regular packages , 对于namespace packages可通过上述链接进行学习 常规包 🍀 常规包时传统的包 , 因为它们存在于Python 3.2 及更早的版本中 ; 常规包通常实现为包含__init__.py 文件的目录 当我们导入常规包时 , 这个__init__.py文件会被隐式执行 (这意味着我们应该在__init__.py 文件中完成我们的导入 , 即初始化包) , 它定义的对象被绑定到包命名空间中 ; Python会在导入时为模块添加一些其他属性 , 如下 : parent/ __init__.py one/ __init__.py two/ __init__.py three/ __init__.py ''' 导入parent.one将隐式执行parent/__init__.py和parent/one/__init__.py 随后导入parent.two或parent.three将执行parent/two/__init__.py和parent/three/__init__.py ''' 在我们使用import导入文件时 , 产生命名空间的名字来源于文件 , import packages产生的命名空间的名字同样来源于文件 , 即包下的__init__.py , 导入包本质就是在导入该文件 注意 : 在Python 3中 , 即使包下没有__init__.py文件 , import packages仍然不会报错 , 而在Python 2中 , 包下一定要有该文件 , 否则import packages就会抛出异常 导入包 🍀 glance包 glance/ ├── __init__.py ├── api │ ├── __init__.py __all__ = ['policy','versions'] │ ├── policy.py │ └── versions.py ├── cmd __all__ = ['manage'] │ ├── __init__.py │ └── manage.py └── db __all__ = ['models'] ├── __init__.py └── models.py import 🍀 import glance.db.models glance.db.models.register_models('mysql') from ... import ... 🍀 # import后接的必须是明确的模块或者方法或者类或者变量,否则会抛出异常 from glance.db import models models.register_models('mysql') from glance.db.models import register_models register_models('mysql') 绝对导入与相对导入 🍀 我们的glance包时写给别人用的 , 但是在glance包内部也会有彼此之间互相导入的需求 , 那么就有了绝对导入和相对导入两种方式 : 绝对导入 : 以glance作为起始 相对导入 : 用.或者.. 的方式最为起始 , 只能在一个包中使用 , 即包内目录 我们在glance/api/version.py中导入glance/cmd/manage.py glance/api/version.py 下 # 绝对导入 from glance.cmd import manage manage.main() # 相对导入,一个点表示当前目录,两个点表示上一层 from ..cmd import manage manage.main() 绝对导入 glance/ ├── __init__.py from glance import api from glance import cmd from glance import db ├── api │ ├── __init__.py from glance.api import policy from glance.api import versions │ ├── policy.py │ └── versions.py ├── cmd from glance.cmd import manage │ ├── __init__.py │ └── manage.py └── db from glance.db import models ├── __init__.py └── models.py 相对导入 glance/ ├── __init__.py from . import api #.表示当前目录 from . import cmd from . import db ├── api │ ├── __init__.py from . import policy from . import versions │ ├── policy.py │ └── versions.py ├── cmd from . import manage │ ├── __init__.py │ └── manage.py from ..api import policy #..表示上一级目录，想再manage中使用policy中的方法就需要回到上一级glance目录往下找api包，从api导入policy └── db from . import models ├── __init__.py └── models.py 单独导入 🍀 单独导入包时不会导入包中所有包含的所有子模块 , 如 : import glance glance.cmd.manage.main() ''' 执行结果: AttributeError: module 'glance' has no attribute 'cmd' ''' 上述导入会隐式执行__init__.py , 所以我们可以让这个文件来初始化 , 如下 : # glance/__init__.py from . import cmd # glance/cmd/__init__.py from . import manage 关于导入系统 : https://docs.python.org/3/reference/import.html "},"01-Python/03-Modules/04-Python - 时间和日期模块.html":{"url":"01-Python/03-Modules/04-Python - 时间和日期模块.html","title":"Python - 时间和日期模块","keywords":"","body":"Python - 时间和日期模块 介绍 🍀 python提供了 time , datetimme 和 calendar 模块可以用于格式化如期和时间 ; 时间间隔是以秒为单位的浮点数 , 每个时间戳都以自从1970年1月1日午夜（历元）经过了多长时间来表示 , 所以1970年之前的日期就不能用时间戳来表示了 , 时间戳是最适合用来做日期运算的 python中时间的三种类型 : float 浮点数 , 即时间戳 struct tuple 时间元组 str 字符串 , 规定格式表示 time 🍀 内置函数 🍀 函数名 描述 time.time() 返回当前时间的时间戳(1970纪元后经过的浮点秒数) time.localtime([secs]) 返回一个时间元组 , 默认返回当前时间戳的时间元组 , secs为秒数 time.sleep(secs) 推迟调用线程的运行 , 即让程序' 睡 '一会 , secs为秒数 time.strftime(fmt[,tupletime]) 将时间元组转换成字符串显示 , 默认为当前时间 , 格式由fmt决定 time.strptime(str,fmt='%a %b %d %H:%M:%S %Y) 将字符串转换成时间元组 , fmt为字符串格式 time.gmtime([secs]) 将时间戳转换成格林威治(本初子午线)天文时间下的时间元组 time.asctime([tupletime]) 将时间元组转换成字符串 , 格式如下 : Tue Aug 8 15:19:00 2016 time.ctime([secs]) 相当于asctime(localtime(secs)) , 不给参数相当于asctime() time.mktime(tupletime) 将时间元组转换成时间戳 time.clock() 返回当前CPU时间戳 , 用来衡量不同程序的耗时 , 比time.time() 更有用 time.tzset() 更改本地时区 time.altzone 返回夏令时地区的偏移秒数 , 无需括号调用 , 对需要夏令时地区才使用 格式化符号 🍀 符号 描述 符号 描述 %y 两位数的年份表示 (00-99) %a 本地简化星期名称 %Y 四位数的年份表示(000-9999) %A 本地完整星期名称 %m 月份(01-12) %b 本地简化的月份名称 %d 月内中的一天(0-31) %B 本地完整的月份名称 %H 24小时制小时数(0-23) %c 本地相应的日期表示和时间表示 %I 12小时制小时数(01-12) %j 年内的一天(001-366) %M 分钟数(00=59) %p 本地A.M.或P.M.的等价符 %S 秒(00-59) %U 一年中的星期数(00-53)星期天为星期的开始 %w 星期(0-6)，星期天为星期的开始 %x 本地相应的日期表示 %W 一年中的星期数(00-53)星期一为星期的开始 %X 本地相应的时间表示 %% %号本身 %Z 当前时区的名称 时间元组说明 🍀 下标 属性 值 0 tm_year 2008 1 tm_mon 1 到 12 2 tm_mday 1 到 31 3 tm_hour 0 到 23 4 tm_min 0 到 59 5 tm_sec 0 到 61 (60或61 是闰秒) 6 tm_wday 0到6 (0是周一) 7 tm_yday 1 到 366(儒略历) 8 tm_isdst -1, 0, 1, -1是决定是否为夏令时的旗帜 实例 🍀 获取本地时间 # 导入time模块 import time # 获取当前时间字符串 now_time = time.strftime(\"%Y-%m-%d %H:%M:%S\") # 获取当前时间戳 now_timestamp = time.time() # 获取当前时间元组 now_timetuples = time.localtime() # 打印当前时间字符串 print(now_time) # 2016-08-08 16:04:35 # 打印当前时间戳 print(now_timestamp) # 1470643278.0 # 打印当前时间元组 print(now_timetuples) # time.struct_time(tm_year=2016, tm_mon=8, tm_mday=8, tm_hour=16, tm_min=1, tm_sec=18, tm_wday=0, tm_yday=221, tm_isdst=-1) calendar 🍀 此模块的函数都是日历相关的 , 例如打印某月的字符串月历 星期一是默认的每周第一天 , 星期天是默认的最后一天 ; 更改设置需要调用 calendar.setfirstweekday() 函数 内置函数 🍀 函数 描述 calendar.calendar(year,w=2,l=1,c=6) 返回一个多行字符串格式的year年年历 , 3个月一行 , 间隔距离为c ; 每日宽度间隔为w字符 , 每行长度为21 W+18+2 C ; l是每星期行数 calendar.firstweekday( ) 返回当前每周起始日期的设置 ; 默认情况下 , 首次载入caendar模块时返回0 , 即星期一 calendar.isleap(year) 是闰年返回True , 否则为false calendar.leapdays(y1,y2) 返回在Y1 , Y2两年之间的闰年总数 calendar.month(year,month,w=2,l=1) 返回一个多行字符串格式的year年month月日历 , 两行标题 , 一周一行 ; 每日宽度间隔为w字符 , 每行的长度为7* w+6 , l是每星期的行数 calendar.monthcalendar(year,month) 返回一个整数的单层嵌套列表 , 每个子列表装载代表一个星期的整数 ; Year年month月外的日期都设为0 ; 范围内的日子都由该月第几日表示 , 从1开始 calendar.monthrange(year,month) 返回两个整数 , 第一个是该月的星期几的日期码 , 第二个是该月的日期码 , 日从0（星期一）到6（星期日）; 月从1到12 calendar.prcal(year,w=2,l=1,c=6) 相当于 print calendar.calendar(year , w , l , c) calendar.prmonth(year,month,w=2,l=1) 相当于 print calendar.calendar（year , w , l , c） calendar.setfirstweekday(weekday) 设置每周的起始日期码 , 0（星期一）到6（星期日） calendar.timegm(tupletime) 和time.gmtime相反: 接受一个时间元组形式 , 返回该时刻的时间辍（1970纪元后经过的浮点秒数） calendar.weekday(year,month,day) 返回给定日期的日期码 , 0（星期一）到6（星期日） , 月份为 1（一月） 到 12（12月） 实例 🍀 打印指定日历 # 导入模块 import calendar # 调用函数 cal = calendar.month(2016,8) # 打印2016年8月的日历 print(cal) ------结果如下------- August 2016 Mo Tu We Th Fr Sa Su 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 python中处理日期和时间的模块还有 pytz , datedutil , datetime 可以通过import module ; help(module) 来进行学习 "},"01-Python/03-Modules/05-Python - 正则表达式.html":{"url":"01-Python/03-Modules/05-Python - 正则表达式.html","title":"Python - 正则表达式","keywords":"","body":"Python - 正则表达式 正则介绍 🍀 正则表达式并不是python的一部分，而是在各个编程语言都有的一种用于处理字符串的强大工具。 使用正则处理字符串在效率上可能不如str自带的方法，但是它的功能十分强大。python中的正则封装在re模块中。 匹配方法 🍀 首先将匹配方法进行说明，即re模块的内置方法 re.match(pattern, string, flags=0) : 👈 从字符串的开头开始匹配，匹配成功返回一个_sre.SRE_Match类型，可用.group() 取出结果，失败返回None pattern : 匹配格式 string : 要匹配的字符串 flags : 编译标志位，用于修改正则表达式的匹配方式 # 导入re模块，后续方法实例省略这一步 >>> import re >>> res = re.match('lyon','lyon') # 查看类型 >>> type(res) # 用.group()取出结果 >>> res.group() 'lyon' re.search(pattern, string, flags=0) : 👈 扫描整个字符串，匹配成功则返回匹配到的第一个对象（_sre.SRE_Match类型），失败返回None pattern : 匹配格式 string : 要匹配的字符串 flags : 编译标志位，用于修改正则表达式的匹配方式 # 匹配数字 >>> re.search('\\d+','abc123abc').group() '123' re.findall(pattern, string, flags=0) : 👈 匹配字符串所有的内容，把匹配到的字符串以列表的形式返回 pattern : 匹配格式 string : 要匹配的字符串 flags : 编译标志位，用于修改正则表达式的匹配方式 # 匹配数字 >>> re.findall('\\d','abc123abc456') ['1','2','3','4','5','6'] re.split(pattern, string, maxsplit=0, flags=0) : 👈 指定格式进行切分，返回一个列表 pattern : 切分格式 string : 要切分的字符串 maxsplit : 切分次数 flags : 编译标志位，用于修改正则表达式的匹配方式 # 以数字进行切分 >>> re.split('\\d+','abc123abc123+-*/45') ['abc', 'abc', '+-*/', ''] re.sub(pattern, repl, string, count=0, flags=0) : 👈 替换匹配到的字符串并返回替换后的结果 pattern : 匹配格式 repl : 替换格式 string : 要匹配替换的字符串 flags : 编译标志位，用于修改正则表达式的匹配方式 >>> re.sub(\"abc\",\"def\",\"abc123abc\") 'def123def' # 只替换查找到的字符串一次 >>> re.sub(\"abc\",\"def\",\"abc123abc\",count=1) 'def123abc' flags说明（轻轻了解） : 标志 说明 re.I (re.IGNORECASE) 忽略大小写（括号内为全拼写法，效果一样） re.M (MULTILINE) 多行模式，改变 '^' 和 '$' 的行为 （改变？见下节匹配模式） re.S (DOTALL) 任意匹配模式，改变 ' . ' 的行为（同上） re.L (LOCALE) 做本地化识别（locale-aware）匹配，法语等 re.X (VERBOSE) 该标志通过给予更灵活的格式以便将正则表达式写得更易于理解 re.U 根据Unicode字符集解析字符，这个标志影响\\w,\\W,\\b,\\B # 忽略大小写 >>> re.findall('a','aA123aAAA',flags=re.I) ['a', 'A', 'a', 'A', 'A', 'A'] 注意转义的问题：当我们的匹配格式中有我们需要匹配的特殊字符，如 ' \\ '、' '、' + '等，为了让解释器知道我们这是需要匹配的，我们可以在格式前加 'r' 进行转义，或者在每个需要匹配的之前加个 ' \\ '来完成转义。* .group()小知识： 在我们使用.group()方法时，要注意如果我们的正则表达式没有匹配到结果，即返回None时，用.group()时就会报错，因为\"NoneType\"是没有该方法的，只有_sre.SRE_Match类型才能使用该方法。 匹配模式 🍀 字符匹配 🍡 字符 描述 . 默认匹配除\\n之外的任意一个字符，若指定flag DOTALL,则匹配任意字符，包括换行 \\d \\D 匹配数字0-9/非数字 \\s 匹配空白字符、\\t、\\n、\\r , re.search(\"\\s+\",\"ab\\tc1\\n3\").group() 结果 '\\t' \\S 非空白字符 \\w 匹配[A-Za-z0-9] \\W 匹配非[A-Za-z0-9] \\b 匹配一个单词边界，也就是指单词和空格间的位置。例如， 'er\\b' 可以匹配\"never\" 中的 'er'，但不能匹配 \"verb\" 中的 'er'。 \\B 匹配非单词边界。'er\\B' 能匹配 \"verb\" 中的 'er'，但不能匹配 \"never\" 中的 'er'。 次数匹配 🍡 字符 描述 * 匹配*号前的字符0次或多次，re.findall(\"ab*\",\"cabb3abcbbac\") 结果为['abb', 'ab', 'a'] + 匹配前一个字符1次或多次，re.findall(\"ab+\",\"ab+cd+abb+bba\") 结果['ab', 'abb'] ? 匹配前一个字符0次或者1次 {m} 匹配前一个字符m次 {n,m} 匹配前一个字符n到m次，re.findall(\"ab{1,3}\",\"abb abc abbcbbb\") 结果'abb', 'ab', 'abb'] *?/+?/?? 转为非贪婪模式（尽可能少的匹配） [...] 字符集，匹配字符集中任意字符，字符集可给出范围或者逐个列出 边界匹配 🍡 字符 描述 ^ 匹配字符串开头，若指定flags MULTILINE，这种也可以匹配上，(r'^a','\\nabc\\neee',flags=re.MULTILINE) $ 匹配字符结尾，或e.search(\"foo$\",\"bfoo\\nsdfsf\",flags=re.MULTILINE).group()也可以 \\A 只从字符开头匹配，re.search(\"\\Aabc\",\"alexabc\") 是匹配不到的 \\Z 匹配字符结尾，同$ 分组匹配 🍡 字符 描述 丨 匹配丨左或丨右的字符，re.search(\"abc丨ABC\",\"ABCBabcCD\").group() 结果'ABC' (...) 分组匹配，re.search(\"(abc){2}a(123丨456)c\", \"abcabca456c\").group() 结果 abcabca456c (?P\\) 命名分组匹配 re.search(\"(?P\\[0-9]{4})(?P\\[0-9]{2})(?P\\[0-9]{4})\",\"371481199306143242\").groupdict(\"city\") 结果{'province': '3714', 'city': '81', 'birthday': '1993'} 匹配方法补充 🍀 补充方法 re.subn(pattern, repl, string, count=0, flags=0) : 返回替换后的字符串和替换次数 re.escape(pattern) : 自动进行转义，除了ASCII字母、数字和'_'之外 re.compile(pattern, flags=0) : 生成一个_sre.SRE_Pattern对象，以便多次调用 re.finditer(pattern, string, flags=0) : 返回一个匹配结果的迭代器，可迭代取值 re.fullmatch(pattern, string, flags=0) : 完整匹配，不完整则返回None re.template(pattern, flags=0) : 没人知道是干嘛的，跟compile差不多 re.purge() : 清除正则表达式缓存 ''' 当你在程序中使用 re 模块，无论是先使用 compile 还是直接使用比如 findall 来使用正则表达式操作文本，re 模块都会将正则表达式先编译一下， 并且会将编译过后的正则表达式放到缓存中，这样下次使用同样的正则表达式的时候就不需要再次编译， 因为编译其实是很费时的，这样可以提升效率，而默认缓存的正则表达式的个数是 100, 当你需要频繁使用少量正则表达式的时候，缓存可以提升效率，而使用的正则表达式过多时，缓存带来的优势就不明显了 ''' 正则实例 🍀 连续匹配 # 导入模块 >>> import re # 获取字符串 >>> source ='192.168.0.1 25/Oct/2012:14:46:34 \"GET /api HTTP/1.1\" 200 44 \"http://abc.com/search\" \"Mozilla/5.0\"' # 设置匹配格式 >>> res = re.match('^(?P[^ ]*) (?P[^ ]*) \"(?P[^\"]*)\" (?P[^ ]*) (?P[^ ]*) \"(?P[^\"]*)\" \"(?P[^\"]*)\"',source) # 返回一个字典，groupdict中的key为组名，value为值 >>> source_dic = res.groupdict() # for循环打印 >>> for k in source_dic: #打印key和vaule ... print(k+\": \"+source_dic[k]) ... # 打印结果 date: 25/Oct/2012:14:46:34 remote_ip: 192.168.0.1 referrer: http://abc.com/search status: 200 user_agent: Mozilla/5.0 size: 44 request: GET /api HTTP/1.1 "},"01-Python/03-Modules/06-Python - 序列化.html":{"url":"01-Python/03-Modules/06-Python - 序列化.html","title":"Python - 序列化","keywords":"","body":"Python - 序列化 介绍 🍀 先说个例子 , 当我们将一个字典或者列表再或者变量存入磁盘中 , 而存入磁盘后原本数据类型就得不到保持了 . 这个时候我们就得用序列化和反序列化了 序列化是将对象进行存储时保持当时对象的状态 , 实现其生命周期的延长 反序列化则是将存储的对象读取出来并转成原本的数据类型 序列化的目的 以某种存储形式使自定义对象持久化 将对象从一个地方传递到另一个地方 使程序更具维护性 此时应该想到 eval :那么问题来了 , 序列化所达到的功能我用eval()也能达到啊 , eval()直接就可以把字符串转换成python解释器能解释的代码 , 即可以直接将字符串中的字典 , 列表都转成原来的数据类型 . 但是要注意的是 , eval本来就是将字符串内容转换成python可以执行的代码 , 并执行它 , 这样看来eval就不安全了 , 因为如果在我能读取的内容中含有一些其他的 ' 危险代码 ' 如 ' 删除文件 ' , 于是造成了毁灭性的打击 , 所以eval是存在风险的 Python为我们提供了三个序列化工具 , 分别是 json , pickle , shelve json 🍀 用于字符串和python数据类型之间进行转换 , 因为json表示出来就是一个字符串 json模块提供了四个方法 方法 描述 dump 接收一个文件句柄 , 将原数据类型转换成字符串写入文件 load 接收一个文件句柄 , 将文件中的字符串转换成原数据类型返回 dumps 接收一个数据类型 , 将其转换成字符串 loads 接收一个字符串 , 将其转换成原数据类型 dump 和 load 实例 # 导入json模块 import json # 创建一个文件句柄 f = open('json_file','w') # 创建一个字典 dic = {'k1':'v1','k2':'v2'} # 将字典转换成字符串写入文件 json.dump(dic,f) # 关闭文件 f.close() # 创建一个文件句柄 f = open('json_file') # 将文件中的字符串读出并转换成原数据类型 dic2 = json.load(f) # 关闭文件句柄 f.close() # 打印类型和结果 print(type(dic2),dic2) # {'k1': 'v1', 'k2': 'v2'} dumps 和 loads 实例 # 导入json模块 import json # 创建一个新列表 lst = ['1','2','3','4'] # 将列表转换成字符串,用j_d来接收返回值 j_d = json.dumps(lst) # 将字符串转换成原数据类型,用j_s来接收返回值 j_s = json.loads(j_d) # 打印j_d的值以及类型 print(j_d,type(j_d)) # [\"1\", \"2\", \"3\", \"4\"] # 打印j_s的值以及类型 print(j_s,type(j_s)) # ['1', '2', '3', '4'] loads的特殊情况 # 导入json模块 import json # 创建一个字符串,内部为一个字典 dic_s = \"{'k1':'v1','k2':'v2','k3':3}\" # 将字符串转换成字典 json.loads(dic_s) # 解释器出现报错 # json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1) ''' 报错原因,用json的loads功能时,字符串类型的字典中的字符串必须由 \"\" 表示 即上面的dic_s应该改为 '{\"k1\":\"v1\",\"k2\":\"v2\",\"k3\":3}' 结论:用json的loads功能时,字符串类型的字典中的字符串必须由 \"\" 表示 ''' PS : json可用于不同语言之间的数据交换 pickle 🍀 用于python特有的类型和python的数据类型间进行转换 pickle模块也提供了四个方法 , 与json一样 dumps , dump , loads , load 由于pickle是对于python特有的类型 , 所以 load 和 loads方法不仅支持字典 , 列表 , 它还能把python中任意的数据类型进行序列化 -------dumps和loads-------- # 导入pickle模块 import pickle # 创建一个字典 dic = {'k1':'v1','k2':'v2'} # 将字典转换成二进制内容 p_d = pickle.dumps(dic) # 将二进制内容转换成字典 p_l = pickle.loads(p_d) # 打印p_d print(p_d) # b'\\x80\\x03}q\\x00(X\\x02\\x00\\x00\\x00k2q\\x01X\\x02\\x00\\x00\\x00v2q\\x02X\\x02\\x00\\x00\\x00k1q\\x03X\\x02\\x00\\x00\\x00v1q\\x04u.' # 打印p_d的类型 print(type(p_d)) # # 打印p_l print(p_l) # {'k2': 'v2', 'k1': 'v1'} # 打印p_l的类型 print(type(p_l)) # ---------dump 和 load--------- # 创建一个文件句柄 f = open('pickle_file','wb') # 写入内容 pickle.dump('lyon',f) # 关闭文件 f.close() # 创建一个文件句柄 f = open('pickle_file','rb') # 读出内容 p_f = pickle.load(f) # 关闭文件 f.close() # 打印 print(p_f) # lyon 但是pickle仅仅只能对python中的数据进行序列化 , 反序列化时其他语言就无法读懂了这是什么了 , 所以我们一般用推荐使用json shelve 🍀 shelve也是python提供给我们的序列化工具 , 比pickle用起来简单一些 shelve只提供给我们一个open方法 , 是用key来访问的 , 使用起来和字典类似 # 导入shelve模块 import shelve # shelve提供open方法 f = shelve.open('shelve_file') # 直接对文件句柄进行操作,就可以写入文件中 f['key'] = {'int':10, 'float':9.5, 'string':'Sample data'} # 关闭文件 f.close() # 打开文件 f1 = shelve.open('shelve_file') # 直接用key取值,key不存在就报错 existing = f1['key'] # 关闭文件 f1.close() # 打印结果 print(existing) # {'float': 9.5, 'int': 10, 'string': 'Sample data'} shelve不支持多个应用同时往一个数据库进行操作 , 所以当我们知道我们的应用如果只进行操作 , 我们可以设置shelve.open() 方法的参数来进行 shelve.open(filename, flag='c', protocol=None, writeback=False) import shelve # flag参数为设置操作模式,r 设置只读模式 f = shelve.open('shelve_file', flag='r') existing = f['key'] f.close() print(existing) writeback参数 , 可以减少我们出错的概率 , 并且让对象的持久化对用户更加的透明了 ; 但这种方式并不是所有的情况下都需要 , 首先 , 使用writeback以后 , shelf在open()的时候会增加额外的内存消耗 , 并且当数据库在close()的时候会将缓存中的每一个对象都写入到数据库 , 这也会带来额外的等待时间 , 因为shelve没有办法知道缓存中哪些对象修改了 , 哪些对象没有修改 , 因此所有的对象都会被写入 import shelve f1 = shelve.open('shelve_file') print(f1['key']) f1['key']['new_value'] = 'this was not here before' f1.close() # 设置writeback f2 = shelve.open('shelve_file', writeback=True) print(f2['key']) f2['key']['new_value'] = 'this was not here before' f2.close() "},"01-Python/04-Object-Oriented/":{"url":"01-Python/04-Object-Oriented/","title":"Object-Oriented","keywords":"","body":"The road to Python - Object-Oriented "},"01-Python/04-Object-Oriented/01-Python - 面向对象初识.html":{"url":"01-Python/04-Object-Oriented/01-Python - 面向对象初识.html","title":"Python - 面向对象初识","keywords":"","body":"Python - 面向对象 介绍 🍀 编程范式 编程是程序员用 特定的语法 + 数据结构 + 算法组成的代码来告诉计算机如何执行任务的过程 , 而实现一个任务的方式有很多种不同的方式 , 对这些不同的编程方式的特点进行归纳总结得出来的编程方式类别，即为编程范式 面向过程编程 Procedural Programming 面向过程编程就是程序从上到下一步步执行 , 基本设计思路就是程序一开始是要着手解决一个大的问题 , 然后把一个大问题分解成很多个小问题或子过程 , 这写子过程再执行的过程再继续分解直到小问题足够简单到可以在一个小步骤范围内解决 在Python中 , 我们通过把大段代码拆成函数 , 通过一层一层的函数调用 , 就可以把复杂任务分解成简单的任务 , 这种分解可以称之为面向过程的程序设计 . 函数就是面向过程的程序设计的基本单元 函数式编程 Functional Programming 函数式编程就是一种抽象程度很高的编程范式 , 纯粹的函数式编程语言编写的函数没有变量 , 函数式编程的一个特点就是 , 允许把函数本身作为参数传入另一个函数 , 还允许返回一个函数 , Python对函数式编程提供部分支持 . 由于Python允许使用变量 , 因此 , Python不是纯函数式编程语言 面向对象编程 Object Oriented Programming 面向对象编程是利用\"类\"和\"对象\"来创建各种模型来实现对真实世界的描述 , 使用面向对象编程的原因一方面是因为它可以使程序的维护和扩展变得更简单 , 并且可以大大提高程序开发效率 , 另外 , 基于面向对象的程序可以使它人更加容易理解你的代码逻辑 , 从而使团队开发变得更从容 类与实例 🍀 类的语法 class 类名: pass 一个栗子🌰 # 创建一个人的'类',首字母要大写 class Person(object): # 构造函数,初始化属性 def __init__(self,name): self.name = name # 人可以吃饭 def eat(self): print(\"I am eatting\") # 创造了一个叫做'Lyon'的人 p = Person('Lyon') # 执行吃饭功能 p.eat() # 执行结果: I am eatting 类 (class) 类就是 对现实生活中一类具有共同特征事物的抽象 类起到一个模板的作用 , 当我们创建一个类时 , 就相当于创建了一个初始的'模型' , 我们可以通过这个'模型' 来创建出一个个具有相同特征或功能的事物 , 来帮助我们更好的处理问题 在上述栗子中类名Person 后有一个(object) , 这是新式类的写法 , 而在python3.x 以上的版本中 , 默认为新式类 , 所以也可直接 class Person: 我们创建类时 , 都默认继承了object类 , object详解见后期文章 实例 (instance) 我们知道类是一个抽象 , 既然是抽象那就是不可操作的 , 所以我们如果进行操作 , 就需要将这一抽象的概念变成具体的事物 , 这个过程我们称为实例化 实例化: 由抽象的类转换成实际存在的对象的过程 实例: 由类进行实例化所得到的对象 , 上述栗子中的 p 就是一个实例 属性与方法 🍀 属性是实体的描述性质或特征 , 比如人有名字 , 年龄 , 性别等 . 当然还有人所能做的事情也是一种属性 , 比如吃饭 , 睡觉 , 喝水等 . 对于这两种属性 , 一种是表示特征的 , 叫做静态属性 , 另一种则是表示功能的 , 叫做动态属性 在Python中 , 我们将静态属性 就称为属性 , 将动态属性 就称为方法 , 并且以变量来表示属性 , 以函数表示方法 , 见下图: PS:类中的函数已经不叫函数了 , 而叫做方法 调用方式: 类名 . 属性名 class Person: # 类变量 role = 'student' # 构造函数 def __init__(self,name): # 实例变量 self.name = name 调用方式: 类名 . 方法名( ) class Person: # 普通方法 def eat(self): pass 特殊的类属性 属性名 说明 __dict__ 查看类或对象成员 , 返回一个字典 __name__ 查看类的名字 __doc__ 查看类的描述信息 , 即注释部分 __base__ 查看第一个父类 __bases__ 查看所有父类 , 返回一个元组 __module__ 查看类当前所在模块 __class__ 查看对象通过什么类实例化而来 PS:对于属性和方法 , 在网上分类各种各样的都有 , 比如字段 , 还有菜鸟教程中的一些 , 其实本质上都是一个东西 构造函数 🍀 在上述例子中 , 可以看到有一个__init__ 方法 , 这个方法叫做构造方法 , 用于初始化属性 , 所以如果我们要设置属性 , 那么构造方法是必须要的 self 我们直接通过实例来说明 class Foo: def __init__(self,name): self.name = name def func(self): print(id(self)) a = Foo('Lyon') # 打印实例a的内存地址 print(id(a)) # 调用类中的func方法,即打印self的内存地址 a.func() ''' 执行结果: 1703689404544 1703689404544 结果分析: 我们发现a的内存地址和self的内存地址是一样的,也就是说self其实就是实例本身 那么在我们进行实例化的时候,self.name = name 就是给实例添加一个name属性,该属性的值就是我们在实例化时传入的'Lyon' 所以如果我们需要给对象添加属性的话,可以直接通过 对象.属性名 = 属性值 的方式进行添加 ''' 将上栗子中的构造函数再换个姿势看看 a = Foo('Lyon') # 等价于如下,用类名调用类中的方法 Foo.__init__(a,'Lyon') 命名空间 🍀 在函数中 , Python解释器在执行时 , 会将函数名称依次加载到命名空间 , 类当然也一样 我们创建一个类时 , Python解释器一执行就会创建一个类的命名空间 , 用来存储类中定义的所有名称( 属性和方法 ) , 而我们进行实例化时 , Python解释器又会为我们创建一个实例命名空间 , 用来存放实例中的名称 当我们利用 对象. 名称 来访问对象属性 ( 静态与动态 ) 时 , Python解释器会先到该对象的命名空间中去找该名称 , 找不到就再到类 ( 该对象实例化之前的类 ) 的命名空间中去找 , 最后如果都没找到 , 那么就抛出异常了 访问属性实例 class A(object): \"\"\" 这是一个类 \"\"\" pass a = A() # 访问实例a的__doc__属性 print(a.__doc__) ''' 执行结果: 这是一个类 ''' 解释说明: 对于实例a本身是肯定没有__doc__ 属性的 , 这毋庸置疑 , 因为我们根本就没有使用构造函数来增加实例属性 . 根据执行结果显示 , 我们是访问到了这个类中的__doc__ 属性 , 那么你会说这个类也没看见 __doc__ 属性啊 , 其实类A是有的 , 因为它继承了object类 , 至于object类是什么 , 它里面有什么 ? 看后续文章吧 属性(静态和动态)与类的关系 🍀 由于Python是动态语言 , 所以Python的赋值机制都是通过动态绑定来实现的 类属性共享给所有对象 先实例后说明 class Foo: # 定义一个类变量,特意用的容器类型来说明 name = ['Lyon'] # 实例化 a = Foo() b = Foo() # 访问a,b中的name属性 print('实例a中的name属性:', a.name) print('实例b中的name属性:', b.name) # 查看a,b,Foo中name属性的内存地址 print(id(a.name)) print(id(b.name)) print(id(Foo.name)) print('------------------') # 修改类变量 Foo.name = 'a' # 再次访问a,b中的name属性 print('实例a中的name属性:', a.name) print('实例b中的name属性:', b.name) # 修改a中的name属性? 不,是新增 a.name = ['Lyon'] # 再次查看a,b中name属性的内存地址 print(id(a.name)) print(id(b.name)) ''' 执行结果: 实例a中的name属性: ['Lyon'] 实例b中的name属性: ['Lyon'] 2247471754696 2247471754696 2247471754696 ------------------ 实例a中的name属性: a 实例b中的name属性: a 2247471792392 2247471754696 ''' 说明: 特意使用容器类型来进行实验 , 因为在Python中容器类型内存地址一样只有一个原因 , 那就是两者作用的是同一个对象 我们第一步查看内存地址时 , a, b, Foo三者中的name属性的内存地址是一样的 , 实例可以通过 实例.类变量名 的方式进行访问 , 并且所有实例都共享类属性name a.name = ['Lyon'] 这一步其实并不是修改a中的name属性 , 要知道name属性是类的并不是实例的 , 执行这一步会为实例a加上一个新的同名name属性 , 由于赋值绑定会将原来访问类属性name的通道破坏掉 , 但是并不会影响b对类属性name的访问 类中的方法是绑定到所有对象的 先实例后说明 class Foo: def func(self): pass a = Foo() b = Foo() # 打印a,b中func的内存地址 print(a.func) print(b.func) # id返回的是10进制表示的内存地址,转换成16进制 print(hex(id(a))) print(hex(id(b))) ''' 执行结果: > > 0x1a7d2f74080 0x1a7d3759898 ''' 说明: 方法名与内存地址存在一个映射关系 , 通过执行结果我们可以发现 , a.func所在的内存地址与a的内存地址是一样的 , 则说明func绑定到了a中 a.func 与b.func 的内存地址是不一样的 , 因为每一个实例都开辟了自己内存空间 , func绑定进去的位置自然不一样 实例本身的属性是实例独有的 我们通过类创建一个实例 , 就会在内存中新开辟一块内存空间来存放这个实例的所有属性 , 实例属性一旦创建 , 基本跟类就没有什么太大的关系了 . 如果要修改实例属性那么就只能通过实例来进行修改了 , 并且实例与实例之间也是互不干扰的 如下图中 , 类与实例 , 实例与实例 都开辟了自己的内存空间 对象交互与类的组合 🍀 对象交互 class Person: def __init__(self, name): self.name = name def attack(self,per): print(\"{} attacked {}\".format(self.name, per.name)) lyon = Person(\"Lyon\") kenneth = Person(\"kenneth\") lyon.attack(kenneth) # 执行结果: Lyon attacked kenneth 类的组合 传参时组合 class BirthDate: def __init__(self, year, month, day): self.year = year self.month = month self.day = day class Person: def __init__(self, name, birthdate): self.name = name self.birthdate = birthdate p = Person('Lyon', BirthDate(2000, 1, 1)) 定义时组合 class BirthDate: def __init__(self, year, month, day): self.year = year self.month = month self.day = day class Person: def __init__(self, name, year, month, day): self.name = name self.birthdate = BirthDate(year, month, day) p = Person('Lyon', 2000, 1, 1) "},"01-Python/04-Object-Oriented/02-Python - 面向对象之继承.html":{"url":"01-Python/04-Object-Oriented/02-Python - 面向对象之继承.html","title":"Python - 面向对象之继承","keywords":"","body":"Python - 面向对象之继承 抽象与继承 🍀 抽象 抽象是从众多的事物中抽取出共同的、本质性的特征，而舍弃其非本质的特征 比如 🍎 , 🍌 , 🍇 , 等 , 它们共同的特性就是水果 , 我们得出水果这个概念的过程就是一个抽象的过程 , 抽象能使复杂度降低 , 好让人们能够以纵观的角度来了解许多特定的事态 有抽象就会有具体 , 我们会用抽象的对象来表示一类事物 , 而用具体的对象表示某个事物 , 比如苹果 , 香蕉 , 葡萄都是具体的对象 , 水果则是抽象的对象 继承 继承是基于抽象的结果 抽象可以让我们来以纵观的角度了解一类事物事物 , 并且这类事物都拥有该抽象中所有的特征 , 相当于继承了该抽象中的特征 , 这样我们就可以只将这类事物不同的特征放到具体中 , 而不需要再次关心共同特征 , 所以先有抽象后才能有继承 介绍抽象的概念时利用了水果来进行说明 , 为了更好的理解 , 继承就用动物为例子 '-----------抽象出动物类-----------' # 从狗和猫中抽取共同的特征,它们都能吃,喝,睡,玩 class Animal(object): # 吃 def eat(self): pass # 喝 def drink(self): pass # 睡 def sleep(self): pass # 玩 def play(self): pass '------------具体动物类------------' # 所有的类默认是继承了object类的,让'猫'类继承动物类 class Cat(Animal): # 抓老鼠 def catch_mouse(self): pass # 让'狗'类继承动物类 class Dog(Animal): # 跳墙 def jump_wall(self): pass 我们把🌰栗子中的Animal类叫做父类 , 基类或超类 , Cat和Dog类叫做子类或派生类 简单的继承方式就是在类名后面加入要继承的类 使用继承可以减少我们代码重用 , 简化代码 新式类与经典类 🍀 在说新式类与经典类之前 , 先说一说单继承和多继承 单继承与多继承 单继承就是只以一个类作为父类进行继承 # 定义基类 class Parent: pass # 继承基类 class Subclass(Parent): pass 多继承就是同时以多个类做为基类进行继承 # 定义第一个基类 class Parent1: pass # 定义第二个基类 class Parent2: pass # 定义第三个基类 class Parent3: pass # 继承三个基类 class Subclass1(Parent1,Parent2,Parent3): pass 在多继承中我们需要考虑一个继承优先的问题 , 就像上面的例子 , 如果我们所定义的三个父类中 , 都拥有一个同样的方法那么Python解释器会怎么去继承父类的方法? 三个同名的方法明显只能选择其中一个进行继承 , 这就关系到经典类和新式类了 经典类和新式类 经典的东西都是比较旧的 , so , 在Python 2.x 中默认都是经典类 , 只有显示继承了object才是新式类 ; 而Python 3.x 中默认都是新式类 , 不必显示的继承object 经典类与新式类在声明时的区别在于 , 新式类需要加上object关键字 # python 2.x 环境下 # 经典类 class A(): pass # 新式类 class A(object): pass # python 3.x 环境下 class A: pass 经典类与新式类多继承顺序的区别在于 , 经典类会按照深度优先 (纵向)的方式查找 , 新式类会按照广度优先 (横向)的方式查找 实例环境Python2 经典类 # 经典类 class A(): def __init__(self): pass def display(self): print \"This is from A\" class B(A): def __init__(self): pass class C(A): def __init__(self): pass def display(self): print \"This is from C\" class D(B,C): def __init__(self): pass obj = D() obj.display() ''' 执行结果: This is from A 说明:经典类深度优先,我们通过实例调用display方法时,Python解释器会先找B类,如果B类中没有就会去B类的父类(即A类)中查找,如果在所有的父类中都没有找到需要的方法,才会开始继续找下一个继承的类(即C类) ''' 新式类 # 新式类 class A(object): def __init__(self): pass def display(self): print \"This is from A\" class B(A): def __init__(self): pass class C(A): def __init__(self): pass def display(self): print \"This is from C\" class D(B,C): def __init__(self): pass obj = D() obj.display() ''' 执行结果: This is from C 说明:新式类广度优先,Python解释器首先到B类进行查找,B类中没有就直接去C类中找,并不会去B类的父类(A类)中去查找,如果C类中没有才会再去B类的父类(A类)中查找,最后如果没找到就会报错 ''' 派生 🍀 利用继承机制 , 新的类可以从已有的类中派生 子类继承了父类 , 父类派生了子类 , 继承是站在子类的角度 , 派生是站在父类的角度 , 我们在子类中可以添加新的属性或方法 . 但是要注意父类属性名与子类属性名相同 , 以及父类与子类中方法名的情况 , 说的有点绕了 , 通过实例进一步描述 属性名 , 方法名不发生冲突 # 创建一个基类 class Person: # 基类属性 country = 'China' # 构造方法 def __init__(self, name, age): self.name = name self.age = age # 工作方法 def work(self): print(\"I am working ...\") # 派生一个子类,继承基类中的属性和方法 class Man(Person): # 子类属性 male = 'man' # 新增睡觉方法 def sleep(self): print(\"I am sleepiing ...\") # 实例化子类 man = Man('Lyon', 18) # 调用从基类继承过来的工作方法 man.work() # 访问从基类继承过来的国家属性 print(man.country) # 调用子类中的睡觉方法 man.sleep() # 访问子类中的male属性 print(man.male) ''' 执行结果: I am working ... China I am sleepiing ... man ''' 属性或方法冲突 , 会按照加载顺序进行覆盖 , 定义过程就已完成 # Python解释器开始执行,将Person类的名字以及类中包含的属性名方法名加载到Person类的命名空间 class Person: country = 'China' # 注意构造方法也是方法,Python解释器加载时仅仅会将__init__这个名字加载到命名空间,并不会执行内部代码 def __init__(self, name, age): self.name = name self.age = age # 加载方法名 def work(self): print(\"I am working ...\") # Python解释器将Man类的名字加载到Man的命名空间,随后由于Person类在这步之前已经完成加载,此时就会通过Person类名从Person的命名空间中取出属性和方法名加载到Man类的命名空间 class Man(Person): # 由于上一已完成Person类中的同名__init__的加载,此时会将其覆盖 def __init__(self, male, country): self.male = male self.country = country # 同__init__,将同名work覆盖 def work(self): print(\"I don't like working ...\") # 加载到Man类的命名空间 def sleep(self): print(\"I am sleepiing ...\") # 实例化Man类 man = Man('male', 'America') # 此work为覆盖后的work即子类自己的work man.work() # country为父类的类属性,在实例化时被实例属性覆盖 print(man.country) # 调用子类中的sleep方法 man.sleep() # 打印实例属性male print(man.male) ''' 执行结果: I don't like working ... America I am sleepiing ... male ''' 当然我们在使用时仅需注意一下几点: 重名时 , 会以子类的方法或属性为主 , 因为父类的会被覆盖 构造方法里是实例属性 , 子类如果也有构造方法 , 以子类的构造方法为主 通俗的讲 : 我有就用我的 , 没有就拿你的 但是上述派生中有两个问题: 当子类父类都有构造方法时 , 如果子类需要父类构造方法中的实例属性怎么办 ? 当子类父类都有同名方法时 , 如果子类需要用父类中的方法怎么办? 这两个问题放到下节 super 中解决 super 🍀 先解决上节中的两个问题 , 既然父类中的方法被覆盖掉了 , 那么我们不妨再加载一次父类中的方法 , 将子类中的再次覆盖 解决问题1 : 子类父类构造方法中实例属性集合 class Person: def __init__(self, name, age): self.name = name self.age = age class Man(Person): # 实例属性集合也还是要传参的,只是传入后各拿各的 def __init__(self, name, age, male): self.male = male # 通过类名.方法调用Person类中的__init__方法,即将__init__中的代码拿过来用了一遍 Person.__init__(self, name, age) # 实例化Man类 man = Man('Lyon', 18, 'male') # 访问man中的name实例属性 print(man.name) # 访问man中的age实例属性 print(man.age) # 访问man中的male print(man.male) ''' 执行结果: Lyon 18 male ''' 解决问题2 : 使用父类中的重名方法 对于第二个问题明显不能利用问题1同样的方式了 , 因为调用就以为着执行 , 虽然我们可以以问题1中的方式执行父类的方法 , 但是子类的方法也还是会照常执行 , so , 我们得换个方式 class Person: def work(self): print(\"I am working ...\") class Man(Person): def work(self): print(\"I don't like working ...\") man = Man() # 将实例man作为self传入Person类中的work方法 # Person().work() Person.work(man) ''' 执行结果: I am working ... ''' 两个问题解决了 , 但是我们发现通过这两种方式来解决会对后期修改造成非常大的麻烦 , 只要类名一变 , 那么我们就得一个个修改 , 开发中来个100个就够你改半小时了 ... 所以就有了super super super只能用在新式类中 , 在经典类中则只能按照上面的方式进行处理了 截取官方文档中的一部分 # 相当于super(type, obj),first argument一般是self实例本身 super() -> same as super(__class__, ) # 返回非绑定父类对象 super(type) -> unbound super object # 返回父类的实例 super(type, obj) -> bound super object; requires isinstance(obj, type) # 返回父类的实例 super(type, type2) -> bound super object; requires issubclass(type2, type) # type参数为子类 Python中一切皆对象 , 所以其实super是一个类 , 在我们使用super时事实上调用了super类的初始化函数 , 产生了一个super对象 首先用super的方式解决上面的问题吧 问题1 class Person: def __init__(self, name, age): self.name = name self.age = age class Man(Person): def __init__(self, name, age, male): self.male = male super().__init__(name, age) 问题2 class Person: def work(self): print(\"I am working ...\") class Man(Person): def work(self): print(\"I don't like working ...\") man = Man() # super的第一个参数是要找父类的那个类 super(Man,man).work() 但是在我们使用多继承时 , 这两者的区别就能显现出来了 使用__init__ class A(object): def __init__(self): print(\"This is from A\") class B(A): def __init__(self): print(\"This is from B\") A.__init__(self) print(\"This is from B\") class C(A): def __init__(self): print(\"This is from C\") A.__init__(self) print(\"This is from C\") class D(B,C): def __init__(self): print(\"This is from D\") B.__init__(self) C.__init__(self) print(\"This is from D\") d = D() ''' 执行结果: This is from D This is from B This is from A This is from B This is from C This is from A This is from C This is from D ''' 使用super class A(object): def __init__(self): print(\"This is from A\") class B(A): def __init__(self): print(\"This is from B\") super().__init__() print(\"This is from B\") class C(A): def __init__(self): print(\"This is from C\") super().__init__() print(\"This is from C\") class D(B,C): def __init__(self): print(\"This is from D\") super().__init__() print(\"This is from D\") d = D() ''' 执行结果: This is from D This is from B This is from C This is from A This is from C This is from B This is from D ''' 用__init__ 和 super我们得到的结果是不一样的 , 因为super是一个类名 , super( ) 事实上调用了super类的初始化函数 , 产生了一个super对象 , 所以使用super可以避免父类被重复调用 PS : super的查找方式遵循MRO表中的顺序 , MRO表后续文章中在研究 抽象类与接口 🍀 Python本身不提供抽象类和接口机制 抽象类 在Java中抽象类的定义是这样的 : 由abstract 修饰的类叫抽象类 , 该类不能被实例化 , 并且仅支持单继承 在Python中如果要实现抽象类 , 需要借助abc模块 . ABC是Abstract Base Class的缩写 在abc模块中有一个用来生成抽象类的元类 ABCMeta 生成抽象类 # 导入抽象元类和抽象方法 from abc import ABCMeta,abstractmethod class Abstract_class(metaclass=ABCMeta): # 使用抽象方法进行约束 @abstractmethod # 父类可以简单实现,子类必须实现 def func(self): print('hello func') 抽象类提供了继承的概念 , 它的出发点就是为了继承 , 否则它没有存在的任何意义 , 所以说定义的抽象类一定是用来继承的 接口 在Java中接口是一个抽象类型 , 是抽象方法的集合 , 接口通常以interface来声明 . 一个类通过继承接口的方式 , 从而来继承接口的抽象方法 , 达到约束的目的 在Python中默认是没有的 , 所以我们如果要使用接口 , 有两种方法 , 第一种就是我们在抽象类的基础上进行定义 , 第二种则是借助第三方模块 zope.interface 这里我们只说第一中方法 # 导入抽象元类和抽象方法 from abc import ABCMeta,abstractmethod class Abstract_class(metaclass=ABCMeta): # 使用抽象方法进行约束 @abstractmethod # 父类不能实现,子类必须实现 def func(self): pass 与抽象类中的例子比较 , 因为在Python中抽象类与接口类这两者区分并不清晰 , 我们在对于方法是否实现上 , 修改之后基本就实现了一个接口 什么时候使用抽象类与接口 当几个子类的父类,有相同的功能需要被实现的时候,就使用抽象类 当几个子类,有相同的功能,但是实现各不相同的时候,就使用接口 (接口归一) 接口归一实例 from abc import ABCMeta, abstractmethod # 定义接口 class Payment(metaclass = ABCMeta): @abstractmethod def pay(self, money): pass # 继承接口 class Applepay(Payment): def pay(self, money): print('The payment method is Applepay , {}'.format(money)) # 继承接口 class Zhifubao(Payment): def pay(self, money): print('The payment method is Zhiwubaopay , {}'.format(money)) # 继承接口 class Wexin(Payment): # 没有接口中的pay方法,实例化时就报错 def fuqian(self, money): print('The payment method is Wexinpay , {}'.format(money)) # 接口归一 def payment(obj,money): obj.pay(money) # 实例化就报错,没有pay方法 # wexin = Wexin() zhifubao = Zhifubao() apple = Applepay() payment(zhifubao,100) payment(apple,1000) 总结 抽象类与接口都不能被实例化 (抽象方法约束) , 所以必须被继承才能使用 抽象类中的方法能够被实现 , 接口中的方法不能被实现 抽象类中可以有构造方法 , 接口中不可有 抽象类最好不要用多继承 , 而接口类可以 isinstance 和 issubclass 🍀 isinstance(obj, cls) 检查obj是否是类cls的对象 class Foo: pass obj = Foo() print(isinstance(obj, Foo)) print(isinstance(obj, object)) print(isinstance(obj, type)) ''' 执行结果: True #obj是类Foo的对象 True #obj是object的对象,Foo类继承了object类 False #object类是有type类的实例 ''' issubclass(sub, super) 检查sub类是否是super类的派生类 class A: pass class B(A): pass print(issubclass(B, B)) print(issubclass(B, A)) print(issubclass(B, object)) print(issubclass(B, type)) ''' 执行结果: True #B类是自己的派生类 True #B类是A类的派生类 True #B类是object类的派生类,因为A类继承了object类 False #B类不是type类的派生类,type类实例化产生了object类 ''' "},"01-Python/04-Object-Oriented/03-Python - 面向对象之多态.html":{"url":"01-Python/04-Object-Oriented/03-Python - 面向对象之多态.html","title":"Python - 面向对象之多态","keywords":"","body":"Python - 面向对象多态 介绍 上一篇中已经得知 , 继承可以扩展已存在的代码模块(类) , 其目的是为了解决代码重用 问题 多态则是为了实现另一个目的 : 接口重用 多态 🍀 多态 (Polymorphism) 按字面的意思就是\"多种状态\" , 比如动物有多种形态 , 人 , 猫 , 狗 ; 文件也有多种格式 exe , txt , md(MarkDown格式) , 这就是多态 在面向对象语言中 , 接口的多种不同的实现方式即为多态 多态性是允许你将父对象设置成为一个或多个他的子对象相等的技术 , 赋值之后 , 父对象就可以根据当前赋值给它的子对象的特性以不同的方式运作 静态多态性 必须在编译时就能确定其处理方式 n1 = 12 n2 = 34 # int类型相加 print(n1 + n2) s1 = 'hello ' s2 = 'word' # str类型相加 print(s1 + s2) ''' 执行结果: 46 hello word ''' 如上述例子我们利用运算符 \"+\", 完成了两种情况下的运算 , 并且Python解释器在执行前就已确定处理方式 , 即编译过程中就已经知道了调用哪个函数 动态多态性 编译时无法立即确定其处理方式 , 只有在执行时才确定处理方式 , 注意一定要同名 from abc import ABCMeta,abstractclassmethod # 接口继承 class Animal(metaclass=ABCMeta): @abstractclassmethod # 约束派生类必须有talk方法 def talk(self): pass class Cat(Animal): def talk(self): print(\"喵喵喵\") class Dog(Animal): def talk(self): print(\"汪汪汪\") c = Cat() d = Dog() # 因为接口的缘故,我们无需考虑实例化后的对象具体是什么类型,因为动物都有talk方法,所以我们可以直接使用 c.talk() d.talk() # 我们进行接口统一 def talk(obj): obj.talk() talk(c) talk(d) ''' 执行结果: 喵喵喵 汪汪汪 喵喵喵 汪汪汪 ''' 上栗中, Python解释器在解释时是无法确定处理方式的 , 因为存在几个同名的方法 , 编译时并不能确定是哪一个 , 只有在执行时 , 才能确定使用哪个类中的talk() 方法 , 这就是动态多态性 小结: 静态多态性与动态多态性的区别在于 , 编译时是否能确定其处理方式 通过多态可以实现用一个函数名调用不同内容的函数 多态性的好处 🍀 多态性是面向对象的三大特性之一 , 有很多人说Python不支持多态 , 事实上Python处处是多态 , 比如内置函数len() 就是多态的一种体现 多态的作用: 增加了程序的灵活性 以不变应万变 , 不论对象有多少中形态 , 使用者都是同一种形式去调用 , 如 talk(obj) 增加了程序的可扩展性 通过继承Animal类派生了一个新的类 , 使用者无需更改自己的代码 , 依旧利用 talk(obj) 进行调用 对于多态 , 可能会觉得比较模糊 , 这是因为 , 我们在写程序时不知不觉就用上了 , 哈哈所以还是说处处是多态 鸭子类型 🍀 Python崇尚鸭子类型 以下是维基百科中对鸭子类型得论述 : 在程序设计中 , 鸭子类型 (英语 : duck typing) 是动态类型的一种风格。在这种风格中 , 一个对象有效的语义 , 不是由继承自特定的类或实现特定的接口 , 而是由当前方法和属性的集合决定 . 这个概念的名字来源于由James Whitcomb Riley提出的鸭子测试 , \" 鸭子测试 \"可以这样表述： \" 如果走起来像鸭子 , 游泳起来像鸭子 , 叫起来也像鸭子 , 那么它就是鸭子 \" 在鸭子类型中 , 关注的不是对象的类型本身 , 而是它是如何使用的 . 例如 , 在不使用鸭子类型的语言中 , 我们可以编写一个函数 , 它接受一个类型为鸭的对象 , 并调用它的走和叫方法 . 在使用鸭子类型的语言中 , 这样的一个函数可以接受一个任意类型的对象 , 并调用它的走和叫方法 . 如果这些需要被调用的方法不存在 , 那么将引发一个运行时错误 . 任何拥有这样的正确的走和叫方法的对象都可被函数接受的这种行为引出了以上表述 , 这种决定类型的方式因此得名。 鸭子类型通常得益于不测试方法和函数中参数的类型 , 而是依赖文档 , 清晰的代码和测试来确保正确使用 . 从静态类型语言转向动态类型语言的用户通常试图添加一些静态的 ( 在运行之前的 ) 类型检查 , 从而影响了鸭子类型的益处和可伸缩性 , 并约束了语言的动态特性 例1 : 利用标准库中定义的各种 ' 与文件类似的对象 ' , 尽管这些对象的工作方式像文件 , 但他们没有继承内置对象的方法 # 文本文件 class TxtFile: def read(self): pass def write(self): pass # 磁盘文件 class DiskFile: def read(self): pass def write(self): pass 二者都像鸭子, 二者看起来都像文件,因而就可以当文件一样去用 例2 : 序列类型有多种形态 : 字符串 , 列表 , 元组 , 但他们没有直接的继承关系 # 三者都是序列类型 name = 'Lyon' namel = ['Lyon'] namet = ('Lyon',) # 字符串,列表,元组并没有直接关系,都可以调用len(),并且我们无需考虑类型 print(len(name)) print(len(namel)) print(len(namet)) "},"01-Python/04-Object-Oriented/04-Python - 面向对象之封装.html":{"url":"01-Python/04-Object-Oriented/04-Python - 面向对象之封装.html","title":"Python - 面向对象之封装","keywords":"","body":"Python - 面向对象特性之封装 介绍 封装就是把客观事物封装成抽象的类 , 并且类可以把自己的数据和方法只让可信的类或者对象操作 , 对不可信的进行信息隐藏 私有问题 🍀 当我们类中的一些属性或者方法想要对不可信的类或者对象隐藏时 , 我们就可以将这些属性或者方法 , 定义成私有属性或者私有方法 在Python中用双下划线开头的方式将属性隐藏起来 , 即带双下划线就为私有属性或者私有方法 私有属性 class A: def __init__(self,name): # 定义私有属性 self.__name = name # 实例化 a = A(\"Lyon\") # 访问a中的__name属性 print(a.__name) # 执行结果 : AttributeError: 'A' object has no attribute '__name' ''' 结果报错,意思是对象A中没有__name这个属性 也就是说,外部已经不能直接利用 .__name 来访问这个属性了 因为此时它是一个私有属性 ''' 将属性定义成私有属性其实是一种变形操作 , 即类中所有以双下划线开头的名称都会自动变形成:_类名+名称 如下: class A: def __init__(self, name): # 定义私有属性 self.__name = name # 实例化 a = A(\"Lyon\") # 访问a中的__name属性 print(a._A__name) # 执行结果: Lyon ''' __name自动变形为 _A__name 所以使用a._A__name是可以访问到的 ''' 由上可知变形的特点如下: 类中定义的__name只能在内部使用 , 并且内部使用是引用的变形的结果,即( self._A__name) 这种变形其实是针对外部的变形 , 在外部是无法通过__name访问的 PS : 这种变形机制其实并没有真正意义上限制我们从外部直接访问属性 , 知道了类名和属性名就可以拼出名字 : _类名__属性 , 然后就可以访问了 , 如 a._A__name . 并且变形的过程只在类的定义时发生一次 私有方法 class A: def __func(self): print(\"In the A\") a = A() a.__func() # 执行结果: AttributeError: 'A' object has no attribute '__func' a._A__func() # 执行结果: In the A 当私有遇到继承 🍀 当我们在继承中使用私有属性或者方法时 , 因为变形机制 , 我们已经不能将私有属性或者方法 , 来与普通属性或者方法那样看待了 私有属性继承 class A: def __init__(self, ame): self.__name = ame class B(A): def __init__(self, name, ame): self.__name = name # 继承父类中的属性 super().__init__(ame) a = B('a', 'b') print(a._A__name) print(a._B__name) ''' 执行结果: b a ''' 例子说明 : 在上节中已经知道变形操作这回事了 , 当遇到继承时需要注意的就是 , 我们表面上看到的是两个类中都只有一个__name属性 , 但是由于变形 , 使其在定义完成后就分别变成了_A__name 和 _B__name , 所以继承时已经是两个不同的属性了 , 所以两个属性都存在 , 只是我们表面上还是看不到 私有方法继承 与私有属性继承一样 , 需要注意私有方法名变形的问题 我们可以利用这一特点 , 来实现继承时达到子类不会覆盖父类方法的效果 class A: def __func(self): print('from A') def test1(self): self.__func() class B(A): def __func(self): print('from B') def test2(self): self.__func() b=B() b.test1() b.test2() ''' 执行结果: from A from B ''' 封装与扩展性 🍀 封装在于明确区分内外 , 使得类实现者可以修改封装内的东西而不影响外部调用者的代码 ; 而外部使用者只知道一个接口(函数) , 只要接口(函数)名 , 参数不变 , 使用者的代码永远无需改变 . 这就提供了一个良好的合作基础 , 相当于只要接口这个基础约定不变 , 则代码改变也不足为虑 原始类 class Room: def __init__(self, name, owner, width, length, high): self.name = name self.owner = owner self.__width = width self.__length = length self.__high = high # 对外提供的求面积接口,隐藏内部实现详解 def tell_area(self): return self.__width * self.__length r1 = Room('卧室','Lyon','0.3','2','2') r1.tell_area() 修改类 class Room: def __init__(self, name, owner, width, length, high): self.name = name self.owner = owner self.__width = width self.__length = length self.__high = high # 对外提供的求体积接口,隐藏内部实现详解 def tell_area(self): return self.__width * self.__length * self.__high r1 = Room('卧室','Lyon','0.3','2','2') r1.tell_area() 我们发现我们将类的功能作出了修改 , 但是对于使用类功能的人来说 , 接口并没有发生变化 , 他们依然可以用原来的接口使用新功能 "},"01-Python/04-Object-Oriented/05-Python - 属性方法-类方法-静态方法.html":{"url":"01-Python/04-Object-Oriented/05-Python - 属性方法-类方法-静态方法.html","title":"Python - 属性方法-类方法-静态方法","keywords":"","body":"Python - 属性方法,类方法,静态方法 属性方法 🍀 属性方法就是通过使用装饰器 @property , 将一个方法变成一个静态属性 , 于是我们就可以通过访问属性 , 来或得一个方法的返回值 from urllib.request import urlopen class Web_page: def __init__(self, url): self.url = url self.__content = None # 将content方法变成属性 @property def content(self): # 返回私有属性 return self.__content if self.__content else urlopen(self.url).read() con = Web_page('http://www.baidu.com') res = con.content print(res) 在property中为我们实现了三种方法 , get , set , delete class Foo: # 获取属性 @property def AAA(self): print(\"执行了get方法\") # 设定属性值 @AAA.setter def AAA(self, value): print(\"执行了set方法\") # 删除属性 @AAA.deleter def AAA(self): print(\"执行了delete方法\") # 实例化 f = Foo() # 获取属性 f.AAA # 设置属性值,必须设置参数,即使不使用 f.AAA = 'aaa' # 删除属性值 del f.AAA ''' 执行结果: 执行了get方法 执行了set方法 执行了delete方法 ''' 换一种写法看看 class Foo: def get_AAA(self): print('执行了get方法') def set_AAA(self,value): print('执行了set方法') def delete_AAA(self): print('执行了delete方法') # 实例化property类 AAA = property(get_AAA, set_AAA, delete_AAA) # 实例化 f = Foo() # 获取属性直接调用,执行了get_AAA f.AAA # 设置属性值,传入参数执行了set_AAA f.AAA = 'aaa' # 删除属性值,执行了delete_AAA del f.AAA ''' 执行结果: 执行了get方法 执行了set方法 执行了delete方法 ''' 实际应用 class Goods: def __init__(self): # 原价 self.original_price = 100 # 折扣 self.discount = 0.8 @property def price(self): # 实际价格 = 原价 * 折扣 new_price = self.original_price * self.discount return new_price @price.setter def price(self, value): self.original_price = value @price.deleter def price(self): del self.original_price goods = Goods() goods.price goods.price = 200 print(goods.price) del goods.price 类方法 🍀 类方法是通过@classmethod装饰器 , 将普通方法变成类方法 , 类方法只能与类属性交互 , 不能访问实例变量 , 并且默认有一个cls参数传进来表示本类 class Person: country = 'China' def __init__(self,name,age): self.name = name self.age = age @classmethod def search(cls): # 在类方法中不能使用实例变量,会抛出AttributeError print(\"I come from {}\".format(cls.country)) # print(\"{} come from {}\".format(self.name,cls.country)) 报错 p = Person('lyon','18') p.search() # 执行结果: I come from China PS:类方法中的默认参数可以改成self , 并不会改变结果 , 同样只能访问类变量 , 不能访问实例变量 静态方法 🍀 静态方法是通过@staticmethod装饰器将类中的方法变成一个静态方法 静态方法就像静态属性一样 , 在类中可以通过 self. 的方式进行调用 , 但是静态是不能够访问实例变量或类变量的 , 也就是说静态方法中的self已经跟本类没有关系了 , 它与本类唯一的关联就是需要通过类名来进行调用 class Person: country = 'China' def __init__(self,name,age): self.name = name self.age = age # 已经跟本类没有太大的关系了,所以类中的属性无法调用 @staticmethod def search(): print(\"我是静态方法\") p = Person('lyon','18') p.search() # 执行结果: 我是静态方法 加上self , self只为一个普通参数而已 class Person: country = 'China' def __init__(self,name,age): self.name = name self.age = age @staticmethod def search(self): print(\"{} come from {}\".format(self.name,self.country)) p = Person('lyon','18') # 将实例传入search方法中 p.search(p) # 执行结果: lyon come from China "},"01-Python/04-Object-Oriented/06-Python - 特殊成员方法.html":{"url":"01-Python/04-Object-Oriented/06-Python - 特殊成员方法.html","title":"Python - 特殊成员方法","keywords":"","body":"Python - 特殊成员方法 __doc__ 🍀 查看类的描述信息 class Foo: \"\"\" 这是一个类,什么都没有的类 \"\"\" def __init__(self): pass print(Foo.__doc__) # 执行结果: 这是一个类,什么都没有的类 __module__ 🍀 查看当前操作对象位于哪个模块 # my_module.py class Foo: def __init__(self): pass # test.py from my_module import Foo print(Foo.__module__) # 执行结果: my_module __class__ 🍀 查看对象的类 class Foo: def __init__(self): pass a = Foo() print(a.__class__) # 执行结果： __new__ \\ __init__ 🍀 __new__ 创建对象时 , 自动触发执行 , 会返回当前对象的一个实例 __init__ 构造方法 , 创建对象时 , 自动触发执行 , 初始化对象的属性 python中的__init__ 在执行的时候 , 其实已经进行实例化了一次 , __init__ 有一个参数self , 就是__new__ 方法返回的实例 __del__ 🍀 析构方法 , 通当对象在内存中被释放时 , 自动触发执行 此方法一般无须定义 , 因为Python是一门高级语言 , 程序员在使用时无需关心内存的分配和释放 , 因为此工作都是交给Python解释器来执行 , 所以 , 析构方法是由解释器在进行垃圾回收时自动触发执行的 (Python采用 ' 引用计数 ' 的算法方式处理) class A: def __del__(self): print(\"析构方法执行!\") a = A() # 自动回收触发析构方法 del a # 执行结果: 析构方法执行! __call__ 🍀 对象后面加括号 , 触发执行 构造方法的执行是由创建对象触发的 , 而对于__call__ 方法的执行是由对象后加括号触发的 class A: def __init__(self): print(\"执行init\") def __call__(self, *args, **kwargs): print(\"执行call\") a = A() # init触发执行 a() #call触发执行 __dict__ 🍀 查看类或对象中的所有成员 class Person: __country = 'China' def __init__(self, name, age): self.name = name self.age = age def func(self): print('func') print(\"打印类成员\".center(30, '-')) for i in Person.__dict__: print('{} : {}'.format(i, Person.__dict__[i])) p = Person(\"Lyon\", 18) print(\"打印对象成员\".center(30, '-')) for i in p.__dict__: print('{} : {}'.format(i, p.__dict__[i])) ''' 执行结果: ------------打印类成员------------- __dict__ : __init__ : _Person__country : China __module__ : __main__ __weakref__ : func : __doc__ : None ------------打印对象成员------------ name : Lyon age : 18 ''' __str__ \\ __repr__ 🍀 改变对象的字符串显示 , 这两个方法都只能返回字符串 __str__ ()用于显示给用户，而__repr__ ()用于显示给开发人员 , 也就是在终端下print(Class)则会调用__repr__，非终端下会调用__str__方法 , 并且__str__ 能够友好的显示__repr__ 方法返回的字符串 , 反之则不能友好的显示 class A: def __str__(self): return \"I am str\" a = A() print(str(a)) print(repr(a)) ''' 执行结果: I am str ''' item 🍀 __getitem__ , __setitem__ , __delitem__ 用于索引操作 , 如字典 , 以上分别表示获取 , 设置 , 删除数据 class Foo(object): def __getitem__(self, key): print('__getitem__', key) def __setitem__(self, key, value): print('__setitem__', key, value) def __delitem__(self, key): print('__delitem__', key) obj = Foo() result = obj['k'] # 触发执行 __getitem__ obj['name'] = 'Lyon' # 触发执行 __setitem__ del obj['k'] #触发执行 __delitem__ ''' 执行结果: __getitem__ k __setitem__ name Lyon __delitem__ k ''' __eq__ 🍀 定义类里的 == 行为 class A(object): def __init__(self, name): self.name = name def __eq__(self, obj): return self.name == obj.name a = A(\"Lyon\") b = A(\"Lyon\") print(a == b) # 执行结果: True 一道面试题 class Person: def __init__(self, name, age): self.name = name self.age = age def __hash__(self): return hash(self.name) def __eq__(self, other): if self.name == other.name: return True p_lst = [] for i in range(84): p_lst.append(Person('Lyon', i)) print(p_lst) print(set(p_lst)) 在定义一个类时，如果我们需要改写该类的__eq__ 函数，特别要注意的是它将会变为不可哈希对象，也就是说如果你将它放到哈希集会报错 "},"01-Python/04-Object-Oriented/07-Python - 反射.html":{"url":"01-Python/04-Object-Oriented/07-Python - 反射.html","title":"Python - 反射","keywords":"","body":"Python - 反射 介绍 反射主要是指程序可以访问、检测和修改它本身状态或行为的一种能力 Python面向对象中的反射是通过字符串的形式来操作对象相关的属性 , 在Python中一切皆对象 , 并且只要是对象就可以使用反射 hasattr 🍀 判断对象中是否具有给定名称的属性 def hasattr(*args, **kwargs): # real signature unknown \"\"\" Return whether the object has an attribute with the given name. This is done by calling getattr(obj, name) and catching AttributeError. \"\"\" pass 实例1 # 定义一个字符串 name = 'lyon' # 查看是否具有给定名称的属性 bool = hasattr(name,'__len__') # 打印bool print(bool) # 执行结果:True ''' 说明:很多初学者可能一直不理解为什么说Python里一切皆对象,因为没有意识到,在Python中str、list、int ...等这些数据类型,其实就是用class写出来的一个模型,那么既然是类就会有属性这一说,就可以利用反射来操作对象了 ''' 实例2 import sys def s1(): pass def s2(): pass this_modules = sys.modules[__name__] print(type(this_modules),hasattr(this_modules,'s1')) # 执行结果: True getattr 🍀 从一个对象中获取属性名称 def getattr(object, name, default=None): # known special case of getattr \"\"\" Get a named attribute from an object; getattr(x, 'y') is equivalent to x.y. When a default argument is given, it is returned when the attribute doesn't exist; without it, an exception is raised in that case. \"\"\" pass 实例 class A: def __init__(self,name,age): self.name = name self.age = age def hello(self): print('hello {}'.format(self.name)) # 创建一个实例a a = A('Lyon',18) # 获取静态属性age age = getattr(a,'age') # 打印age print(age) # 获取动态属性hello,即方法 hello = getattr(a,'hello') # 执行hello hello() # 如果不存在就需要设置default参数,否则就报错 birthday = getattr(a,'birthday','today') # 打印birthday,即为default参数 print(birthday) ''' 执行结果: 18 hello Lyon today ''' setattr 🍀 定义属性 def setattr(x, y, v): # real signature unknown; restored from __doc__ \"\"\" Sets the named attribute on the given object to the specified value. setattr(x, 'y', v) is equivalent to ``x.y = v'' \"\"\" pass 实例 class B: def __init__(self): pass b = B() # 新增属性,如果存在即为修改 setattr(b, 'age', 18) # 打印age属性 print(b.age) # 新增add方法 setattr(b, 'add', lambda age: age + 1) # 修改age属性 b.age = b.add(b.age) # 打印age属性 print(b.age) ''' 执行结果: 18 19 ''' delattr 🍀 删除对象中的属性 def delattr(x, y): # real signature unknown; restored from __doc__ \"\"\" Deletes the named attribute from the given object. delattr(x, 'y') is equivalent to ``del x.y'' \"\"\" pass 实例 class C: def __init__(self,name,age): self.name = name self.age = age def add(self): self.age = self.age + 1 c = C('Lyon',18) # 删除c中的 delattr(c,'name') # print(c.name) 报错 delattr(c,'add') # c.add() 报错 "},"01-Python/04-Object-Oriented/08-Python - 异常处理.html":{"url":"01-Python/04-Object-Oriented/08-Python - 异常处理.html","title":"Python - 异常处理","keywords":"","body":"Python - 异常处理 介绍 🍀 在我们写程序时难免会出现错误 , 一种为语法错误 , 即为python解释器的语法检测都通不过的错误 , 这种错误只能我们在程序执行前就处理好 . 另一种为逻辑错误 , 这是我们在程序设计时所出现的错误 , 也就是我们通常所说的bug 在编程过程中为了增加友好性 , 在程序出现bug时一般不会将错误信息显示给用户 , 而是显示一个提示错误的页面 基本语法 try: pass except Exception as e: pass # except: 默认就为Exception 实例 try:0 # 用户输入 num = input(\"Please input the number:\") # 遇到无法int的对象就用except进行捕获 int(num) # 利用ValueError来捕获错误,并将捕获的错误返回给e except ValueError as e: # 打印捕获信息 print(e) ''' 执行结果: Please input the number:Lyon invalid literal for int() with base 10: 'Lyon' ''' PS : 在try代码块中只要出现异常 , 那么代码块中异常后面的代码就不会执行了 异常种类 🍀 Python中的异常种类非常多 , 上述中说了个ValueError只能处理值错误 , 当我们需要处理其他的错误时 , 就需要对症下药了 , 并且异常其实也是class , 并且所有的异常都继承了BaseException类 常用异常 异常名称 说明 ValueError 传入无效的参数 AttributeError 与对象的属性相关 IOError 输入/输出操作失败 , 基本上是无法打开文件 ImportError 无法引入模块或包 , 基本上是路径问题或名称错误 IndentationError 缩进错误 IndexError 下标索引超出范围 , 即索引不存在 KeyError 字典中不存在该key KeyboardInterrupt 用户中断执行 , 即被Ctrl + C NameError 变量还未声明/初始化 SyntaxError 语法错误 TypeError 传入对象类型与要求的不符合 UnboundLocalError 试图访问一个还未被设置的局部变量，基本上是由于另有一个同名的全局变量，导致你以为正在访问它 ValueError 传入无效的参数 继承关系与其他异常 # 所有异常都继承自BaseException类 BaseException +-- SystemExit +-- KeyboardInterrupt +-- GeneratorExit +-- Exception +-- StopIteration +-- StopAsyncIteration +-- ArithmeticError | +-- FloatingPointError | +-- OverflowError | +-- ZeroDivisionError +-- AssertionError +-- AttributeError +-- BufferError +-- EOFError +-- ImportError +-- ModuleNotFoundError +-- LookupError | +-- IndexError | +-- KeyError +-- MemoryError +-- NameError | +-- UnboundLocalError +-- OSError | +-- BlockingIOError | +-- ChildProcessError | +-- ConnectionError | | +-- BrokenPipeError | | +-- ConnectionAbortedError | | +-- ConnectionRefusedError | | +-- ConnectionResetError | +-- FileExistsError | +-- FileNotFoundError | +-- InterruptedError | +-- IsADirectoryError | +-- NotADirectoryError | +-- PermissionError | +-- ProcessLookupError | +-- TimeoutError +-- ReferenceError +-- RuntimeError | +-- NotImplementedError | +-- RecursionError +-- SyntaxError | +-- IndentationError | +-- TabError +-- SystemError +-- TypeError +-- ValueError | +-- UnicodeError | +-- UnicodeDecodeError | +-- UnicodeEncodeError | +-- UnicodeTranslateError +-- Warning +-- DeprecationWarning +-- PendingDeprecationWarning +-- RuntimeWarning +-- SyntaxWarning +-- UserWarning +-- FutureWarning +-- ImportWarning +-- UnicodeWarning +-- BytesWarning +-- ResourceWarning 为什么要说继承关系 , 因为在使用except是 , 它不但捕获该异常 , 还会把该异常类的子类也全部捕获 所以我们把 Exception 也叫做万能异常 , 因为除了SystemExit , KeyboardInterrupt 和 GeneratorExit 三个异常之外 , 其余所有异常基本都为Exception的子类 异常其他结构 🍀 多分支 name = 'Lyon' try: int(name) except IndexError as e: print(e) except KeyError as e: print(e) # ValueError捕获成功 except ValueError as e: print(e) # 执行结果:invalid literal for int() with base 10: 'Lyon' else num = '1' try: int(num) except ValueError as e: print(e) # 与for..else 和 while...else类似,没被打断就执行 else: print('没有异常就执行我') # 执行结果: 没有异常就执行我 finally num = 'Lyon' try: int(num) except ValueError as e: print(e) else: print('没有异常就执行我') finally: print('不管怎么样都执行我') ''' 执行结果: invalid literal for int() with base 10: 'Lyon' 不管怎么样都执行我 ''' 主动触发异常 🍀 raise try: raise TypeError('类型错误') except Exception as e: print(e) # 执行结果: 类型错误 自定义异常 🍀 通过继承BaseException来实现 class LyonException(BaseException): def __init__(self,msg): self.msg = msg def __str__(self): return self.msg try: # 主动触发异常 raise LyonException('你就是错了,别问为什么') # 捕获LyonException except LyonException as e: print(e) # 执行结果: 你就是错了,别问为什么 断言 🍀 断定条件成立 , 不成立就出现AssertionError异常 try: # 断定1等于1 assert 1 == 1 print('第一个断言成功就执行') assert 2 == 1 print(\"第二个断言失败不执行\") # 捕获AssertionError异常 except Exception: print(\"抓到你了\") ''' 执行结果: 第一个断言成功就执行 抓到你了 ''' 注意 : ​ 不要在任何地方都使用try...except , 因为它本身就是你附加给你程序的一种异常处理的逻辑 , 与你的主要的工作是没有关系的 , 这种东西加多了 , 会导致你的代码可读性变差 , 只有在有些异常无法与之的情况下 , 才应该使用try...except , 其他的逻辑错误应该尽量自行修正 "},"01-Python/04-Object-Oriented/Python - 特殊操作符.html":{"url":"01-Python/04-Object-Oriented/Python - 特殊操作符.html","title":"Python - 特殊操作符","keywords":"","body":"Python - 特殊操作符 介绍 🍀 在 Python 中 , 我们自定义类都是基于 Object 对象实现的 , 而在 Object 对象中有一些特殊的操作符 (__method__) 控制着整个对象的行为 , 所以 , 如果我们想对对象的行为进行控制 , 我们就需要自己来实现这些方法 ; 当然很多人称这些方法为 Python 魔法方法 (魔术方法) 下面 , 看看这些方法吧 基本行为 🍀 操作符 控制行为 调用说明 __new__ 对象创建 __init__ 只是用处初始化 , __new__ 调用的结果会交给 __init__ 进一步处理 __init__ 对象初始化 构造函数 , 进行属性设置 __del__ 对象删除 析构函数 , 进行对象的销毁 __repr__ 对象显示 , 针对对象 终端显示 , 返回值必须为字符串 , 实例见表下方 __str__ 对象显示 , 针对 print print 显示结果 , 返回值必须为字符串 , 如果未实现该方法 , print 将使用 __repr__ __bytes__ 字节对象转换 返回值必须为一个bytes对象 , bytes(obj) __format__ 格式化字符串 返回值必须为字符串对象 , format(obj) __lt__ 运算 x , 返回布尔值 , 下同 __le__ 运算 x __eq__ = 运算 x == y __ne__ != 运算 x != y __gt__ > 运算 x > y __ge__ >= 运算 x >= y __hash__ 可哈希 返回一个哈希对象 , hash(obj) , 注意 : 定义该方法同时应该定义 __eq__ __bool__ 真假测试 返回布尔值 __call__ 对象调用 在对象被调用时执行 __len__ len() 使用 len(obj) 时被调用 , 为防止值测试抛出 OverflowError , 必须定义 __bool__() __repr__ 与 __str__ 对比实例 : # 类定义 class Foo: def __init__(self, name): self.name = name def __repr__(self): return '' % self.name def __str__(self): return '' % self.name # 终端结果 >>> obj = Foo('Lyon') >>> obj >>> print(obj) 访问行为 🍀 操作符 控制行为 调用说明 __getattr__ . 属性访问运算 获取 x.name , __getattribute__ 查询失败后被调用 , 下方实例进一步说明 __getattribute__ . 属性访问运算 获取 x.name , 查询属性时被调用 __setattr__ . 属性赋值运算 self.attr = value → self.__setattr__(\"attr\", value) , 见下方实例进一步说明 __delattr__ . 属性删除运算 del obj.name 时被调用 __dir__ dir 运算 dir() 调用时被调用 , 必须返回一个序列 , dir() 会将序列转换成 list 并排序 __getattr__ 说明实例 : # __getattr__ # 注意在定义__getattr__或者__getattribute__时,不要出现 self. 因为这样会导致递归调用 # 正确的方式是,使用object的__getattr__,__getattribute__,或者直接定义返回值 class Foo: def __init__(self, name): self.name = name def __getattr__(self, item): return 'Attribute fetch failure' % item def __getattribute__(self, item): # return object.__getattribute__(self, item) if item == \"name\": return 'Lyon' else: raise AttributeError(item) x = Foo('Lyon') print(x.name) print(x.age) \"\"\" 执行结果: Lyon Attribute fetch failure \"\"\" __setattr__ 说明实例 : # __setattr__ # 与__getattr__一样,在定义__setattr__时,不要出现 self. 因为这样会导致递归调用 # 正确的方式是,使用object的__setattr__,或者使用self.__dict__[key] class Foo: def __init__(self, name): self.name = name def __setattr__(self, key, value): # object.__setattr__(self, key, value) if key == \"name\": self.__dict__[key] = value else: raise AttributeError(key + ' not allowed') x = Foo('Lyon') x.name = \"Kenneth\" x.age = 18 print(x.__dict__) \"\"\" 执行结果: {'name': 'Kenneth'} Traceback (most recent call last): File \"test.py\", line 19, in x.age = 18 File \"test.py\", line 11, in __setattr__ raise AttributeError(key + ' not allowed') AttributeError: age not allowed \"\"\" 描述器行为 🍀 操作符 控制行为 调用说明 __get__ . 对象访问运算 访问对象时被调用 , 对象访问意指 . 后面接的不是一个属性而是一个对象 , 见下方实例说明 __set__ . 对象赋值运算 对象赋值时被调用 __delete__ . 对象删除运算 对象删除时被调用 __set_name__ 所有者创建 在创建所有者时被调用 , Python 3.6 新增 __get__ , __set__ , __delete__ 实例 # 关于对象访问一说,是建立在两个的使用基础上的 # 单纯来讲,就是所有者类中的一个属性,是另一个类的实例 class Dependency: \"\"\" 附属类 \"\"\" def __get__(self, instance, owner): print('%s.%s is called...' % ('Dependency', '__get__')) def __set__(self, instance, value): print('%s.%s is called...' % ('Dependency', '__set__')) def __delete__(self, instance): print('%s.%s is called...' % ('Dependency', '__delete__')) class Owner: \"\"\" 所有者类 \"\"\" dependency = Dependency() o = Owner() o.dependency o.dependency = 'Lyon' del o.dependency \"\"\" 执行结果: Dependency.__get__ is called... Dependency.__set__ is called... Dependency.__delete__ is called... \"\"\" __set_name__ 是在上例 Owner 实例创建时被调用 , Python 3.6 新增 容器行为 🍀 操作符 控制行为 调用说明 __getitem__ 序列方式访问 self[key] 时被调用 __missing__ 序列方式访问失败 self[key] 时 key 不在字典中被调用 __setitem__ 序列方式赋值 self[key] = value 时被调用 __delitem__ 序列方式删除 del self[key] 时被调用 __iter__ 迭代环境 通过 iter(obj) 调用 , 如使用for循环进行遍历 __reversed__ reversed() reversed(obj) 时被调用 __contains__ 成员关系 in item in self 时调用 运算行为 🍀 # 基本运算行为 object.__add__(self, other) # + object.__sub__(self, other) # - object.__mul__(self, other) # * object.__matmul__(self, other) # @ object.__truediv__(self, other) # / object.__floordiv__(self, other) # // object.__mod__(self, other) # % object.__divmod__(self, other) # divmod() object.__pow__(self, other[, modulo]) # pow() ** object.__lshift__(self, other) # > object.__and__(self, other) # & object.__xor__(self, other) # ^ object.__or__(self, other) # | # 二进制运算行为 object.__radd__(self, other) object.__rsub__(self, other) object.__rmul__(self, other) object.__rmatmul__(self, other) object.__rtruediv__(self, other) object.__rfloordiv__(self, other) object.__rmod__(self, other) object.__rdivmod__(self, other) object.__rpow__(self, other) object.__rlshift__(self, other) object.__rrshift__(self, other) object.__rand__(self, other) object.__rxor__(self, other) object.__ror__(self, other) # 加=运算行为 object.__iadd__(self, other) # += object.__isub__(self, other) # -= object.__imul__(self, other) # *= object.__imatmul__(self, other) object.__itruediv__(self, other) object.__ifloordiv__(self, other) object.__imod__(self, other) object.__ipow__(self, other[, modulo]) object.__ilshift__(self, other) object.__irshift__(self, other) object.__iand__(self, other) object.__ixor__(self, other) object.__ior__(self, other) # 一元算数运算 object.__neg__(self) object.__pos__(self) object.__abs__(self) object.__invert__(self) # complex(),int(),float() object.__complex__(self) object.__int__(self) object.__float__(self) # 整数值hex(X),bin(X),oct(X),o[X],O[X:] object.__index__(self) # round(),trunc(),floor(),ceil() object.__round__(self[, ndigits]) object.__trunc__(self) object.__floor__(self) object.__ceil__(self) 上下文管理行为 🍀 操作符 控制行为 调用说明 __enter__ 进入上下文环境 使用with进入上下文环境时被调用 __exit__ 退出上下文环境 退出上下文环境时被调用 实例 class Foo: def __init__(self, name): self.name = name def __enter__(self): # 返回值赋值给as指定变量 return self def __exit__(self, exc_type, exc_val, exc_tb): print('exc_type',exc_type) # 异常类型 print('exc_val',exc_val) # 异常值 print('exc_tb',exc_tb) # 追溯信息 return True # 返回值为True,那么异常会被清空,就好像啥都没发生一样, # with后的语句正常执行 # 为False异常会抛出 with Foo('Lyon') as f: raise AttributeError('ignore exception') print('over') __slots__ 🍀 __slots__ 的作用是阻止在实例化类时为实例分配dict , 默认情况下每个类都会有一个dict,通过__dict__ 访问 , 这个dict维护了这个实例的所有属性 作用 : 减少内存使用 限制对实例添加新的属性 缺点 : 不可被继承 不可动弹添加新属性 实例 class Foo: __slots__ = ['name', 'age'] def __init__(self, name, age): self.name = name self.age = age f = Foo('Lyon', 18) print(f.name) print(f.age) # 报错 f.sex = 'Man' 更多 Data model "},"01-Python/05-Network/":{"url":"01-Python/05-Network/","title":"Network","keywords":"","body":"The road to Python - Network "},"01-Python/05-Network/01-Python - 网络编程初识.html":{"url":"01-Python/05-Network/01-Python - 网络编程初识.html","title":"Python - 网络编程初识","keywords":"","body":"Python - 网络编程初识 前言 🍀 在互联网没有诞生之前 , 我们都是在自己的计算机上自娱自乐 , 那时候的程序也都是单机版的程序 , 随后互联网诞生了 , 用网络把各个计算机连接到了一起 , 让处在网络中的计算机可以互相通信 , 网络编程就是如何在程序中实现两台计算机之间的通信 最基本的例子莫过于我们传输文件了 , 没有网络的情况下我们只能利用U盘或者硬盘 , 先从我的计算机上将要传输的文件写入到我们的U盘或者硬盘 , 然后再用已有文件的U盘或者硬盘写入其他计算机 , 这样的局限性有多大可想而知 ; 利用网络我们可以直接十万八千里进行文件传输 , 比如用我的QQ传文件给你的QQ , 当然这个例子可能不怎么好 , 因为你传文件一般可能不会用QQ来传 网络协议 🍀 网络的存在是为了能使计算机之间进行通信 , 既然是通信那么就得有一门大家都会的语言吧 . 就像我跟你说话 , 我只会中文而你只会英文 , 那么我们两个拿什么交流 ? 花钱请个翻译官 ? 不存在的 ...... 那么在网络上的各台计算机之间也需要一种大家都会的语言 , 这就是网络协议 网络协议是网络上所有设备之间通信规则的集合 , 它规定了通信时信息必须采用的格式和这些格式的意义 为了使不同计算机厂家生产的计算机能够相互通信 , 以便在更大的范围内建立计算机网络 , 国际标准化组织( ISO ) 在1987年提出了 \"开放系统互联参考模型\" , 即著名的OSI/RM模型(Open System Interconection/Reference Model) . 它将计算机网络体系结构的通信协议分为七层 , 如下图 在上图中右边协议部分我们可以了解各层中所包含的协议 , 互联网协议包含了上百种协议 , 但是最重要的两个协议是TCP和IP协议 , 所以我们把互联网的协议简称TCP/IP协议 IP协议 🍀 IP ( Internet Protocol ) 就是为计算机网络相互连接进行通信而设计的协议 , 翻译过来即\"因特网协议\" , 简称\"网协\" 它定义的地址称为IP地址 , 广泛采用v4版本即IPv4 , 它规定网络地址由32位2进制表示 , 范围为 0.0.0.0 ~ 255.255.255.255 , 一个IP地址通常协程四段十进制数 , 例如 : 127.0.0.1 . 还有IPv6地址 , 规定网络地址由128位2进制表示 , 它是目前使用的IPv4的升级版 , 以字符串表示如 : 2001:0db8:85a3:0042:1000:8a2e:0370:7334 通信的时候 , 双方必须知道对方的标识 , 好比发邮件必须知道对方的邮件地址 . 互联网上每个计算机的唯一标识就是IP地址 , 如果一台计算机同时接入到两个或更多的网络 , 比如路由器 , 它就会有两个或多个IP地址 , 所以 , IP地址对应的实际上是计算机的网络接口 , 通常是网卡 IP协议负责把数据从一台计算机通过网络发送到另一台计算机 . 数据被分割成一小块一小块 , 然后通过IP包发送出去 , 由于互联网链路复杂 , 两台计算机之间经常有多条线路 , 因此 , 路由器就负责决定如何把一个IP包转发出去 ; IP包的特点是按块发送 , 途径多个路由 , 但不保证能到达 , 也不保证顺序到达 一个IP包除了包含要传输的数据外 , 还包含源IP地址和目标IP地址 , 源端口和目标端口 TCP协议 🍀 TCP协议则是建立在 IP协议 之上的 , TCP协议负责在两台计算机之间建立可靠连接 , 保证数据包按顺序到达 ; TCP协议会通过握手建立连接 , 然后 , 对每个IP包编号 , 确保对方按顺序收到 , 如果包丢掉了 , 就自动重发 许多常用的更高级的协议都是建立在TCP协议基础上的 , 比如用于浏览器的HTTP协议、发送邮件的SMTP协议等 互联网本质上就是一系列的网络协议 , 互联网协议的功能是定义计算机如何接入internet , 以及接入internet的计算机通信标准 网络编程 🍀 互联网已经建立成功了 , 也就是说一大堆协议都准备好了 , 你只是规定好了计算机怎么接入互联网 , 但是却没告诉计算机接入之后怎么收发消息 , 也就是说并没有完全实现通信 , 仅仅是\"通\"了而已 网络编程就是以实现计算机之间通信为目的的编程 , 而实现计算机之间的通信实质上是实现计算机上两个进程的通信 , 比如我在两台计算机上都装有QQ , 我用一台计算机上的QQ给另一台计算机上的QQ发消息 , 明显实现该通信并不是两台计算机直接通信的 , 而是通过QQ这个正在运行的软件即一个进程来实现该通信的 所以我们可以这样说网络编程就是以实现进程间通信为目的的编程 "},"01-Python/05-Network/02-Python - 网络编程之Socket.html":{"url":"01-Python/05-Network/02-Python - 网络编程之Socket.html","title":"Python - 网络编程之Socket","keywords":"","body":"Python - 网络编程之Socket C/S架构 🍀 在网络通信中 , 一般是一方求一方应 , 求的一方就是客户端即 Client , 应的一方就是服务端即Server , 这就是C/S架构 , 在互联网中处处是C/S架构 , 比如我们访问百度 , 百度就是一个服务端 , 而我们的浏览器就是一个客户端 Socket 🍀 Socket是应用层与TCP/IP协议族通信的中间软件抽象层 , 它是一组接口 , 是从顶上三层 (osi七层协议的应用层) 进入传输层的接口 ; 顶上三层通常构成所谓的用户进程 , 底下四层却通常作为操作系统内核的一个部分提供 Socket又叫做套接字 , Python中socket为我们封装好了TCP/UDP协议 , 所以我们无需深入理解 , 只要遵循socket的规定去编程就可以了 创建socket对象 创建socket对象就是一个建立TCP的过程 , 即三次握手 , 断开当然就是四次挥手了 代码实现 # 导入socket模块 import socket # 调用socket模块中的socket类实例化出对象 sock = socket.socket(socket.AF_INET,socket.SOCK_STREAM,0) '''或者可以使用 from module import * ,可以大幅度减少代码,仅仅提一下,毕竟有弊端''' # 导入socket模块中的所有内容 from socket import * # 实例化socket类 sock = socket(AF_INET,SOCK_STREAM,0) socket类参数说明 其构造函数源码 def __init__(self, family=AF_INET, type=SOCK_STREAM, proto=0, fileno=None): # 下面内容就不摘了 pass family : 地址簇 参数 说明 AF_INET IPv4 , 即默认为IPv4 AF_INET6 IPv6 AF_UNIX 针对Unix系统进程间通信 type : 类型 参数 说明 SOCK_STREAM 面向流 , 即TCP SOCK_DGRAM 面向数据报 , 即UDP SOCK_RAW 原始套接字 , 可处理ICMP,IGMP等网络报文 ; 可以处理特殊的IPv4报文 ; 利用原始套接字 , 可以通过IP_HDRINCL套接字选项由用户构造IP头 SOCK_RDM 一种可靠的UDP形式 . SOCK_RAM用来提供对原始协议的低级访问 , 在需要执行某些特殊操作时使用 , 如发送ICMP报文 , SOCK_RAW通常仅限于高级用户或管理员运行的程序使用 SOCK_SEQPACKET 可靠的连续数据包服务 proto : 协议 参数 说明 0 与特定的地址家族相关的协议 , 如果是0 , 则系统就会根据地址格式和套接类别 , 自动选择一个合适的协议 还有一个fileno参数是无需理会的 基于TCP 🍀 TCP协议是有链接的 , 面向流的 , 数据传输可靠 , 必须先启动服务端 TCP服务端 创建套接字对象 创建socket对象 绑定IP和端口 绑定 bind() 开始监听链接 监听 listen() 阻塞 , 等待客户端成功连接 阻塞 accept() 接收请求数据 接收 recv() 处理并发送请求数据 发送 send() 通信完毕 , 关闭链接 , 关闭套接字 关闭 close() TCP客户端 创建套接字对象 创建socket对象 连接服务端 , 按照IP和端口连接 连接 connet() 发送请求数据 发送 send() 接收请求数据 接收 recv() 通信完毕 , 关闭套接字 关闭 close() 简单实例 tcp_server.py # 导入socket模块 import socket # 创建socket对象,默认参数就不填了 sock = socket.socket() # 绑定IP和端口,参数是一个元组(ip,port) sock.bind(('127.0.0.1', 8080)) # 开始监听,最大监听数为5 sock.listen(5) # 阻塞,等待连接,返回一个链接通道和一个地址 conn,addr = sock.accept() # 接收请求数据,接收大小为1024字节 content = conn.recv(1024) # 打印结果(bytes转成str显示) print(content.decode()) # 发送请求结果,必须以bytes类型 conn.send(b'Hello Lyon') # 关闭链接 conn.close() # 关闭套接字 sock.close() tcp_client.py # 导入socket模块 import socket # 创建socket对象 sock = socket.socket() # 建立链接 sock.connect(('127.0.0.1', 8080)) # 发送请求数据,必须以bytes类型 sock.send(b\"I'm Lyon\") # 接收请求结果 content = sock.recv(1024) # 打印结果 print(content.decode()) # 关闭套接字 sock.close() 基于UDP 🍀 UDP协议是无链接的 , 面向数据报的 , 数据传输全靠吼 , 不可靠 , 先启动哪一端都不会报错 UDP服务端 创建套接字对象 创建socket对象 绑定IP和端口 绑定 bind() 接收请求数据 接收 recvfrom() 通信完毕 , 关闭套接字 关闭 close() UDP客户端 创建套接字对象 创建socket对象 发送请求数据 发送 sendto() 通信完毕 , 关闭套接字 关闭 close() 简单实例 udp_server.py # 导入socket模块 import socket # 创建socket对象 sock = socket.socket(type=socket.SOCK_DGRAM) # 绑定ip和端口 sock.bind(('127.0.0.1', 8090)) # 接收请求,返回数据和地址 data,addr = sock.recvfrom(1024) # 打印请求 print(data.decode()) # 关闭套接字 sock.close() udp_client.py # 导入socket模块 import socket # 创建socket对象 sock = socket.socket(type=socket.SOCK_DGRAM) # 发送请求到指定地址 sock.sendto(b\"I'm Lyon\", ('127.0.0.1', 8090)) # 关闭套接字 sock.close() Socket对象方法 🍀 方法 描述 s.bind() 绑定地址（host,port）到套接字， 在AF_INET下,以元组（host,port）的形式表示地址。 s.listen() 开始TCP监听。backlog指定在拒绝连接之前，操作系统可以挂起的最大连接数量。该值至少为1，大部分应用程序设为5就可以了。 s.accept() 被动接受TCP客户端连接,(阻塞式)等待连接的到来 s.connect() 主动初始化TCP服务器连接，。一般address的格式为元组（hostname,port），如果连接出错，返回socket.error错误。 s.connect_ex() connect()函数的扩展版本,出错时返回出错码,而不是抛出异常 s.recv() 接收TCP数据，数据以字符串形式返回，bufsize指定要接收的最大数据量。flag提供有关消息的其他信息，通常可以忽略。 s.send() 发送TCP数据，将string中的数据发送到连接的套接字。返回值是要发送的字节数量，该数量可能小于string的字节大小。 s.sendall() 完整发送TCP数据，完整发送TCP数据。将string中的数据发送到连接的套接字，但在返回之前会尝试发送所有数据。成功返回None，失败则抛出异常。 s.recvfrom() 接收UDP数据，与recv()类似，但返回值是（data,address）。其中data是包含接收数据的字符串，address是发送数据的套接字地址。 s.sendto() 发送UDP数据，将数据发送到套接字，address是形式为（ipaddr，port）的元组，指定远程地址。返回值是发送的字节数。 s.close() 关闭套接字 s.getpeername() 返回连接套接字的远程地址。返回值通常是元组（ipaddr,port）。 s.getsockname() 返回套接字自己的地址。通常是一个元组(ipaddr,port) s.setsockopt(level,optname,value) 设置给定套接字选项的值。 s.getsockopt(level,optname[.buflen]) 返回套接字选项的值。 s.settimeout(timeout) 设置套接字操作的超时期，timeout是一个浮点数，单位是秒。值为None表示没有超时期。一般，超时期应该在刚创建套接字时设置，因为它们可能用于连接的操作（如connect()） s.gettimeout() 返回当前超时期的值，单位是秒，如果没有设置超时期，则返回None。 s.fileno() 返回套接字的文件描述符。 s.setblocking(flag) 如果flag为0，则将套接字设为非阻塞模式，否则将套接字设为阻塞模式（默认值）。非阻塞模式下，如果调用recv()没有发现任何数据，或send()调用无法立即发送数据，那么将引起socket.error异常。 s.makefile() 创建一个与该套接字相关连的文件 解决OSError: [Errno 48] Address already in use 问题 添加一条socket配置 , 重用ip和端口 import socket sock = socket.socket() # 添加在bind前 sock.setsockopt(socket.SOL_SOCKET,SO_REUSEADDR,1) sock.bind(address) "},"01-Python/05-Network/03-Python - Socket实现QQ聊天.html":{"url":"01-Python/05-Network/03-Python - Socket实现QQ聊天.html","title":"Python - Socket实现QQ聊天","keywords":"","body":"Python - Socket实现QQ聊天 介绍 🍀 在上一篇中写了最基本版的socket服务端和客户端 , 即仅能通信一次后就自动关闭了 , 显然实际应用中可不是这样的 , 那就来写一个像QQ一样的聊天程序吧 TCP实现 🍀 因为TCP是有链接的 , 这就导致只能有一个服务端 , 但是可以有多个客户端 tcpqq_server.py import socket sock = socket.socket() sock.bind(('127.0.0.1', 8080)) sock.listen(5) # 实现链接循环 while True: print(\"Watiting for the link...\") conn, addr = sock.accept() print(\"Your friend {} is online...\".format(addr)) # 实现通信循环 while True: messages = conn.recv(1024) print(\"Messages from [{}]:{}\".format(addr, messages.decode('utf-8'))) if messages == b'q': break else: while True: data = input(\"Please input the messages to be sent:\").strip().encode('utf-8') # 注意发送的内容不能为空,否则接收方就会一直等下去 if not data: print(\"Can't be empty...\") continue conn.send(data) break print(\"Your friend {} is offline...\".format(addr)) conn.close() sock.close() tcpqq_client.py import socket sock = socket.socket() sock.connect(('127.0.0.1', 8080)) # 实现通信循环 while True: messages = input(\"Please input your messages to be sent:\").strip().encode('utf-8') # 注意发送的内容不能为空,否则接收方就会一直等下去 if not messages: print(\"Can't be empty...\") continue elif messages == b'q': break else: sock.send(messages) data = sock.recv(1024) print(\"Messages from [{}]:{}\".format(('127.0.0.1', 8080), data.decode('utf-8'))) sock.close() 当然实际应用中是不会用TCP来完成的 , 而是用UDP , 这里只是模拟 , 并且以上还有有问题没有解决的 , 比如如果发送的消息大于1024字节 , 那么就不能完整接收信息了 , 后续再进行处理 TCP版本的服务端可以允许同时连入5个客户端 , 值得注意的是并不是同时连入 , 按照顺序排队 , 只有前面的人说完了会连入后序的客户端 UDP实现 🍀 以为UDP是无链接的 , 所以它可以实现想跟谁说话就跟谁说话 udpqq_server.py import socket sock = socket.socket(type=socket.SOCK_DGRAM) sock.bind(('127.0.0.1', 8080)) # 实现通信循环 while True: data, addr = sock.recvfrom(1024) print(\"Receive a message from {}:{}\".format(addr, data.decode('utf-8'))) if data == b'q': break while True: messages = input(\"Please input the messages to be sent:\").strip().encode('utf-8') if not messages: print(\"Can't be empty...\") continue sock.sendto(messages, addr) break sock.close() udpqq_client.py import socket sock = socket.socket(type=socket.SOCK_DGRAM) # 实现通信循环 while True: messages = input(\"Please input your messages to be sent:\").strip().encode('utf-8') if not messages: print(\"Can't be empty...\") continue elif messages == b'q': break else: sock.sendto(messages, ('127.0.0.1',8080)) data, addr = sock.recvfrom(1024) print(\"Receive a message from {}:{}\".format(addr, data.decode('utf-8'))) sock.close() 利用UDP实现才更接近现实 , 我们只需要知道他的ip和端口 , 我们就可以跟他讲话 , 在他即可以是服务端 , 也可以是客户端 , 不过必须注意接收和发送流程的问题 以上两种实现方式 , 都只是最基础的版本 , 在UDP中我们可以将所有人的ip和端口放到一个字典里或者其他存储里 , 利用ip和端口就可以实现跟所有人进行聊天了 "},"01-Python/05-Network/04-Python - Socket实现远程执行命令.html":{"url":"01-Python/05-Network/04-Python - Socket实现远程执行命令.html","title":"Python - Socket实现远程执行命令","keywords":"","body":"Python - Socket实现远程执行命令 os模块实现 🍀 osssh_server.py # 导入socket模块 import socket # 导入os模块 import os # 创建套接字对象 sock = socket.socket() # 重置ip和端口 sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) # 绑定ip和端口 sock.bind(('127.0.0.1', 8080)) # 监听 sock.listen(5) # 链接循环 while True: print(\"Waitting for connection...\") # 阻塞 conn, addr = sock.accept() print(\"{}successful connection...\".format(addr)) while True: cmd = conn.recv(1024) # 接收为空说明客户端断开了连接 if not cmd: print(\"Client is disconnected...\") break print(\"The command is {}\".format(cmd.decode())) # 利用os模块进行系统调用,py3中popen参数为str,所以先decode data = os.popen(cmd.decode()).read() # 发送命令执行结果 conn.send(data.encode('utf-8')) # 关闭链接 conn.close() # 关闭套接字 sock.close() osssh_client.py # 导入socket模块 import socket # 创建套接字对象 sock = socket.socket() # 连接服务端 sock.connect(('127.0.0.1', 8080)) while True: cmd = input(\"Please input the command:\").strip() if not cmd: print(\"Can't empty...\") continue elif cmd == 'exit': break # 发送命令 sock.send(cmd.encode('utf-8')) # 接收命令执行结果 data = sock.recv(1024) print(data.decode('utf-8')) # 关闭套接字 sock.close() subprocess模块实现 🍀 subprocess_server.py import socket import subprocess sock = socket.socket() sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) sock.bind(('127.0.0.1', 8080)) sock.listen(5) while True: print(\"Waitting for connection...\") conn, addr = sock.accept() print(\"{}successful connection...\".format(addr)) while True: cmd = conn.recv(1024) if not cmd: print(\"Client is disconnected...\") break print(\"The command is {}\".format(cmd.decode())) # 利用subprocess模块进行系统调用 data = subprocess.Popen(cmd.decode(),shell=True, stdout=subprocess.PIPE, stdin=subprocess.PIPE, stderr=subprocess.PIPE) stdout = data.stdout.read() stderr = data.stderr.read() # 打包执行结果 res = stdout + stderr # 发送执行结果 conn.send(res) conn.close() sock.close() subprocess_client.py import socket sock = socket.socket() sock.connect(('127.0.0.1', 8080)) while True: cmd = input(\"Please input the command:\").strip() if not cmd: print(\"Can't empty...\") continue elif cmd == 'exit': break sock.send(cmd.encode('utf-8')) data = sock.recv(1024) # Windows终端默认编码是gbk,所以得用gbk进行解码 print(data.decode('gbk')) sock.close() 以上两种方法实现了简单的ssh , 即远程执行命令 , 但是这两个都一个问题 , 当我们执行多次命令后 , 结果就不是我们想要得到了 , 它会发生粘包 , 即有可能上条命令的结果粘到这条命令的结果了 , 如何解决粘包问题 ? 下一篇整理 "},"01-Python/05-Network/05-Python - 网络编程之粘包.html":{"url":"01-Python/05-Network/05-Python - 网络编程之粘包.html","title":"Python - 网络编程之粘包","keywords":"","body":"Python - 网络编程之粘包 粘包 🍀 由上一篇Python之路 - Socket实现远程执行命令>中所出现的问题引出了粘包这个问题 , 粘包到底是什么? 首先 , 粘包现象只出现在TCP中 , 为什么说只有在TCP中才会发生粘包现象 , 先来详细解释一下TCP与UDP吧 TCP TCP (transprot control protocol, 传输控制协议) 是面向连接的 , 面向流的 , 提供高可靠性服务 . 收发两端都有要一一对应的socket(一对一模式) , 因此发送端为了将多个发往接收端的包 , 更有效的发到对方 , 使用了优化方法(Nagle算法) , 将多次间隔较小且数据量小的数据 , 合并成一个大的数据块 , 然后进行封包 . 必须提供科学的拆包机制 , 才能进行合理的分辨 , 所以说面向流的通信是无消息保护边界的 UDP UDP(user datagram protocol, 用户数据报协议) 是无连接的 , 面向消息的 , 提供高效率服务 . 不使用块的合并优化算法 , 由于UDP支持的是一对多的模式 , 所以接收端的skbuff (套接字缓冲区) 采用了链式结构来记录每一个到达的UDP包 , 在每个UDP包中就有了消息头 (消息来源地址 , 端口等信息) , 这样 , 对于接收端来说 , 就容易进行区分处理了 . 即面向的通信是有消息保护边界的 区别 TCP是基于数据流的 , 于是收发的消息不能为空 , 这就需要在客户端和服务端都添加空消息的处理机制 , 防止程序卡住 , 而UDP是基于数据报的 , 就算收发空内容 , 也不是空消息 , UDP协议会自动帮你封装上消息头 粘包现象发生的原因 粘包分为两种 发送方引起的粘包 这种情况下引起的粘包是TCP协议本身造成的 , TCP为了提高传输效率 , 发送方往往要收集到足够多的数据后才发送一个TCP段 (超过时间间隔也会发送,时间间隔是很短的) , 如果连续几次需要发送的数据都很少 , 通常TCP会根据优化算法把这些数据合成一个TCP段后一次发送出去 , 所以几次的数据到接收方时就粘成一包了 如下 : # 发送方第一次发送 send(b\"I'm \") # 立马第二次,不超过时间间隔 send(b\"Lyon\") ------------- # 接收 data = recv(1024) # 收到的是两次粘在一起的数据 print(data.decode()) # 打印结果: I'm Lyon 接收方引起的粘包 这种情况引起的粘包则是因为接收方不及时接收缓冲区的数据包造成的 , 比如发送方一次发送了10字节的数据 , 而接收方只接收了2字节 , 那么剩余的8字节的数据将都在缓冲区等待接收 , 而此时发送方又发送了2字节的数据 , 过了一会接收方接收了20字节(大于剩余10字节) , 接收完毕 , 缓冲区剩余的数据就和第二次发送的数据粘成了一个包 , 产生粘包 如下 : # 发送4字节内容 send(b\"I'm \") # 接收1字节,缓冲区还有3字节 data1 = recv(1) print(\"data1:\",data1) # 发送4字节内容,粘到缓冲区中剩余的3字节后面 send(b\"Lyon\") # 接收7字节,接收完毕 data2 = recv(7) print(\"data2:\",data2) ''' 打印结果: data1:I data2:'m Lyon ''' SO : 所以所谓粘包问题主要还是因为接收方不知道消息之间的界限 , 不知道一次性提取多少字节的数据所造成的 解决方法 🍀 既然粘包是因为接收方不知道消息界限 , 那么我们就自己创建界限 low方法 🍀 我们只需要对上一篇中subprocess_server.py以及subprocess_client.py 做一点点修改就行了 subprocess_server_development.py import socket import subprocess sock = socket.socket() sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) sock.bind(('127.0.0.1', 8080)) sock.listen(5) while True: print(\"Waitting for connection...\") conn, addr = sock.accept() print(\"{}successful connection...\".format(addr)) while True: # 接收指令 cmd = conn.recv(1024) if not cmd: print(\"Client is disconnected...\") break print(\"The command is {}\".format(cmd.decode())) # 获取执行结果 data = subprocess.Popen(cmd.decode(),shell=True, stdout=subprocess.PIPE, stdin=subprocess.PIPE, stderr=subprocess.PIPE) # 获取错误句柄 err = data.stderr.read() if err: res = err else: res = data.stdout.read() # 发送数据长度 conn.send(str(len(res)).encode('utf-8')) # 防止与两次发送数据粘在一起 ready = conn.recv(1024) if ready == b'OK': # sendall连续调用send完成发送 conn.sendall(res) conn.close() sock.close() subprocess_client_development.py import socket sock = socket.socket() sock.connect(('127.0.0.1', 8080)) while True: cmd = input(\"Please input the command:\").strip() if not cmd: print(\"Can't empty...\") continue elif cmd == 'exit': break # 发送指令 sock.send(cmd.encode('utf-8')) # 获取数据长度 length = sock.recv(1024).decode('utf-8') # 发送标志 sock.send(b'OK') recvsize = 0 data = b'' # 循环接收 while recvsize 利用这种方式 , 我们需要提前先将数据大小发送过去 , 这无疑会放大网络延迟带来的性能损耗 制作报头 🍀 既然需要将大小发送过去 , 那我们是不是可以为字节流加上自定义固定长度报头 , 报头中包换数据大小等信息 , 然后一次直接发送过去 , 对方只要在接收的时候先从取出报头 , 再取数据 所以我们只需要固定好报头的长度可以了 , 我们可以利用struct模块来制作报头 , 只需对上方法稍作修改 subprocess_struct_server.py import socket,struct import subprocess sock = socket.socket() sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) sock.bind(('127.0.0.1', 8080)) sock.listen(5) while True: print(\"Waitting for connection...\") conn, addr = sock.accept() print(\"{}successful connection...\".format(addr)) while True: cmd = conn.recv(1024) if not cmd: print(\"Client is disconnected...\") break print(\"The command is {}\".format(cmd.decode())) data = subprocess.Popen(cmd.decode(),shell=True, stdout=subprocess.PIPE, stdin=subprocess.PIPE, stderr=subprocess.PIPE) err = data.stderr.read() if err: res = err else: res = data.stdout.read() # 制作4位固定报头并发送 conn.send(struct.pack('i', len(res))) # 直接循环发送 conn.sendall(res) conn.close() sock.close() subprocess_struct_client.py import socket,struct sock = socket.socket() sock.connect(('127.0.0.1', 8080)) while True: cmd = input(\"Please input the command:\").strip() if not cmd: print(\"Can't empty...\") continue elif cmd == 'exit': break sock.send(cmd.encode('utf-8')) res = sock.recv(4) # 解开报头取出数据长度 length = struct.unpack('i', res)[0] recvsize = 0 data = b'' # 循环接收 while recvsize "},"01-Python/05-Network/06-Python - Socketserver实现多并发.html":{"url":"01-Python/05-Network/06-Python - Socketserver实现多并发.html","title":"Python - Socketserver实现多并发","keywords":"","body":"Python - Socketserver实现多并发 阅读指引 🍀 在上面的整理篇章中 , 简单的网络编程基本已经会了 , 一个TCP , 一个UDP , 然后就是粘包问题 但是在上述中有一个问题 , 在现实生活中 , 一个服务端肯定常常需要同时服务好几个客户端 , 而上述篇章中并没有实现一对多同时进行的情况 , TCP中只能等前一个链接断开后续的才能连上 , 没连上就一直等 ; UDP则是接一次发一次 , 并不能同时接两次发两次 . 为了处理这个问题 , 即实现并发 (后续文章详细讲解) , Python中有一个socketserver模块可以满足我们的要求 socketserver 🍀 Python提供了两个级别访问的网络服务: 低级别的网络服务支持基本的socket , 它提供了标准的BSD Socket API , 可以访问底层操作系统Socket接口的全部方法 高级别的网络服务模块socketserver , 它提供了服务器中心类 , 可以简化网络服务器的开发 socket就不用说了 , now socketserver 我们知道基于TCP的套接字 , 关键就是两个循环 , 一个链接循环(多人) , 一个通信循环(多消息) 在socketserver模块中分为两大类 : server类 (解决链接问题) 和request类 (解决通信问题) 如果想进一步了解 , 可以看看官方文档 , socketserver官方文档 > 实现多并发 🍀 multi_socketserver_server.py import socketserver class MyServer(socketserver.BaseRequestHandler): def handle(self): # 创建一个链接,继承于socketserver中的BaseRequestHandler类 conn = self.request # 发送登录提示 conn.sendall(b\"Welcome to login...\") print(\"Client connect...\") while True: print(\"Waitting for recving message...\") # 接收消息 message = conn.recv(1024) print(message.decode('utf-8')) # 收到exit就退出 if message == \"exit\": break # 回复消息 data = input(\"Reply message:\") # 发送消息 conn.sendall(data.encode('utf-8')) if __name__ == \"__main__\": 　# 实例化 server = socketserver.ThreadingTCPServer(('127.0.0.1', 999, ), MyServer) # 调用serve_forever方法 server.serve_forever() ''' def serve_forever(self, poll_interval=0.5): \"\"\" Handle one request at a time until shutdown. Polls for shutdown every poll_interval seconds. Ignores self.timeout. If you need to do periodic tasks, do them in another thread. \"\"\" ''' multi_socketserver_client.py # 就是一个简单的TCP客户端 import socket sock = socket.socket() # 连接服务端 sock.connect(('127.0.0.1', 999, )) login = sock.recv(1024) print(login.decode('utf-8')) while True: message = input(\"Please input the message:\").strip() if message == \"exit\": sock.sendall(b'exit') break else: sock.sendall(message.encode('utf-8')) print(\"Waitting for recving message...\") data = sock.recv(1024) print(data.decode('utf-8')) sock.close() 到这里 , 我们成功实现了多并发 , 多并发是什么? 这就关系到操作系统中的进程和线程了 , 网络编程既然是实现两个进程间的通信 , 那么就逃不过进程 , 线程等了 "},"01-Python/06-Concurrent/":{"url":"01-Python/06-Concurrent/","title":"Concurrent","keywords":"","body":"The road to Python - Concurrent "},"01-Python/06-Concurrent/01-Python - 进程与线程.html":{"url":"01-Python/06-Concurrent/01-Python - 进程与线程.html","title":"Python - 进程与线程","keywords":"","body":"Python - 进程与线程 前言 🍀 进程与线程是操作系统中的概念 , 这也是操作系统中最核心的概念 进程 🍀 进程是对正在运行程序的一个抽象 , 即一个进程就是一个正在执行程序的实例 从概念上说 , 每个进程拥有它自己的虚拟CPU . 当然 , 实际上真正的CPU在各进程之间来回切换 . 这种快速切换就是多道程序设计 . 但是某一瞬间 , CPU只能运行一个进程 , 但在1秒钟期间 , 它可能运行多个进程 , 就是CPU在进行快速切换 , 有时人们所说的 伪并行 就是指这种情形 创建进程 🍀 操作系统中 , 有4种事件导致进程的创建 系统初始化 , 启动操作系统时 , 通常会创建若干个进程 , 分为前台进程和后台进程 执行了正在运行的进程所调用的进程创建系统调用 用户请求创建一个新的进程 一个批处理作业的初始化 从技术上看 , 在所有这些情况中 , 新进程都是由一个已存在的进程执行了一个用于创建进程的系统调用而创建的 . 这个进程可以是一个运行的用户进程 , 一个由键盘或鼠标启动的系统进程或者一个批处理管理进程 . 这个进程所做的工作是 , 执行一个用来创建新进程的系统调用 . 在Linux/Unix中提供了一个fork() 系统调用就是用来创建进程的 (子进程) , 当然在Windows中也有相对应的系统调用 在Python中的os模块封装了常见的系统调用 , 其中就包括fork , 可以在Python程序中轻松创建子进程 '''因为Windows中没有fork调用,所以下程序只能在Unix/Linux下执行''' import os # os.getpid()获取父进程的ID print(\"Process %s start...\" % os.getpid()) # fock()调用一次会返回两次 pid = os.fork() # 子进程返回0 if pid == 0: print(\"I am child process %s and my parent is %s\" % (os.getpid(), os.getppid())) # 父进程返回子进程的ID else: print(\"I %s just created a child process %s\" % (os.getpid(), pid)) 终止进程 🍀 进程不可能永恒的存在 , 迟早都会终止 , 通常由下列条件引起 : 正常退出(自愿的) , 任务完成退出 出错退出(自愿的) , 进程中的错误 严重错误(非自愿) , 由进程引起的错误 被其他进程杀死(非自愿) , 某进程执行一个系统调用通知操作系统杀死某个其他进程 在有些系统中 , 当一个进程终止时 , 不论是自愿的还是其他原因 , 由该进程所创建的所有进程也一律立即被杀死 . 不过Unix和Windows都不是这种工作方式 进程状态 🍀 每个进程都有自己的程序计数器和内部状态 , 但进程之间经常需要相互作用 , 一个进程的输出结构可能作为另一个进程的输入 , 所以进程就会出现如下三种状态 : 运行态(该时刻进程实际占用CPU) 就绪态(可运行 , 但因为其他进程正在运行而暂时停止) 阻塞态(除非某中外部事件发生 , 否则进程不能运行) 进程的三种状态之间有四种可能的转换关系 一个进程状态 另一个进程状态 过程 运行态 阻塞态 进程为等待输入而 运行态 就绪态 调度程序选择另一个进程 就绪态 运行态 调度程序选择这个进程 阻塞态 就绪态 出现有效输入 进程中还有一点就是进程实现的问题 , 这就是依靠进程表了 , 具体就不说明了 进程的作用主要是提供了多道编程(多进程) , 并且提高了计算机的利用率 , 但是有两点是进程没有解决的 : 进程在同一时间只能做一件事 , 显然这不够我们的需求 进程在执行过程中一旦阻塞 , 整个进程就挂起了 , 这也是对计算机资源的一种浪费 人们想到的解决办法就是 , 在一个进程里面再有一类进程 , 称为迷你进程 , 也就是下面要说的线程 线程 🍀 在传统操作系统中 , 每个进程有一个地址空间和一个控制线程 , 事实上 , 这几乎就是进程的定义 所以我们可以知道 , 线程是操作系统能够进程运算调度的最小单位 , 它被包含在进程之中 , 是进程中的实际运作单位 . 不过 , 经常存在在同一个地址空间中准并行运行多个控制线程的情况 , 这些线程就像分离的进程 一个线程指的是进程中一个单一顺序的控制流 , 一个进程中可以并发多个线程 线程的使用 🍀 人们需要使用线程有两个理由 : 在多进程模型中 , 没有并行实体共享同一个地址空间和所有可用数据的能力 线程比进程更轻量级 , 在许多系统中 , 创建一个线程较创建一个进程要快10~100倍 线程与进程的区别 🍀 线程是执行的指令集 , 进程是资源的集合 线程的启动速度要比进程的启动速度要快 两个线程的执行速度是一样的 进程与线程的运行速度是没有可比性的 线程共享创建它的进程的内存空间 , 进程的内存是独立的 两个线程共享的数据都是同一份数据 , 两个子进程的数据不是共享的 , 而且数据是独立的 同一个进程的线程之间可以直接交流 , 同一个主进程的多个子进程之间是不可以进行交流 , 如果两个进程之间需要通信 , 就必须要通过一个中间代理来实现 一个新的线程很容易被创建 , 一个新的进程创建需要对父进程进行一次克隆 一个线程可以控制和操作同一个进程里的其他线程 , 线程与线程之间没有隶属关系 , 但是进程只能操作子进程 改变主线程 , 有可能会影响到其他线程的行为 , 但是对于父进程的修改是不会影响子进程 并发与并行 🍀 并发 🍀 在早期操作系统只有一个处理器 , 所以想达到同时运行多个程序 , 显然是不可能的 , 唯一的办法就是骗自己 , 告诉自己这几个是\"同时\"在运行 , 怎么骗 ? 如下 🌰一 现在你女朋友要你同时做三件事 1.洗衣服 2.洗碗 3.拖地 明显你要同时完成是不可能的,那现在我赋予你超能力,你获得了光速加成,你可以在一瞬间到达洗衣房(厕所吧),厨房,客厅.然后你女朋友就发现了惊悚的一幕 1.你女朋友看向客厅,你正在客厅拖地 2.接着转头看向厨房,你正在洗碗 3.而后转头看向洗衣房,你正在洗衣服 你女朋友就会告诉你:亲爱的,你是不是有分身呀,怎么可以同时做三件事情?我不管你得再分一个分身出来陪我玩,最后你成功的骗了你女朋友 这就是操作系统中 , 单个CPU + 多道技术实现的并发 CPU就是你本人 , 多道技术就是我赋予你的用速度\"同时\"干多件事的能力 🌰二 现在你女朋友已经知道你有超能力了,原来你一下只能干一件事情,她不高兴了,说道:我不管你得同时陪我还得做事情 于是你又想出了一个办法 1.陪女朋友0.25秒 2.洗衣服0.25秒 3.洗碗0.25秒 4.拖地0.25秒 以你女朋友的眼力绝对不可能看出你不在,就这样把1秒钟的时间平摊下来,然后一直循环下去,完美,再一次骗到了你女朋友 这就是分时系统的并发 , 按时间进行分配 并发 , 就是伪并行的 并行 🍀 真正的同时运行 , 只有具备多个CPU才能实现 并发事实上就是串行 , 还是一个人在做多个任务 , 而并行则是多个人在做多个任务 . 明显一个人 , 即只有一个执行者同时不可能做两件事的 , 但是并行 , 多个执行者就能够同时做多件事 所以并发与并行 , 就是一瞬间是否能存在多个进程 同步与异步 🍀 同步 🍀 所谓同步 , 就是在发出一个功能调用时 , 在没有得到结果之前，该调用就不会返回 . 按照这个定义，其实绝大多数函数都是同步调用 . 但是一般而言 , 我们在说同步、异步的时候 , 特指那些需要其他部件协作或者需要一定时间完成的任务 异步 🍀 异步的概念和同步相对 , 当一个异步功能调用发出后 , 调用者不能立刻得到结果 . 当该异步功能完成后 , 通过状态、通知或回调来通知调用者 , 如果异步功能用状态来通知 , 那么调用者就需要每隔一定时间检查一次 , 效率就很低(有些初学多线程编程的人 , 总喜欢用一个循环去检查某个变量的值 , 这其实是一 种很严重的错误) . 如果是使用通知的方式 , 效率则很高 , 因为异步功能几乎不需要做额外的操作 . 至于回调函数 , 其实和通知没太多区别 阻塞与非阻塞 🍀 阻塞 🍀 阻塞调用是指调用结果返回之前，当前线程会被挂起（如遇到io操作）。函数只有在得到结果之后才会将阻塞的线程激活。有人也许会把阻塞调用和同步调用等同起来，实际上他是不同的。对于同步调用来说，很多时候当前线程还是激活的，只是从逻辑上当前函数没有返回而已 非阻塞 🍀 非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前也会立刻返回，同时该函数不会阻塞当前线程 小结 🍀 对于进程和线程 , 直接阅读《现代操作系统》 一书再好不过了 并发与并行要注意执行顺序的问题 同步与异步针对的是函数/任务的调用方式 , 是否等待结果 阻塞与非阻塞针对的是进程或线程 , 阻塞进程则挂起 , 非阻塞即不挂起 这一篇基本属于纯理论 , 罗哩罗嗦了半天 "},"01-Python/06-Concurrent/02-Python - 并发编程之多线程.html":{"url":"01-Python/06-Concurrent/02-Python - 并发编程之多线程.html","title":"Python - 并发编程之多线程","keywords":"","body":"Python - 多线程编程 前言 🍀 在上一篇中说了一大堆理论 , 那么现在就开始实践了 先说线程再说进程 , 为什么 ? 因为在Python中有一个Python GIL全局解释器锁 , 这是个什么东西? 最后来说 总之线程和进程都是与操作系统有关的知识 , 所以操作系统基础 , 对于这两节内容的理解会有很大的帮助 Threading 🍀 Python通过两个标准库_thread (built-in) 和threading提供对线程的支持 , threading对_thread进行了封装 _thread.py ''' This module provides primitive operations to write multi-threaded programs. The 'threading' module provides a more convenient interface. ''' So , 明显我们一般直接使用threading threading模块中提供了Thread , Lock , RLock , Semaphore , Event , Condition , Timer等组件 Thread 🍀 参数说明 参数 说明 group 未使用 , 值始终 target 表示调用对象 , 即子线程要执行的任务 name 子线程的名称 args 传入target函数中的位置参数 , 是一个元组 , 参数后必须加逗号 kwargs 表示调用对象的字典 方法说明 方法 说明 Thread.run (self) 进程启动时运行的方法 , 由该方法调用target参数所指定的函数 , 在子类中可以进行重构 , 与线程中一样 Thread.start (self) 启动进程 , start方法就是去帮你调用run方法 Thread.terminate (self) 强制终止线程 , 不会进行任何清理操作 , 使用时需小心其子进程与锁的问题 Thread.join (self, timeout=None) 阻塞调用 , 主线程进行等待 , timeout为超时时间 Thread.is_alive (self) 这个方法在run()方法开始之前返回True , 在run()方法结束之后 , 返回所有活动线程的列表 Thread.isDaemon(self) 判断是否为守护线程 , 返回bool值 Thread.setDaemon(self,daemonic) 将子线程设置为守护线程 , daemonic = daemon Thread.getName(self,name) 获取线程名称 Thread.setName(self,name) 设置线程名称 实例属性说明 属性 说明 Thread.daemon 默认值为False , True则为守护线程 Thread.name 线程的名称 Thread.isAlive 即为is_alive的返回值 Thread.ident 线程标识符 , 没启动则为None 创建线程 Python中使用线程有两种方式 : 函数或者用类来包装线程对象 函数调用 import threading import time # 定义线程要运行的函数 def func(name): print(\"I am %s\" % name) # 为了便于观察,让它睡上2秒 time.sleep(2) # 防止被导入执行两次 if __name__ == '__main__': # 创建一个线程实例,args参数是一个元组,必须加逗号 t1 = threading.Thread(target=func, args=(\"Lyon\",)) # 再创建一个线程实例 t2 = threading.Thread(target=func, args=(\"Kenneth\",)) # 启动线程 t1.start() # 启动另一个线程 t2.start() # 打印线程名 print(t1.getName()) # 打印线程名 print(t2.getName()) ''' 执行结果: I am Lyon I am Kenneth Thread-1 Thread-2 ''' 类继承调用 import threading import time # 继承threading中的Thread类 class MyThread(threading.Thread): # 线程中所需要的参数 def __init__(self, name): # threading.Thread.__init__(self) super().__init__() self.name = name # 重构run方法,注意这个是表示线程活动的方法,必须有 def run(self): print(\"I am %s\" % self.name) time.sleep(2) # 防止被导入执行两次 if __name__ == '__main__': # 创建一个线程实例 t1 = MyThread('Lyon') # 创建另一个线程实例 t2 = MyThread('Kenneth') # 启动线程,调用了类中的run方法 t1.start() # 启动另一个线程 t2.start() # 获取线程名 print(t1.getName()) # 获取线程名 print(t2.getName()) ''' 执行结果: I am Lyon I am Kenneth Lyon Kenneth ''' Thread实例对象的方法 # isAlive(): 返回线程是否活动的。 # getName(): 返回线程名。 # setName(): 设置线程名。 threading模块提供的一些方法： # threading.currentThread(): 返回当前的线程变量。 # threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程。 # threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果。 Join & setDaemon 🍀 在说这两个方法之前 , 需要知道主线程与子线程的概念 主线程 : 当一个程序启动时 , 就有一个进程被操作系统创建 , 与此同时一个线程也立刻运行 , 该线程通常叫做程序的主线程 子线程 : 因为程序是开始时就执行的 , 如果你需要再创建线程 , 那么创建的线程就是这个主线程的子线程 主线程的重要性体现在两方面 : 1. 是产生其他子线程的线程 ; 2. 通常它必须最后完成执行比如执行各种关闭作 在Python中线程的一些机制与C/C++不同 , 在C/C++中 , 主线程结束后 , 其子线程会默认被主线程kill掉 . 而在Python中 , 主线程结束后 , 会默认等待子线程结束后 , 主线程才退出 Join 在上面的线程的创建时 , 获取线程名并不是在最后执行的 , 而是遇到sleep阻塞自动切换执行的 , 而sleep(2)则是在最后执行的 , 如果还不明白在看下面一个例子 遇到阻塞自动切换 import threading import time # 定义线程要执行的函数 def run(name): # 打印内容 print(\"I am %s\" % name) # 睡两秒 time.sleep(2) # 睡完继续起来干活 print(\"When I'm done, I'm going to keep talking...\") if __name__ == '__main__': # 创建一个线程实例 lyon = threading.Thread(target=run, args=('Lyon',)) # 创建另一个线程实例 kenneth = threading.Thread(target=run, args=('Kenneth',)) # 启动线程 lyon.start() # 启动另一个线程 kenneth.start() # 我是主线程,我应该最后执行的 print(\"I was the main thread, and I ended up executing\") ''' 执行结果: I am Lyon I am Kenneth I was the main thread, and I ended up executing When I'm done, I'm going to keep talking... When I'm done, I'm going to keep talking... 结果分析: 第一行打印了 I am Lyon,这没问题第一个线程启动了 第二行打印了 I am Kenneth,这就有问题了,这明明是第二个线程中的事情,我擦我的第一个线程都没执行完 第三行打印了 I was the main thread, and I ended up executing,你牛逼把我主线程的事都打印了 睡了两秒,看来是遇到阻塞自动切换了 最后打印了两个线程中的 When I'm done, I'm going to keep talking... ''' 在很多情况下 , 我们需要的是让各个线程执行完毕后 , 才接着往下执行 , 也就是不跳过阻塞 , 就让它等下去 , 这个时候就需要用join了 join : 阻塞调用程序 , 知道join () 方法的线程调用终止 , 才会继续往下执行 上面加上join后 import threading import time def run(name): print(\"I am %s\" % name) time.sleep(2) print(\"When I'm done, I'm going to keep talking...\") if __name__ == '__main__': lyon = threading.Thread(target=run, args=('Lyon',)) kenneth = threading.Thread(target=run, args=('Kenneth',)) lyon.start() lyon.join() kenneth.start() kenneth.join() print(\"I was the main thread, and I ended up executing\") ''' 执行结果: I am Lyon # sleep 2 seconds When I'm done, I'm going to keep talking... I am Kenneth # sleep 2 seconds When I'm done, I'm going to keep talking... I was the main thread, and I ended up executing ''' 程序按照我们的意愿按顺序执行了 setDaemon 无论进程还是线程 , 都遵循 : 守护进程 (线程) 会等待主进程 (线程) 运行完毕后被销毁 对于主进程来说 , 运行完毕指的是主进程代码运行完毕 对于主线程来说 , 运行完毕指的是主线程所在的进程内所有非守护线程统统运行完毕 setDaemon() 与 join() 基本上是相对的 , join会等子线程执行完毕 ; 而setDaemon则不会等 , 只要主线程执行完了 , 我才不管你子线程执没执行完毕 , 统统给我回收 , 这样才能保证进程能正常结束 setDaemon设置守护线程 import threading import time def run(name): print(\"I am %s\" % name) time.sleep(2) print(\"When I'm done, I'm going to keep talking...\") if __name__ == '__main__': lyon = threading.Thread(target=run, args=('Lyon',)) kenneth = threading.Thread(target=run, args=('Kenneth',)) # 设置守护线程,必须在启动前设置 lyon.setDaemon(True) # 启动线程 lyon.start() # 设置守护线程 kenneth.setDaemon(True) kenneth.start() print(\"I was the main thread, and I ended up executing\") ''' 执行结果: I am Lyon I am Kenneth I was the main thread, and I ended up executing 结果说明: 主线程一旦执行完毕,那么守护线程就一并退出,不管被守护线程是否执行完毕 所以lyon和kenneth两个子线程并没有执行完毕,如果在主线程中在加上sleep(5), 即超过子线程阻塞,那么这两个子线程就能执行完毕了 ''' 将主线程设置为守护线程 import threading import time def run(num): print(\"I like num %d\" % num) time.sleep(2) print(\"When I'm done, I'm going to keep talking...\") def main(): for i in range(1, 6): # 创建线程实例 t = threading.Thread(target=run, args=(i,)) # 启动线程 t.start() # 阻塞调用 t.join() if __name__ == '__main__': # 创建一个主线程 m = threading.Thread(target=main, args=[]) # 设置为守护线程 m.setDaemon(True) # 启动线程 m.start() # 等待其子线程执行完毕后,再8秒退出 m.join(timeout=8) ''' 执行结果: I like num 1 When I'm done, I'm going to keep talking... I like num 2 When I'm done, I'm going to keep talking... I like num 3 When I'm done, I'm going to keep talking... I like num 4 结果说明: 子线程并没有执行完毕,主线程退出,守护线程一并退出 ''' Python GIL 🍀 ''' In CPython, the global interpreter lock, or GIL, is a mutex that prevents multiple native threads from executing Python bytecodes at once. This lock is necessary mainly because CPython’s memory management is not thread-safe. (However, since the GIL exists, other features have grown to depend on the guarantees that it enforces.) ''' 基本意思是说 , 在CPython解释器中 , 同一个进程下开启的多线程 , 同一时刻只能有一个线程执行 , 无法利用多核优势 GIL并不是Python的一种特性 , 它是在实现Python解释器(CPhthon)时引入的一个概念 , 就比如同一段代码可以通过CPython , PyPy , Psyco等不同的Python执行环境来执行 , 像JPython中就没有GIL . 由于CPython是大部分环境下默认的Python执行环境 , 所以在很多人的概念里CPython就是Python , 但是要记住 , GIL并不是Python的特性 , Python完全可以不依赖GIL GIL GIL本质就是一把互斥锁 , 即会将并发运行变成串行 , 以此来控制同一时间内共享数据只能被一个任务进行修改 , 从而保证数据的安全性 保护不同的数据时 , 应该加不同的锁 , GIL是解释器级别的锁 , 又叫做全局解释器锁 CPython加入GIL主要的原因是为了降低程序的开发复杂度 , 让你不需要关心内存回收的问题 , 你可以理解为Python解释器里有一个独立的线程 , 每过一段时间它起wake up做一次全局轮询看看哪些内存数据是可以被清空的 , 此时你自己的程序 里的线程和Python解释器自己的线程是并发运行的 , 假设你的线程删除了一个变量 , py解释器的垃圾回收线程在清空这个变量的过程中的clearing时刻 , 可能一个其它线程正好又重新给这个还没来及得清空的内存空间赋值了 , 结果就有可能新赋值的数据被删除了 , 为了解决类似的问题 , Python解释器简单粗暴的加了锁 , 即当一个线程运行时 , 其它人都不能动 , 这样就解决了上述的问题 , 这可以说是Python早期版本的遗留问题 . 毕竟Python出来的时候 , 多核处理还没出来呢 , 所以并没有考虑多核问题 以上就可以说明 , Python多线程不适合CPU密集型应用 , 但适用于IO密集型应用 Lock 🍀 多线程与多进程最大的不同在于 , 多进程中 , 同一个变量 , 各自有一份拷贝存在于每个进程中 , 互不影响 , 但是在多线程中 , 所有变量对于所有线程都是共享的 , 因此 , 线程之间共享数据最大的危险在于多个线程同时修改一个变量 , 那就乱套了 , 所以我们需要GIL一样 , 来锁住数据 上面说了 , 保护不同的数据 , 要加不同的锁 , GIL是为了保护解释器的数据 , 明显我们还需要保护用户数据的锁 所以为了保证用户数据的安全 , 我们需要另一个锁 , 互斥锁(Mutex) 无锁版本 # 线程的调度是由操作系统决定的,一旦线程交替执行,并且次数足够多,那么就可能出问题了 # 直接用廖大大的例子,地址:www.liaoxuefeng.com import threading # 假定这是你的银行存款: balance = 0 def change_it(n): # 先存后取，结果应该为0: global balance balance = balance + n balance = balance - n def run_thread(n): for i in range(100000): change_it(n) for j in range(10000): t1 = threading.Thread(target=run_thread, args=(5,)) t2 = threading.Thread(target=run_thread, args=(8,)) # 这里跟join的位置有关系,因为join也是可以实现锁的功能的,下面说 t1.start() t2.start() t1.join() t2.join() print(balance,end=\"\") ''' 执行结果: 0 0 5 5 5 # 这里我就只给出5次的结果,因为5次就已经出现错误了 # 正常情况下数据不混乱,结果应该一直为0 ''' 加锁版本 import threading # 假定这是你的银行存款: balance = 0 def change_it(n): # 先存后取，结果应该为0: global balance balance = balance + n balance = balance - n # 创建一把锁 lock = threading.Lock() def run_thread(n): for i in range(100000): # 先要获取锁: lock.acquire() try: # 放心地改吧: change_it(n) finally: # 改完了一定要释放锁: lock.release() for j in range(10000): t1 = threading.Thread(target=run_thread, args=(5,)) t2 = threading.Thread(target=run_thread, args=(8,)) t1.start() t2.start() t1.join() t2.join() print(balance) ''' 执行结果: 0 # 这里的结果一直都是0,So我就只写出一个结果了 ''' join vs lock 上面第一个无锁版本的例子中 , 其实join()就可以实现我们想要的功能 , 只需要各个线程后面不加多余的东西直接接join()就行 , 因为我们知道join()的功能是进行阻塞 , 一加join() , 肯定其他就没有线程能动了 , 上面例子中故意将t1.join() 加在了t2.start()的后面 , 就是为了能让t2\"有机可趁\" , 既然join() 就可以实现 , 那我们还要锁干嘛? 我们应该想想 , join实现的原理 , join会使线程进行阻塞 , 也就是说会让真个线程变成完全串行的 , 既然只有一个线程在进行操作 , 那么它肯定就不会乱 , 但是使用join影响了执行效率 , 所以我们想能不能只让线程中的一部分串行? 答案是能的 , 就是利用互斥锁 , 想让哪里串行就让哪里串行 PS : Python3.x好像会自动加锁 , 但是Python2.x是不会的 , 写的时候还是都加上把 , 保证安全性 RLock 🍀 RLock叫做递归锁 , 在说之前先说一个死锁问题 进程也有死锁和递归锁 , 所谓死锁 : 是指两个或两个以上的进程或线程在执行过程中 , 因争夺资源而造成的一种互相等待的现象 , 若无外力作用 , 他们都将无法推进下去 . 此时称系统处于死锁状态或系统产生了死锁 , 这些永远在互相等待的进程称为死锁进程 , 如下 import threading import time # 创建两个锁 mutexA = threading.Lock() mutexB = threading.Lock() class MyThread(threading.Thread): # 重构run方法 def run(self): self.func1() self.func2() def func1(self): # 获取锁A mutexA.acquire() print(\"\\033[31m%s get mutexA...\\033[0m\" % self.name) # 获取锁B mutexB.acquire() print(\"\\033[33m%s get mutexB...\\033[0m\" % self.name) # 释放锁B mutexB.release() # 释放锁A mutexA.release() def func2(self): mutexB.acquire() print(\"\\033[35m%s get mutexB...\\033[0m\" % self.name) # 睡1秒 time.sleep(1) mutexA.acquire() print(\"\\033[37m%s get mutexA...\\033[0m\" % self.name) mutexA.release() mutexB.release() if __name__ == '__main__': for i in range(10): t = MyThread() t.start() ''' 执行结果: Thread-1 get mutexA... Thread-1 get mutexB... Thread-1 get mutexB... Thread-2 get mutexA... # 到这里整个程序就永远等着了 结果说明: 首先执行了func1,没有阻塞,顺利执行完毕 然后执行func2,获取了锁B后就开始睡1一秒,也就是阻塞开始 于是系统自动切换,再次执行了func1,而B的锁在阻塞前没释放 最后func1中的mutexB.acquire()就一直等前面一个线程把锁给释放了 等到天荒地老,海枯石烂,也等不到了 ''' 为了解决这样的问题 , 于是就有了递归锁 , 在Python中为了支持在同一线程中多次请求同一资源 , Python提供了可重入锁RLock 这个RLock内部维护着一个Lock和一个counter变量 , counter记录了acquire的次数 , 从而使得资源可以被多次require . 直到一个线程所有的acquire都被release , 其他的线程才能获得资源 RLock版本 # 仅仅只需如下修改 mutexA = threading.Lock() mutexB = threading.Lock() # 以上两行修改为 mutexA = mutexB = threading.RLock() # 注意如果仅仅修改后部分,即将Lock() -> RLock()是不行的,那样等于创建了两把递归锁 queue 🍀 我们可以使用队列处理线程编程中多个线程之间交换的安全问题 在queue中有三种模式 , Queue (先进先出 , FIFO) , LifoQueue (后进先出 , LIFO) , 还有一个可以设置优先级的队列PriorityQueue Queue import Queue q = Queue.Queue() q.put('First') q.put('Second') q.put('Third') print(q.get()) print(q.get()) print(q.get()) ''' 执行结果: First Second Third ''' LifoQueue import Queue q = Queue.LifoQueue() q.put('First') q.put('Second') q.put('Third') print(q.get()) print(q.get()) print(q.get()) ''' 执行结果: Third Second First ''' PriorityQueue import Queue q = Queue.PriorityQueue() # put进入一个元组,元组的第一个元素是优先级,越小优先级越高 q.put((20, 'A')) q.put((10, 'B')) q.put((30, 'C')) print(q.get()) print(q.get()) print(q.get()) ''' 执行结果: (10, 'B') (20, 'A') (30, 'C') ''' 更多请阅读Python标准库目录下的queue模块内容 Producer-Consumer 🍀 生产者 - 消费者问题 又称有界缓冲区问题 , 在进程中 , 两个进程共享一个公共的固定大小的缓冲区 , 其中一个是生产者 , 将信息放入缓冲区 ; 另一个是消费者 , 从缓冲区取出信息 . 问题在于当缓冲区满时 , 而此时生产者还想向其中放入一个新的数据项的情况 ; 相反 , 当缓冲区为空时 , 消费者视图从缓冲区中取数据 , 该如何去解决? 为了解决这个问题于是引入了生产者和消费者模式 , 基本思路也是如进程中睡眠和唤醒 生产者消费模式 通过一个容器来解决生产者和消费者的强耦合问题 . 生产者与消费者彼此之间不直接通讯 , 而通过阻塞队列来进行通讯 , 所以生产者生产完数据之后不用等待消费者处理 , 直接扔给阻塞队列 , 消费者不找生产者要数据 , 而是直接从阻塞队列里取 , 阻塞队列就相当于一个缓冲区 , 平衡了生产者和消费者的处理能力 在并发编程中使用生产者和消费者模式能解决绝大多数并发问题 , 在线程世界里 , 生产者就是生产数据的线程 , 消费者就是消费数据的线程 . 以下有两个生产者消费者问题的例子 基础版本 import threading import queue def producer(): for i in range(10): # 进行生产,放入队列 q.put(\"%d bottle of milk\" % i) print(\"Start waiting for all the milk to be taken...\") q.join() print(\"All the milk was taken out...\") def consumer(name): # 队列中有就取 while q.qsize() > 0: print(\"%s got %s\" % (name, q.get())) q.task_done() # 创建一个队列对象 q = queue.Queue() p = threading.Thread(target=producer,) p.start() c1 = consumer(\"Lyon\") 生产与消费同时进行 import time import random import queue import threading q = queue.Queue() def Producer(name): count = 1 while count Semaphore 🍀 信号量(Semaphore) , 引入一个整型变量来累计线程的唤醒次数 , threading模块中 , 有一个Semaphore类管理一个内置的计数器 , 每当调用acquire()时内置计数器 -1 ;调用release()时内置计数器 +1;计数器不能小于0 ; 当计数器等于0时 , acquire()将阻塞线程知道其他线程调用release() 一次最多连接5个线程 import threading import time def func(): # 内置计数器 -1 sm.acquire() print('%s get semaphores' % threading.current_thread().getName()) time.sleep(2) # 内置计数器 +1 sm.release() if __name__ == '__main__': # 一次最多只能有5个线程获取信号量 sm = threading.Semaphore(5) for i in range(10): t = threading.Thread(target=func) t.start() 利用信号量可以解决生产者与消费者问题 , 《现代操作系统中》一书中进行了简单的实现 Event 🍀 在多线程中 , 每个线程都是互相独立的 , 互不影响 , 如果我们需要通过某个线程的状态来控制程序的执行过程 , 是非常难的 . 为了解决这些问题 , 我们就可以使用threading中的Event对象来实现我们的目的 Event对象中包含一个可由线程设置的信号标志 , 它允许线程等待某些事件的发生 . 在初始情况下 , Event对象中的信号标志被设置为假 ; 如果有线程等待一个Event对象 , 而这个Event对象的标志为假 , 那么这个线程将会被一直阻塞直至该标志为真 . 一个线程如果将一个Event对象的信号标志设置为真 , 它将唤醒所有等待这个Event对象的线程 . 如果一个线程等待一个已经被设置为真的Event对象 , 那么它将忽略这个事件 , 继续执行 方法 描述 Event.isSet() 返回Event的状态 , isSet == is_set Event.wait() 如果Event.isSet() == False将阻塞线程 Event.set() 设置Event的状态值为True , 所有阻塞池中的线程激活进入就绪状态 , 等待操作系统调度 Event.clear() 回复Event的状态值为False 解决重复连接问题 import threading import time import random def conn_mysql(): count = 1 while not event.is_set(): # 大于3次主动触发TimeoutError if count > 3: raise TimeoutError('Connection timeout...') print('%s %sth attempt to connect' % (threading.current_thread().getName(), count)) # 阻塞0.5秒 event.wait(0.5) count += 1 print('%s connect successfully' % threading.current_thread().getName()) def check_mysql(): print('%s is checking mysql' % threading.current_thread().getName()) time.sleep(random.randint(2, 4)) # 激活线程 event.set() if __name__ == '__main__': event = threading.Event() conn1 = threading.Thread(target=conn_mysql) conn2 = threading.Thread(target=conn_mysql) check = threading.Thread(target=check_mysql) conn1.start() conn2.start() check.start() Condition 🍀 使线程等待 , 只有满足条件时 , 才释放线程 import threading def condition_func(): ret = False inp = input('>>>') # 只有当inp等于1时才会执行 if inp == '1': ret = True return ret def run(n): con.acquire() con.wait_for(condition_func) print(\"run the thread: %s\" %n) con.release() if __name__ == '__main__': con = threading.Condition() for i in range(10): t = threading.Thread(target=run, args=(i,)) t.start() Timer 🍀 threading模块中还有一个Timer类 , 可以指定时间后执行某操作 import threading def hello1(): print(\"I am Lyon\") def hello2(): print(\"Hello, future\") # 1秒后执行 t1 = threading.Timer(1, hello1) # 两秒后执行 t2 = threading.Timer(2,hello2) t1.start() t2.start() "},"01-Python/06-Concurrent/03-Python - 并发编程之多进程.html":{"url":"01-Python/06-Concurrent/03-Python - 并发编程之多进程.html","title":"Python - 并发编程之多进程","keywords":"","body":"Python - 多进程编程 前言 🍀 上一篇《多线程编程》中已经对Python中多线程部分进行了整理 , 进程中有很多也是相似的 概念在并发编程第一篇中就已经介绍了 , So直接开始操作 multiprocessing 🍀 从上一篇我们也已经知道了 , Python中的多线程无法利用多核优势 , 所以如果我们想要充分地使用多核CPU的资源 , 那么就只能靠多进程了 , 因为进程是系统调度的 , Python提供了multiprocessing模块了对多进程的支持 multiprocessing模块中提供了Process , Queue , Pipe , Lock , RLock , Event , Condition等组件 , 与threading模块有很多相似之处 Process 🍀 用于创建进程的类 , 与threading模块中的_Thread类类似 ''' Process类的构造函数 def __init__(self, group=None, target=None, name=None, args=(), kwargs={}): ''' 参数说明 参数 说明 group 未使用 , 值始终 target 与threading.Tread中的target参数一样 , 表示调用对象 , 即子进程要执行的任务 name 子进程的名称 args 传入target函数中的位置参数 , 是一个元组 , 与线程一样 , 参数后必须加逗号 kwargs 表示调用对象的字典 方法说明 方法 说明 Process.run (self) 进程启动时运行的方法 , 由该方法调用target参数所指定的函数 , 在子类中可以进行重构 , 与线程中一样 Process.start (self) 启动进程 , start方法就是去帮你调用run方法 Process.terminate (self) 强制终止进程 , 不会进行任何清理操作 , 使用时需小心其子进程与锁的问题 Process.join (self, timeout=None) 与线程中一样 , 阻塞调用 , 主进程进行等待 , timeout为超时时间 Process.is_alive (self) 判断进程是否正在运行 , 返回bool值 实例属性说明 属性 说明 Process.daemon 默认值为False , True则为守护进程 Process.name 进程的名称 Process.pid 进程的pid Process.exitcode 进程运行时为None , 如果为-N , 表示被信号N结束 Process.authkey 进程的身份验证键 , 默认是由os.urandom()随机生成的32字符的字符串 . 这个键的用途是为涉及网络连接的底层进程间通信提供安全性 , 这类连接只有在具有相同的身份验证键时才能成功 创建进程 与创建线程的方式一样 , 有两种 函数调用 import multiprocessing import time def hello(name): print(\"I am %s\" % name) time.sleep(1) print(\"Hello future...\") if __name__ == '__main__': # 创建一个进程实例 p = multiprocessing.Process(target=hello, args=(\"Lyon\",)) # 启动进程,实质调用run() p.start() print(\"End of main process...\") ''' 执行结果: End of main process... I am Lyon Hello future... ''' 类继承调用 import multiprocessing import time # 自定义进程类,继承multiprocessing中的Process类 class MyProcess(multiprocessing.Process): def __init__(self, name): super().__init__() self.name = name # 重构父类中的run方法 def run(self): print(\"I am %s\" % self.name) time.sleep(1) print(\"Hello future...\") if __name__ == '__main__': # 创建一个进程实例 p = MyProcess('Lyon') # 启动进程 p.start() print(\"End of main process...\") ''' 执行结果: End of main process... I am Lyon Hello future... ''' 在上栗创建进程中有一个问题 , 就是如果我们在Windows下 , 使用start()方法 , 就必须加上if __name__ == '__main__': , 进程是通过fork系统调用 , 而Windows中并没有fork , 所以多处理模块启动了一个新的Python进程 , 并导入了调用模块 . 如果进程在导入的时候被调用 , 那么这就会引发无限的新进程 , 后果不言而喻 . 当然还是可以直接使用run()的 Join & Daemon 🍀 join 进程中join与线程中的join是一样的 , 就进行阻塞调用 , 让主进程进行等待 , 整体串行 实例 # 多线程中的例子,换汤不换药 import multiprocessing import time def run(name): print(\"I am %s\" % name) time.sleep(2) print(\"When I'm done, I'm going to keep talking...\") if __name__ == '__main__': lyon = multiprocessing.Process(target=run, args=('Lyon',)) kenneth = multiprocessing.Process(target=run, args=('Kenneth',)) lyon.start() lyon.join() kenneth.start() kenneth.join() print(\"I was the main thread, and I ended up executing\") ''' 执行结果: I am Lyon When I'm done, I'm going to keep talking... I am Kenneth When I'm done, I'm going to keep talking... I was the main thread, and I ended up executing ''' Daemon 守护进程会在主进程代码执行结束后就终止 # 还是多线程中的例子 import multiprocessing import time def run(num): print(\"I like num %d\" % num) time.sleep(2) print(\"When I'm done, I'm going to keep talking...\") def main(): for i in range(1, 6): t = multiprocessing.Process(target=run, args=(i,)) t.daemon = True t.start() t.join() if __name__ == '__main__': m = multiprocessing.Process(target=main, args=[]) m.start() m.join(timeout=8) ''' 执行结果: I like num 1 When I'm done, I'm going to keep talking... I like num 2 When I'm done, I'm going to keep talking... I like num 3 When I'm done, I'm going to keep talking... I like num 4 When I'm done, I'm going to keep talking... I like num 5 When I'm done, I'm going to keep talking... ''' PS : 与线程不同的是 , 守护进程内无法再开启子进程 , 否则就抛出异常 Lock 🍀 进程之间的数据是不共享的 , 因为每个进程之间是相互独立的 , 但是进程共享一套文件系统 , 所以访问同一个文件 , 是没有问题的 , 但是如果有多个进程对同一文件进行修改 , 就会造成错乱 , 所以我们为了保护文件数据的安全 , 就需要给其进行加锁 同样的 , join为整体串行 , lock为局部串行 廖大大实例 , Lock import multiprocessing # 假定这是你的银行存款: balance = 0 def change_it(n): # 先存后取，结果应该为0: global balance balance = balance + n balance = balance - n # 创建一把锁 lock = multiprocessing.Lock() def run_thread(n): for i in range(100000): # 先要获取锁: lock.acquire() try: # 放心地改吧: change_it(n) finally: # 改完了一定要释放锁: lock.release() # 在多线程例子中并没有写这句,但是多进程中使用start()必须加 if __name__ == '__main__': for j in range(10000): t1 = multiprocessing.Process(target=run_thread, args=(5,)) t2 = multiprocessing.Process(target=run_thread, args=(8,)) t1.start() t2.start() t1.join() t2.join() print(balance) ''' 执行结果: 0 . # 数据安全得到了保障,所以全为0 ... RLock import multiprocessing import time mutexA = mutexB = multiprocessing.RLock() class MyThread(multiprocessing.Process): def run(self): self.func1() self.func2() def func1(self): mutexA.acquire() print(\"\\033[31m%s get mutexA...\\033[0m\" % self.name) mutexB.acquire() print(\"\\033[33m%s get mutexB...\\033[0m\" % self.name) mutexB.release() mutexA.release() def func2(self): mutexB.acquire() print(\"\\033[35m%s get mutexB...\\033[0m\" % self.name) time.sleep(1) mutexA.acquire() print(\"\\033[37m%s get mutexA...\\033[0m\" % self.name) mutexA.release() mutexB.release() if __name__ == '__main__': for i in range(10): t = MyThread() t.start() Producer-consumer 🍀 生产者消费者模式 , 在多线程中已经有过说明了 , 目的是为了解决并发问题 实例 # 可与多线程篇中进行对照 import time import random import multiprocessing q = multiprocessing.Queue() def Producer(name, q): count = 1 while count Queue 🍀 multiprocessing模块支持进程间通信有两种主要形式 , 队列和管道 在多线程中有queue模块 , 供我们实现队列接口 , 在多进程中则是Queue类为我们提供队列接口 Queue为单向通道 , 先进先出(FIFO) class Queue(object): def __init__(self, maxsize=-1): self._maxsize = maxsize # 返回队列中目前项目数量,使用时防止竞争,最好令其串行 def qsize(self): return 0 # 队列是否为空,返回True,使用时防止竞争,最好令其串行 def empty(self): return False # 队列是否已满,返回True,使用时防止竞争,最好令其串行 def full(self): return False # 将数据放入队列 def put(self, obj, block=True, timeout=None): pass # 同上put def put_nowait(self, obj): pass # 从队列中取出项 def get(self, block=True, timeout=None): pass # 同上get def get_nowait(self): pass # 关闭队列,垃圾回收会调用此方法 def close(self): pass # 连接队列的后台线程,用于等待所有队列项消耗 def join_thread(self): pass # 不会在在进程退出时自动连接后台线程,可防止join_thread()方法阻塞 def cancel_join_thread(self): pass 实例 import multiprocessing q = multiprocessing.Queue(3) q.put(\"First\") q.put(\"Second\") q.put(\"Third\") print(q.full()) print(q.get()) print(q.get()) print(q.get()) print(q.empty()) ''' 执行结果: True First Second Third True ''' Pipe 🍀 介绍 # Pipe在进程之间创建一条管道,并返回元组(connection(),connection()) def Pipe(duplex=True): return Connection(), Connection() # 管道端的连接对象 class Connection(object): # 发送对象 def send(self, obj): pass # 接收另一端发送的对象 def recv(self): pass # 返回连接使用的整数文件描述符 def fileno(self): return 0 # 关闭链接 def close(self): pass # 如果链接上的数据可用,返回True def poll(self, timeout=None): pass # 发送字节到数据缓冲区,buffer是支持缓冲区接口的任意对象,offset为偏移量,size为字节数 def send_bytes(self, buffer, offset=-1, size=-1): pass # 接收一条完整字节消息 def recv_bytes(self, maxlength=-1): pass # 接收一条完整的字节消息,并把它保存在buffer对象中,该对象支持可写入的缓冲区接口 def recv_bytes_into(self, buffer, offset=-1): pass ''' Connection类与我们网络编程中所使用的socket(TCP)类似,socket(TCP)对象之间通信也是双向的 ... 基于管道实现进程间通信 import multiprocessing def producer(seq, p): left,right = p # 关闭不使用的一端 right.close() for i in seq: # 发送进管道中 left.send(i) else: # 关闭管道 left.close() def consumer(p, name): left,right = p # 关闭不使用的一端 left.close() while True: # 如果消费者不使用的一端忘记关闭,消费者中的recv()就一直等下去 try: bun = right.recv() print('%s got %s buns...' % (name, bun)) # 触发EOFError except EOFError: right.close() break if __name__ == '__main__': # 创建管道实例 left, right = multiprocessing.Pipe() c1 = multiprocessing.Process(target=consumer, args=((left, right), 'c1')) c1.start() seq = (i for i in range(10)) producer(seq, (left, right)) right.close() left.close() c1.join() print('End of main process...') Manager 🍀 进程之间是相互独立的 , 在multiprocessing模块中的Manager可以实现进程间数据共享 , 并且Manager还支持进程中的很多操作 , 比如Condition , Lock , Namespace , Queue , RLock , Semaphore等 由于基于消息传递(Queue , Pipe)的并发编程才是未来的主流 , 所以对于Manager应该尽量避免使用 Manager实例 import multiprocessing # 既然数据共享了,就需要像多线程那样,防止竞争 def run(d,lock): # 演示没加锁的实例 # lock.acquire() d['count'] -= 1 # lock.release() if __name__ == '__main__': # lock = multiprocessing.Lock() with multiprocessing.Manager() as m: dic = m.dict({'count' : 100}) process_list = [] for i in range(100): p = multiprocessing.Process(target=run, args=(dic, lock,)) process_list.append(p) p.start() for p in process_list: p.join() print(dic) ''' 执行结果: # 该结果看缘分了,没加锁数据共享,导致混乱,与线程中一样 {'count': 1} ''' 更多详细内容multiprocessing.Manager > Semaphore 🍀 与线程中一样 class Semaphore(object): def __init__(self, value=1): pass def acquire(self, blocking=True, timeout=None): pass def release(self): pass 实例 import multiprocessing import time def func(sem, num): sem.acquire() print('%s get semaphores' % num) time.sleep(2) sem.release() if __name__ == '__main__': sem = multiprocessing.Semaphore(5) for i in range(1,11): t = multiprocessing.Process(target=func, args=(sem, i,)) t.start() Event 🍀 与线程中一样 class Event(object): def is_set(self): return False def set(self): pass def clear(self): pass def wait(self, timeout=None): pass 实例 import multiprocessing import time import random def conn_mysql(conn, event): count = 1 while not event.is_set(): if count > 3: # 主动触发超时异常 raise TimeoutError('Connection timeout...') print('%s %sth attempt to connect' % (conn, count)) event.wait(0.5) count += 1 print('%s connect successfully' % conn) def check_mysql(conn, event): print('%s is checking mysql' % conn) time.sleep(random.randint(2, 4)) event.set() if __name__ == '__main__': event = multiprocessing.Event() for i in range(10): conn = multiprocessing.Process(target=conn_mysql, args=('conn'+str(i), event)) conn.start() Pool 🍀 multiprocessing中的Process实现了我们对多进程的需求 , 但是当我们进行并发编程时 , 一旦需要开启的进程数量非常大时 , 使用Process已经不能满足我们的要求了 . 因为进程是需要占用系统资源的 , 操作系统不可能去无限的开启进程 ; 并且使用Process动态生成多个进程 , 我们还需要手动的去限制进程的数量 , 所以这个时候我们就应该用进程池(Pool)来实现了 multiprocessing.Pool 参数说明 参数 说明 numprocess 要创建的进程数 , 如果省略 将默认使用cpu_count() initializer 每个进程启动时要执行的可调用对象 initargs 传给initializer的参数组 方法说明 方法 说明 Pool.apply(self, func, args=(), kwds={}) 在一个进程池中执行func(args , *kwargs) , 并返回结果 Pool.apply_async(self, func, args=(), kwds={}, callback=None, 与apply()方法一样 , 该方法为异步版本应用的方法 , 返回结果是AsyncResult类的实例 , callback指定回调的函数 . callback禁止执行任何阻塞操作 , 否则将接收其他异步操作中的结果 Pool.close(self) 关闭进程池 , 如果所有操作持续挂起 , 它们将在工作进程终止前完成 Pool.join(self) 等待所有工作进程退出 Pool.get(self, timeout=None) 获取结果 , timeout可选 Pool.ready(self) 完成调用就返回True Pool.successful(self) 完成调用并且没有引发异常返回True , 在结果就绪之前调用此方法会引发异常 Pool.wait(self, timeout=None) 等待结果变为可用 Pool.terminate(self) 立即终止所有工作进程 , 垃圾回收会自动调用此方法 同步调用apply from multiprocessing import Pool import os import time def run(n): print(\"%s run...\" % os.getpid()) # 不令其阻塞,结果会同时打印 time.sleep(2) return n**2 if __name__ == '__main__': # 进程池没满就新创建进程执行请求,否则就等待 # 注意,这里指定进程池数量为3,会一直是这三个进程在执行,只不过执行的请求可能改变 pool = Pool(3) res_list = [] for i in range(10): # 获取执行结果,同步运行,会阻塞等待拿到结果,等待过程中无论是否阻塞都会在原地等 # 注意等待过程中由于阻塞,其cpu权限会被夺走 res = pool.apply(run, args=(i,)) res_list.append(res) print(res_list) 异步调用apply_async from multiprocessing import Pool import os import time def run(n): print(\"%s run...\" % os.getpid()) time.sleep(2) return n**2 if __name__ == '__main__': # 进程池没满就新创建进程执行请求,否则就等待 # 注意,这里指定进程池数量为3,会一直是这三个进程在执行,只不过执行的请求可能改变 pool = Pool(3) res_list = [] for i in range(10): res = pool.apply_async(run, args=(i,)) res_list.append(res) pool.close() pool.join() for res in res_list: print(res.get()) "},"01-Python/06-Concurrent/04-Python - 多进程实例及回调函数.html":{"url":"01-Python/06-Concurrent/04-Python - 多进程实例及回调函数.html","title":"Python - 多进程实例及回调函数","keywords":"","body":"Python - 多进程实例及回调函数 进程池实例 🍀 使用进程池维护固定数目的进程 server.py import socket import os import multiprocessing server = socket.socket(socket.AF_INET, socket.SOCK_STREAM) server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) server.bind(('127.0.0.1', 8080)) server.listen(5) def talk(conn, client_addr): print(\"Process pid : %s\" % os.getpid()) while True: try: msg = conn.recv(1024) if not msg:break conn.send(msg.upper()) except Exception: break if __name__ == '__main__': pool = multiprocessing.Pool() while True: conn, client_addr = server.accept() # 同步则一时间只有一个客户端能访问,所以使用异步 pool.apply_async(talk,args=(conn, client_addr,)) client.py import socket client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) client.connect(('127.0.0.1', 8080)) while True: msg = input(\"Please input message:\").strip() if not msg: continue client.send(msg.encode('utf-8')) data = client.recv(1024) print(data.decode('utf-8')) 回调函数 🍀 回调函数就是一个通过函数指针调用的函数 , 如果你把函数的指针(地址)作为参数传递给另一个函数 , 当这个指针被用来调用其所指向的函数时 , 我们就说这是回调函数 回调函数不是由该函数的实现方直接调用 , 而是在特定的事件或条件发生时由另外的一方调用的 , 用于对该事件或条件进程响应 进程池中使用回调函数 apply_async(func[, args[, kwds[, callback[, error_callback]]]]) If callback is specified then it should be a callable which accepts a single argument. When the result becomes ready callback is applied to it, that is unless the call failed, in which case the error_callback is applied instead. ''' 意思是如果指定了回调,那么它应该是可调用的,调用失败则会应用error_callback ''' 实例 import multiprocessing import requests import os def get_page(url): print('Process %s get %s...' % (os.getpid(), url)) respone = requests.get(url) if respone.status_code == 200: return {'url': url, 'text': respone.text} # 进行回调的函数,处理结果 def pasrse_page(res): print('Process %s parse %s...' % (os.getpid(), res['url'])) parse_res = 'url : %s\\nsize : %s\\n' % (res['url'], len(res['text'])) with open('db.txt', 'a') as f: f.write(parse_res) if __name__ == '__main__': urls = [ 'https://www.baidu.com', 'https://www.python.org', 'https://www.openstack.org', 'https://help.github.com/', 'http://www.sina.com.cn/' ] p = multiprocessing.Pool(3) res_list = [] for url in urls: # 执行并返回结果,异步, res = p.apply_async(get_page, args=(url,), callback=pasrse_page) res_list.append(res) p.close() p.join() # 拿到的是get_page的结果,其实完全没必要拿该结果,该结果已经传给回调函数处理了 print([res.get() for res in res_list]) 处理结果db.txt url : https://www.openstack.org size : 60191 url : https://www.python.org size : 49081 url : https://www.baidu.com size : 2443 url : https://help.github.com/ size : 118622 url : http://www.sina.com.cn/ size : 601426 爬虫案例 from multiprocessing import Pool import requests import re def get_page(url, pattern): response = requests.get(url) if response.status_code == 200: print(response.text) return (response.text,pattern) def parse_page(info): page_content, pattern = info res=re.findall(pattern, page_content) for item in res: dic={ 'index' : item[0], 'title' : item[1], 'actor' : item[2].strip()[3:], 'time' : item[3][5:], 'score' : item[4]+item[5] } print(dic) if __name__ == '__main__': pattern1=re.compile(r'.*?board-index.*?>(\\d+)(.*?)(.*?)(.*?)(.*?) "},"01-Python/06-Concurrent/05-Python - 并发编程之协程.html":{"url":"01-Python/06-Concurrent/05-Python - 并发编程之协程.html","title":"Python - 并发编程之协程","keywords":"","body":"Python - 并发编程之协程 前言 🍀 在前面的文章中 , 基本已经可以解决并发编程中的基本问题了 , 但是如果我们要利用单线程来实现并发 , 线程是轻量级的进程 , 为了使计算机资源能更充分的利用 , 那么我们就需要用到协程了 并发的本质就是上下文切换加上保存状态 , 那么我们就可以想到关键字yield , 我们在生成器篇章中 , 就是利用了yield实现了状态的保存 , 来看一个廖大大的例子 生产者消费者模型yield版 import time def consumer(): r = '' time.sleep(1) while True: n = yield r if not n: return time.sleep(1) print('[CONSUMER] Consuming %s...' % n) r = '200 OK' def produce(c): c.send(None) n = 0 while n 上述例子中yield确实实现了并发 , 但是并没有实现遇到IO操作进行自动切换 , 所以协程出场了 协程 🍀 首先通过上述例子 , 我们知道 , 对于单线程下 , 我们不可避免程序中出现IO操作 , 但是如果我们能够在自己的程序中去实现这一步 , 就以为着线程可以最大限度地处于就绪态 , 相当于我们在用户程序级别将自己的IO操作最大限度地隐藏起来 , 这样线程的计算效率将会得到进一步的提升 协程(Coroutine) : 是单线程下的并发 , 又称微线程 , 纤程 . 协程是一种用户态的轻量级线程 , 即协程有用户自己控制调度 协程的本质就是在单线程下 , 由用户自己控制一个任务遇到IO阻塞了就切换另外一个任务去执行 , 以此来提升效率 在单线程内开启协程 , 一旦遇到IO , 就会从应用程序级别控制切换 , 非IO操作的切换与效率无关 使用协程的优缺点 优点 : 协程的切换开销更小 , 属于程序级别的切换 , 更加轻量级 单线程内就可以实现并发的效果 , 最大限度利用CPU 缺点 : 协程的本质是单线程下 , 无法利用多核 , 可以是一个程序开启多个进程 , 每个进程内开启多个线程 , 每个线程内开启协程 协程指的是单个线程 , 因而一旦协程出现阻塞 将会阻塞整个线程 Greenlet 🍀 我们在前面已经用yield实现了协程 , 但是使用yield需要先得到初始化一次的生成器 , 然后再调用send , 这无疑是非常麻烦的 , 所以我们可以使用greenlet模块可以非常简单地实现协程 import greenlet def eat(name): print(\"%s eat 1\" % name) # 如果协程从来没有被执行过,就会调用self.run() # 切换到play协程 g2.switch(\"Lyon\") # 执行完毕 print(\"%s eat 2\" % name) def play(name): print(\"%s play 1\" % name) # 切换到eat协程 g1.switch() # 没有切换回来,所以不执行 print(\"%s play 2\" % name) # 创建一个协程对象,不会执行 # greenlet(run=None, parent=None) g1 = greenlet.greenlet(eat) g2 = greenlet.greenlet(play) g1.switch(\"Lyon\") ''' 执行结果: Lyon eat 1 Lyon play 1 Lyon eat 2 ''' greenlet在没有IO的情况下或者没有重复开辟内存空间的操作下 , 反而会降低程序的执行速度 , 因为greenlet仅仅是单纯的切换 , 比如下面的例子 普通版本 import time def add1(): num = 1 for i in range(10000000): num *= i def add2(): num = 1 for i in range(10000000): num *= i start_time = time.time() add1() add2() end_time = time.time() print(end_time - start_time) ''' 执行结果: 1.015699863433838 ''' greenlet版本 import greenlet import time def add1(): num = 1 for i in range(10000000): num *= i g2.switch() def add2(): num = 1 for i in range(10000000): num *= i g1.switch() start_time = time.time() g1 = greenlet.greenlet(add1) g2 = greenlet.greenlet(add2) g1.switch() end_time = time.time() print(end_time - start_time) ''' 执行结果: 6.432543992996216 ''' greenlet只是提供了一种比generator(yield)更加快捷的切换方式 , 当切到一个任务执行时如果遇到IO , 那就原地阻塞 , 仍然是没有解决遇到IO自动切换来提升效率的问题 , 所以为了真正的提高效率 , 我们就需要使用Gevent模块了 Gevent 🍀 Gevent是一个第三方库 , 可以通过gevent轻松实现并发同步或异步编程 , 在gevent中用到的主要模式是Greenlet , 它是以C扩展模块形式接入Python的轻量级协程 简单使用介绍 # 在gevent库中,主要使用Greenlet模式 # 创建一个协程对象,参数通过Greenlet.__init__传递 g = gevent.spawn(run=None, *args, **kwargs) # 等待协程执行完毕,或者超时结束 g.join(timeout=None) # 将上述两步并一步 gevent.joinall(greenlets, timeout=None, raise_error=False, count=None) # 让协程睡眠 gevent.sleep(seconds=0, ref=True) # 更多详细介绍请阅读官方文档 IO阻塞自动切换 import gevent def eat(name): print('%s eat 1' % name) # 睡2秒 gevent.sleep(2) print('%s eat 2' % name) def play(name): print('%s play 1' % name) # 睡1秒 gevent.sleep(1) print('%s play 2' % name) # 创建协程实例 g1 = gevent.spawn(eat, 'Lyon') g2 = gevent.spawn(play, 'Lyon') # join中由执行开关 g1.join() g2.join() # gevent.joinall([g1,g2]) print('End of main thread...') PS : 上例中gevent.sleep(2) 模拟的是gevent可以识别的IO阻塞 , 如果是不能直接识别的需要将from gevent import monkey ; monkey.patch_all()放到文件的开头 Gevent同步与异步 from gevent import spawn, joinall, monkey # 打补丁,使其能直接识别 monkey.patch_all() import time def task(pid): \"\"\" Some non-deterministic task \"\"\" time.sleep(0.5) print('Task %s done' % pid) # 异步执行 def synchronous(): for i in range(10): task(i) # 同步执行 def asynchronous(): greenlet_list = [spawn(task, i) for i in range(10)] joinall(greenlet_list) if __name__ == '__main__': print('Synchronous:') synchronous() print('Asynchronous:') asynchronous() Gevent实例 🍀 爬虫 from gevent import monkey monkey.patch_all() import gevent import requests import time def get_page(url): print('GET: %s' % url) response = requests.get(url) if response.status_code == 200: print('%d bytes received from %s' % (len(response.text), url)) start_time = time.time() gevent.joinall([ gevent.spawn(get_page, 'https://www.python.org/'), gevent.spawn(get_page, 'https://www.yahoo.com/'), ]) end_time = time.time() print('run time is %s' % (end_time - start_time)) socket并发 server.py from gevent import monkey monkey.patch_all() import socket import gevent def server(server_ip, port): s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) s.bind((server_ip, port)) s.listen(5) while True: conn,addr = s.accept() gevent.spawn(talk, conn, addr) def talk(conn, addr): try: while True: res = conn.recv(1024) print('Client %s:%s msg: %s' % (addr[0], addr[1], res)) conn.send(res.upper()) except Exception as e: print(e) finally: conn.close() if __name__ == '__main__': server('127.0.0.1', 8080) client.py import socket client = socket.socket(socket.AF_INET,socket.SOCK_STREAM) client.connect(('127.0.0.1', 8080)) while True: msg = input('>>: ').strip() if not msg: continue client.send(msg.encode('utf-8')) msg = client.recv(1024) print(msg.decode('utf-8')) "},"01-Python/06-Concurrent/06-Python - 并发编程之IO多路复用.html":{"url":"01-Python/06-Concurrent/06-Python - 并发编程之IO多路复用.html","title":"Python - 并发编程之IO多路复用","keywords":"","body":"Python - 并发编程之IO多路复用 前言 🍀 在网络编程中 , 如果服务端需要面临同时接收上千甚至上万次的客户端请求 , 利用 \"进程池\" 或 \"线程池\" 或许可以缓解部分压力 , 但是并不是一个好的选择 , 因为超过数量还是得等 ; 又或者线程一旦进行堵塞 ; 以及任务之间的高度独立 , 并不需要互相通信或者等待时 , 我们就需要用到I/O多路复用(IO Multiplexing) 了 , 又叫做事件驱动IO (Event driven IO) I/O多路复用 🍀 I/O多路复用是指单个线程中 , 通过记录跟踪每个I/O流(sock)的状态 , 来同时管理多个I/O流 在I/O多路复用中只要一遇到IO就注册一个事件 , 然后主程序就可以继续干其他的事情了 , 直到IO处理完毕 , 继续恢复之前中断的任务 , 也就是说一个线程可以同时处理多个请求 举🌰 在UI编程中 , 常常要对鼠标点击进行响应 , 还要同时对键盘敲击也进行响应 多进程多线程方式 : 创建一个进程 , 进程中由两个线程 , 一个循环检测鼠标点击 , 一个循环检测键盘敲击 , 一旦检测到有情况就再开一个线程去处理 , 然后一直开下去......基本上是由创建进程/线程 , 维护进程/线程来解决的 , 这样对于CPU的资源是很浪费的 IO多路复用(事件驱动) : 创建一个事件(消息)队列 , 鼠标点击就往队列中增加一个鼠标点击事件 , 键盘敲击就往队列中增加一个键盘敲击事件 , 创建一个线程(IO线程)负责不断从队列中取出事件 , 根据不同的事件 , 调用不同的函数 , 如onClick() , onKeyDown()等 , 即一个线程解决了所有事件的问题 , 这就是复用 比较 : 与多进程多线程技术相比 , I/O多路复用最大的优势是系统开销小 , 系统不必创建进程/线程 , 也不必维护这些进程/线程 , 从而大大减小了系统的开销 目前常见支持I/O多路复用的系统调用select , poll , epoll ,I/O多路复用就是通过一种机制 , 一个进程可以监视多个描述符 , 一旦某个描述符就绪(一般是读就绪或者写就绪) , 能够通知程序进行相应的读写操作 而I/O多路复用的具体实现就是 , select , poll , epoll Select 🍀 select 监视的文件描述符(FD)分3类 , 分别是writefds、readfds和exceptfds , 程序启动后select函数会阻塞 , 直到有描述符就绪(有数据 可读、可写、或者有except) , 或者超时(timeout指定等待时间 , 如果立即返回设为null即可) , 函数返回 , 当select函数返回后 , 可以通过遍历fdset , 来找到就绪的描述符 I/O多路复用概念被提出来后 , select是第一个实现的 , select虽然实现了I/O多路复用 , 但是暴露出了很多问题 : select 会修改传入的参数数组 , 这对于一个需要调用很多次的函数 , 是非常不友好的 select 如果任何一个sokc(I/O stream) 出现了数据 , select仅仅会返回 , 但是并不会告诉你是哪个sock上有数据 , 于是你只能自己一个一个的找 , 十几个sock还好 , 但是数量一旦多了 , 这无谓的开销可就大了 select 只能监视1024个链接 select对socket进行扫描时是线性扫描 , 即采用轮询的方法 , 效率较低 select 不是线程安全的 , 如果你把一个sock(I/O stream) 加入到select , 然后突然另外一个线程发现这个sock不用 , 需要收回 , 那么对不起 , select不支持 , 并且如果你想关掉这个sock , 那么select的标准行为是不可预测的 If a file descriptor being monitored by select() is closed in another thread , the result is unspecified Python实现select模型代码 import select import socket sk1 = socket.socket() sk1.bind(('127.0.0.1', 8002, )) sk1.listen() demo_li = [sk1] outputs = [] message_dict = {} while True: r_list, w_list, e_list = select.select(sk1, outputs, [], 1) print(len(demo_li),r_list) for sk1_or_conn in r_list: if sk1_or_conn == sk1: conn, address = sk1_or_conn.accept() demo_li.append(conn) message_dict[conn] = [] else: try: data_bytes = sk1_or_conn.recv(1024) # data_str = str(data_bytes, encoding=\"utf-8\") # print(data_str) # sk1_or_conn.sendall(bytes(data_str+\"good\", encoding=\"utf-8\")) except Exception as e: demo_li.remove(sk1_or_conn) else: data_str = str(data_bytes, encoding=\"utf-8\") message_dict[sk1_or_conn].append(data_str) outputs.append(sk1_or_conn) for conn in w_list: recv_str = message_dict[conn][0] del message_dict[conn][0] conn.sendall(bytes(recv_str+\"Good\", encoding=\"utf-8\")) outputs.remove(conn) Poll 🍀 poll本质上和select没有区别 , 它将用户传入的数组拷贝到内核空间 , 然后查询每个fd对应的设备状态 , 如果设备就绪则在设备等待队列中加入一项并继续遍历 , 如果遍历完所有fd后没有发现就绪设备 , 则挂起当前进程 , 直到设备就绪或者主动超时 , 被唤醒后它又要再次遍历fd , 这个过程经历了多次无谓的遍历 它没有最大连接数的限制 , 原因是它是基于链表来存储的 , 但是同样有缺点 : 大量的fd的数组被整体复制于用户态和内核地址空间之间 , 而不管这样的复制是不是有意义 poll还有一个特点是\"水平触发\" , 如果报告了fd后 , 没有被处理 , 那么下次poll时会再次报告该fd 同样不是线程安全的 Epoll 🍀 poll是在2.6内核中提出的 , 是之前的select和poll的增强版本 , 相对于select和poll来说 , epoll更加灵活 , 没有描述符限制 ; epoll使用一个文件描述符管理多个描述符 , 将用户关系的文件描述符的事件存放到内核的一个事件表中 , 这样在用户空间和内核空间的copy只需一次 基本原理 : epoll支持水平触发和边缘触发 , 最大的特点在于边缘触发 , 它只告诉进程哪些fd刚刚变为就绪态 , 并且只会通知一次 ; 还有一个特点是 , epoll使用\"事件\"的就绪通知方式 , 通过epoll_ctl注册fd , 一旦该fd就绪 , 内核就会采用类似callback的回调机制来激活该fd , epoll_wait便可以收到通知 epoll的优点 : 没有最大并发连接的限制 , 能打开的FD的上限远大于1024(1G的内存上能监听约10万个端口) 效率提升 , 不是轮询的方式 , 不会随着FD数目的增加效率下降 , 只有活跃可用的FD才会调用callback函数 ; 即Epoll最大的优点就在于它只管你\"活跃\"的连接 , 而跟连接总数无关 , 因此在实际的网络环境中 , Epoll的效率就会远远高于select和poll 内存拷贝 , 利用mmap()文件映射内存加速与内核空间的消息传递 ; 即epoll使用mmap减少复制开销 是线程安全的 epoll对文件描述符的操作有两种模式 : LT(level trigger)和ET(edge trigger) , LT模式是默认模式 , LT模式与ET模式的区别如下 : LT模式 : 当epoll_wait检测到描述符事件发生并将此事件通知应用程序 , 应用程序可以不立即处理该事件 , 下次调用epoll_wait时 , 会再次响应应用程序并通知此事件 ET模式 : 当epoll_wait检测到描述符事件发生并将此事件通知应用程序 , 应用程序必须立即处理该事件 , 如果不处理 , 下次调用epoll_wait时 , 不会再次响应应用程序并通知此事件 LT模式 LT(level triggered)是缺省的工作方式 , 并且同时支持block和no-block socket , 在这种做法中 , 内核告诉你一个文件描述符是否就绪了 , 然后你可以对这个就绪的fd进行IO操作 , 如果你不作任何操作 , 内核还是会继续通知你的 ET模式 ET(edge-triggered)是高速工作方式 , 只支持no-block socket , 在这种模式下 , 当描述符从未就绪变为就绪时 , 内核通过epoll告诉你 , 然后它会假设你知道文件描述符已经就绪 , 并且不会再为那个文件描述符发送更多的就绪通知 , 直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如 , 你在发送 , 接收或者接收请求 , 或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误) , 但是请注意 , 如果一直不对这个fd作IO操作(从而导致它再次变成未就绪) , 内核不会发送更多的通知(only once) , ET模式在很大程度上减少了epoll事件被重复触发的次数 , 因此效率要比LT模式高 , epoll工作在ET模式的时候 , 必须使用非阻塞套接口 , 以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死 在select/poll中 , 进程只有在调用一定的方法后 , 内核才对所有监视的文件描述符进行扫描 , 而epoll事先通过epoll_ctl()来注册一个文件描述符 , 一旦基于某个文件描述符就绪时 , 内核会采用类似callback的回调机制 , 迅速激活这个文件描述符 , 当进程调用epoll_wait()时便得到通知 (此处去掉了遍历文件描述符 , 而是通过监听回调的的机制 , 这正是epoll的魅力所在) "},"01-Python/06-Concurrent/Python - 实现线程池.html":{"url":"01-Python/06-Concurrent/Python - 实现线程池.html","title":"Python - 实现线程池","keywords":"","body":"Python - 实现线程池 🍀 方式一 🍀 import Queue import threading class ThreadPool(object): def __init__(self, max_num=20): self.queue = Queue.Queue(max_num) for i in xrange(max_num): self.queue.put(threading.Thread) def get_thread(self): return self.queue.get() def add_thread(self): self.queue.put(threading.Thread) \"\"\" 使用: pool = ThreadPool(10) def func(arg, p): import time time.sleep(2) p.add_thread() for i in range(30): thread = pool.get_thread() t = thread(target=func, args=(i, pool)) t.start() \"\"\" 方式二 🍀 import queue import threading import contextlib import time StopEvent = object() class ThreadPool(object): def __init__(self, max_num, max_task_num = None): if max_task_num: self.q = queue.Queue(max_task_num) else: self.q = queue.Queue() self.max_num = max_num self.cancel = False self.terminal = False self.generate_list = [] self.free_list = [] def run(self, func, args, callback=None): \"\"\" 线程池执行一个任务 :param func: 任务函数 :param args: 任务函数所需参数 :param callback: 任务执行失败或成功后执行的回调函数，回调函数有两个参数1、任务函数执行状态；2、任务函数返回值（默认为None，即：不执行回调函数） :return: 如果线程池已经终止，则返回True否则None \"\"\" if self.cancel: return if len(self.free_list) == 0 and len(self.generate_list) "},"01-Python/07-Standard-Library/":{"url":"01-Python/07-Standard-Library/","title":"Standard-Library","keywords":"","body":"The road to Python - Standard-Library "},"01-Python/07-Standard-Library/Python - 标准库之os.html":{"url":"01-Python/07-Standard-Library/Python - 标准库之os.html","title":"Python - 标准库之os","keywords":"","body":"Python - 标准库之os 介绍 🍀 os模块为我们提供了与操作系统相关的诸多接口 在Python中 , 使用字符串类型来表示文件名 , 命令行参数和环境变量 os模块功能总体分为以下几个部分 : 当前进程和用户操作 文件描述符操作 文件和目录操作 进程管理 调度程序接口 (仅在一些Unix平台上) 系统信息处理 总体概况 DESCRIPTION This exports: - all functions from posix, nt or ce, e.g. unlink, stat, etc. - os.path is either posixpath or ntpath - os.name is either 'posix', 'nt' or 'ce'. - os.curdir is a string representing the current directory ('.' or ':') - os.pardir is a string representing the parent directory ('..' or '::') - os.sep is the (or a most common) pathname separator ('/' or ':' or '\\\\') - os.extsep is the extension separator (always '.') - os.altsep is the alternate pathname separator (None or '/') - os.pathsep is the component separator used in $PATH etc - os.linesep is the line separator in text files ('\\r' or '\\n' or '\\r\\n') - os.defpath is the default search path for executables - os.devnull is the file path of the null device ('/dev/null', etc.) 注意 : 在os模块中有很多方法只有在Unix系统上才能使用 由于os模块提供的方法太多 , 所以本文仅介绍一些在windows下常用的方法 OS 🍀 os.getcwd() \"\"\" Return a string representing the current working directory. \"\"\" os.chdir(path) \"\"\" Change the current working directory to path. \"\"\" os.curdir \"\"\" The constant string used by the operating system to refer to the current directory. This is '.' for Windows and POSIX. Also available via os.path. \"\"\" os.pardir \"\"\" The constant string used by the operating system to refer to the parent directory. This is '..' for Windows and POSIX. Also available via os.path. \"\"\" os.makedirs(name, mode=0o777, exist_ok=False) \"\"\" Recursive directory creation function. Like mkdir(), but makes all intermediate-level directories needed to contain the leaf directory. \"\"\" os.removedirs(name) \"\"\" Remove directories recursively. Works like rmdir() except that, if the leaf directory is successfully removed, removedirs() tries to successively remove every parent directory mentioned in path until an error is raised \"\"\" os.rmdir(path, *, dir_fd=None) \"\"\" Remove (delete) the directory path. Only works when the directory is empty, otherwise, OSError is raised. In order to remove whole directory trees, shutil.rmtree() can be used. \"\"\" os.listdir(path='.') \"\"\" Return a list containing the names of the entries in the directory given by path. The list is in arbitrary order, and does not include the special entries '.' and '..' even if they are present in the directory. \"\"\" os.remove(path, *, dir_fd=None) \"\"\" Remove (delete) the file path. If path is a directory, OSError is raised. Use rmdir() to remove directories. \"\"\" os.rename(src, dst, *, src_dir_fd=None, dst_dir_fd=None) \"\"\" Rename the file or directory src to dst. \"\"\" os.stat(path, *, dir_fd=None, follow_symlinks=True) \"\"\" Get the status of a file or a file descriptor. \"\"\" os.sep \"\"\" The character used by the operating system to separate pathname components. This is '/' for POSIX and '\\\\' for Windows. \"\"\" os.linesep \"\"\" The string used to separate (or, rather, terminate) lines on the current platform. This may be a single character, such as '\\n' for POSIX, or multiple characters, for example, '\\r\\n' for Windows. \"\"\" os.pathsep \"\"\" The character conventionally used by the operating system to separate search path components (as in PATH), such as ':' for POSIX or ';' for Windows. Also available via os.path. \"\"\" os.name \"\"\" The name of the operating system dependent module imported. The following names have currently been registered: 'posix', 'nt', 'java'. \"\"\" os.system(command) \"\"\" Execute the command (a string) in a subshell. \"\"\" os.popen(cmd, mode='r', buffering=-1) \"\"\" Open a pipe to or from command cmd. The return value is an open file object connected to the pipe, which can be read or written depending on whether mode is 'r' (default) or 'w'. \"\"\" os.environ \"\"\" A mapping object representing the string environment. \"\"\" 更多os模块相关 : os — Miscellaneous operating system interfaces OS.Path 🍀 os.path.abspath(path) \"\"\" Return a normalized absolutized version of the pathname path. On most platforms, this is equivalent to calling the function normpath() as follows: normpath(join(os.getcwd(), path)). \"\"\" os.path.exists(path) \"\"\" Return True if path refers to an existing path or an open file descriptor. Returns False for broken symbolic links. \"\"\" os.path.isabs(path) \"\"\" Return True if path is an absolute pathname. \"\"\" os.path.isfile(path) \"\"\" Return True if path is an existing regular file. \"\"\" os.path.isdir(path) \"\"\" Return True if path is an existing directory. \"\"\" os.path.join(path, *paths) \"\"\" Join one or more path components intelligently. \"\"\" os.path.getatime(path) \"\"\" Return the time of last access of path. \"\"\" os.path.getmtime(path) \"\"\" Return the time of last modification of path. \"\"\" os.path.getsize(path) \"\"\" Return the size, in bytes, of path. Raise OSError if the file does not exist or is inaccessible. \"\"\" 更多os.path相关 : os.path — Common pathname manipulations 补充 : 如果需要读取命令行上所有文件中的所有行 , 可以查看fileinput 模块 如果需要创建临时文件和目录 , 可以查看tempfile 模块 关于文件和文件集合的高级操作 , 可以查看shutil 模块 "},"01-Python/07-Standard-Library/Python - 标准库之random.html":{"url":"01-Python/07-Standard-Library/Python - 标准库之random.html","title":"Python - 标准库之random","keywords":"","body":"Python - 标准库之random 介绍 🍀 random模块为我们提供了各种分布的伪随机数生成器 random模块功能分为以下几个部分 : Bookkeeping functions Functions for integers Functions for sequences Real-valued distributions Bookkeeping functions 🍀 random.seed(a=None, version=2): \"\"\" Initialize the random number generator. \"\"\" random.getstate(): \"\"\" Return an object capturing the current internal state of the generator. This object can be passed to setstate() to restore the state. \"\"\" random.setstate(state): \"\"\" State should hava been obtained from a previous call to getstate(), and setstate() restores the internal state of the generator to what it was at the time getstate() was called. \"\"\" random.getrandbits(k): \"\"\" Returns a Python integer with k random bits. This method is supplied with the Mersenne Twister generator and some other generators may also provide it as an optional part of the API. When available, getrandbits() enables randrange() to handle arbitrarily large ranges. \"\"\" Functions for integers 🍀 random.randrange(stop) random.randrange(start, stop[, step]): \"\"\" Return a randomly selected element from range(start, stop, step). This is equivalent to choice(range(start, stop, step)), but doesn't actually build a range object. \"\"\" random.randint(a, b): \"\"\" Return a random integer N such that a Functions for sequences 🍀 random.choice(seq): \"\"\" Return a random element from the non-empty sequence seq. If seq is empty, raises IndexError. \"\"\" random.choices(population, weights=None, *, cum_weights=None, k=1): \"\"\" Return a k sized list of elements chosen from the population with replacement. If the population is empty, raises IndexError. \"\"\" random.shuffle(x[, random]): \"\"\" Shuffle the sequence x in place. \"\"\" random.sample(population, k): \"\"\" Return a k length list of unique elements chosen from the population sequence or set. Used for random sampling without replacement. \"\"\" Real-valued distributions 🍀 random.random(): \"\"\" Return the next random floating point number in the range [0.0, 1.0). \"\"\" random.uniform(a, b): \"\"\" Return a random floating point number N such that a 0 and beta > 0. Returned values range between 0 and 1. \"\"\" random.expovariate(lambd): \"\"\" Exponential distribution. lambd is 1.0 divided by the desired mean. \"\"\" random.gammavariate(alpha, beta): \"\"\" Gamma distribution. (Not the gamma function!) Conditions on the parameters are alpha > 0 and beta > 0. \"\"\" random.gauss(mu, sigma): \"\"\" Gaussian distribution. mu is the mean, and sigma is the standard deviation. This is slightly faster than the normalvariate() function defined below. \"\"\" random.lognormvariate(mu, sigma): \"\"\" Log normal distribution. \"\"\" random.normalvariate(mu, sigma): \"\"\" Normal distribution. mu is the mean, and sigma is the standard deviation. \"\"\" random.vonmisesvariate(mu, kappa): \"\"\" mu is the mean angle, expressed in radians between 0 and 2*pi, and kappa is the concentration parameter, which must be greater than or equal to zero. If kappa is equal to zero, this distribution reduces to a uniform random angle over the range 0 to 2*pi. \"\"\" random.paretovariate(alpha): \"\"\" Pareto distribution. alpha is the shape parameter. \"\"\" random.weibullvariate(alpha, beta): \"\"\" Weibull distribution. alpha is the scale parameter and beta is the shape parameter. \"\"\" Examples and Recipes 🍀 Basic examples : >>> import random >>> random.random() # Random float: 0.0 >> random.uniform(2.5, 10.0) # Random float: 2.5 >> random.expovariate(1 / 5) # Interval between arrivals averaging 5 seconds 5.148957571865031 >>> random.randrange(10) # Integer from 0 to 9 inclusive 7 >>> random.randrange(0, 101, 2) # Even integer from 0 to 100 inclusive 26 >>> random.choice(['win', 'lose', 'draw']) # Single random element from a sequence 'draw' >>> deck = 'ace two three four'.split() >>> random.shuffle(deck) # Shuffle a list >>> deck ['four', 'two', 'ace', 'three'] >>> random.sample([10, 20, 30, 40, 50], k=4) # Four samples without replacement [40, 10, 50, 30] Simulations : >>> # Six roulette wheel spins (weighted sampling with replacement) >>> random.choices(['red', 'black', 'green'], [18, 18, 2], k=6) ['red', 'green', 'black', 'black', 'red', 'black'] >>> # Deal 20 cards without replacement from a deck of 52 playing cards >>> # and determine the proportion of cards with a ten-value >>> # (a ten, jack, queen, or king). >>> import collections >>> deck = collections.Counter(tens=16, low_cards=36) >>> seen = random.sample(list(deck.elements()), k=20) >>> seen.count('tens') / 20 0.15 >>> # Estimate the probability of getting 5 or more heads from 7 spins >>> # of a biased coin that settles on heads 60% of the time. >>> trial = lambda: random.choices('HT', cum_weights=(0.60, 1.00), k=7).count('H') >= 5 >>> sum(trial() for i in range(10000)) / 10000 0.4169 >>> # Probability of the median of 5 samples being in middle two quartiles >>> trial = lambda : 2500 >> sum(trial() for i in range(10000)) / 10000 0.7958 更多random相关 : random — Generate pseudo-random numbers "},"01-Python/07-Standard-Library/Python - 标准库之sys.html":{"url":"01-Python/07-Standard-Library/Python - 标准库之sys.html","title":"Python - 标准库之sys","keywords":"","body":"Python - 标准库之sys 介绍 🍀 sys模块为我们提供了对解释器使用或维护的一些变量的访问 , 以及解释器交互的函数 sys模块总体分为四个部分 : Dynamic objects , 动态对象 Static objects , 静态对象 Functions , 函数 Data , 配置 Dynamic objects 🍀 argv -- command line arguments; argv[0] is the script pathname if known path -- module search path; path[0] is the script directory, else '' modules -- dictionary of loaded modules displayhook -- called to show results in an interactive session excepthook -- called to handle any uncaught exception other than SystemExit To customize printing in an interactive session or to install a custom top-level exception handler, assign other functions to replace these. stdin -- standard input file object; used by input() stdout -- standard output file object; used by print() stderr -- standard error object; used for error messages By assigning other file objects (or objects that behave like files) to these, it is possible to redirect all of the interpreter's I/O. last_type -- type of last uncaught exception last_value -- value of last uncaught exception last_traceback -- traceback of last uncaught exception These three are only available in an interactive session after a traceback has been printed. Static objects 🍀 builtin_module_names -- tuple of module names built into this interpreter copyright -- copyright notice pertaining to this interpreter exec_prefix -- prefix used to find the machine-specific Python library executable -- absolute path of the executable binary of the Python interpreter float_info -- a struct sequence with information about the float implementation. float_repr_style -- string indicating the style of repr() output for floats hash_info -- a struct sequence with information about the hash algorithm. hexversion -- version information encoded as a single integer implementation -- Python implementation information. int_info -- a struct sequence with information about the int implementation. maxsize -- the largest supported length of containers. maxunicode -- the value of the largest Unicode code point platform -- platform identifier prefix -- prefix used to find the Python library thread_info -- a struct sequence with information about the thread implementation. version -- the version of this interpreter as a string version_info -- version information as a named tuple dllhandle -- [Windows only] integer handle of the Python DLL winver -- [Windows only] version number of the Python DLL __stdin__ -- the original stdin; don't touch! __stdout__ -- the original stdout; don't touch! __stderr__ -- the original stderr; don't touch! __displayhook__ -- the original displayhook; don't touch! __excepthook__ -- the original excepthook; don't touch! Functions 🍀 displayhook() -- print an object to the screen, and save it in builtins._ excepthook() -- print an exception and its traceback to sys.stderr exc_info() -- return thread-safe information about the current exception exit() -- exit the interpreter by raising SystemExit getdlopenflags() -- returns flags to be used for dlopen() calls getprofile() -- get the global profiling function getrefcount() -- return the reference count for an object (plus one :-) getrecursionlimit() -- return the max recursion depth for the interpreter getsizeof() -- return the size of an object in bytes gettrace() -- get the global debug tracing function setcheckinterval() -- control how often the interpreter checks for events setdlopenflags() -- set the flags to be used for dlopen() calls setprofile() -- set the global profiling function setrecursionlimit() -- set the max recursion depth for the interpreter settrace() -- set the global debug tracing function Data 🍀 __stderr__ = ' mode='w' encoding='cp9... __stdin__ = ' mode='r' encoding='cp936... __stdout__ = ' mode='w' encoding='cp9... api_version = 1013 argv = [''] base_exec_prefix = r'C:\\Users\\Lyon\\AppData\\Local\\Programs\\Python\\Pytho... base_prefix = r'C:\\Users\\Lyon\\AppData\\Local\\Programs\\Python\\Python35' builtin_module_names = ('_ast', '_bisect', '_codecs', '_codecs_cn', '_... byteorder = 'little' copyright = 'Copyright (c) 2001-2016 Python Software Foundati...ematis... dllhandle = 1373306880 dont_write_bytecode = False exec_prefix = r'C:\\Users\\Lyon\\AppData\\Local\\Programs\\Python\\Python35' executable = r'C:\\Users\\Lyon\\AppData\\Local\\Programs\\Python\\Python35\\py... flags = sys.flags(debug=0, inspect=0, interactive=0, opt...ing=0, quie... float_info = sys.float_info(max=1.7976931348623157e+308, max_...epsilo.. . float_repr_style = 'short' hash_info = sys.hash_info(width=64, modulus=2305843009213693...iphash2... hexversion = 50660080 implementation = namespace(cache_tag='cpython-35', hexversion=506...in... int_info = sys.int_info(bits_per_digit=30, sizeof_digit=4) maxsize = 9223372036854775807 maxunicode = 1114111 meta_path = [, , '_ast': , >> ' ps2 = '... ' stderr = ' mode='w' encoding='cp936'> stdin = ' mode='r' encoding='cp936'> stdout = ' mode='w' encoding='cp936'> thread_info = sys.thread_info(name='nt', lock=None, version=None) version = '3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1... version_info = sys.version_info(major=3, minor=5, micro=2, releaseleve.. . warnoptions = [] winver = '3.5' 更多见 : sys — System-specific parameters and functions "},"01-Python/07-Standard-Library/Python - 标准库之wsgiref.html":{"url":"01-Python/07-Standard-Library/Python - 标准库之wsgiref.html","title":"Python - 标准库之wsgiref","keywords":"","body":"Python - 标准库之wsgiref 介绍 🍀 wsgiref模块是WSGI规范的一个参考实现 , 它可以用于将WSGI支持添加到Web服务器或框架中 , 它提供了用于操作WSGI环境变量和响应头的实用工具 、 用于实现WSGI服务器的基类 、 用于服务WSGI应用程序的样本HTTP服务器 、以及检查WSGI服务器和应用程序的验证工具 , 以满足WSGI规范(PEP3333) 包内容 handlers - server/gateway base classes headers - WSGI response header tools simple_server - a simple WSGI HTTP server util - WSGI environment utilities validate - WSGI conformance checker handlers 🍀 这个模块提供了用于实现WSGI服务器和网关的基本处理程序类 . 这些基类处理与WSGI应用程序通信的大部分工作 , 只要它们提供了一个CGI-like环境 , 以及输入、输出和错误流 CLASSES builtins.object BaseHandler \"\"\"管理WSGI应用程序的调用\"\"\" SimpleHandler \"\"\"初始化数据流,环境等的处理程序\"\"\" BaseCGIHandler \"\"\"CGI-like系统,使用输入/输出/错误流和环境映射\"\"\" CGIHandler \"\"\"CGI-based调用,通过sys.stdin/stdout/stderr和os.environ\"\"\" IISCGIHandler \"\"\"CGI-based调用与IIS路径错误的解决方法\"\"\" # 由上到下是一个基类到子类的过程 以上类中主要的实现在BaseHandler中 , 其它几个都是在基类基础上做了简单的实现 FUNCTIONS read_environ() \"\"\"读取环境,修改HTTP变量\"\"\" 本文中所有思维导图全部来自这里 , 点我吧 对于各个类中的具体实现 , 可以去阅读源代码https://pypi.python.org/pypi/wsgiref headers 🍀 这个模块提供了一个类(Headers) , 可以使用mapping-like的接口来方便地操作WSGI响应头 , 也就是一个类似于dict的数据结构 , 并且其实现了dict操作中的get , keys , values 函数 CLASSES builtins.object Headers class Headers(builtins.object) \"\"\"管理一个HTTP响应头的集合\"\"\" headers思维导图 ! simple_server 🍀 这个模块实现了一个WSGI应用程序的简单HTTP服务器 (基于HTTP.server) , 每个服务器实例都在给定的主机和端口上提供一个WSGI应用 CLASSES http.server.BaseHTTPRequestHandler(socketserver.StreamRequestHandler) WSGIRequestHandler # WSGIRequestHandler继承体系 # +--------------------+ # | BaseRequestHandler | # +--------------------+ # ↓ # +-----------------------+ # | StreamRequestHandler | # +-----------------------+ # ↓ # +------------------------+ # | BaseHTTPRequestHandler | # +------------------------+ # ↓ # +--------------------+ # | WSGIRequestHandler | # +--------------------+ http.server.HTTPServer(socketserver.TCPServer) WSGIServer # WSGIServer继承体系 # +------------+ # | BaseServer | # +------------+ # ↓ # +------------+ # | TCPServer | # +------------+ # ↓ # +------------+ # | HTTPServer | # +------------+ # ↓ # +------------+ # | WSGIServer | # +------------+ class WSGIRequestHandler(http.server.BaseHTTPRequestHandler) \"\"\"HTTP请求处理程序基类\"\"\" class WSGIServer(http.server.HTTPServer) \"\"\"实现Python WSGI协议的BaseHTTPServer\"\"\" FUNCTIONS demo_app(environ, start_response) \"\"\"应用程序部分\"\"\" make_server(host, port, app, server_class=, handler_class=) \"\"\"创建一个新的WSGI服务器,监听主机和端口\"\"\" simple_server思维导图 simple_server模块主要有两部分内容 应用程序 函数demo_app是应用程序部分 服务器程序 服务器程序主要分成Server和Handler两部分 , 另外make_server函数用来生成一个服务器实例 图上可知simple_server中还有一个ServerHandler模块 , 它继承于handlers模块中的SimpleHandler , 继承体系如下 # +-------------+ # | BaseHandler | # +-------------+ # ↓ # +----------------+ # | SimpleHandler | # +----------------+ # ↓ # +---------------+ # | ServerHandler | # +---------------+ 该模块主要完成的功能如下 : 启动服务器 模块用户请求 处理用户请求 执行simple_server.py时内容如下 httpd = make_server('', 8000, demo_app) sa = httpd.socket.getsockname() print \"Serving HTTP on\", sa[0], \"port\", sa[1], \"...\" # M: webbrowser provides a high-level interface to allow displaying Web-based documents # to users. Under most circumstances import webbrowser webbrowser.open('http://localhost:8000/xyz?abc') httpd.handle_request() # serve one request, then exit demo_app 🍀 demo_app(environ, start_response) ''' 参数说明: environ:为一个字典 start_response:为一个可调用函数 return:返回一个可迭代对象 另外demo_app中会调用start_response函数 ''' def demo_app(environ,start_response): from StringIO import StringIO stdout = StringIO() print >> stdout, \"Hello world!\" print >> stdout h = environ.items() h.sort() for k,v in h: print >> stdout, k,'=',`v` start_response(\"200 OK\", [('Content-Type','text/plain')]) return [stdout.getvalue()] make_server 🍀 def make_server(host, port, app, server_class=WSGIServer, handler_class=WSGIRequestHandler) ''' 参数说明: host:主机名 port:端口号 server_class:生成server实例时所使用的基类,默认为WSGIServer handler_class:用于处理请求的handler类,默认为WSGIRequestHandler ''' def make_server(host, port, app, server_class=WSGIServer, handler_class=WSGIRequestHandler): '''引用no_1y的注释,文尾有详细链接''' # no_1y: -> HTTPServer.__init__ # -> TCPServer.__init__ # -> TCPServer.server_bind # -> TCPServer.socket.bind # -> TCPServer.server_activate # -> TCPServer.socket.listen server = server_class((host, port), handler_class) # no_1y: conresponding to WSGIRequestHandler.handle() # -> handler.run(self.server.get_app()) server.set_app(app) return server \"\"\" server_class为WSGIServer,生成时会沿着继承方向到达最底层的TCPServer,并完成对socket的绑定和监听 set_app设置了app,它会在handler_class的handle函数中被取出来,交给handler的run函数执行 \"\"\" util 🍀 这个模块提供了用于处理WSGI环境的各种实用函数 , WSGI环境是一个包含在PEP 3333中描述的HTTP请求变量的字典 CLASSES builtins.object FileWrapper class FileWrapper(builtins.object): \"\"\" 将文件类对象转换为迭代器的包装器 \"\"\" FUNCTIONS application_uri(environ) \"\"\"返回应用程序的基本URI\"\"\" guess_scheme(environ) \"\"\"返回一个猜测wsgi.url_scheme是否是http或https\"\"\" request_uri(environ, include_query=True) \"\"\"返回完整的请求URI,包括任意的查询字符串\"\"\" setup_testing_defaults(environ) \"\"\"用于设置虚拟环境的服务器和应用程序,目的是使WSGI的单元测试更加容易\"\"\" shift_path_info(environ) \"\"\"将一个名称从PATH_INFO转移到SCRIPT_NAME,并返回它,如果在pathinfo中没有其他路径段，则返回None\"\"\" util思维导图 validate 🍀 在创建新的WSGI应用程序对象 , 框架 , 服务器或中间件时 , 使用wsgiref.validate验证新代码的一致性是很有用的 这个模块提供了一个函数 , 它创建了WSGI应用程序对象 , 它可以验证WSGI服务器或网关和WSGI应用程序对象之间的通信 , 从而检查双方是否符合协议的一致性 简单的说就是检查你对WSGI的实现是否满足标准 思维导图如下 本文主要参考http://blog.csdn.net/on_1y/article/details/18818081 思维导图来自https://github.com/minixalpha/SourceLearning/tree/master/wsgiref-0.1.2 "},"01-Python/08-Third-Library/":{"url":"01-Python/08-Third-Library/","title":"Third-Library","keywords":"","body":"The road to Python - Third-Library "},"01-Python/08-Third-Library/04-Python - 第三方库之PyMySQL.html":{"url":"01-Python/08-Third-Library/04-Python - 第三方库之PyMySQL.html","title":"Python - 第三方库之PyMySQL","keywords":"","body":"Python - 第三方库之PyMySQL 介绍 🍀 pymysql是用于Python 3.x 链接MySQL数据库的一个第三方库 , 其使用方法和MySQLdb几乎相同 , pymysql的目的就是为了称为MySQLdb的替代品 , 因为MySQLdb不支持Python 3.x以后的版本 安装 $ pip install PyMySQL 包内容 PACKAGE CONTENTS _compat _socketio charset connections constants (package) converters cursors err optionfile tests (package) times util 使用 🍀 包中我们主要需要了解connectinos.py 中的内容 在pymysql包中我们只需要使用Connect() 来创建一个Connection对象 def Connect(*args, **kwargs): \"\"\" Connect to the database; see connections.Connection.__init__() for more information. \"\"\" from .connections import Connection return Connection(*args, **kwargs) # 返回一个Connection对象 Connection.__init __() 参数如下 Connect(*args, **kwargs) Establish a connection to the MySQL database. Accepts several arguments: host: Host where the database server is located user: Username to log in as password: Password to use. database: Database to use, None to not use a particular one. port: MySQL port to use, default is usually OK. (default: 3306) bind_address: When the client has multiple network interfaces, specify the interface from which to connect to the host. Argument can be a hostname or an IP address. unix_socket: Optionally, you can use a unix socket rather than TCP/IP. charset: Charset you want to use. sql_mode: Default SQL_MODE to use. read_default_file: Specifies my.cnf file to read these parameters from under the [client] section. conv: Conversion dictionary to use instead of the default one. This is used to provide custom marshalling and unmarshaling of types. See converters. use_unicode: Whether or not to default to unicode strings. This option defaults to true for Py3k. client_flag: Custom flags to send to MySQL. Find potential values in constants.CLIENT. cursorclass: Custom cursor class to use. init_command: Initial SQL statement to run when connection is established. connect_timeout: Timeout before throwing an exception when connecting. (default: 10, min: 1, max: 31536000) ssl: A dict of arguments similar to mysql_ssl_set()'s parameters. For now the capath and cipher arguments are not supported. read_default_group: Group to read from in the configuration file. compress; Not supported named_pipe: Not supported autocommit: Autocommit mode. None means use server default. (default: False) local_infile: Boolean to enable the use of LOAD DATA LOCAL command. (default: False) max_allowed_packet: Max size of packet sent to server in bytes. (default: 16MB) Only used to limit size of \"LOAD LOCAL INFILE\" data packet smaller than default (16KB). defer_connect: Don't explicitly connect on contruction - wait for connect call. (default: False) auth_plugin_map: A dict of plugin names to a class that processes that plugin. The class will take the Connection object as the argument to the constructor. The class needs an authenticate method taking an authentication packet as an argument. For the dialog plugin, a prompt(echo, prompt) method can be used (if no authenticate method) for returning a string from the user. (experimental) db: Alias for database. (for compatibility to MySQLdb) passwd: Alias for password. (for compatibility to MySQLdb) 连接数据库 🍀 import pymysql # 连接MySQL数据库 connection = pymysql.connect(host='localhost', port=3306, user='root', password='myroot', db='mydatabase', charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor) pymysql包中的cursors.py 中的class Cursor(object) 可供我们建立与数据库进行交互的对象 , cursor(游标) , 下面就开始与数据库进行交互了 创建表 🍀 import pymysql.cursors # 连接MySQL数据库 connection = pymysql.connect(host='localhost', port=3306, user='root', password='myroot', db='mydatabase', charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor) try: # 创建游标实例 with connection.cursor() as cursor: sql = \"\"\"CREATE TABLE EMPLOYEE ( FIRST_NAME CHAR(20) NOT NULL, LAST_NAME CHAR(20), AGE INT, SEX CHAR(1), INCOME FLOAT );\"\"\" # 执行sql,并返回受影响行数 cursor.execute(sql) # executemany()可一次性执行多个sql语句,提高了多行插入的性能 # 提交,不然无法保存新建或者修改的数据 connection.commit() finally: connection.close() execute介绍 def execute(self, query, args=None): \"\"\"Execute a query :param str query: Query to execute. :param args: parameters used with query. (optional) :type args: tuple, list or dict :return: Number of affected rows :rtype: int If args is a list or tuple, %s can be used as a placeholder in the query. If args is a dict, %(name)s can be used as a placeholder in the query. \"\"\" # list example cursor.execute(\"update hosts set host = '1.1.1.2' where nid > %s\", (1,)) # tuple example cursor.execute(\"insert into hosts(host,color_id) values(%s,%s)\", [(\"1.1.1.11\",1),(\"1.1.1.11\",2)]) 查询表 🍀 Python查询MySQL获取数据使用方法如下 : fetchone(self) : 获取下一行查询结果 fetchmany(self, size=None) : 获取size行数的查询结果 fetchall(self) : 获取全部的返回结果 rowcount : 这是一个只读属性 , 并返回执行execute() 方法后影响的行数 在fetch数据时按照顺序进行 , 可以使用scroll(num, mode)来移动游标位置 , 如 : cursor.scroll(1, mode='relative') , 相对当前位置移动 cursor.scroll(2, mode='absolute') , 相对绝对位置移动 import pymysql.cursors # 连接MySQL数据库 connection = pymysql.connect(host='localhost', port=3306, user='root', password='myroot', db='mydatabase', charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor) try: # 创建游标实例 with connection.cursor() as cursor: sql = \"SELECT * FROM user_info\" # 执行sql,并返回受影响行数 cursor.execute(sql) # 查询结果 result = cursor.fetchall() print(result) # 提交 connection.commit() finally: connection.close() ''' 执行结果: [{'username': 'Lyon', 'id': 1, 'password': '456'}] ''' 注意 : fetch默认获取的数据是元组类型 , 可以在建立cursor(游标)对象时 , 设置cursor属性进行修改 , 如设置为字典类型 : cursor(cursor=pymysql.cursors.DictCursor) 获取最新自增ID : cursor.lastrowid 修改表 🍀 import pymysql.cursors # 连接MySQL数据库 connection = pymysql.connect(host='localhost', port=3306, user='root', password='myroot', db='mydatabase', charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor) try: # 创建游标实例 with connection.cursor() as cursor: sql = \"UPDATE user_info SET password = '456' WHERE username = 'Lyon'\" # 执行sql,并返回受影响行数 effect_row = cursor.execute(sql) print(effect_row) # 提交 connection.commit() except: # 发生错误时回滚 connection.rollback() # 关闭连接 connection.close() 删除表 🍀 import pymysql.cursors # 连接MySQL数据库 connection = pymysql.connect(host='localhost', port=3306, user='root', password='myroot', db='mydatabase', charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor) try: # 创建游标实例 with connection.cursor() as cursor: sql = \"DROP TABLE EMPLOYEE\" # 执行sql,并返回影响行数 cursor.execute(sql) # 提交 connection.commit() finally: # 关闭连接 connection.close() "},"01-Python/08-Third-Library/05-Python - 第三方库之MySQLdb.html":{"url":"01-Python/08-Third-Library/05-Python - 第三方库之MySQLdb.html","title":"Python - 第三方库之MySQLdb","keywords":"","body":"Python - 第三方库之MySQLdb 介绍 🍀 MySQLdb是用于Python链接MySQL数据库的接口 , 它实现了Python数据库API规范V2.0 , 基于MySQL C API 上建立的 Python DB-API使用流程 : 导入API模块 获取与数据的连接 执行SQL语句和存储过程 关闭数据库连接 MySQLdb只支持Python 3.x之前的版本 , 在Python 3.x中则是用PyMySQL来代替 安装 https://sourceforge.net/projects/mysql-python/ # 安装相关教程可以通过google,baidu等进行查找 在上一篇已经介绍了PyMySQL , MySQLdb的用户与PyMySQL是一样的 , 所以这篇直接以实例进行整理 , 并补充对于事务的说明 连接数据库 🍀 import MySQLdb connection = MySQLdb.Connect(host='localhost', user='root', passwd='myroot', db='test', port='3306', charset='utf8') 创建表 🍀 import MySQLdb # 连接数据库 connection = MySQLdb.Connect(host='localhost', user='root', passwd='myroot', db='test', port='3306', charset='utf8') # 创建游标 cursor = connection.cursor() # 定义sql语句 sql = \"\"\"CREATE TABLE EMPLOYEE ( FIRST_NAME CHAR(20) NOT NULL, LAST_NAME CHAR(20), AGE INT, SEX CHAR(1), INCOME FLOAT )\"\"\" # 执行sql cursor.execute(sql) # 关闭连接 connection.close() 查询表 🍀 查询方法如下 : fetchone() : 获取下一条查询结果 , 结果集是一个对象 fetchall() : 获取全部查询结果 rowcount : 这是一个只读属性 , 并返回执行execute() 方法后的影响行数 import MySQLdb # 连接数据库 connection = MySQLdb.Connect(host='localhost', user='root', passwd='myroot', db='test', port='3306', charset='utf8') # 创建游标 cursor = connection.cursor() # 定义sql语句 sql = \"SELECT * FROM EMPLOYEE \\ WHERE INCOME > '%d'\" % (1000) try: # 执行SQL语句 cursor.execute(sql) # 获取所有记录列表 results = cursor.fetchall() for row in results: fname = row[0] lname = row[1] age = row[2] sex = row[3] income = row[4] # 打印结果 print \"fname=%s,lname=%s,age=%d,sex=%s,income=%d\" % \\ (fname, lname, age, sex, income ) except: print \"Error: unable to fecth data\" # 关闭连接 connection.close() 修改表 🍀 插入数据 import MySQLdb # 连接数据库 connection = MySQLdb.Connect(host='localhost', user='root', passwd='myroot', db='test', port='3306', charset='utf8') # 创建游标 cursor = connection.cursor() # 定义sql语句 sql = \"\"\"INSERT INTO EMPLOYEE(FIRST_NAME, LAST_NAME, AGE, SEX, INCOME) VALUES ('Mac', 'Mohan', 20, 'M', 2000)\"\"\" try: # 执行sql语句 cursor.execute(sql) # 提交到数据库执行 connection.commit() except: # 出现异常回滚 connection.rollback() # 关闭连接 connection.close() 更新数据 import MySQLdb # 连接数据库 connection = MySQLdb.Connect(host='localhost', user='root', passwd='myroot', db='test', port='3306', charset='utf8') # 创建游标 cursor = connection.cursor() # 定义sql语句 sql = \"UPDATE EMPLOYEE SET AGE = AGE + 1 WHERE SEX = '%c'\" % ('M') try: # 执行SQL语句 cursor.execute(sql) # 提交到数据库执行 connection.commit() except: # 发生错误时回滚 connection.rollback() # 关闭连接 connection.close() 删除表 🍀 import MySQLdb # 连接数据库 connection = MySQLdb.Connect(host='localhost', user='root', passwd='myroot', db='test', port='3306', charset='utf8') # 创建游标 cursor = connection.cursor() # 定义sql语句 sql = \"DELETE FROM EMPLOYEE WHERE AGE > '%d'\" % (20) try: # 执行SQL语句 cursor.execute(sql) # 提交修改 connection.commit() except: # 发生错误时回滚 connection.rollback() # 关闭连接 connection.close() 事务 🍀 事务机制是为了确保数据的一致性 事务应该具有4个属性 : 原子性 : 一个事务是一个不可分割的工作单位 , 事务中包括的诸操作要么都做 , 要么都不做 一致性 : 事务必须是数据库从一个一致性状态变到另一个一致性状态 , 一致性与原子性是密切相关的 隔离性 : 一个事务的执行不能被其他事务干扰 , 即一个事务内部的操作及使用的数据对并发的其他事务是隔离的 , 并发执行的各个事务之间不能互相干扰 持久性 : 也成为永久性 , 指一个事务一旦提交 , 它对数据库中数据的改变就应该是永久性的 , 接下来的其他操作或故障不应该对其有任何影响 Python DB-API 2.0的事务提供了两个方法 commit 和rollback , 在上述实例中已经见过了 try: # 执行SQL语句 cursor.execute(sql) # 向数据库提交 connection.commit() except: # 发生错误时回滚 connection.rollback() "},"01-Python/08-Third-Library/06-Python - 第三方库之SQlAlchemy.html":{"url":"01-Python/08-Third-Library/06-Python - 第三方库之SQlAlchemy.html","title":"Python - 第三方库之SQlAlchemy","keywords":"","body":"Python - 第三方库之SQlAlchemy SQLAlchemy官方文档 介绍 🍀 在介绍SQLAlchemy之前先介绍一下什么是ORM ORM ORM即Object Relational Mapping , 简称ORM , 中文意思就是对象关系映射 ; 是一种程序技术 , 用于实现面向对象编程语言里不同类型系统的数据之间的转换 换一个方式介绍 , 我们知道面向对象是从软件工程基本原则(如耦合 , 聚合 , 封装) 的基础上发展起来的 , 而关系型数据库是从数学理论发展而来的 , 两套理论完全是不匹配的 , 那么正是为了解决这个问题 , 对象关系映射技术诞生了 SQLAlchemy SQLAlchemy是Python中最有名的一款ORM框架 , 该框架建立在数据库API之上 , 使用关系对象映射进行数据库操作 SQLAlchemy对象关系映射代表了用户使用Python定义类来与数据库中的表相关联的一种方式 , 类的实例则对应数据表中的一行数据 , SQLAlchemy包括了一套将对象中的变化同步到数据库表中的系统 , 这套系统被称之为工作单元(unit of work) , 同时也提供了使用类查询来实现数据库查询以及查询表之间关系的功能 安装 $ pip3 install SQLAlchemy 版本检查 >>>import sqlalchemy >>>sqlalchemy.__version__ '1.1.14' 各数据库Dialect MySQL-Python mysql+mysqldb://:@[:]/ pymysql mysql+pymysql://:@/[?] MySQL-Connector mysql+mysqlconnector://:@[:]/ cx_Oracle oracle+cx_oracle://user:pass@host:port/dbname[?key=value&key=value...] -- 更多详见：http://docs.sqlalchemy.org/en/latest/dialects/index.html 内部处理 SQLAlchemy操作数据库是利用Engine/ConnectionPooling/Dialect进行的 , Engine(引擎)使用ConnectionPooling连接数据库 , 然后再通过Dialect执行SQL语句 , SQLAlchemy Core如下 SQLAlchemy Core +-----------------+ +-------------------------+ +-----------------+ | Schema/Types | | SQL Expression Language | | Engine | +-----------------+ +-------------------------+ +-----------------+ ↓ +------------------+ +-------+ |Connection Pooling| |Dialect| +------------------+ +-------+ --------------------------------------------------------------------- DBAPI 连接数据库 🍀 from sqlalchemy import create_engine engine = create_engine(\"mysql+pymysql://root:myroot@localhost:3306/t1\", echo=True) echo参数是用来设置SQLAlchemy日志的 , 通过Python标准库logging模块实现 ; 设置为True表示所有操作记录可见 , 也可设置为False来减少日志的输出 create_engine() 的返回值是Engine的一个实例 , 此实例代表了操作数据库的核心接口 , 通过Dialect来处理数据库和数据库的API PS : 初次调用create_engine()时并不会真正的去连接数据库 , 只有在真正执行一条命令的时候才会去简历真正的DBAPI连接 ; 很多地方都会使用这种方式 , 以达到省资源的目的 声明映射 🍀 当使用ORM的时候 , 配置过程以描述数据库的表来开始 , 然后定义与之匹配的类 ; 而在SQLAlchemy中 , 这两个过程一般结合在一起 , 通过一个声明(Declarative)系统实现 , 该系统帮我们定义类以及实现与表的对应 声明系统实现类与表的对应是通过一系列基类实现的 , 即声明基类(Declarative Base Class) , 我们的应用程序经常只有一个此基类的实例 from sqlalchemy.ext.declarative import declarative_base Base = declarative_base() 根据声明的基类\"Base\" , 我们就可以通过它定义任何数量的映射类 使用原生SQL from sqlalchemy import create_engine from consts import DB_URI eng = create_engine(DB_URI) with eng.connect() as con: con.execute('drop table if exists users') con.execute('create table users(Id INT PRIMARY KEY AUTO_INCREMENT, ' 'Name VARCHAR(25))') con.execute(\"insert into users(name) values('Lyon')\") con.execute(\"insert into users(name) values('Kenneth')\") rs = con.execute('select * from users') for row in rs: print(row) 使用表达式 SQLAlchemy 支持使用表达式的方式来操作数据库 from sqlalchemy import (create_engine, Table, MetaData, Column, Integer, String, tuple_) from sqlalchemy.sql import select, asc, and_ from consts import DB_URI eng = create_engine(DB_URI) meta = MetaData(eng) users = Table( 'Users', meta, Column('Id', Integer, primary_key=True, autoincrement=True), Column('Name', String(50), nullable=False), ) if users.exists(): users.drop() users.create() # 创建表 def execute(s): print('-' * 20) rs = con.execute(s) for row in rs: print(row['Id'], row['Name']) with eng.connect() as con: for username in ('xiaoming', 'wanglang', 'lilei'): user = users.insert().values(Name=username) con.execute(user) stm = select([users]).limit(1) execute(stm) k = [(2,)] stm = select([users]).where(tuple_(users.c.Id).in_(k)) execute(stm) stm = select([users]).where(and_(users.c.Id > 2, users.c.Id ORM功能使用 🍀 流程如下 : 使用者通过ORM对象提交命令 将命令给SQLAlchemy Core转换成SQL 匹配使用者事先配置好的engine engine从连接池中取出一个链接 基于该链接通过Dialect调用DBAPI , 将SQL转交给数据库去执行 创建表 🍀 # 创建单表 from sqlalchemy import create_engine from sqlalchemy.ext.declarative import declarative_base from sqlalchemy import Column, Integer, String, Index, UniqueConstraint # 根据Dialet创建引擎,echo=True表示输出所有操作日志 engine = create_engine('mysql+pymysql://root:myroot@localhost:3306/test', echo=True) # 声明基类 Base = declarative_base() # 定义映射类 class Userinfo(Base): # 表名 __tablename__ = 'user_info' # 设置主键自增列 id = Column(Integer, primary_key=True, autoincrement=True) name = Column(String(32)) extra = Column(String(16)) __table_args__ = ( # 唯一索引,索引名为uix_id_name UniqueConstraint('id', 'name', name='uix_id_name'), # 联合索引 Index('ix_id_name', 'name', 'extra'), ) # 定义格式 def __repr__(self): return \"\" % (self.id, self.name) # 初始化函数 def init_db(): # 将所有继承Base类的类,创建表结构 Base.metadata.create_all(engine) def drop_db(): # 将所有继承Base类的类,删除表 Base.metadata.drop_all(engine) init_db() 对应的SQL语句 CREATE TABLE `UserInfo` ( id INTEGER NOT NULL AUTO_INCREMENT, name VARCHAR(32), extra VARCHAR(16), PRIMARY KEY (id), CONSTRAINT uix_id_name UNIQUE (id, name) ) 创建其他表 # 创建单表:业务线 class Business(Base): __tablename__='business' id=Column(Integer,primary_key=True,autoincrement=True) bname=Column(String(32),nullable=False,index=True) # 一对多:多个服务可以属于一个业务线,多个业务线不能包含同一个服务 class Service(Base): __tablename__='service' id=Column(Integer,primary_key=True,autoincrement=True) sname=Column(String(32),nullable=False,index=True) ip=Column(String(15),nullable=False) port=Column(Integer,nullable=False) business_id=Column(Integer,ForeignKey('business.id')) __table_args__=( UniqueConstraint(ip,port,name='uix_ip_port'), Index('ix_id_sname',id,sname) ) # 一对一:一种角色只能管理一条业务线,一条业务线只能被一种角色管理 class Role(Base): __tablename__='role' id=Column(Integer,primary_key=True,autoincrement=True) rname=Column(String(32),nullable=False,index=True) priv=Column(String(64),nullable=False) business_id=Column(Integer,ForeignKey('business.id'),unique=True # 多对多:多个用户可以是同一个role,多个role可以包含同一个用户 class Users(Base): __tablename__='users' id=Column(Integer,primary_key=True,autoincrement=True) uname=Column(String(32),nullable=False,index=True) class Users2Role(Base): __tablename__='users2role' id=Column(Integer,primary_key=True,autoincrement=True) uid=Column(Integer,ForeignKey('users.id')) rid=Column(Integer,ForeignKey('role.id')) __table_args__=( UniqueConstraint(uid,rid,name='uix_uid_rid'), ) class Favor(Base): __tablename__ = 'favor' nid = Column(Integer, primary_key=True, autoincrement=True) caption = Column(String(50), default='red', unique=True) class Person(Base): __tablename__ = 'person' nid = Column(Integer, primary_key=True, autoincrement=True) favor_id = Column(Integer, ForeignKey(\"favor.nid\")) ''' 设置外键的另一种方式 ForeignKeyConstraint(['other_id'], ['othertable.other_id']) ''' 扩展分析 : 根据流程可以发现 , 如果我们不依赖于SQLAlchemy的转换而自己写好sql语句 , 那么我们完全可以只用SQLAlchemy执行纯sql语句 , 即利用配置好的engine执行 , engine.execute() 删除表 🍀 Base.metadata.drop_all(engine) # 把所有继承Base类的类，删除表 操作表 🍀 ORM处理数据库的方式是通过Session来实现的 , 当我们需要与数据库进行对话时 , 就需要创建一个Session实例 : engine对象已经创建完成时 from sqlalchemy.orm import sessionmaker # 创建Session工厂,并连接engine Session = sessionmaker(bind=engine) # 创建Session实例 session = Session() engine未创建时 from sqlalchemy.orm import sessionmaker from sqlalchemy import create_engine # 创建Session工厂 Session = sessionmaker() # 创建引擎 engine = create_engine() # 连接Session与engine Session.configure(bind=engine) # 创建Session实例 session = Session() 增加数据 🍀 单条数据 Session = sessionmaker(bind=engine) session = Session() # 创建一条数据 users = Userinfo(name='Hello', password='World') # 把数据添加到表内 session.add(users) # 提交生效 session.commit() 多条数据 session.add_all([ Userinfo(name='Lyon',extra='xxx'), Userinfo(name='Kenneth Reitz',extra='xxx'), ]) session.commit() 删除数据 🍀 session.query(Userinfo).filter(Userinfo.name == 'Kenneth Reitz').delete() session.commit() 修改数据 🍀 session.query(Userinfo).filter(Users.id > 2).update({\"name\" : \"099\"}) # synchronize_session同步会话 session.query(Userinfo).filter(Users.id > 2).update({Users.name: Users.name + \"099\"}, synchronize_session=False) # 设置评估标准 session.query(Userinfo).filter(Users.id > 2).update({\"num\": Users.num + 1}, synchronize_session=\"evaluate\") session.commit() ''' 更多synchronize_session的参数可以查看官方文档 ''' 查询数据 🍀 # 查所有,取所有字段 res = session.query(Userinfo).all() print(res) # 查所有,取指定字段,按照id排序 res = session.query(Userinfo.name).order_by(Userinfo.id).all() print(res) # 查所有,取指定字段,第一条信息 res = session.query(Userinfo.name).first() print(res) # 过滤查,逗号分隔,默认为and res = session.query(Userinfo).filter(Userinfo.id > 1,Userinfo.id ] [('Lyon',)] ('Lyon',) [] ''' 其他查询 🍀 #　条件 ret = session.query(MyClass).filter_by(name = 'some name') ret = session.query(MyClass).filter(MyClass.id > 1, MyClass.name == 'Lyon').all() ret = session.query(MyClass).filter(MyClass.id.between(1, 3), MyClass.name == 'eric').all() ret = session.query(MyClass).filter(MyClass.id.in_([1,2,3])).all() ret = session.query(MyClass).filter(~MyClass.id.in_([1,2,3])).all() ret = session.query(MyClass).filter(MyClass.id.in_(session.query(MyClass.id).filter_by(name='Lyon'))).all() from sqlalchemy import and_, or_ ret = session.query(MyClass).filter(and_(MyClass.id > 3, MyClass.name == 'Lyon')).all() ret = session.query(MyClass).filter(or_(MyClass.id 3), MyClass.extra != \"\" )).all() # 通配符 ret = session.query(MyClass).filter(MyClass.name.like('e%')).all() ret = session.query(MyClass).filter(~MyClass.name.like('e%')).all() # 限制 ret = session.query(MyClass)[1:2] # 排序 ret = session.query(MyClass).order_by(MyClass.name.desc()).all() ret = session.query(MyClass).order_by(MyClass.name.desc(), MyClass.id.asc()).all() # 分组 from sqlalchemy.sql import func ret = session.query(MyClass).group_by(MyClass.extra).all() ret = session.query( func.max(MyClass.id), func.sum(MyClass.id), func.min(MyClass.id)).group_by(MyClass.name).all() ret = session.query( func.max(MyClass.id), func.sum(MyClass.id), func.min(MyClass.id)).group_by(MyClass.name).having(func.min(MyClass.id) >2).all() # 连表 ret = session.query(Users, Favor).filter(Users.id == Favor.nid).all() ret = session.query(Person).join(Favor).all() ret = session.query(Person).join(Favor, isouter=True).all() # 组合 q1 = session.query(MyClass.name).filter(MyClass.id > 2) q2 = session.query(Favor.caption).filter(Favor.nid 2) q2 = session.query(Favor.caption).filter(Favor.nid "},"01-Python/09-In-Depth/":{"url":"01-Python/09-In-Depth/","title":"In-Depth","keywords":"","body":"The road to Python - In-Depth Python总体架构 🍀 Python总体分为三个部分 , 即文件组 , Python核心 (解释器) , 运行环境 , 如下 : File Groups Python Core Runtime Environment INTERPRETER +---------------+ +----------------+ | Core Modules | | Scanner | ↓ +---------------+ +----------------+ +--------------------------+ | Library | | Parser | ↓ | Object/Type Structures | +---------------+ +----------------+ +--------------------------+ | User-defined | | Compiler | ↓ | Memory Allocator | | Modules | +----------------+ +--------------------------+ +---------------+ | Code Evauator | ↓ | Current State of Python | +----------------+ +--------------------------+ 源码组织 🍀 我们可以在Python官网中获取源码 , 即http://www.python.org 本目录下深入整理主要参考Python 2.7 与Python 3.5.4源码 参考书籍 : Python源码剖析——深度探索动态语言核心技术 Python 源码目录结构如下 : Python ├── Doc ├── Grammar ├── Include ├── Lib ├── Mac ├── Misc ├── Modules ├── Objects ├── Parser ├── PC ├── PCbuild ├── Programs ├── Python └── Tools 主要说明 , 其中加粗部分为主要分析对象 : Include : 该目录下包含了Python提供的所有头文件 , 如果用户需要自己用C或C++来编写自定义模块扩展Python , 那么就需要用到这里提供的头文件 Lib : 该目录包含了Python自带的所有标准库 , Lib中的库都是用Python语言编写的 Modules : 该目录中包含了所有用C语言编写的模块 , 比如random , cStringIO等 ; Modules中的模块时那些对速度要求非常严格的模块 , 而有一些对速度没有太严格要求的模块 , 比如os , 就是用Python编写的 , 并且放在Lib目录下 Parser : 该目录中包含了Python解释器中的Scanner和Parser部分 , 即对Python源代码进行词法分析和语法分析的部分 ; 除了这些 , Parser目录下还包含了一些有用的工具 , 这些工具能够根据Python语言的语法自动生成Python语言的词法和语法分析器 , 与YACC非常类似 Objects : 该目录中包含了所有Python的内建对象 , 包括整数 , list , dict等 , 同时 , 该目录还包括了Python在运行时需要的所有的内部使用对象的实现 Python : 该目录下包含了Pyton解释器中的Compiler和执行引擎部分 , 是Python运行的核心所在 PCBuild : 包含了VS使用的工程文件 "},"01-Python/09-In-Depth/01-Python - 对象机制.html":{"url":"01-Python/09-In-Depth/01-Python - 对象机制.html","title":"Python - 对象机制","keywords":"","body":"Python - 对象机制 欢迎收藏交流 , 如需转载 , 请注明出处 介绍 🍀 在Python中一切皆对象 我们知道Python是用C语言设计出来的 , 而在Python中 , 对象就是C中的结构体在堆上申请的一块内存 对象是不能被静态初始化的 , 并且也不能在栈空间上生存 ; 唯一列外的就是类型对象 , Python中所有的内建类型对象 (如整数类型对象 , 字符串类型对象) 都是被静态初始化的 在Python中 , 一个对象一旦被创建 , 那么它在内存中的大小就固定不变了 , 这就意味着对于那些可变长度的数据对象 (如列表) , 只能在对象内维护一个指向一块可变大小的内存区域的指针 利用这种对象机制可以使由指针维护对象的工作变得非常的简单 对象机制的基石 🍀 Python中一切皆对象 , 而所有的对象都拥有一些相同的内容 , 其被定义在PyObject中 我们先对比源码 , 从源码目录Python-2.7\\Include\\object.h中 , 截取如下片段 : 106:typedef struct _object { 107: PyObject_HEAD /*这个宏如下*/ 108:} PyObject; 77:/* PyObject_HEAD defines the initial segment of every PyObject. */ 78:#define PyObject_HEAD \\ 79: _PyObject_HEAD_EXTRA \\ /* Py_ssize_t 是一个所占字节数与 size_t 相同的有符号的整数类型*/ 80: Py_ssize_t ob_refcnt; \\ 81: struct _typeobject *ob_type; 65:/* Define pointers to support a doubly-linked list of all live heap objects. */ 66:#define _PyObject_HEAD_EXTRA \\ 67: struct _object *_ob_next; \\ 68: struct _object *_ob_prev; 从源码目录Python-3.5.4\\Include\\object.h中 , 截取如下片段 : 106:typedef struct _object { 107: _PyObject_HEAD_EXTRA /* 与2.7相比没有发生任何实质性变化 */ 108: Py_ssize_t ob_refcnt; 109: struct _typeobject *ob_type; 110:} PyObject; 82:/* PyObject_HEAD defines the initial segment of every PyObject. */ 83:#define PyObject_HEAD PyObject ob_base; 70:/* Define pointers to support a doubly-linked list of all live heap objects. */ 71:#define _PyObject_HEAD_EXTRA \\ 72: struct _object *_ob_next; \\ 73: struct _object *_ob_prev; 75:#define _PyObject_EXTRA_INIT 0, 0, 78:#else 79:#define _PyObject_HEAD_EXTRA 两个版本源码并没有什么真正意义上的改变 , 从中我们可以看出 , PyObject主要由ob_refcnt , ob_type , _PyObject_HEAD_EXTRA 几个部分组成 , 而对于_PyObject_HEAD_EXTRA , 我们发现它只有在DEBUG模式下才不为空 , 所以我们可以将其忽略 ob_refcnt 🍀 ob_refcnt 是内存管理机制的核心 , 它实现了基于引用计数的垃圾回收机制 , 例如 : 对于某一个对象A , 当有一个新的PyObject * (对象指针) 引用该对象时 , A的引用计数 (ob_refcnt) 就会增加 ; 而当这个PyObject * 被删除时 , A的引用计数就会减少 , 并且当A的引用计数减少到0时 , A就可以从堆上被删除 , 以释放出内存供别的对象使用 ob_refcnt是一个32位的整型变量 , 这实际蕴含着Python所做的一个假设 , 即对一个对象的引用不会超过一个整型变量的最大值 , 这个假设如果不是恶意代码的话 , 明显是成立的 ob_type 🍀 ob_type是对象类型的核心 , 源码中我们可以看到 , 它是一个指向_typeobject的结构体的指针 , 该结构体对应的是一种特殊的对象 , 它是用来指定一个对象类型的类型对象 , 也就是说ob_type所指向的位置存放着一个对象的类型信息 Python就是利用ob_type构造了对象类型的基石 PyObject中定义了所有Python对象中都必须有的内容 , 即ob_refcnt和ob_type , 当然一个对象中肯定不止于这些 , 不同的对象中还保存了各自的特殊信息 , 于是才实现了各种基础数据类型 定长对象和变长对象 🍀 定长对象 🍀 我们把不包含可变长度数据的对象称为 \"定长对象\" , 并且定长对象在内存中所占的大小是一样的 , 比如我们的整数对象 , 内存中 1 和 100占用的内存大小都是sizeof(PyIntObject) 你可能会将定长对象理解为 \"不可变对象\" , 但是实际上并不是这样 , 因为像Python的字符串 , 元组这两者都是 \"不可变对象\" , 但是他们却是 \"变长对象\" , 我们通过源码来看看Python中的整数对象 : 目录Python-2.7\\Include\\intobject.h中 , 截取如下片段 : 23:typedef struct { 24: PyObject_HEAD /*PyObject对象宏 */ 25: long ob_ival; /*PyIntObject的特殊信息*/ 26:} PyIntObject; 如上 , 也就是说在Python 2.x中 , 整数对象都是定长对象 , 因为PyIntObject结构体中没有任何多余的内容 , 但是别忘了数字还有Long类型 , 而Long则是变长对象 源码如下 : Python-2.7\\Include\\longintrepr.h中 , 截取如下片段 : 90:struct _longobject { 91: PyObject_VAR_HEAD /*变长对象基石*/ 92: digit ob_digit[1]; 93:}; 注意 : 在Python 3.x中 , Long类型和Int类型合并到一起去了 , 我们在3.x中所看到的Int类型 , 实际上是Long 类型 , 关于数字类型将会在下一篇中整理 Python 3.x中这部分源码也在logintrepr.h中 , 分别在第89 - 92行 变长对象 🍀 上面已经说明了定长对象 , 变长对象则就是包含可变长度数据的对象 定长对象与变长对象的区别在于 : 定长对象占用的内存大小是一样的 , 而变长对象占用的大小不一样 , 实例如下 : >>> a = 1 >>> type(a) >>> a.__sizeof__() 24 >>> b = 100 >>> type(b) >>> b.__sizeof__() 24 注意 : 字符串是变长对象 , Python2.7中源码如下 : // Python2.7\\Include\\stringobject.h 35:typedef struct { 36: PyObject_VAR_HEAD /*变长对象基石*/ 37: long ob_shash; 38: int ob_sstate; 39: char ob_sval[1]; /* 省略注释 */ 49:} PyStringObject; 实例说明 # env : Python 2.x >>> a = \"lyon\" >>> b = \"lyonyang\" >>> a.__sizeof__() 37 >>> b.__sizeof__() 41 PyVarObject 🍀 PyVarObject就是Python中变长对象的基石 , 上面的PyStringObject中我们已经见过了, 那么继续翻源码 : Python-2.7\\Include\\object.h : 110:typedef struct { 111: PyObject_VAR_HEAD 112:} PyVarObject; /* PyObject_VAR_HEAD defines the initial segment of all variable-size * container objects. These end with a declaration of an array with 1 * element, but enough space is malloc'ed so that the array actually * has room for ob_size elements. Note that ob_size is an element count, * not necessarily a byte count. */ 96:#define PyObject_VAR_HEAD \\ 97: PyObject_HEAD \\ 98: Py_ssize_t ob_size; /* Number of items in variable part */ Python-3.5.4\\Include\\object.h : 112:typedef struct { 113: PyObject ob_base; /* 等价于PyObject_HEAD */ 114: Py_ssize_t ob_size; /* Number of items in variable part */ 115:} PyVarObject; 版本2.7 与 3.5.4无变化 , 我们可以看出 , PyVarObject其实就是在PyObject上的一个扩展而已 , 而这个扩展就是在PyVarObject中多出了一个ob_size变量 , 这是一个整型变量 , 该变量记录的是变长对象中一共容纳了多少个元素 注意 : 变长对象通常都是容器 , 并且ob_size指明的是所容纳元素的个数 , 而不是字节的数量 , 比如一个列表中有5个元素 , 那么ob_size的值就是5 所以对于判断Python底层实现的对象是否是变长对象 , 只需查看其定义中是否具有ob_size属性 类型对象 🍀 上面已经提到过了在PyObject中有一个ob_type指针 , 它指向对象的类型信息 , 这样在分配内存空间时 , 就可以根据ob_type所指向的信息来决定对象申请多大的空间 ob_type指向结构体_typeobject , 如下 : Python-2.7\\Include\\object.h : 324:typedef struct _typeobject { 325: PyObject_VAR_HEAD 326: const char *tp_name; /* For printing, in format \".\" */ 327: Py_ssize_t tp_basicsize, tp_itemsize; /* For allocation */ 329: /* Methods to implement standard operations */ ... 338: /* Method suites for standard classes */ ... 344: /* More standard operations (here for binary compatibility) */ ... 411:} PyTypeObject; Python-3.5.4\\Include\\object.h : 343:typedef struct _typeobject { 344: PyObject_VAR_HEAD 345: const char *tp_name; /* For printing, in format \".\" */ 346: Py_ssize_t tp_basicsize, tp_itemsize; /* For allocation */ 348: /* Methods to implement standard operations */ ... 358: /* Method suites for standard classes */ ... 364: /* More standard operations (here for binary compatibility) */ 432:} PyTypeObject; 同样 , 在版本2.7 与 3.5.4之间不能存在差异 我们可以将该结构体主要分为4个部分 : 类型名 , 即tp_name , 主要是Python内部以及调试的时候使用 创建该类型对象时分配内存空间大小的信息 , 即 tp_basicsize , tp_itemsize 与该类型对象相关联的操作信息 , 可以通过源码进行详查 类型的类型信息 由于在PyObject的定义中包含了PyTypeObject , 我们可以认为PyObject对象是继承了PyTypeObject对象 , 而PyTypeObject则是最原始的抽象 因为在实际的Python中确实如此 : object类 (即PyObject) 的基类就是type类 (即PyTypeObject) 我们用Python简单描述 : >>> isinstance(object, type) True 并且由于Python对外提供了C API , 以及Python本身就是用C写成的 , 所以Python内部也大量使用了这些API Python中的API分为两种 : 范型API , 或者称为AOL (Abstract Object Layer) , 这类API都具有诸如Pyobject_*的形式 , 可以应用于任何Python对象上 类型相关API , 或者称为COL (Concrete Object Layer) , 这类API通常只能作用在某一种类型的对象上 , 对于Python内建对象 , 都提供了这样一组API , 诸如PyInt_Type 所以对于Python中的内建类型对象 , 可以利用以上两种API进行创建 : 范型API : PyObject *intobj = PyObject_New(PyObject, &PyInt_Type) 类型API : PyObject *intobj = PyInt_FromLong(10) 注意 : 我们经常所见到的中的 int 代表的就是Python内部的PyInt_Type 总结 : 通过这一篇文章我们已经理清了Python对象机制中的核心定义 以下从上往下依次扩展 PyTypeObject - - 类型对象基石 PyObject - - 对象基石 PyVarObject - - 变长对象基石 "},"01-Python/09-In-Depth/02-Python - 对象的创建.html":{"url":"01-Python/09-In-Depth/02-Python - 对象的创建.html","title":"Python - 对象的创建","keywords":"","body":"Python - 对象的创建 欢迎收藏交流 , 如需转载 , 请注明出处 介绍 🍀 上一篇关于Python中对象实现中我们知道 , 创建一个对象Python提供了两种API , 即范型API和类型API 而在对象真正创建时 , Python为我们使用的是类型API 因为如果使用范型API , 那么意味着Python要提前为我们准备好PyObject_New 这一系列的API , 对于创建内置类型的对象这并没有问题 , 但是如果对于创建用户自定义的类型这样就非常的不明智了 , 因为需要提前创建好诸多的_New对象 创建对象 🍀 我们定义一个类 , 通过这个自定义类来说明Python对象的创建流程 # Python对象的基石,即PyObject class object(): pass # 自定义类 class MyObject(object): pass 创建object对象 在分析自定义类型的对象创建之前 , 我们需要分析一下object对象是如何创建的 , 虽然我们在实际中是不会也不需要去创建object对象的 , 但是这有利于我们下一步的分析 : object对象的创建 : 如上图 , 创建object对象首先调用类型API (PyBaseObject_Type) , 并且会首先调用API中的tp_new , 因为这里是创建object , 所以tp_new中不会为NULL 创建自定义对象 无论是Python 2.x还是3.x , Python中所有的类都是以object类为基础的 , 也就是说所有的类都继承了object类 , 所以自定义类型对象的创建流程如下 : 无论是自定义对象的创建还是object对象的创建 , 其创建对象的流程都是一样的 : 首先都会调用其类型API中的tp_new , 如果我们自定义类型中tp_new为NULL , 那么它将通过tp_base指定的基类继续去寻找tp_new , 直到找到tp_new为止 , 不要担心会找不到 , Python中所有的类都继承了object类 , 而object类中是一定有tp_new的 在找到tp_new之后会回到原点拿取tp_basicsize , 这里面记录了该对象应该占用内存大小的信息 , 拿取后申请内存完成创建 , 返回一个新对象 拿到新对象我们对新对象进行初始化 通过这三大步 , 一个对象的创建基本就完成了 站在Python的角度来看 , tp_new对应的就是特殊操作符中的__new__方法 , 此方法返回一个对象实例 , tp_init 对应的就是特殊操作符中的__init__方法 , 当我们创建一个类时一般都会对__init__方法进行重载以达到我们的目标 当然PyBaseObject_Type并不是类型对象的终点 , 在其之上还存在着一个PyType_Type 更多关于类型对象的信息详见上一篇 , 其中定义了对象的行为 类型的类型 🍀 我们知道PyObject中有一个 ob_type指针 , 记录着PyObject的类型信息 , 但是这个结构体也是一个对象 , 就是上一篇中所说的类型对象PyTypeObject 既然是对象 , 那么就肯定有类型 , 而这个类型就是PyType_Type Python-2.7\\Objects\\typeobject.c 2730:PyTypeObject PyType_Type = { PyVarObject_HEAD_INIT(&PyType_Type, 0) \"type\", /* tp_name */ sizeof(PyHeapTypeObject), /* tp_basicsize */ sizeof(PyMemberDef), /* tp_itemsize */ (destructor)type_dealloc, /* tp_dealloc */ 0, /* tp_print */ 0, /* tp_getattr */ 0, /* tp_setattr */ 0, /* tp_compare */ (reprfunc)type_repr, /* tp_repr */ 0, /* tp_as_number */ 0, /* tp_as_sequence */ 0, /* tp_as_mapping */ (hashfunc)_Py_HashPointer, /* tp_hash */ (ternaryfunc)type_call, /* tp_call */ 0, /* tp_str */ (getattrofunc)type_getattro, /* tp_getattro */ (setattrofunc)type_setattro, /* tp_setattro */ 0, /* tp_as_buffer */ Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HAVE_GC | Py_TPFLAGS_BASETYPE | Py_TPFLAGS_TYPE_SUBCLASS, /* tp_flags */ type_doc, /* tp_doc */ (traverseproc)type_traverse, /* tp_traverse */ (inquiry)type_clear, /* tp_clear */ type_richcompare, /* tp_richcompare */ offsetof(PyTypeObject, tp_weaklist), /* tp_weaklistoffset */ 0, /* tp_iter */ 0, /* tp_iternext */ type_methods, /* tp_methods */ type_members, /* tp_members */ type_getsets, /* tp_getset */ 0, /* tp_base */ 0, /* tp_dict */ 0, /* tp_descr_get */ 0, /* tp_descr_set */ offsetof(PyTypeObject, tp_dict), /* tp_dictoffset */ type_init, /* tp_init */ 0, /* tp_alloc */ type_new, /* tp_new */ PyObject_GC_Del, /* tp_free */ (inquiry)type_is_gc, /* tp_is_gc */ 2772:}; 在Python 3.5.4中内容是一样就不列出了 , 行数3328-3369 所有的对象中的类型对象都是由PyType_Type对象进行创建的 , 包括PyObject , 如下 : >>> object.__class__ >>> int.__class__ >>> class A(object): ... pass ... >>> A.__class__ >>> type.__class__ >>> 通过这一实验 , 我们可以知道其实所有类的祖宗实际上是type , 也就是PyType_Type , 所以它在Python中被称为 metaclass(元类) 我们发现就算是type类竟然也是由type (PyType_Type)产生的 , 就像在type类中成了一个 \"圈一样\" , 自己引用自己 , 事实上确实是这样 , 同样以上一小节的例子进行说明 , 如下图 : 也就是说PyType_Type中的ob_type指针最终指向了自己本身 这些基本上就是Python对象的创建流程了 , 但是注意对于Python内部的类型 , 创建时可能存在一些差异 , 但是这些差异并不会影响我们分析的结果 总结 : 这一篇主要整理了对象创建的流程 , 以及对类型对象的整理 tp_new对应到C++中 , 可以视为new操作符 , Python中则是__new__操作符 tp_init则是Python中的__init__ 也就是类的构造函数 , 功能就是对创建的新对象进行初始化 Python中一切皆对象 , 类型也是对象 ; 对象必然具有类型 , PyType_Type是类型对象的创造者 PyType_Type的类型就是其本身 "},"01-Python/09-In-Depth/03-Python - 整数对象.html":{"url":"01-Python/09-In-Depth/03-Python - 整数对象.html","title":"Python - 整数对象","keywords":"","body":"Python - 整数对象 欢迎收藏交流 , 如需转载 , 请注明出处 介绍 🍀 在Python的应用程序中 , 整数的使用非常地广泛 这就意味着整数对象的创建和销毁肯定是非常的频繁的 , 并且我们知道Python中采用了引用计数机制 , 即一个整数类型的变量ob_refcnt , 这样Python中对于整数对象的创建和销毁会更加的疯狂 , 这样的执行效率明显我们是无法接受的 , 更何况Python已经背负了人们对其执行效率的不满 , 所以Python中大量采用了内存对象池的技术 整数对象必然也使用了内存对象池技术 , 也就是整数对象池 , 当然我们应该从整数对象的创建开始说起 , 以及Python 2.x中与Python 3.x两个版本之间的差异 整数类型 🍀 Python 2.x中的整数类型 在Python 2.x中有两种整数类型 , 一种是int 也就是我们通常说的整型 , 另一种是long也就是长整型 , 根据两种对象的源码 , 我们可以知道 , int (PyIntObject) 属于定长对象 , 而long (PyLongObject) 属于变长对象 对于int , 当其进行运算时 , 如果值溢出 , 那么Python将会将值自动转为long类型 , 如下 : # python 2.x >>> n = 2147483647 >>> type(n) # 加法溢出 >>> n = n + 1 >>> n 2147483648L >>> type(n) >>> n = -2147483647 >>> type(n) # 减法溢出 >>> n = n - 2 >>> n -2147483649L >>> type(n) 但是long就不会出现这种溢出情况了 , 因为long是一个变长对象 , 当空间不够存放这个数字值 , 加空间就是了 , 无非是从1Byte 到2 Byte的过程 , 以此类推 Python 3.x中的整数类型 在Python 3.x中 , 只有long了 , 我们所见到的int实际上就是long , 根据源码的注释所说 , 大概意思就是对于未来而言 , long比int好 , 并且在Python 3.x的官方文档中 , 第一句就说明了 : All integers are implemented as “long” integer objects of arbitrary size. 还有一点值得注意的就是 , 在3.x的源码中 , 已经没有intobject.h这个文件了 , 而只有longobject.h , 我们可以在Python-3.5.4\\Objects\\longobject.c中看到long的类型信息 : 5179:PyTypeObject PyLong_Type = { PyVarObject_HEAD_INIT(&PyType_Type, 0) \"int\", /* tp_name */ offsetof(PyLongObject, ob_digit), /* tp_basicsize */ sizeof(digit), /* tp_itemsize */ long_dealloc, /* tp_dealloc */ 0, /* tp_print */ 0, /* tp_getattr */ 0, /* tp_setattr */ 0, /* tp_reserved */ long_to_decimal_string, /* tp_repr */ &long_as_number, /* tp_as_number */ 0, /* tp_as_sequence */ 0, /* tp_as_mapping */ (hashfunc)long_hash, /* tp_hash */ 0, /* tp_call */ long_to_decimal_string, /* tp_str */ PyObject_GenericGetAttr, /* tp_getattro */ 0, /* tp_setattro */ 0, /* tp_as_buffer */ Py_TPFLAGS_DEFAULT | Py_TPFLAGS_BASETYPE | Py_TPFLAGS_LONG_SUBCLASS, /* tp_flags */ long_doc, /* tp_doc */ 0, /* tp_traverse */ 0, /* tp_clear */ long_richcompare, /* tp_richcompare */ 0, /* tp_weaklistoffset */ 0, /* tp_iter */ 0, /* tp_iternext */ long_methods, /* tp_methods */ 0, /* tp_members */ long_getset, /* tp_getset */ 0, /* tp_base */ 0, /* tp_dict */ 0, /* tp_descr_get */ 0, /* tp_descr_set */ 0, /* tp_dictoffset */ 0, /* tp_init */ 0, /* tp_alloc */ long_new, /* tp_new */ PyObject_Del, /* tp_free */ 5220:}; 注意 : 在此文件中还有一个long_as_number 域 , 其中定义了一个对象作为数值对象时所有可选的操作 , 其中2.7中一共有39个函数指针 , 3.5.2中一共有34个函数指针 , 每一个函数指针都代表着一种可选的操作 , 包括加法 , 减法 , 乘法 , 模运算等等 ; 具体行数见5142-5176 创建方式 对于整数对象的创建 , 其途径都定义在intobject.c或者longobject.c中 , 方式都不止一种 , 例如创建int就有以下3种方式 : 从long值创建 , PyInt_FromLong(long ival) 从Py_UNICODE对象生成 , PyInt_FromUnicode(Py_UNICODE *s, int length, int base) 从字符串生成 , PyInt_FromString(char *s, char **pend, int base) 而对于创建long方法就更多了 , 这些创建方法都定义在Python\\Objects\\目录下对应的.c文件中 小整数对象池 🍀 在实际编程中 , 数值比较小的整数 , 比如 1, 2, 29等 , 可能在程序中会非常频繁地使用 ; 在Python中 , 所有的对象都存货在系统堆上 , 也就是说 , 如果没有特殊的机制 , 对于这些频繁使用的小整数对象 , Python将一次又一次使用malloc在堆上申请空间 , 并且不厌其烦地一次次free释放空间 , 这样的操作会严重影响Python的整体性能 所以Python中对于小整数对象使用了对象池技术 , 也就是Python会直接将小整数对象缓存在内存中 , 并将其指针存放在small_ints中 , 这个小整数集合的范围无论是在Python 2.x 还是在Python 3.x , 其范围都设定在[-5, 257) , 源码如下 : Python-2.7\\Objects\\intobject.c 67:#ifndef NSMALLPOSINTS 68:#define NSMALLPOSINTS 257 69:#endif 70:#ifndef NSMALLNEGINTS 71:#define NSMALLNEGINTS 5 72:#endif 73:#if NSMALLNEGINTS + NSMALLPOSINTS > 0 /* References to small integers are saved in this array so that they can be shared. The integers that are saved are those in the range -NSMALLNEGINTS (inclusive) to NSMALLPOSINTS (not inclusive). */ 79:static PyIntObject *small_ints[NSMALLNEGINTS + NSMALLPOSINTS]; Python-3.5.4\\Objects\\longobject.c 12:#ifndef NSMALLPOSINTS 13:#define NSMALLPOSINTS 257 14:#endif 15:#ifndef NSMALLNEGINTS 16:#define NSMALLNEGINTS 5 17:#endif 25:#if NSMALLNEGINTS + NSMALLPOSINTS > 0 /* Small integers are preallocated in this array so that they can be shared. The integers that are preallocated are those in the range -NSMALLNEGINTS (inclusive) to NSMALLPOSINTS (not inclusive). */ 31:static PyLongObject small_ints[NSMALLNEGINTS + NSMALLPOSINTS]; 小整数池测试 # Python 2.7 >>> a = 1 >>> id(a) 87319208L >>> b = 1 >>> id(b) 87319208L # Python 3.5.3 >>> a = 1 >>> id(a) 1852703184 >>> b = 1 >>> id(b) 1852703184 超出小整数集合的整数对象 , 内存地址就不一样了 , 这一点可以自己尝试 对于小整数集合的范围我们是可以修改的 , 但是修改的方法非常原始 , 那就是修改Python的源码然后重新编译 注意 : 小整数对象池中完全地缓存其对象 , 也就是说在执行我们的程序之前小整数对象池就已经激活 通用整数对象池 🍀 小整数对象池解决了小整数频繁的使用问题 , 但是我们并不能保证大整数就不会被频繁的使用 , 所以对于这些整数 , Python运行环境将提供一块内存空间 , 供这些大整数轮流使用 , 结构体如下 : Python-2.7\\Objects\\intobject.c 33:#define BLOCK_SIZE 1000 /* 1K less typical malloc overhead */ 34:#define BHEAD_SIZE 8 /* Enough for a 64-bit pointer */ 35:#define N_INTOBJECTS ((BLOCK_SIZE - BHEAD_SIZE) / sizeof(PyIntObject)) 37:struct _intblock { 38: struct _intblock *next; 39: PyIntObject objects[N_INTOBJECTS]; 40:}; 42:typedef struct _intblock PyIntBlock; 44:static PyIntBlock *block_list = NULL; 45:static PyIntObject *free_list = NULL; 在上述结构体中 , N_INTOBJECTS表示所维护的对象的个数 , 在32位的系统上 , 一个int类型所需要的内存为12bytes , 所以可以计算出这个值应该是82 , 这一个值我们也可以通过修改源码进行修改 而PyIntBlock的单向列表通过block_list维护 , 每一个block中都维护了一个PyIntObject数组 , 这就是真正用于存储被缓存的PyIntObject对象的内存 , 而对于这个内存中的空闲内存则是由单向链表free_list进行管理 ; 最开始时这两个指针都指向一个空值 (NULL) 在Python 3.5.4中 , 我没有找到如同2.7一样的源码 , 但是我们可以通过两个版本的实验发现 , 通用对象池机制是一样的 : # Python 2.x >>> id(257),id(258),id(259) (81956248L, 81956224L, 81956200L) >>> n = 258 >>> id(n) 81956248L # Python 3.x >>> id(257),id(258),id(259) (1910529789904, 1910534766192, 1910534766096) >>> n = 258 >>> id(n) 1910529789904 在进行实验时 , 走了很多弯路 , 有兴趣的话可以自己尝试 , 下面是上面实验的结果总结 : 申请完内存之后 , Python解释器就再也不会返回内存给操作系统了 , 就算对象被销毁 创建大整数对象时 , 会到堆里面找最近的那一块空内存 , 注意堆里面存储数据是由高到低进行存储的 也就是说 , 通用整数对象池机制所做的优化就是 , 解决了内存的频繁开辟问题 注意 : 如果第一块空间满了 , 那么就会往第二块进行存储 ; 添加和删除 🍀 通过使用PyInt_FromLong API为例 , 创建一个整数对象的过程如下 : Python-2.7\\Objects\\intobject.c 87:PyInt_FromLong(long ival) 88:{ 89: register PyIntObject *v; 90:#if NSMALLNEGINTS + NSMALLPOSINTS > 0 /* 尝试使用小整数对象池 */ 91: if (-NSMALLNEGINTS = 0) 96: quick_int_allocs++; 97: else 98: quick_neg_int_allocs++; 99:#endif 100: return (PyObject *) v; 101: } 102:#endif /* 为通用整数对象池申请新的内存空间 */ 103: if (free_list == NULL) { 104: if ((free_list = fill_free_list()) == NULL) 105: return NULL; 106: } 107: /* Inline PyObject_New */ 108: v = free_list; 109: free_list = (PyIntObject *)Py_TYPE(v); 110: PyObject_INIT(v, &PyInt_Type); 111: v->ob_ival = ival; 112: return (PyObject *) v; 113:} Python-3.5.4\\Objects\\longobject.c 中25行至296行 可以查看到关于Python 3中的一些处理 37:get_small_int(sdigit ival) { PyObject *v; assert(-NSMALLNEGINTS = 0) quick_int_allocs++; else quick_neg_int_allocs++; #endif return v; 50:} 51:#define CHECK_SMALL_INT(ival) \\ do if (-NSMALLNEGINTS 也就是说整数对象的创建会通过两步来完成 : 如果小整数对象池机制被激活 (默认就已激活) , 则尝试使用小整数对象池 如果不能使用小整数对象池 , 则使用通用的整数对象池 对于整数对象的实现大概核心就是这些东西了 , 关于通用对象池的创建 , 可以通过源码或者 , 《Python源码剖析》一书进行探索 "},"01-Python/09-In-Depth/04-Python - 字符串对象.html":{"url":"01-Python/09-In-Depth/04-Python - 字符串对象.html","title":"Python - 字符串对象","keywords":"","body":"Python - 字符串对象 欢迎收藏交流 , 如需转载 , 请注明出处 介绍 🍀 在前面有提到过 \"定长对象\" 和 \"变长对象\" , 这是一种对对象的二分法 当然不止这一种 , 还有一种就是 \"可变对象(mutable)\" 和 \"不可变对象(immutable)\" , 这种二分法是根据对象维护数据的可变性来进行区分的 , 在Python的官方文档中也是有说到的 可变对象维护的数据在对象被创建后还能再变化 , 比如一个list被创建后 , 可以向其中添加元素或删除元素 , 这些操作都会改变其维护的数据 ; 而不可变对象所维护的数据在对象创建之后就不能再改变了 , 比如Python中的string和tuple , 他们都不支持添加或删除的操作 Python 2.x 与 Python 3.x # Python 2.7 >>> name = 'lyon' >>> type(name) >>> name.decode('utf-8') u'lyon' >>> uname = u'lyon' >>> type(uname) # Python 3.5.4 >>> name = 'lyon' >>> type(name) >>> name.decode('utf-8') Traceback (most recent call last): File \"\", line 1, in AttributeError: 'str' object has no attribute 'decode' >>> uname = u'lyon' >>> type(uname) 在进行对比两种版本的差异前 , 我们需要知道在它们中有哪些字符串类型 : Python 3.x中 , 有3种字符串类型 : str , 表示Unicode文本 (8位的和更宽的) bytes , 表示二进制数据 bytearray , 是bytes的一种可变的变体 Python 2.x中 , 有2中字符串类型 : str , 表示8位文本和二进制数据 unicode , 表示宽字符Unicode文本 虽然在2中没有bytesarray , 但是在Python 2.6 及之后的版本都可以使用bytesarray 总体差异 : 在Python 2.x 与 Python 3.x中 , 字符串的实现主要体现在 , Python 3.x中将Python 2.x中常规的str和Unicode字符串整合到了一个单独的类型str中 , 以支持常规的和Unicode文本 ; 这样的处理使得Python在编码处理方面更加的方便 接下来就来分析Python中的字符串对象了 PyStringObject 🍀 在Python中 , PyStringObject是对字符串对象的实现 , PyStringObject 是一个拥有可变长度内存的对象 , 比如 : \"Lyon\" 和 \"KennethReitz\" 这两个字符串对象所需要的内存空间明显是不一样的 同时 , PyStringObject 对象又是一个不可变对象 , 即当创建了一个PyStringObject对象之后 , 该对象内部维护的字符串就不能再被改变了 , 这一点特性使得PyStringObject对象可以作为dict的键 , 但是同时也使得一些字符串的操作效率大大降低 , 比如多个字符串的连接操作 PyStringObject对象的定义如下 : Python-2.7\\Include\\stringobject.h : 35:typedef struct { 36: PyObject_VAR_HEAD /* 在前面的篇章已经介绍过了,变长对象宏 */ 37: long ob_shash; 38: int ob_sstate; 39: char ob_sval[1]; 41: /* Invariants: 42: * ob_sval contains space for 'ob_size+1' elements. 43: * ob_sval[ob_size] == 0. 44: * ob_shash is the hash of the string or -1 if not computed yet. 45: * ob_sstate != 0 iff the string object is in stringobject.c's 46: * 'interned' dictionary; in this case the two references 47: * from 'interned' to this object are *not counted* in ob_refcnt. 48: */ 49:} PyStringObject; 定义说明 : PyObject_VAR_HEAD中有一个ob_size变量保存着对象中维护的可变长度内存的大小 ob_shash变量的作用是缓存该对象的hash值 , 这样可以避免每一次都重新计算该字符串对象的hash值 , 如果一个PyStringObject对象还没有被计算过hash值 , 那么ob_shash的初始值是-1 这个hash值在后期dict类型中发挥了巨大的作用 ob_sstate变量标记了该对象是否已经过intern机制的处理 , intern机制见下文 , 预存的字符串的hash值与intern机制将Python虚拟机的执行效率提升了20% ob_sval在定义中虽然是一个字符的字符数组 , 但是ob_sval实际上是作为一个字符指针指向一段内存的 , 这段内存保存着这个字符串对象所维护的实际字符串 , 而这段内存的实际长度(字节) , 正式通过ob_size来维护的 , 这就是变长对象的实现机制 , 比如一个字符串对象 \"Lyon\" , ob_size的值就是4 在Python 3.x中 , 遗留的字符串定义在unicodeobject.h中 , 不另行说明了 PyString_Type 🍀 如下是PyStringObject的类型对象的定义 : Python-2.7\\Objects\\stringobject.c : 3800:PyTypeObject PyString_Type = { PyVarObject_HEAD_INIT(&PyType_Type, 0) \"str\", PyStringObject_SIZE, sizeof(char), ...... string_repr, /* tp_repr */ &string_as_number, /* tp_as_number */ &string_as_sequence, /* tp_as_sequence */ &string_as_mapping, /* tp_as_mapping */ (hashfunc)string_hash, /* tp_hash */ 0, /* tp_call */ ...... &PyBaseString_Type, /* tp_base */ ...... string_new, /* tp_new */ PyObject_Del, /* tp_free */ 3842:}; 对于类型对象就无需多说了 , 在前面的篇章也已经介绍过了 , 这里值得注意的是 , tp_itemsize和ob_size共同决定了应该额外申请的内存之总大小是多少 , tp_itemsize指明了由变长对象保存的元素的单位长度 , 这里就是单个字符在内存中的长度 tp_as_number , tp_as_sequence , tp_as_mapping 三个域都被设置了 , 表示PyStringObject对数值操作 , 序列操作和映射操作都支持 创建PyStringObject对象 🍀 Python 2.7 提供了两个接口 : PyString_FromString 和 PyString_FromStringAndSize Python-2.7\\Objects\\stringobject.c : PyString_FromString 119:PyString_FromString(const char *str) { register size_t size; register PyStringObject *op; // 判断字符串长度 assert(str != NULL); size = strlen(str); if (size > PY_SSIZE_T_MAX - PyStringObject_SIZE) { PyErr_SetString(PyExc_OverflowError, \"string is too long for a Python string\"); return NULL; } // 处理null string if (size == 0 && (op = nullstring) != NULL) { #ifdef COUNT_ALLOCS null_strings++; #endif Py_INCREF(op); return (PyObject *)op; } // 处理字符 if (size == 1 && (op = characters[*str & UCHAR_MAX]) != NULL) { #ifdef COUNT_ALLOCS one_strings++; #endif Py_INCREF(op); return (PyObject *)op; } /* Inline PyObject_NewVar */ op = (PyStringObject *)PyObject_MALLOC(PyStringObject_SIZE + size); if (op == NULL) return PyErr_NoMemory(); PyObject_INIT_VAR(op, &PyString_Type, size); op->ob_shash = -1; op->ob_sstate = SSTATE_NOT_INTERNED; Py_MEMCPY(op->ob_sval, str, size+1); /* share short strings */ if (size == 0) { PyObject *t = (PyObject *)op; PyString_InternInPlace(&t); op = (PyStringObject *)t; nullstring = op; Py_INCREF(op); } else if (size == 1) { PyObject *t = (PyObject *)op; PyString_InternInPlace(&t); op = (PyStringObject *)t; characters[*str & UCHAR_MAX] = op; Py_INCREF(op); } return (PyObject *) op; 169:} 传给PyString_FromString的参数必须是一个指向以NUL('\\0') 结尾的字符串的指针 根据定义我们知道 , 在创建PyStringObject时 : 首先会检查该字符串数组的长度 , 如果字符数组的长度大于PY_SSIZE_T_MAX , 那么Python将不会创建对应的PyStringObject对象 , PY_SSIZE_T_MAX是一个与平台相关的值 , 在WIN32系统下 , 该值为2147483647 , 即2GB 接下来检查传入的字符串是不是一个空串 , 对于空串 , Python并不是每一次都会创建相应的PyStringObject ; Python运行时有一个PyStringObject对象指针nullstring专门负责处理空的字符数组 , 如果第一次在一个空字符串基础上创建PyStringObject , 由于nullstring指针被初始化为NULL , 所以iPython会为这个字符建立一个PyStringObject对象 , 将这个对象通过intern机制进行共享 , 然后将nullstring指向这个被共享的对象 , 以后再创建空字符串就直接返回nullstring的引用了 如果不是创建空字符串对象 , 那么就申请内存 , 创建PyStringObject对象 ; 处理申请字符串本身所需要的内存外 , 还会申请额外的内存 , 存放了其他的属性 , 以字符数组\"Python\"为例 , 如下图 PyString_FromStringAndSize Python-2.7\\Objects\\stringobject.c : 61:PyString_FromStringAndSize(const char *str, Py_ssize_t size) { register PyStringObject *op; if (size PY_SSIZE_T_MAX - PyStringObject_SIZE) { PyErr_SetString(PyExc_OverflowError, \"string is too large\"); return NULL; } /* Inline PyObject_NewVar */ op = (PyStringObject *)PyObject_MALLOC(PyStringObject_SIZE + size); if (op == NULL) return PyErr_NoMemory(); PyObject_INIT_VAR(op, &PyString_Type, size); op->ob_shash = -1; op->ob_sstate = SSTATE_NOT_INTERNED; if (str != NULL) Py_MEMCPY(op->ob_sval, str, size); op->ob_sval[size] = '\\0'; /* share short strings */ if (size == 0) { PyObject *t = (PyObject *)op; PyString_InternInPlace(&t); op = (PyStringObject *)t; nullstring = op; Py_INCREF(op); } else if (size == 1 && str != NULL) { PyObject *t = (PyObject *)op; PyString_InternInPlace(&t); op = (PyStringObject *)t; characters[*str & UCHAR_MAX] = op; Py_INCREF(op); } return (PyObject *) op; 116:} PyString_FromStringAndSize 的操作和PyString_FromString几乎一样 , 只有一点 , PyString_FromString传入的参数必须是以NUL('\\0') 结尾的字符数组的指针 , 而PyString_FromStringAndSize则没有这个要求 , 因为通过传的size参数就可以确定需要拷贝的字符的个数 intern机制 🍀 从上面两种创建方式的源码中发现 , 无论是PyString_FromString还是PyString_FromStringAndSize , 当字符数组的长度为0或1时 , 需要进行一个特别的操作 : PyString_InternInPlace , 这就是字符串的intern机制 , 也就是上面代码中share short strings 注释下的代码 /* share short strings */ if (size == 0) { PyObject *t = (PyObject *)op; PyString_InternInPlace(&t); op = (PyStringObject *)t; nullstring = op; Py_INCREF(op); } else if (size == 1 && str != NULL) { PyObject *t = (PyObject *)op; PyString_InternInPlace(&t); op = (PyStringObject *)t; characters[*str & UCHAR_MAX] = op; Py_INCREF(op); } return (PyObject *) op; 字符串对象的intern机制的目的是 : 对于被共享之后的字符串 , 比如\"Ruby\" , 在整个Python的运行期间 , 系统中都只有唯一的一个与字符串\"Ruby\"对应的 PyStringObject对象 当判断两个字符串对象是否相同时 , 如果它们都被共享了 , 那么只需要检查它们对应的PyObject *是否相同就可以了 , 这个机制节省了空间 , 如下 : # Python 2.7 >>> str1 = 'lyon' >>> str2 = 'lyon' >>> id(str1) 79116928L >>> id(str2) 79116928L # Python 3.5.4 >>> str1 = 'lyon' >>> str2 = 'lyon' >>> id(str1) 2767446375480 >>> id(str2) 2767446375480 这个例子的创建过程 : 因为'lyon' 对象不存在 , 所以调用接口创建PyStringObject对象 (创建时经过intern机制处理) Python在查找系统中记录的已经被intern机制处理了的PyStringObject 对象 (上一步中同样会进行查找) , 发现'lyon'字符数组对应的PyStringObject已经存在 , 于是返回该对象的引用返回 PyString_InternInPlace 🍀 我们已经知道了创建字符串对象时进行了特殊的操作PyString_InternInPlace , 其源码如下 : Python-2.7\\Objects\\stringobject.c : 4712:void PyString_InternInPlace(PyObject **p) { register PyStringObject *s = (PyStringObject *)(*p); PyObject *t; // 对PyStringObject进行类型和状态检查 if (s == NULL || !PyString_Check(s)) Py_FatalError(\"PyString_InternInPlace: strings only please!\"); /* If it's a string subclass, we don't really know what putting it in the interned dict might do. */ if (!PyString_CheckExact(s)) return; if (PyString_CHECK_INTERNED(s)) return; // 创建记录经intern机制处理后的PyStringObject的dict if (interned == NULL) { interned = PyDict_New(); if (interned == NULL) { PyErr_Clear(); /* Don't leave an exception */ return; } } // 检查PyStringObject对象s是否存在对应的intern后的PyStrinObject对象 t = PyDict_GetItem(interned, (PyObject *)s); if (t) { // 调整引用计数 Py_INCREF(t); Py_DECREF(*p); *p = t; return; } // 在interned中记录检查PyStringObject对象s if (PyDict_SetItem(interned, (PyObject *)s, (PyObject *)s) PyString_InternInPlace 首先会进行一系列检查 : 检查传入的对象是否是一个PyStringObject对象 , intern机制只能应用在PyStringObject对象上 , 甚至对于它的派生类对象系统都不会应用intern机制 检查传入的PyStringObject对象是否已经被intern机制处理过 在代码中 , 我们可以清楚的看到 , intern机制的核心在于interned , 它指向一个由PyDict_new创建的对象 , 也就是一个字典 , 也就是说intern机制的关键就是在系统中有一个存在映射关系的集合 , 它的名字叫做interned , 这个集合里面记录了被intern机制处理过的 特殊的引用计数 🍀 intern机制进行处理时 , 会将PyStringObject对象的PyObject指针分别作为key和value添加到interned中, 也就是说在这里该对象的引用计数应该加了2 , 如果按照正常的引用计数机制 , 那么明显这个对象是永远都不会被删除的 , 比如a = 1;del a , 我们只能够让引用计数减1 , 却无法让其减2 , 所以这里肯定用了特殊的引用计数机制 特殊就在于 , interned中的指针不能作为对象的有效引用 , 这也是为什么在PyString_InternInPlace的代码清单中第4746行为什么会将引用计数减2的原因 一个对象的引用计数在某个时刻减为0之后 , 系统将会销毁该对象 , 那么字符串中到底是怎么解决的呢 ? 看看string_dealloc代码清单 : Python-2.7\\Objects\\stringobject.c : 582:static void string_dealloc(PyObject *op) { switch (PyString_CHECK_INTERNED(op)) { case SSTATE_NOT_INTERNED: break; case SSTATE_INTERNED_MORTAL: /* revive dead object temporarily for DelItem */ Py_REFCNT(op) = 3; if (PyDict_DelItem(interned, op) != 0) Py_FatalError( \"deletion of interned string failed\"); break; case SSTATE_INTERNED_IMMORTAL: Py_FatalError(\"Immortal interned string died.\"); default: Py_FatalError(\"Inconsistent interned string state.\"); } Py_TYPE(op)->tp_free(op); 602:} 在这份代码清单中 , SSTATE_INTERNED_MORTAL 和 SSTATE_INTERNED_IMMORTAL 表示着PyStringObject的两种状态 , 也就是说被intern机制处理后的PyStringObject对象分为两类 , 这两类的区别在于 , SSTATE_INTERNED_IMMORTAL 状态的PyStringObject对象是永远不会被销毁的 PyString_IntenInPlace 只能创建SSTATE_INTERNED_MORTAL 状态的PyStringObject对象 , 如果想创建SSTATE_INTERNED_IMMORTAL状态的对象 , 必须通过另外的接口 , 在调用了PyString_InternInPlace后 , 强制改变PyStringObject的intern状态 注意 : intern机制节省了内存空间 , 但是在我们创建PyStringObject时 , 无论在interned中是否存在 , 都是会创建一个PyStringObject对象的 , 只不过这是一个临时的对象 , 如果interned中有 , 那么就PyString_InternInPlace 会对这个对象的引用计数减1 , 于是它就会被销毁了 字符缓冲池 🍀 与Python整数对象类似 , Python的设计者为PyStringObject中的一个字节的字符对应的PyStringObject对象也设计了一个对象池characters Python-2.7\\Objects\\stringobject.c : 13:static PyStringObject *characters[UCHAR_MAX + 1] 其中UCHAR_MAX是在系统头文件中定义的常量 , 这一个跟平台相关的常量 , 在Win32平台下 : #define UCHAR_MAX 0xff /* maximum unsigned char value */ 在Python的整数对象体系中 , 小整数的缓冲池是在Python初始化时被创建的 , 而字符串对象体系中的字符串缓冲池则是以静态变量的形式存在着的 , 在Python初始化完成之后 , 缓冲池中的所有PyStringObject指针都为空 当我们创建一个字符串对象时 , 无论是通过调用PyString_FromString 还是PyString_FromStringAndSize , 如果字符串实际上是一个字符 , 则会对所创建字符串 (字符) 对象进行intern操作 , 再将intern的结果缓存到字符缓冲池characters中 万恶的加号 🍀 字符串拼接绝对是再正常不过的事情了 , 一拼接 , 那么效率问题就来了 Python中提供了 \"+\" 来进行字符串拼接 , 可惜这实际上就是万恶之源 ; 我们除了使用\"+\" 外 , 还有一种方法就是使用list的join方法 , 这也是官方推荐我们使用的 \"+\" 与 join 通过\"+\"操作符对字符串进行拼接时 , 会调用string_concat函数 : 1014:static PyObject * string_concat(register PyStringObject *a, register PyObject *bb) { register Py_ssize_t size; register PyStringObject *op; ...... #define b ((PyStringObject *)bb) /* Optimize cases with empty left or right operand */ ...... // 计算字符串连接后的长度size size = Py_SIZE(a) + Py_SIZE(b); /* Check that string sizes are not negative, to prevent an overflow in cases where we are passed incorrectly-created strings with negative lengths (due to a bug in other code). */ ...... // 创建新的PyStringObject对象,其维护的用于存储字符的内存长度为size op = (PyStringObject *)PyObject_MALLOC(PyStringObject_SIZE + size); if (op == NULL) return PyErr_NoMemory(); PyObject_INIT_VAR(op, &PyString_Type, size); op->ob_shash = -1; op->ob_sstate = SSTATE_NOT_INTERNED; // 将a和b中的字符拷贝到新创建的PyStringObject中 Py_MEMCPY(op->ob_sval, a->ob_sval, Py_SIZE(a)); Py_MEMCPY(op->ob_sval + Py_SIZE(a), b->ob_sval, Py_SIZE(b)); op->ob_sval[size] = '\\0'; return (PyObject *) op; #undef b 1071:} 小结 : 对于任意两个PyStringObject对象的连接 , 就会进行一次内存申请的动作 通过join函数对字符串进行拼接时 , 会调用string_join函数 : 1573:static PyObject * string_join(PyStringObject *self, PyObject *orig) { char *sep = PyString_AS_STRING(self); const Py_ssize_t seplen = PyString_GET_SIZE(self); PyObject *res = NULL; char *p; Py_ssize_t seqlen = 0; size_t sz = 0; Py_ssize_t i; PyObject *seq, *item; // 拼接字符 seq = PySequence_Fast(orig, \"\"); if (seq == NULL) { return NULL; } // 拼接字符长度 seqlen = PySequence_Size(seq); if (seqlen == 0) { Py_DECREF(seq); return PyString_FromString(\"\"); } if (seqlen == 1) { item = PySequence_Fast_GET_ITEM(seq, 0); if (PyString_CheckExact(item) || PyUnicode_CheckExact(item)) { Py_INCREF(item); Py_DECREF(seq); return item; } } /* There are at least two things to join, or else we have a subclass * of the builtin types in the sequence. * Do a pre-pass to figure out the total amount of space we'll * need (sz), see whether any argument is absurd, and defer to * the Unicode join if appropriate. */ // 遍历list中每一个字符串,获取所有字符串长度 for (i = 0; i tp_name); Py_DECREF(seq); return NULL; } sz += PyString_GET_SIZE(item); if (i != 0) sz += seplen; if (sz PY_SSIZE_T_MAX) { PyErr_SetString(PyExc_OverflowError, \"join() result is too long for a Python string\"); Py_DECREF(seq); return NULL; } } /* Allocate result space. */ // 创建长度为sz的PyStringObject对象 res = PyString_FromStringAndSize((char*)NULL, sz); if (res == NULL) { Py_DECREF(seq); return NULL; } /* Catenate everything. */ // 将list中的字符串拷贝到新创建的PyStringObject对象中 p = PyString_AS_STRING(res); for (i = 0; i 小结 : 首先统计出list中的对象个数 , 并统计这些对象的字符串总长度 , 申请一次内存空间 , 将所有的PyStringObject对象维护的字符串都拷贝到新开辟的内存空间中 通过小结可以很直接的得出答案 , 如果要拼接n个字符串对象 , 那么使用 \"+\" 需要申请空间n-1次 , 而使用join则仅需一次 "},"01-Python/09-In-Depth/05-Python - List对象.html":{"url":"01-Python/09-In-Depth/05-Python - List对象.html","title":"Python - List对象","keywords":"","body":"Python - List对象 欢迎收藏交流 , 如需转载 , 请注明出处 介绍 🍀 元素的一个群是一个非常重要的抽象概念 , 我们可以将符合某一特性的一堆元素聚集为一个群 群的概念对于编程语言十分重要 , C语言就内建了数组的概念 , 每一种实现都为某种目的的元素聚集或元素访问提供极大的方便 PyListObject是Python提供的对列表的抽象 , 它可以支持对元素的插入 , 删除 , 添加等操作 , 所以它是一个可变对象 PyListObject 🍀 Python-2.7\\Include\\listobject.h 22:typedef struct { 23: PyObject_VAR_HEAD 24: /* Vector of pointers to list elements. list[0] is ob_item[0], etc. */ 25: PyObject **ob_item; 26: 27: /* ob_item contains space for 'allocated' elements. The number 28: * currently in use is ob_size. 29: * Invariants: 30: * 0 分析 : PyObject_VAR_HEAD , Python中的列表是一个变长对象 PyObject **ob_item , ob_item为指向元素列表的指针 , 实际上 , Python中的list[0] 就是ob_item[0] Py_ssize_t allocated , 与PyListObject对象的内存管理有关 实际上 , 在PyObject_VAR_HEAD中的ob_size和allocated 都和PyListObject对象的内存管理有关 : PyListObject采用的内存管理策略和C++中vector采取的内存管理策略是一样的 , 它并不是存了多少东西就申请对应大小的内存 , 因为这样的策略显然是低效的 , 而我们使用列表就是为了用户方便用户频繁地插入或删除元素 , 所以 , 在每一次需要申请内存的时候 , PyListObject总会申请一大块内存 , 这时申请的总内存的大小记录在allocated中 , 而其实际被使用了的内存的数量记录在了ob_size中 假如有一个能容纳10个元素的列表已经装入了5个元素 , 那么这个列表的ob_size就是5 , 而allcoated则是10 即 : 0 在Python-3.5.4\\Include\\listobject.h的22至40行 , 我们可以找到相同的代码 , 也就是说2.7与3.5.4的这一部分是没有区别的 创建与维护 🍀 在之前对于Python对象创建方式已有说明 , 为了创建一个列表 , Python只提供了唯一的一条途径 , 就是PyList_New Python-2.7\\Objects\\listobject.c 112:PyObject * PyList_New(Py_ssize_t size) { PyListObject *op; size_t nbytes; #ifdef SHOW_ALLOC_COUNT static int initialized = 0; if (!initialized) { Py_AtExit(show_alloc); initialized = 1; } #endif if (size PY_SIZE_MAX / sizeof(PyObject *)) return PyErr_NoMemory(); // 计算需要使用的内存总量 nbytes = size * sizeof(PyObject *); if (numfree) { // 缓冲池可用 numfree--; op = free_list[numfree]; _Py_NewReference((PyObject *)op); #ifdef SHOW_ALLOC_COUNT count_reuse++; #endif } else { // 缓冲池不可用 op = PyObject_GC_New(PyListObject, &PyList_Type); if (op == NULL) return NULL; #ifdef SHOW_ALLOC_COUNT count_alloc++; #endif } // 为对象中维护的元素列表申请空间 if (size ob_item = NULL; else { op->ob_item = (PyObject **) PyMem_MALLOC(nbytes); if (op->ob_item == NULL) { Py_DECREF(op); return PyErr_NoMemory(); } memset(op->ob_item, 0, nbytes); } Py_SIZE(op) = size; op->allocated = size; _PyObject_GC_TRACK(op); return (PyObject *) op; 163:} 分析 : 这个函数接受一个size参数 , 也就是我们可以在创建时指定PyListObject对象的初始元素个数 在创建时 , 首先计算需要使用的内存总量 , 因为PyList_New指定的仅仅是元素的个数 , 而不是元素实际将占用的内存空间 , 在这里 , Python会检查指定的元素个数是否会大到使所需内存数量产生溢出的程度 , 并根据判断结果做出相应的操作 检查缓冲池是否可用 为维护对象申请内存空间 , 维护对象与PyListOjbect对象本身通过ob_item建立了连接 当Python创建了新的PyListObject对象之后 , 会立即根据调用PyList_New时传递的size参数创建PyListObject对象所维护的元素列表 , 其中每一个元素都被初始化为NULL 在完成了PyListObject对象及维护的列表的创建之后 , Python会调整该PyListObject对象 , 用于维护元素列表中元素数量的ob_size和allocated两个变量 对于缓冲池free_list中的对象个数 , 我们可以在源码中找到 , free_list最多会维护80个PyListObject对象 Python-2.7\\Objects\\listobject.c 94:#ifndef PyList_MAXFREELIST 95:#define PyList_MAXFREELIST 80 96:#endif 97:static PyListObject *free_list[PyList_MAXFREELIST]; 98:static int numfree = 0; Python-3.5.4\\Objects\\listobject.c 95:#ifndef PyList_MAXFREELIST 96:#define PyList_MAXFREELIST 80 97:#endif 98:static PyListObject *free_list[PyList_MAXFREELIST]; 99:static int numfree = 0; 设置元素 🍀 在我们创建第一个PyListObject对象时 , 这时候缓冲池是不可用的 , 于是会调用PyObject_GC_New在系统堆上创建一个新的PyListObject对象 , 假如我们创建一个包含6个元素的PyListObject , 那么创建成功之后 , 这个对象的ob_size为6 , allocated为6 , 而ob_item则是指向这些元素的指针 而当我们设置元素时 , 如现有一个列表la = [1, 2, 3] , 当我们执行la[0] = 4时 , 在Python内部 , 会调用PyList_SetItem来完成这个动作 ; 首先Python会进行类型检查 , 随后会进行索引的有效性检查 , 当这两者都通过后 , 将新设置的元素指针放到指定的位置 , 然后调整引用计数 , 将这个位置原来存放的对象的引用计数减1 , 源码如下 : Python-2.7\\Objects\\listobject.c 198:int PyList_SetItem(register PyObject *op, register Py_ssize_t i, register PyObject *newitem) { register PyObject *olditem; register PyObject **p; if (!PyList_Check(op)) { Py_XDECREF(newitem); PyErr_BadInternalCall(); return -1; } if (i = Py_SIZE(op)) { Py_XDECREF(newitem); PyErr_SetString(PyExc_IndexError, \"list assignment index out of range\"); return -1; } p = ((PyListObject *)op) -> ob_item + i; olditem = *p; *p = newitem; Py_XDECREF(olditem); return 0; 220:} Python-3.5.4\\Objects\\listobject.c 215:int PyList_SetItem(PyObject *op, Py_ssize_t i, PyObject *newitem) { PyObject *olditem; PyObject **p; if (!PyList_Check(op)) { Py_XDECREF(newitem); PyErr_BadInternalCall(); return -1; } if (i = Py_SIZE(op)) { Py_XDECREF(newitem); PyErr_SetString(PyExc_IndexError, \"list assignment index out of range\"); return -1; } p = ((PyListObject *)op) -> ob_item + i; olditem = *p; *p = newitem; Py_XDECREF(olditem); return 0; 237:} 在两个版本中 , 没有变化 插入元素 🍀 设置元素和插入元素的动作是不同的 , 设置元素不会导致ob_item指向的内存发生变化 , 但是插入元素的动作则有可能使得ob_item指向的内存发生变化 Python内部通过调用PyList_Insert来完成元素的插入动作 , 而PyList_Insert实际上是调用了内部的insl , 如下 : Python-2.7\\Objects\\listobject.c 222:static int ins1(PyListObject *self, Py_ssize_t where, PyObject *v) { Py_ssize_t i, n = Py_SIZE(self); PyObject **items; if (v == NULL) { PyErr_BadInternalCall(); return -1; } if (n == PY_SSIZE_T_MAX) { PyErr_SetString(PyExc_OverflowError, \"cannot add more objects to list\"); return -1; } // 调整列表容量 if (list_resize(self, n+1) == -1) return -1; // 确定插入点 if (where n) where = n; // 插入元素 items = self->ob_item; for (i = n; --i >= where; ) items[i+1] = items[i]; Py_INCREF(v); items[where] = v; return 0; } 255:int 256:PyList_Insert(PyObject *op, Py_ssize_t where, PyObject *newitem) { // 类型检查 if (!PyList_Check(op)) { PyErr_BadInternalCall(); return -1; } return ins1((PyListObject *)op, where, newitem); 263:} Python-3.5.4\\Objects\\listobject.c 239:static int ins1(PyListObject *self, Py_ssize_t where, PyObject *v) { Py_ssize_t i, n = Py_SIZE(self); PyObject **items; if (v == NULL) { PyErr_BadInternalCall(); return -1; } if (n == PY_SSIZE_T_MAX) { PyErr_SetString(PyExc_OverflowError, \"cannot add more objects to list\"); return -1; } // 调整列表容量 if (list_resize(self, n+1) == -1) return -1; // 确定插入点 if (where n) where = n; // 插入元素 items = self->ob_item; for (i = n; --i >= where; ) items[i+1] = items[i]; Py_INCREF(v); items[where] = v; return 0; } 272:int 273:PyList_Insert(PyObject *op, Py_ssize_t where, PyObject *newitem) { // 类型检查 if (!PyList_Check(op)) { PyErr_BadInternalCall(); return -1; } return ins1((PyListObject *)op, where, newitem); 280:} 在insl中 , 为了完成元素的插入工作 , 首先必须保证PyListObject对象有足够的内存来容纳我们期望插入的元素 , 这一步是通过insl中的list_resize函数来实现的 , 正是这个函数改变了PyListObject所维护的PyObject * 列表的大小 Python-2.7\\Objects\\listobject.c 24:static int list_resize(PyListObject *self, Py_ssize_t newsize) { PyObject **items; size_t new_allocated; Py_ssize_t allocated = self->allocated; /* Bypass realloc() when a previous overallocation is large enough to accommodate the newsize. If the newsize falls lower than half the allocated size, then proceed with the realloc() to shrink the list. */ // 不需要重新申请内存 if (allocated >= newsize && newsize >= (allocated >> 1)) { assert(self->ob_item != NULL || newsize == 0); Py_SIZE(self) = newsize; return 0; } /* This over-allocates proportional to the list size, making room * for additional growth. The over-allocation is mild, but is * enough to give linear-time amortized behavior over a long * sequence of appends() in the presence of a poorly-performing * system realloc(). * The growth pattern is: 0, 4, 8, 16, 25, 35, 46, 58, 72, 88, ... */ // 计算重新申请的内存大小 new_allocated = (newsize >> 3) + (newsize PY_SIZE_MAX - newsize) { PyErr_NoMemory(); return -1; } else { new_allocated += newsize; } if (newsize == 0) new_allocated = 0; // 扩展列表 items = self->ob_item; if (new_allocated ob_item = items; Py_SIZE(self) = newsize; self->allocated = new_allocated; return 0; 73:} 同样的 , 在Python-3.5.4\\Objects\\listobject.c 中的第25至74行为该函数的定义 在调整PyListObject对象所维护的列表的内存时 , Python分两种情况处理 : newsize allocated/2 , 也就是说当插入后使用的实际内存大小要小于总内存大小 , 以及要大于总内存大小的一半时 , 就简单调整ob_size值 其他情况 , 调用realloc , 重新分配空间 我们可以发现 , 对于第二种情况 , 比如newsize 时 , Python也会调用realloc来收缩列表的内存空间 , 不得不说这是物尽其用的设计 删除元素 🍀 以list对象方法remove为例 , 当我们使用remove方法时 , PyListObject中的listremove操作就会被激活 Python-2.7\\Objects\\listobject.c 2336:static PyObject * listremove(PyListObject *self, PyObject *v) { Py_ssize_t i; for (i = 0; i ob_item[i], v, Py_EQ); if (cmp > 0) { if (list_ass_slice(self, i, i+1, (PyObject *)NULL) == 0) Py_RETURN_NONE; return NULL; } else if (cmp Python-3.5.4\\Objects\\listobject.c 第2197至2215见同上代码清单 首先Python会对整个列表进行遍历 , 在遍历PyListObject中所有元素的过程中 , 将待删除元素与PyListObject中的每个元素一一进行比较 , 比较操作是通过PyObject_RichCompareBool完成的 , 如果返回值大于0 , 则表示要删除的元素与列表中的元素匹配成功 , Python将立即调用list_ass_slice删除该元素 Python-2.7\\Objects\\listobject.c 607:/* a[ilow:ihigh] = v if v != NULL. // 不为空就替换 * del a[ilow:ihigh] if v == NULL. // 为空就删除 * * Special speed gimmick: when v is NULL and ihigh - ilow Python-3.5.4\\Objects\\listobject.c 第572至579见同上代码清单 如上 , 对于list_ass_slice其实是有两种语义的 , 即replace和remove ; 于是 , 在Python列表中删除元素我们还可以这样做 : # Python 2.x & 3.x >>> la = [1,2,3,4,5] >>> la[1:3] = [] >>> la [1, 4, 5] 对于list对象的pop方法 , 同样也是调用list_ass_slice来进行删除 , 源码位于listobject.c文件中 对象缓冲池 🍀 在PyList_New中我们见过一个free_list , 这就是PyListObject对象缓冲池 ; 但是我们在PyList_New中并没有看到缓冲池中的PyListObject对象的添加过程 , 这是因为缓冲池对象并不像前面的字符串对象或者整数对象一样 , 是在创建时添加的 , Python列表的缓冲池是在其销毁的时候添加的 Python-2.7\\Objects\\listobject.c 296:static void list_dealloc(PyListObject *op) { Py_ssize_t i; PyObject_GC_UnTrack(op); Py_TRASHCAN_SAFE_BEGIN(op) // 销毁PyListObject对象维护的元素列表 if (op->ob_item != NULL) { /* Do it backwards, for Christian Tismer. There's a simple test case where somehow this reduces thrashing when a *very* large list is created and immediately deleted. */ i = Py_SIZE(op); while (--i >= 0) { Py_XDECREF(op->ob_item[i]); } PyMem_FREE(op->ob_item); } // 释放PyListObject自身 if (numfree tp_free((PyObject *)op); Py_TRASHCAN_SAFE_END(op) 318:} 与PyListObject对象创建一样 , PyListObject对象的销毁也是分离的 , 首先销毁PyListObject对象所维护的元素列表 , 然后再释放PyListObject对象本身 ; 这样的工作无非是改变该对象的引用计数 , 然后再释放内存 , 但是我们发现 , 在释放PyListObject本身时 , Python会检查前面提到的这个缓冲池free_list 首先Python会查看其中缓存的PyListObject对象的数量是否已经满了 , 如果没有 , 就将该待删除的PyListObject对象放到缓冲池中 , 以备后用 注意 , 我们也已经发现了 , 添加进缓冲池的是PyListObject对象本身 , 而不包括它之前维护的元素列表 , 也就是说我们在创建新的PyListObject时 , Python会首先唤醒这些已经 \"死去\" 的PyListObject , 然后赋予它们新的元素列表 , 使其能够重新做 \"人\" 对于每次创建PyListObject对象时必须创建元素列表 , 这是Python为了避免过多的消耗系统内存 , 采取的时间换空间的做法 "},"01-Python/09-In-Depth/06-Python - Dict对象.html":{"url":"01-Python/09-In-Depth/06-Python - Dict对象.html","title":"Python - Dict对象","keywords":"","body":"Python - Dict对象 欢迎收藏交流 , 如需转载 , 请注明出处 介绍 🍀 为了刻画某种元素之间的对应关系 , 现代编程语言通常都在语言级或标准库中提供某种关联式的容器 ; 关联容器的设计总会极大地关注键的搜索效率 , 因为我们希望根据我们手中已有的某个元素来快速获得与之有某种联系的另一元素 在Python中同样提供关联式容器 , 即PyDictObject 对象 , 与map不同的是 , PyDictObject对搜索的效率要求极其苛刻 , 这也是因为PyDictObject对象在Python本身的实现中被大量采用 ; 比如Python会通过PyDictObject来建立执行Python字节码的运行环境 , 其中会存放变量名和变量值的元素对 , 通过查找变量名获得变量值 , 因此PyDictObject采用的是散列表 (hash table) , 因为理论上 , 在最优情况下 , 散列表能提供O(1)复杂度的搜索效率 散列表 🍀 散列表的基本思想 , 是通过一定的函数将需搜索的键值映射为一个整数 , 将这个整数视为索引值去访问某片连续的区域 对散列表这种数据结构的采用是以加速键的搜索过程为终极目标的 , 所以 , 将元素映射为整数的过程对于Python中dict的实现就显得尤为关键 ; 用于映射的函数称为散列函数 (hash function) , 映射后的值称为元素的散列值 (hash value) , 在散列表的实现中 , 所选择的散列函数的优劣直接决定所实现的散列表的搜索效率的高低 在使用散列表的过程中 , 不同的对象经过散列函数的作用 , 可能被映射为相同的散列值 , 这就是散列冲突 根据研究表明 , 当散列表的装载率大于2/3时 , 散列冲突发生的概率就会大大增加 解决散列冲突的方法有很多种 , 在Python中采用的是开放定址法 当产生散列冲突时 , Python会通过一个二次探测函数f , 计算下一个候选位置addr , 如果位置addr可用 , 则可将待插入元素放到位置addr ; 如果位置addr不可用 , 则Python会再次使用探测函数f , 获得下一个候选位置 , 以此依次寻找下去 最后 , 这些位置会形成一个\"冲突探测链\"(或简称探测序列) , 而当我们要删除某条探测链上的某个元素时 , 按照探测链会发生什么样的情况 ; 假如这条链的首元素位置为a , 尾元素的位置为c , 现在需要删除中间的某个位置b上的元素 , 如果直接将位置b上的元素删除 , 则会导致探测链的断裂 , 于是探测函数在探测时将再也不能到达位置c了 , 所以删除某条探测链上的元素时不能进行真正的删除 , 而是进行一种 \"伪删除\" 操作 , 必须要让该元素还存在于探测链上 在Python中 , 这种伪删除是在PyDictObject对象中实现的 PyDictObject 🍀 在Python2.7中 , 关联容器的一个(键 , 值)元素对称为一个entry或slot Python-2.7\\Include\\dictobject.h 50:typedef struct { /* Cached hash code of me_key. Note that hash codes are C longs. * We have to use Py_ssize_t instead because dict_popitem() abuses * me_hash to hold a search finger. */ Py_ssize_t me_hash; PyObject *me_key; PyObject *me_value; 58:} PyDictEntry; 在PyDictEntry中 , me_hash域存储的是me_key的散列值 , 利用一个域来记录这个散列值可以避免每次查询的时候都要重新计算一遍散列值 在Python中 , 在一个PyDictObject对象生存变化的过程中 , 其中的entry会在不同的状态间转换 ; PyDictObject中entry可以在3种状态之间转换 : Unused , Active , Dummy Unused : 当一个entry的me_key和me_value都为NULL时 , entry处于Unused态 ; 表明目前该entry中并没有存储(key , value)对 , 而且在此之前 , 也没有存储过它们 , 这时每一个entry在初始化时的状态 , 并且也只有在Unused态下 , entry的me_key域才会为NULL Active : 当entry中存储了一个(key , value)对时 , entry便转到了Active态 , 在Active态下 , me_key和me_value都不能为NULL Dummy : 当entry中存储的(key , value)对被删除后 , entry的状态不能直接从Active态转为Unused态 , 因为这样会导致冲突探测链的中断 , 所以entry中的me_key将指向dummy对象 , 从而entry进入Dummy态 , 这就是\"伪删除\"技术 ; 当Python沿着某条冲突链搜索时 , 如果发现一个entry处于Dummy态 , 说明目前该entry虽然是无效的 , 但是其后的entry可能是有效的 , 是应该被搜索的 , 这样就保证了冲突探测链的连续性 在Python中 , 关联容器是通过PyDictObject对象来实现的 , 而一个PyDictObject 对象实际上是一大堆entry的集合 : Python-2.7\\Include\\dictobject.h 70:typedef struct _dictobject PyDictObject; struct _dictobject { PyObject_HEAD Py_ssize_t ma_fill; /* # Active + # Dummy */ Py_ssize_t ma_used; /* # Active */ /* The table contains ma_mask + 1 slots, and that's a power of 2. * We store the mask instead of the size because the mask is more * frequently needed. */ Py_ssize_t ma_mask; /* ma_table points to ma_smalltable for small tables, else to * additional malloc'ed memory. ma_table is never NULL! This rule * saves repeated runtime null-tests in the workhorse getitem and * setitem calls. */ PyDictEntry *ma_table; PyDictEntry *(*ma_lookup)(PyDictObject *mp, PyObject *key, long hash); PyDictEntry ma_smalltable[PyDict_MINSIZE]; 90:}; 定义说明 : ma_fill , ma_fill域中维护着从PyDictObject对象创建开始直到现在 , 曾经及正处于Active态的entry个数 , 而ma_used则维护着当前正处于Active态的entry的数量 在定义的最后 , 有一个名为ma_smalltable的PyDictEntry数组 , 这个数组意味着当创建一个PyDictObject对象时 , 至少有PyDict_MINSIZE个entry被同时创建 , 在dictobject.h中 , 这个值被设定为8 , 这个值被认为时通过大量的实验得出的最佳值 ; 它既不会态浪费内存空间 , 又能很好地满足Python内部大量使用PyDictObject的环境的需求 ma_table , ma_table域是关联对象的关键所在 , 它将指向一片作为PyDictEntry集合的内存的开始位置 , 当一个PyDictObject对象是一个比较小的dict时 (entry数量少于8) , ma_table域将指向ma_smalltable , 而当PyDictObject中的entry数量超过8个时 , 将会申请额外的内存空间 , 并将ma_table指向这块空间 , 这样 , 无论何时 , ma_table域都不会为NULL , 那么在程序运行时就不需要一次又一次的检查ma_table的有效性了 , 因为ma_table总是有效的 , 这两种ma_table见下图 ma_mask , PyDictObject中的ma_mask记录了一个PyDictObject对象中所拥有的entry数量 创建与维护 🍀 Python内部通过PyDict_New来创建一个新的dict对象 Python-2.7\\Include\\dictobject.c 210:#define INIT_NONZERO_DICT_SLOTS(mp) do { \\ (mp)->ma_table = (mp)->ma_smalltable; \\ // PyDict_MINSIZE定义在dictobject.h中,默认值为8 (mp)->ma_mask = PyDict_MINSIZE - 1; \\ } while(0) \\ #define EMPTY_TO_MINSIZE(mp) do { \\ memset((mp)->ma_smalltable, 0, sizeof((mp)->ma_smalltable)); \\ (mp)->ma_used = (mp)->ma_fill = 0; \\ INIT_NONZERO_DICT_SLOTS(mp); \\ 219:} while(0) 220:/* Dictionary reuse scheme to save calls to malloc, free, and memset */ #ifndef PyDict_MAXFREELIST #define PyDict_MAXFREELIST 80 #endif static PyDictObject *free_list[PyDict_MAXFREELIST]; 226:static int numfree = 0; ...... 240:PyObject * PyDict_New(void) { register PyDictObject *mp; // 自动创建dummy对象 if (dummy == NULL) { /* Auto-initialize dummy */ dummy = PyString_FromString(\"\"); if (dummy == NULL) return NULL; #ifdef SHOW_CONVERSION_COUNTS Py_AtExit(show_counts); #endif #ifdef SHOW_ALLOC_COUNT Py_AtExit(show_alloc); #endif #ifdef SHOW_TRACK_COUNT Py_AtExit(show_track); #endif } if (numfree) { // 使用缓冲池 mp = free_list[--numfree]; assert (mp != NULL); assert (Py_TYPE(mp) == &PyDict_Type); _Py_NewReference((PyObject *)mp); if (mp->ma_fill) { EMPTY_TO_MINSIZE(mp); } else { /* At least set ma_table and ma_mask; these are wrong if an empty but presized dict is added to freelist */ INIT_NONZERO_DICT_SLOTS(mp); } assert (mp->ma_used == 0); assert (mp->ma_table == mp->ma_smalltable); assert (mp->ma_mask == PyDict_MINSIZE - 1); #ifdef SHOW_ALLOC_COUNT count_reuse++; #endif } else { // 创建PyDictObject对象 mp = PyObject_GC_New(PyDictObject, &PyDict_Type); if (mp == NULL) return NULL; EMPTY_TO_MINSIZE(mp); #ifdef SHOW_ALLOC_COUNT count_alloc++; #endif } mp->ma_lookup = lookdict_string; #ifdef SHOW_TRACK_COUNT count_untracked++; #endif #ifdef SHOW_CONVERSION_COUNTS ++created; #endif return (PyObject *)mp; 293:} 在定义的开始部分我们可以发现 , 自动创建dummy对象 , 这个dummy对象竟然时一个PyStringObject对象 , 实际上 , 它仅仅时用来作为一种指示标志 , 表明该entry曾被使用过 , 且探测序列下一个位置的entry有可能时有效的 , 从而防止探测序列中断 如果不使用缓冲池 , 创建时将调用EMPTY_TO_MINSIZE , 将ma_smalltable清零 , 同时设置ma_size和ma_fill , 初始时 , 这两个变量都为0 , 随后调用INIT_NONZERO_DICT_SLOTS , 其功能是将ma_table指向ma_smalltable , 并设置ma_mask为7 在创建过程的最后 , 将lookdict_string赋给了ma_lookup , 这个ma_lookup指定了PyDictObjec在entry集合中搜索某一特定entry时需要进行的动作 , 在ma_lookup中 , 包含了散列函数和发生冲突时二次探测函数的具体实现 , 它时PyDictObject的搜索策略 PyDictObject缓冲池见下文 元素搜索 🍀 Python为PyDictObject对象提供了两种搜索策略 , lookdict和lookdict_string , 但是实际上 , 这两种策略使用的相同的算法 , lookdict_string只是对lookdict的一种针对PyStringObject对象的特殊形式 , 这是因为以PyStringObject对象作为PyDictObject对象中entry的键在Python中应用非常广泛 lookdict 🍀 Python-2.7\\Include\\dictobject.c 319:static PyDictEntry * lookdict(PyDictObject *mp, PyObject *key, register long hash) { register size_t i; register size_t perturb; register PyDictEntry *freeslot; register size_t mask = (size_t)mp->ma_mask; PyDictEntry *ep0 = mp->ma_table; register PyDictEntry *ep; register int cmp; PyObject *startkey; // 散列,定位冲突探测链的第一个entry 331: i = (size_t)hash & mask; ep = &ep0[i]; // entry处于Unused态 if (ep->me_key == NULL || ep->me_key == key) return ep; // entry处于Dummy态 if (ep->me_key == dummy) 337: freeslot = ep; else { // 检查Active态entry if (ep->me_hash == hash) { startkey = ep->me_key; Py_INCREF(startkey); cmp = PyObject_RichCompareBool(startkey, key, Py_EQ); Py_DECREF(startkey); if (cmp ma_table && ep->me_key == startkey) { if (cmp > 0) return ep; } else { /* The compare did major nasty stuff to the * dict: start over. * XXX A clever adversary could prevent this * XXX from terminating. */ return lookdict(mp, key, hash); } } freeslot = NULL; } //------------------ 以上为第一检查-------------------- /* In the loop, me_key == dummy is by far (factor of 100s) the least likely outcome, so test for that last. */ // 寻找探测链上的下一个entry for (perturb = hash; ; perturb >>= PERTURB_SHIFT) { i = (i me_key == NULL) return freeslot == NULL ? ep : freeslot; // 检查引用是否相同 if (ep->me_key == key) return ep; // 检查值是否相同 if (ep->me_hash == hash && ep->me_key != dummy) { startkey = ep->me_key; Py_INCREF(startkey); cmp = PyObject_RichCompareBool(startkey, key, Py_EQ); Py_DECREF(startkey); if (cmp ma_table && ep->me_key == startkey) { if (cmp > 0) return ep; } else { /* The compare did major nasty stuff to the * dict: start over. * XXX A clever adversary could prevent this * XXX from terminating. */ return lookdict(mp, key, hash); } } // 设置freeslot else if (ep->me_key == dummy && freeslot == NULL) freeslot = ep; } assert(0); /* NOT REACHED */ return 0; 396:} 第一次检查 PyDictObject中维护的entry的数量是有限的 , 而传入lookdict中的key的hash值却不一定在限定范围内 , 所以这就要求lookdict将hash值映射到某个entry上去 , lookdict采取的策略是 , 直接将hash值与entry的数量做一个&操作(见331行) , 该操作的结果就是entry的数量 , 也就是ma_mask 之所以命名为mask而不是size , 是因为ma_mask会被用来进行大量的&操作 , 所以entry数量相关的变量被命名为ma_mask freeslot指向一个指示失败且立即可用的entry : 在搜索过程中 , 如果探测链中的某个位置上 , entry处于Dummy态 , 那么如果在这个序列中搜索不成功 , 就会返回这个处于Dummy态的entry , 这个freeslot正是用来指向探测序列中第一个处于Dummy态的entry (me_value为NULL); 如果探测序列并没有Dummy态entry , 搜索失败时 , freeslot则指向一个处于Unused态的entry , 同样是一个能指示失败且立即可用的entry 在元素搜索时 , 会先进行两个key的值检查 , 首先检查两个对象的hash值是否相同 , 如果不相同 , 就直接中断 ; 而如果相同 , 那么Python将通过PyObject_RichCompareBool进行比较 , 其原型如下 : int PyObject_RichCompareBool(PyObject *v, PyObject *w, int op) 当v op w成立时 , 返回1 ; 不成立时 , 返回0 ; 如果在比较中发生了错误返回-1 在lookdict代码清单中 , 指定的Py_EQ , 表示进行相等比较操作 对于lookdict代码清单的前半部分 , 也就是第一次检查小结 : 根据hash值获取entry索引 , 这是冲突探测链上的第一个entry索引 两种情况下 , 搜索结束 : entry处于Unused态 , 表明冲突探测链搜索完成 , 搜索失败 ep->me_key == key , 表明entry的key与待搜索的key匹配 , 搜索成功 若当前entry处于Dummy态 , 设置freeslot 检查Active态entry中的key与待查找的key是否值相同 后续操作 在第一个entry检查完毕后 , 后续的动作本质都是一样的 对于lookdict代码清单的前半部分小结 : 根据Python所采用的探测函数 , 获得探测链中的下一个待检查的entry 检查到一个Unused态entry , 表明搜索失败 , 有如下两种结果 : 如果freeslot不为空 , 则返回freeslot 所指entry 如果freeslot为空 , 则返回该Unused态entry 检查entry中的key与待查找的key是否引用相同 检查entry中的key与待查找的key是否值相同 在遍历过程中 , 如果发现Dummy态entry , 且freeslot未设置 , 则设置freeslot lookdict_string 🍀 Python-2.7\\Include\\dictobject.c 407:static PyDictEntry * lookdict_string(PyDictObject *mp, PyObject *key, register long hash) { register size_t i; register size_t perturb; register PyDictEntry *freeslot; register size_t mask = (size_t)mp->ma_mask; PyDictEntry *ep0 = mp->ma_table; register PyDictEntry *ep; /* Make sure this function doesn't have to handle non-string keys, including subclasses of str; e.g., one reason to subclass strings is to override __eq__, and for speed we don't cater to that here. */ // 选择搜索策略 if (!PyString_CheckExact(key)) { #ifdef SHOW_CONVERSION_COUNTS ++converted; #endif mp->ma_lookup = lookdict; return lookdict(mp, key, hash); } // 检查冲突链上第一个entry i = hash & mask; ep = &ep0[i]; // entry处于Unused态,entry中的key与待搜索的key匹配 if (ep->me_key == NULL || ep->me_key == key) return ep; // 第一个entry处于Dummy态,设置freeslot if (ep->me_key == dummy) freeslot = ep; else { // 检查Active态entry if (ep->me_hash == hash && _PyString_Eq(ep->me_key, key)) return ep; freeslot = NULL; } /* In the loop, me_key == dummy is by far (factor of 100s) the least likely outcome, so test for that last. */ // 遍历冲突链,检查每一个entry for (perturb = hash; ; perturb >>= PERTURB_SHIFT) { i = (i me_key == NULL) return freeslot == NULL ? ep : freeslot; if (ep->me_key == key || (ep->me_hash == hash && ep->me_key != dummy && _PyString_Eq(ep->me_key, key))) return ep; if (ep->me_key == dummy && freeslot == NULL) freeslot = ep; } assert(0); /* NOT REACHED */ return 0; 457:} lookdict_string是一种有条件限制的搜索策略 , 即待搜索的key是一个PyStringObject对象 , 只有当假设成立时 , lookdict_string才会被使用 , 其中_PyString_Eq将保证能正确处理非PyStringObject *参数 其实lookdict_string仅仅是一个lookdict的优化版本 , 因为在Python中大量的使用了PyDictObject对象 , 以用来维护一个命名空间(名字空间)中变量名与变量值之间的对应关系 , 又或者是用来在为函数传递参数名与参数值的对应关系 , 而这些对象几乎都是用PyStringObject对象作为entry中的key , 所以lookdict_string的出现是很有必要的 , 它对Python整体的运行效率都有着重要的影响 插入与删除 🍀 PyDictObject对象中元素的插入动作是建立在搜索的基础之上的 Python-2.7\\Include\\dictobject.c 512:static int insertdict(register PyDictObject *mp, PyObject *key, long hash, PyObject *value) { PyObject *old_value; register PyDictEntry *ep; typedef PyDictEntry *(*lookupfunc)(PyDictObject *, PyObject *, long); assert(mp->ma_lookup != NULL); ep = mp->ma_lookup(mp, key, hash); if (ep == NULL) { Py_DECREF(key); Py_DECREF(value); return -1; } MAINTAIN_TRACKING(mp, key, value); // 搜索成功 if (ep->me_value != NULL) { old_value = ep->me_value; ep->me_value = value; Py_DECREF(old_value); /* which **CAN** re-enter */ Py_DECREF(key); } // 搜索失败 else { if (ep->me_key == NULL) mp->ma_fill++; else { assert(ep->me_key == dummy); Py_DECREF(dummy); } ep->me_key = key; ep->me_hash = (Py_ssize_t)hash; ep->me_value = value; mp->ma_used++; } return 0; 546:} insertdict中 , 根据搜索的结果采取不同的动作 : 搜索成功 , 返回处于Active的entry , 并直接替换me_value 搜索失败 , 返回Unused或Dummy态的entry , 完整设置me_key , me_hash 和 me_value 在Python中 , 对PyDictObject对象插入或设置元素两种情况 , 如下代码 : d = {} # entry不存在 d[1] = 1 # entry已存在 d[1] = 2 当这段代码执行时 , Python并不是直接调用insertdict , 因为insertdict需要一个hash值作为调用参数 , 所以在调用insertdict会先调用PyDict_SetItem Python-2.7\\Include\\dictobject.c 747:int PyDict_SetItem(register PyObject *op, PyObject *key, PyObject *value) { register PyDictObject *mp; register long hash; register Py_ssize_t n_used; if (!PyDict_Check(op)) { PyErr_BadInternalCall(); return -1; } assert(key); assert(value); mp = (PyDictObject *)op; // 计算hash值 if (PyString_CheckExact(key)) { hash = ((PyStringObject *)key)->ob_shash; if (hash == -1) hash = PyObject_Hash(key); } else { hash = PyObject_Hash(key); if (hash == -1) return -1; } assert(mp->ma_fill ma_mask); /* at least one empty slot */ // 插入(key, value)元素对 n_used = mp->ma_used; Py_INCREF(value); Py_INCREF(key); // 必要时调整dict的内存空间 if (insertdict(mp, key, hash, value) != 0) return -1; /* If we added a key, we can safely resize. Otherwise just return! * If fill >= 2/3 size, adjust size. Normally, this doubles or * quaduples the size, but it's also possible for the dict to shrink * (if ma_fill is much larger than ma_used, meaning a lot of dict * keys have been * deleted). * * Quadrupling the size improves average dictionary sparseness * (reducing collisions) at the cost of some memory and iteration * speed (which loops over every possible entry). It also halves * the number of expensive resize operations in a growing dictionary. * * Very large dictionaries (over 50K items) use doubling instead. * This may help applications with severe memory constraints. */ // 可转换为 (mp->mafill)/(mp->ma_mask+1) >= 2/3 if (!(mp->ma_used > n_used && mp->ma_fill*3 >= (mp->ma_mask+1)*2)) return 0; return dictresize(mp, (mp->ma_used > 50000 ? 2 : 4) * mp->ma_used); 794:} 我们可以看到 , 在PyDict_SetItem中 , 会首先获取key的hash值 , 随后会调用insertdict来插入元素对 , 再接下来会检查是否需要改变PyDictObject内部ma_table所维护的内存区域的大小 至于如何调整 , 可以查看dictobject.c中的dictresize函数 , 接下来看如何删除一个元素 Python-2.7\\Include\\dictobject.c 796:int PyDict_DelItem(PyObject *op, PyObject *key) { register PyDictObject *mp; register long hash; register PyDictEntry *ep; PyObject *old_value, *old_key; if (!PyDict_Check(op)) { PyErr_BadInternalCall(); return -1; } assert(key); // 同样先获取hash值 if (!PyString_CheckExact(key) || (hash = ((PyStringObject *) key)->ob_shash) == -1) { hash = PyObject_Hash(key); if (hash == -1) return -1; } // 搜索entry mp = (PyDictObject *)op; ep = (mp->ma_lookup)(mp, key, hash); if (ep == NULL) return -1; if (ep->me_value == NULL) { set_key_error(key); return -1; } // 删除entry所维护的元素,将entry的状态转为dummy态 old_key = ep->me_key; Py_INCREF(dummy); ep->me_key = dummy; old_value = ep->me_value; ep->me_value = NULL; mp->ma_used--; Py_DECREF(old_value); Py_DECREF(old_key); return 0; 832:} 与插入操作类似 , 先计算hash值 , 然后搜索相应的entry , 最后删除entry中维护的元素 , 并将entry从Active态变换为Dummy态 , 同时还将调整PyDictObject对象中维护table使用情况的变量 小结 : 无论是插入还是删除元素 , 都会先计算hash值 , 随后进行搜索相应的entry , 随后插入或删除元素 , 转换entry的状态 ; 而PyDictObject对象元素的插入则主要是通过freeslot所指向的entry来进行的 对象缓冲池 🍀 在PyDictObject的实现机制中 , 同样使用了缓冲池计数 , 并且其缓冲池机制与PyListObject中使用的缓冲池机制是一样的 Python-2.7\\Include\\dictobject.c 974:static void dict_dealloc(register PyDictObject *mp) { register PyDictEntry *ep; Py_ssize_t fill = mp->ma_fill; PyObject_GC_UnTrack(mp); Py_TRASHCAN_SAFE_BEGIN(mp) // 调整dict中对象的引用计数 for (ep = mp->ma_table; fill > 0; ep++) { if (ep->me_key) { --fill; Py_DECREF(ep->me_key); Py_XDECREF(ep->me_value); } } // 释放从系统堆中申请的内存空间 if (mp->ma_table != mp->ma_smalltable) PyMem_DEL(mp->ma_table); // 将被销毁的PyDictObject对象放入缓冲池 if (numfree tp_free((PyObject *)mp); Py_TRASHCAN_SAFE_END(mp) 995:} 开始时 , 这个缓冲池中什么也没有 , 直到第一个PyDictObject被销毁时 , 这个缓冲池才开始接纳被缓冲的PyDictObject对象 , 与PyListObject对象一样 , 只保留了PyDictObject对象 但是需要注意的是 , 销毁时根据ma_table的两种情况处理方式也是不同的 : 如果ma_table指向的是从系统堆申请的内存空间 (额外的内存) , 那么Python将释放这块内存空间归还给系统堆 如果ma_table指向的是PyDictObject的ma_smalltable , 那么只需要调整ma_smalltable中的对象的引用计数就可以了 在创建新的PyDictObject对象时 , 如果在缓冲池中有可以使用的对象 , 则直接从缓冲池中取出使用 , 而不需要再重新创建 , 这一点在PyDict_New中就已经体现了 至此 , 对于Python 2.7中的dict对象就差不多了 , 对于Python 3.5.4版本的比较待后期继续 , 不过简单的对比之下就可以发现 , 在Python 3.5.4的版本中 , 新增了一个dictnotes.txt文件 , 而且由2.7的3个状态变成了4个状态 , 数据层次也发生了一些改变 , 比如PyDictObject从2.7中的一种形式 , 变成了两种形式 (联合表和分割表) , 新增了PyDictKeyObject对象等 "},"01-Python/09-In-Depth/07-Python - Tuple对象.html":{"url":"01-Python/09-In-Depth/07-Python - Tuple对象.html","title":"Python - Tuple对象","keywords":"","body":"Python - Tuple对象 欢迎收藏交流 , 如需转载 , 请注明出处 介绍 🍀 Python中的tuple与str一样 , 都属于不可变对象 , 即其所维护的数据在对象创建之后就不能再改变了 直接看PyTupleObject吧 PyTupleObject 🍀 Python-2.7\\Include\\tupleobject.h: 24:typedef struct { 25: PyObject_VAR_HEAD 26: PyObject *ob_item[1]; 27: 28: /* ob_item contains space for 'ob_size' elements. 29: * Items must normally not be NULL, except during construction when 30: * the tuple is not yet visible outside the function that builds it. 31: */ 32:} PyTupleObject; 通过上面的代码清单 , 我们可以看到 , PyTupleObject除了是一个不可变对象之外 , 它还是一个变长对象 ; 而ob_item 则为指向元素列表的指针 通过前面的整理 , 对于这些再熟悉不过了 创建与维护 🍀 PyTupleObject对象的创建同其他对象一样 , 其是通过PyTuple_New来创建的 Python-2.7\\Objects\\tupleobject.c 48:PyObject * PyTuple_New(register Py_ssize_t size) { register PyTupleObject *op; Py_ssize_t i; // 大小为负数 if (size 0 // 如果是空元组,直接取free_list第一个返回 if (size == 0 && free_list[0]) { op = free_list[0]; Py_INCREF(op); #ifdef COUNT_ALLOCS tuple_zero_allocs++; #endif return (PyObject *) op; } // 缓冲池可用 if (size ob_item[0]; numfree[size]--; #ifdef COUNT_ALLOCS fast_tuple_allocs++; #endif /* Inline PyObject_InitVar */ #ifdef Py_TRACE_REFS Py_SIZE(op) = size; Py_TYPE(op) = &PyTuple_Type; #endif _Py_NewReference((PyObject *)op); } // 缓冲池不可用 else #endif { // 通过传入的size参数计算需要的内存总量 Py_ssize_t nbytes = size * sizeof(PyObject *); /* Check for overflow */ if (nbytes / sizeof(PyObject *) != (size_t)size || (nbytes > PY_SSIZE_T_MAX - sizeof(PyTupleObject) - sizeof(PyObject *))) { return PyErr_NoMemory(); } // 创建PyTupleObject对象 op = PyObject_GC_NewVar(PyTupleObject, &PyTuple_Type, size); if (op == NULL) return NULL; } // 初始化每个元素 for (i=0; i ob_item[i] = NULL; #if PyTuple_MAXSAVESIZE > 0 // 第一次分配时将空数组放入缓冲池的第一个位置 if (size == 0) { free_list[0] = op; ++numfree[0]; Py_INCREF(op); /* extra INCREF so that this is never freed */ } #endif #ifdef SHOW_TRACK_COUNT count_tracked++; #endif _PyObject_GC_TRACK(op); return (PyObject *) op; 108:} 分析 : 我们不难发现 , PyTuple_New与PyList_New有很多相同之处 , 首先这个函数同样接受一个size参数 , 也就是我们在创建时指定PyTupleObject对象的初始元素个数 , 不同的地方在于两种对象在计算需要的内存总量的时机不同 随后检查缓冲池是否可用 , 如果可用 , 那么不用多说 ; 如果缓冲池不可用 , 那么现在才计算所需内存总量 , 而在PyList_New中 , 无论缓冲池是否可用都会计算其所需内存总量 缓冲池不可用之后 , 接下来就是创建PyTupleObject对象了 , 再然后初始化每个元素 最后的一步 , 则是将空元组放入缓冲池的第一位置 , 在整个Python的执行过程中 , 这个操作只会执行一次 而对于缓冲池free_list , 如下 : Python-2.7\\Objects\\tupleobject.c 7:#ifndef PyTuple_MAXSAVESIZE 8:#define PyTuple_MAXSAVESIZE 20 /* Largest tuple to save on free list */ 9:#endif 10:#ifndef PyTuple_MAXFREELIST 11:#define PyTuple_MAXFREELIST 2000 /* Maximum number of tuples of each size to save */ 12:#endif 13: 14:#if PyTuple_MAXSAVESIZE > 0 15:/* Entries 1 up to PyTuple_MAXSAVESIZE are free lists, entry 0 is the empty 16: tuple () of which at most one instance will be allocated. 17:*/ 通过定义我们可以看到 , PyTupleObject对象缓冲池中维护的最大个数为2000 , 但是注意 , 不是所有的元组都会放入缓冲池 , 不用想也知道 , 这肯定是有一个界限的 , 也就是要小于PyTuple_MAXSAVESIZE的 , 从上面我们知道 , 这个值为20 , 也就是说只有tuple长度小于20的PyTupleObject才能被放入缓冲池 并且缓冲池的第一个位置是留给()的 (有且仅有一个) , 也就是空元组 ; 对于空元组它是在PyTupleObject对象创建时就已经被放入缓冲池了的 , 而其他的PyTupleObject对象什么时候会放入缓冲池中 , 与PyListObject对象也是一样的 , 就是在对象被销毁时 , 这一点同前面的篇章一样 , 放在最后来说 设置元素 🍀 与PyListObject一样 , 在我们创建第一个PyTupleObject对象时 , 这时候缓冲池是不可用的 , 于是会调用PyObject_GC_New在系统堆上创建一个新的PyTupleObject对象 而当我们设置元素时 , 在Python内部会调用PyTupe_SetItem来完成这个动作 135:int PyTuple_SetItem(register PyObject *op, register Py_ssize_t i, PyObject *newitem) { register PyObject *olditem; register PyObject **p; // 类型与引用计数检查 if (!PyTuple_Check(op) || op->ob_refcnt != 1) { Py_XDECREF(newitem); PyErr_BadInternalCall(); return -1; } // 索引有效性检查 if (i = Py_SIZE(op)) { Py_XDECREF(newitem); PyErr_SetString(PyExc_IndexError, \"tuple assignment index out of range\"); return -1; } p = ((PyTupleObject *)op) -> ob_item + i; olditem = *p; *p = newitem; Py_XDECREF(olditem); return 0; 156:} 与PyListObject非常相似 , 首先进行类型检查 ,随后进行索引的有效性检查 , 当这两者都通过后 , 将新设置的元素指针放到指定的位置 , 然后调整引用计数 , 将这个位置原来存放的对象的引用计数减1 PyTupleObject对象是不可变对象 , 所以没有类似于PyListObject对象的插入等操作 对象缓冲池 🍀 通过前面我们已经知道 , PyTupleObject对象的缓冲池机制在创建PyTupleObject对象时 , 仅仅会将空元组加入缓冲池中 , 而对于其他的PyTupleObject对象并没有出现在PyTuple_New中 其实PyTupleObject对象的缓冲池与PyListObject对象是一样 , 是在其销毁时添加的 Python-2.7\\Objects\\tupleobject.c 210:static void tupledealloc(register PyTupleObject *op) { register Py_ssize_t i; register Py_ssize_t len = Py_SIZE(op); PyObject_GC_UnTrack(op); Py_TRASHCAN_SAFE_BEGIN(op) // 销毁PyTupeObject对象维护的元素列表 if (len > 0) { i = len; while (--i >= 0) Py_XDECREF(op->ob_item[i]); #if PyTuple_MAXSAVESIZE > 0 // 检查是否满足放入缓冲池的条件 if (len ob_item[0] = (PyObject *) free_list[len]; numfree[len]++; free_list[len] = op; goto done; /* return */ } #endif } Py_TYPE(op)->tp_free((PyObject *)op); done: Py_TRASHCAN_SAFE_END(op) 236:} 根据上面的代码清单 , 可以看出 , 在PyTupleObject对象进行销毁时 , 首先会销毁PyTupleObject对象维护的元素列表 , 然后判断该PyTupleObject的大小是否超过缓冲池可缓冲的最大大小 (PyTuple_MAXSAVESIZE=20) , 以及缓冲池是否已满 , 对象是否为PyTupleObject对象 随后 , 如果满足使用缓冲池的要求 , 那么就将这个PyTupleObject对象放入缓冲池中 , 这时这个PyTupleObject对象中的元素列表是已经被销毁了的 ; 如果不满足就直接销毁整个PyTupleObject对象 小结 : 通过与PyListObject对象的实现相比较 , 其与PyTupleObject的差异基本取决于一个是可变对象 , 一个是不可变对象 , 我们可以看到在设置元素和缓冲池机制 , 在两种对象的源码上差别都非常的小 ; 而在对象创建时有所不同的是 , PyTupleObject对象会在创建时将空元组放入缓冲池中 (第一个位置) , 而PyListObject对象则不会 , 如下小实验 : # Python 2.7 >>> list1 = [] >>> list2 = [] >>> id(list1) 79581256L >>> id(list2) 79684744L >>> tuple1 = () >>> tuple2 = () >>> id(tuple1) 77598792L >>> id(tuple2) 77598792L # Python 3.5.3结果相同 由于缓冲池实现的小差异 , 空元组是不会反复创建的 , 并且在缓冲池的第一位置 "},"01-Python/09-In-Depth/08-Python - 垃圾回收.html":{"url":"01-Python/09-In-Depth/08-Python - 垃圾回收.html","title":"Python - 垃圾回收","keywords":"","body":"Python - 垃圾回收 介绍 🍀 引用计数在对Python内置数据类型的分析时 , 已经见过太多次了 , 就是通过对象中的ob_refcnt变量来实现的 在Python中引用计数是一种垃圾收集机制 , 并且是一种最直观 , 最简单的垃圾收集技术 虽然引用计数必须在每次分配和释放内存的时候加入管理引用计数的动作 , 然而与其他主流的垃圾收集技术相比 , 引用计数有一个最大的优点 , 即实时性 , 任何内存 , 一旦没有指向它的引用 , 就会立即被回收 ; 而其他的垃圾收集计数必须在某种特殊条件下 (比如内存分配失败) 才能进行无效内存的回收 引用计数机制所带来的维护引用计数的额外操作与Python运行中所进行的内存分配和释放 , 引用赋值的次数是成正比的 , 这是Python的一个弱点 , 因此在Python内置数据类型中就大量使用了对象缓冲池机制 , 就是为了竭力弥补引用计数机制的软肋 除了执行效率这个软肋之外 , 引用计数还存在一个致命的弱点 , 那就是循环引用 循环引用 🍀 我们知道 , 当一个对象的引用被创建或复制时 , 对象的引用计数就会加1 ; 而当一个对象的引用被销毁时 , 对象的引用计数就会减1 ; 如果对象的引用计数减少为0 , 那么就以为着这个对象不会被任何人使用 , 那么就可以进行回收了 而引用计数的另一个现象就是循环引用了 , 就相当于有两个对象a和b , 其中a引用了b , b引用了a , 这样a和b的引用计数都为1 , 并且永远都不会为0 , 这就意味着 , 这两个对象永远都不会被回收了 , 这就是循环引用 , a与b形成了一个引用循环 , 示例如下 : # 我们让list1中包含list2的引用,而list2中又包含list1的引用,形成引用循环 >>> list1 = [] >>> list2 = [] >>> list1.append(list2) # 此时还没有形成引用循环 >>> list1 [[]] # 循环引用 >>> list2.append(list1) >>> l1 [[[...]]] >>> l2 [[[...]]] ''' [...]:这就是list循环引用的结果 ''' 除了上述两个对象互相引用之外 , 还可以引用自身 , 示例如下 : >>> list3 = [] >>> list3.append(list3) >>> list3 [[...]] 循环引用与手动进行内存管理所产生的内存泄漏毫无区别 , 不过循环引用对于int或者str类型明显是不存在的 所以为了解决循环引用的问题 , Python引入了主流垃圾收集技术中的标记——清除和分代收集两种技术来填补其内存管理机制中最致命的漏洞 标记清除 🍀 垃圾收集机制一般分为两个阶段 : 垃圾检测和垃圾回收 垃圾检测是从所有的已分配的内存中区别出可以回收的内存和不可回收的内存 , 而垃圾回收则是使系统重新掌握在垃圾检测阶段被标识出来的可回收内存块 对于标记——清除方法其简要工作过程如下 : 寻找根对象的集合 , 所谓根对象就是一些全局引用和函数栈中的引用 , 这些引用的对象是不可被删除的, 而这个根对象集合也是垃圾检测动作的起点 从根对象的集合 , 沿着根对象集合中的每一个引用 , 如果能到达某个对象A , 则A称为可达的 , 可达的对象也不可被删除 , 这个阶段就是垃圾检测阶段 当垃圾检测阶段结束后 , 所有的对象分为了可达的和不可达的两部分 , 所有的可达的对象都必须予以保留 , 而所有的不可达对象所占用的内存将被回收 , 这就是垃圾回收阶段 分代回收 🍀 我们的开发程序 , 其一定比例的内存块的生存周期都比较短 , 通常是几百万条机器指令的时间 , 而只有剩下的极少部分内存块 , 生存周期比较长 , 而对于不同的语言 , 不同的应用程序 , 生存周期比较短的内存块的比例通常在80%到98%之间游走 从上面我们知道 , 标记——清除技术所带来的额外操作实际上与系统中总的内存块的数量是相关的 , 当需要回收的内存块越多时 , 垃圾检测带来的额外操作就越多 , 而垃圾回收带来的额外操作就越少 所以通常为了提高垃圾收集的效率 , 我们就可以采用一种以空间换时间的策略 , 分代回收计数 , 这也是当前支撑着Java的关键技术 分代回收 : 将系统中的所有内存块根据其存活时间划分为不同的集合 , 每一个集合就称为一个 \"代\" , 垃圾收集的频率随着 \"代\" 的存活时间的增大而减小 也就是说 , 活得越长的对象 , 就越可能不是垃圾 , 就应该越少去收集 . 而这个存活时间通常就是利用经过了几次垃圾收集动作来衡量 ; 如果一个对象经过的垃圾收集次数越多, 那么显然 , 其存活时间就越长 在Python中 , 一个 \"代\" 就是一个链表 , Python采用了三代的分代收集机制 Python-2.7\\Modules\\gcmodule.c 32:struct gc_generation { 33: PyGC_Head head; /* 回收阀值 */ 34: int threshold; /* collection threshold */ /* 实时个数 */ 35: int count; /* count of allocations or collections of younger 36: generations */ 37:}; 39:#define NUM_GENERATIONS 3 40:#define GEN_HEAD(n) (&generations[n].head) 41: 42:/* linked lists of container objects */ 43:static struct gc_generation generations[NUM_GENERATIONS] = { 44: /* PyGC_Head, threshold, count */ /* 第0代,可收集700个container对象,一旦超出就立即触发垃圾回收机制 */ 45: {{{GEN_HEAD(0), GEN_HEAD(0), 0}}, 700, 0}, 46: {{{GEN_HEAD(1), GEN_HEAD(1), 0}}, 10, 0}, 47: {{{GEN_HEAD(2), GEN_HEAD(2), 0}}, 10, 0}, 48:}; 49: 50:PyGC_Head *_PyGC_generation0 = GEN_HEAD(0); "},"01-Python/09-In-Depth/09-Python - 元类.html":{"url":"01-Python/09-In-Depth/09-Python - 元类.html","title":"Python - 元类","keywords":"","body":"元类 🍀 定义 🍀 元类 ( metaclass ) , 是一种实例是类的类 普通的类定义的是特定对象的行为 , 元类定义的则是特定的类及其对象的行为 , 不是所有面向对象编程语言都支持元类 type 🍀 元类在 Wiki 中的解释已经说的很明确了 , 它是一种实例是类的类 , 这也就意味着元类可以创造类 这么说你可能会不太清晰 , 我们从问题出发 , 在 Python 中是谁创建了类 , 也就是说 Python 中的元类是谁? 如果你看过 Python 这一部分的源码 , 那么想必你对这个问题肯定了然于心 , 没错就是 type 类 >>> object.__class__ 至于 type 类为什么是元类 , 你可以从我的另一篇文章中获得答案 《对象的创建》 看下面的例子 : >>> class Foo: ... pass ... >>> f = Foo() 在这个例子中 , Foo() , 也就是调用 Foo 的 __call__ 方法 , 它会做两件事情 : 调用 __new__ , 创建对象 调用 __init__ , 初始化对象 但是注意 , 这个 __call__ 是 object 类的 , 因为 Python 3 中所有的类都默认继承了 object , 至于 Python 2 没什么好谈的 , 相信你查查就能知道 我们本就可以通过重载 __new__ 来控制对象的创建 , 如下 : def new(cls): x = object.__new__(cls) x.attr = 100 return x Foo.__new__ = new f = Foo() print(f.attr) g = Foo() print(g.attr) \"\"\" 执行结果如下: 100 100 \"\"\" 但是不同的是 , 你对 type 不能这么干 , Python 也不允许你这么干 , 如果唯一的元类都被动了 , 那就乱套了 def new(cls): x = type.__new__(cls) x.attr = 100 return x type.__new__ = new \"\"\" Traceback (most recent call last): File \"\", line 1, in TypeError: can't set attributes of built-in/extension type 'type' \"\"\" 所以你从这里也可以知道 , type 和 object 的区别就在于 : type 的 __new__ , 返回了一个类 object 的 __new__ , 返回了一个对象实例 如果我们要定义一个元类 , 只需要如下 : class Meta(type): def __new__(cls, name, bases, dct): x = super().__new__(cls, name, bases, dct) x.attr = 100 return x 当然你也看出来了 , 这只是继承 , 要让它真正成为元类 , 你还需要如下 : class Foo(metaclass=Meta): pass print(Foo.attr) 我们再看看这个 Foo 和普通的对象有什么不同 : class Meta(type): def __new__(cls, name, bases, dct): x = super().__new__(cls, name, bases, dct) x.attr = 100 return x class Foo(metaclass=Meta): pass class Bar(Foo): pass print(type(Meta)) print(type(object)) print(type(Foo)) print(type(Bar)) \"\"\" 执行结果如下: \"\"\" 当指定了 metaclass 之后 , 类的创建将不再由 type 负责 , 而是由元类 Meta 负责 , 也就是说 type 类与这类的 Meta 类都是元类 , 大家是同一级 元类的作用 🍀 元类可以用来改变类的行为 , 这和类并没有什么差别 , 因为我们定义类也可以改变对象的行为 , 我们来看一个例子 class Foo: pass # 调用__call__ f = Foo() # 如果我们想改变 () 也就是 __call__的行为要怎么做? # 当然不可能是在Foo类中重载 __call__ 因为那是控制 Foo 实例化出来的对象的 # 所以我们需要用元类来控制它 # 单例模式直接用metaclass来实现, 而且它是线程安全的 class SingletonMeta(type): _instances = {} def __call__(self, *args, **kwargs): if self not in self._instances: self._instances[self] = super(SingletonMeta, self).__call__(*args, **kwargs) return self._instances[self] class Singleton(metaclass=SingletonMeta): pass a = Singleton() b = Singleton() c = Singleton() d = Singleton() e = Singleton() 如果你想要改变类的行为 , 除了 Python 默认提供的一个魔术方法 (__new__) , 你必须通过元类来改变 因为 __new__ 是唯一一个第一个参数不是 self 而是 cls 的魔术方法 所以上面这个例子 , 除了用元类 , 你也可以通过覆盖 __new__ 来实现 元类其实就是一个类工厂 , 而类则是对象工厂 , 但是实际上我们不需要使用元类同样可以达到生产的目的 , 因为通常我们不会需要去改变类的行为 , 需要改变的是对象的行为 看下面几个例子 继承 >>> class Base: ... attr = 100 ... >>> class X(Base): ... pass ... >>> class Y(Base): ... pass ... >>> class Z(Base): ... pass ... >>> X.attr 100 >>> Y.attr 100 >>> Z.attr 100 类装饰器 >>> def decorator(cls): ... class NewClass(cls): ... attr = 100 ... return NewClass ... >>> @decorator ... class X: ... pass ... >>> @decorator ... class Y: ... pass ... >>> @decorator ... class Z: ... pass ... >>> X.attr 100 >>> Y.attr 100 >>> Z.attr 100 总而言之 , 元类的作用就是用来创造类的 , 我们通常更多的是使用继承 (也就是利用抽象) 的方式来达到我们的目的 Python 之禅中这么说到 : 元类是深层次的魔术代码 , 99% 的用户都不需要关心它 , 如果你好奇你是否需要 , 那你就不需要 , 真正需元类的人 , 是很清楚他们需要的 , 并且 , 不需要一个理由来解释 简单的说 , 元类不适合在生产的代码中使用 , 它更适合用来设计 , 比如 Django , SQLAlchemy 中 , 你就能发现它的身影 , 总而言之 , 元类控制类 , 类控制对象 "},"02-Go/":{"url":"02-Go/","title":"Go","keywords":"","body":"Golang 动一笔先 , 基础的语法等不会写 , 所以本目录下更新会比较慢 ... OOP 封装 : Golang 中的封装就不用说了 , 通过大小写控制 , 和 Python 的 __ 相比 , 差异还是比较大的 继承 : Golang 中的继承通过内嵌的方式实现 多态 : Golang 不像 Python , 天生多态 , 在 Golang 中 , 多态通过 interface 实现 , 详细后期慢慢慢慢更新... "},"02-Go/Golang - 语言基础.html":{"url":"02-Go/Golang - 语言基础.html","title":"Golang - 语言基础","keywords":"","body":"Golang - 语言基础 变量 在 Go 语言中定义变量有两种方式 : 一般声明和简短声明 一般声明 一般声明就是使用关键字 var 进行声明 , 格式如下 // 声明单个变量 var variableName type // 声明多个变量 var variableName1, variableName2, variableName3 type 或 var ( variableName1 type variableName2 type variableName3 type ) // 初始化值 variableName = value variableName1, variableName2, variableName3 = value1, value2, value3 // 声明并初始化值 var variableName type = value var variableName1, variableName2, variableName3 type = value1, value2, value3 var ( variableName1 type = value1 variableName2 type = value2 variableName3 type = value3 ) // 如果初始化值存在, 可以省略类型, 变量会从初始值中获取类型 var variableName1, variableName2, variableName3 = value1, value2, value3 当一个变量声明之后 , Go 会自动赋予它该类型的零值 简短声明 简短声明是使用 := 来定义变量 , 但是它只能在函数中使用 , 也就是说它只能用来定义局部变量 , 如果要定义全局变量 , 还是需要通过一般声明 var 来进行 func main() { variableName := value variableName1, variableName2, variableName3 := value1, value2, value3 } 常量 常量用于存储不会改变的数据 , 它在编译阶段就已经被确定了 , 并且在程序运行时无法改变 常量的声明与变量类似 , 只不过是使用 const 关键字 , 但是常量只能使用一般声明 , 不能使用简短声明 ( := ) const constantName = value // 你也可以明确指定常量的类型 const constantName type = value // 定义多个常量 const constantName1, constantName2, constantName3 = value1, value2, value3 基础类型 Go 的数据类型有 bool string int int8 int16 int32 int64 uint uint8 uint16 uint32 uint64 uintptr byte // uint8 的别名 rune // int32 的别名 // 表示一个 Unicode 码点 float32 float64 complex64 complex128 关于 Go 中的其他派生类型 , 如 array , slice , map 等 , 后续会详细介绍 流程控制 if if 条件表达式 { } // 也可使用初始化语句 if 初始化语句; 条件表达式 { } 如下 if x if-else if 条件表达式 { } else if 条件表达式 { } else { } // 使用初始化语句 if 初始化语句; 条件表达式 { } else if 初始化语句; 条件表达式 { } else { } 如下 if x 5 { } else { } } switch switch 是编写一连串 if - else 语句的简便方法 , 它运行第一个值等于条件表达式的 case 语句 switch 值 { case 值: ... case 值, 值...: ... default: ... } // 没有条件的switch switch { case 条件表达式: ... case 条件表达式, 条件表达式...: ... default: ... } // 带有初始化语句 switch 初始化语句; 值 { case 值: ... case 值, 值...: ... default: ... } switch 初始化语句; { case 条件表达式: ... case 条件表达式, 条件表达式...: ... default: ... } 如下 i := 10 switch i { case 1: case 2, 3, 4: case 10: default: } // 没有条件的switch switch { case i 1, i 1, i switch 语句从上到下执行 , 当匹配成功的时候停止 , 如果需要往下继续执行 , 可以使用 fallthrough 强制执行后面的 case i := 10 switch i { case 10: fmt.Println(10) fallthrough case 9: fmt.Println(9) fallthrough case 8: fmt.Println(8) case 7: fmt.Println(7) } /* 执行结果: 10 9 8 */ for for 初始化语句; 条件表达式; 后置语句 { } // 初始化语句和后置语句是可选的 for ; 条件表达式; { } // for去掉分号之后将会变成while for 条件表达式 { } // 当省略条件表达式时, for将变成无限循环 for 初始化语句; ; 后置语句 { } // while同样 for { } 如下 for i := 0; i 当然 break 和 continue 就不用说了 for-range 用于迭代可迭代的结构 , 如 array 和 map for k, v := range map { } goto goto 必须与标签配合使用 func main() { i := 0 HERE: print(i) i++ if i == 5 { return } goto HERE } 特别注意 : 使用标签和 goto 语句是不被鼓励的 , 因为它们会很快导致非常糟糕的程序设置 , 而且总有更加可读的代替方案来实现相同的需求 除了 goto 之外 , fot , switch 和 select 与都也可以与标签配合使用 func main() { LABEL1: for i := 0; i 函数 // 无返回值 func funcName(input1 type1, input2 type2) { return value1, value2 } // 一个返回值 func funcName(input1 type1, input2 type2) type { return value1 } // 多个返回值 func funcName(input1 type1, input2 type2) (output1 type1, output2 type2) { return value1, value2 } // 可变参数 func funcName(input1 type1, input2 ...type2) (output1 type1, output2 type2) { return value1, value2 } 如下 func max(a, b int) int { if a > b { return a } return b } // 可变参数 func sum(a ...int) int { total := 0 for _, value := range a { total = total + value } return total } defer defer 语句会在函数执行都最后时执行 func main() { defer fmt.Println(\"world\") fmt.Println(\"hello\") } "},"03-MySQL/":{"url":"03-MySQL/","title":"MySQL","keywords":"","body":"MySQL 前言 为了科学地组织和存储数据 , 实现高效获取和维护数据 , 我们需要使用一个系统软件 , 数据库管理系统 (DataBase Management System , BDMS) , 简称数据库 数据库又分为关系型和非关系型两种 : 关系型数据库 : MySQL , Oracle , SqlServer , Access , Db2 , SQLite , MariaDB 非关系型数据库 : Redis , MongoDB , Memcached , Cassandra MySQL介绍 MySQL是一种快速易用的关系型数据库管理系统(RDBMS) , 由瑞典MySQL AB公司开发 , 目前属于Oracle旗下公司 , MySQL是目前最流行的关系型数据库管理系统 , 在Web应用方面MySQL是最好的RDBMS应用软件之一 具备以下优点 : 开源 , 免费使用 自身功能非常强大 , 足以匹敌绝大多数功能强大但却价格昂贵的数据库软件 使用业内所熟悉的标准SQL数据库语言(SQL语句通用) 可运行于多个操作系统 , 支持多种语言 , 包括PHP , C , C++ , Java等语言 非常迅速 , 即使面对大型数据集也毫无滞涩 非常适用Web应用开发 支持大型数据库 , 最高可在一个表中容纳5千多万行 ; 每张表的默认文件大小限制4GB , 不过如果操作系统支持 , 可以将期理论限制增加到800万TB 可以自定义 , 开源GPL许可保证了程序员可以自由修改MySQL , 以便适应各自特殊的开发环境 RDBMS术语 术语 描述 数据库(Database) 数据库是带有相关数据的表的集合 表(Table) 表是带有数据的矩阵 , 数据库中的表就像一种简单的电子表格 列(Column) 每一列 (数据元素) 都包含着同种类型的数据 , 比如邮编 行(Row) 行 (又被称为元组 , 项或者记录) 是一组相关数据 , 比如有关订阅量的数据 冗余(Redundancy) 存储两次数据 , 以便使系统更快速 主键(Primary key) 主键是唯一的 , 同一张表中不允许出现同样两个键值 , 一个键值只对应着一行 外键(Foreign key) 用于连接两张表 复合键(Compound key) 复合键 (又称组合键) 是一种由多列组成的键 , 因为一列并不足以确定唯一性 索引(Index) 它在数据库中的作用就像书后的索引一样 引用完性(Referential Integrity) 用来确保外键一直指向已存在的一行 "},"03-MySQL/01-MySQL - 库操作.html":{"url":"03-MySQL/01-MySQL - 库操作.html","title":"MySQL - 库操作","keywords":"","body":"MySQL - 库操作 SQL介绍 🍀 SQL是Structured Query Language(结构化查询语言)的缩写 , SQL是转为数据库而建立的操作命令集 , 是一种功能齐全的数据库语言 SQL分类 SQL语句主要可以划分为一下3个类别 : DDL(Data Definition Languages) 语句 : 数据定义语句 , 这些语句定义了不同的数据段 , 数据库 , 表 , 列 , 索引等数据库对象 ; 常用的语句关键字主要包括create , drop , alter等 DML(Data Manipulation Language) 语句 : 数据操纵语句 , 用于添加 , 删除 , 更新和查询数据库记录 , 并检查数据完整性 ; 常用的语句关键字主要包括insert , delete , update和select等 DCL(Data Control Language) 语句 : 数据控制语句 , 用于控制不同数据段直接许可和访问级别的语句 , 这些语句定义了数据库 , 表 , 字段 , 用户的访问权限和安全级别 ; 主要的语句关键字包括grant , revoke等 SQL规范 在数据库系统中 , SQL语句不区分大小写 (建议用大写) , 但字符串常量区分大小写 ; 建议命令大写 , 表名库名小写 SQL语句可单行或多行书写 , 以\" ; \"结尾 , 关键字不能跨多行或简写 用空格和缩进来提高语句的可读性 , 子句通常位于独立行 , 便于编辑 , 提高可读性 单行注释 : -- 多行注释 : / *... */ SQL语句可拆行操作 数据库操作 🍀 在MySQL数据中有如下默认数据库 默认数据库 描述 information_schema 虚拟库 , 不占用磁盘空间 , 存储的是数据库启动后的一些参数 , 如用户表信息 , 列信息 , 权限信息 , 字符信息等 test 用户用来测试的数据库 (MySQL 5.7没有) mysql 授权库 , 主要存储系统用户的权限信息 performance_schema MySQL 5.5 后新增的 , 主要用于收集数据库服务器性能参数 , 记录处理查询请求时发生的各种事件 , 锁等现象 sys 包含了一系列视图、函数和存储过程 查看数据库 🍀 SHOW DATABASES; 查看所有数据库 SHOW CREATE DATABASE dbname; 查看数据库的创建信息 实例 mysql> SHOW DATABASES; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec) /* 查看mysql库的创建信息 */ mysql> show create database mysql; +----------+----------------------------------------------------------------+ | Database | Create Database | +----------+----------------------------------------------------------------+ | mysql | CREATE DATABASE `mysql` /*!40100 DEFAULT CHARACTER SET utf8 */ | +----------+----------------------------------------------------------------+ 1 row in set (0.00 sec) 创建数据库 🍀 CREATE DATABASE dbname DEFAULT CHARSET utf8 COLLATE utf8_general_ci; 创建字符串为utf-8的数据库 CREATE DATABASE dbname DEFAULT CHARACTER SET gbk COLLATE gbk_chinese_ci; 创建字符串为gbk的数据库 实例 mysql> CREATE DATABASE test DEFAULT CHARSET utf8 COLLATE utf8_general_ci; Query OK, 1 row affected (0.00 sec) /* 查看所有数据库 */ mysql> SHOW DATABASES; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | | test | +--------------------+ 5 rows in set (0.00 sec) 删除数据库 🍀 DROP DATABASE dbname; 删除数据库 使用数据库 🍀 USE dbname; 进入数据库 SHOW TABLES; 查看当前数据库中所有的表 SELECT DATABASE(); 查看当前使用的数据库 实例 mysql> SELECT DATABASE(); +------------+ | DATABASE() | +------------+ | NULL | +------------+ 1 row in set (0.00 sec) /* 使用mysql数据库 */ mysql> USE mysql; Database changed mysql> SELECT DATABASE(); +------------+ | DATABASE() | +------------+ | mysql | +------------+ 1 row in set (0.00 sec) 用户管理 🍀 CREATE USER 'lyon'@'%' IDENTIFIED BY '123'; 创建`lyon`用户,允许任意IP访问,密码为`123` RENAME USER 'lyon'@'%' TO 'mylyon'@'127.0.0.1'; 修改用户 SET PASSWORD FOR 'mylyon'@'127.0.0.1' = PASSWORD('456'); 修改密码为`456` DROP USER 'mylyon'@'127.0.0.1'; 删除用户`lyon` 实例 /* 用户权限信息都在mysql库中,先进入mysql库 */ mysql> USE mysql; Database changed /* 查看原有用户 */ mysql> SELECT HOST,USER FROM USER; +-----------+-----------+ | HOST | USER | +-----------+-----------+ | localhost | mysql.sys | | localhost | root | +-----------+-----------+ 2 rows in set (0.00 sec) /* 创建新用户'lyon',允许任意IP */ mysql> CREATE USER 'lyon'@'%' IDENTIFIED BY '123'; Query OK, 0 rows affected (0.00 sec) /* 查看所有用户 */ mysql> SELECT HOST,USER FROM USER; +-----------+-----------+ | HOST | USER | +-----------+-----------+ | % | lyon | | localhost | mysql.sys | | localhost | root | +-----------+-----------+ 3 rows in set (0.00 sec) /* 修改用户 */ mysql> RENAME USER 'lyon'@'%' TO 'mylyon'@'127.0.0.1'; Query OK, 0 rows affected (0.00 sec) /* 查看所有用户 */ mysql> SELECT HOST,USER FROM USER; +-----------+-----------+ | HOST | USER | +-----------+-----------+ | 127.0.0.1 | mylyon | | localhost | mysql.sys | | localhost | root | +-----------+-----------+ 3 rows in set (0.00 sec) /* 修改用户密码 */ mysql> SET PASSWORD FOR 'mylyon'@'127.0.0.1' = PASSWORD('456'); Query OK, 0 rows affected, 1 warning (0.00 sec) /* 删除用户 */ mysql> DROP USER 'mylyon'@'127.0.0.1'; Query OK, 0 rows affected (0.00 sec) /* 查看所有用户 */ mysql> SELECT HOST,USER FROM USER; +-----------+-----------+ | HOST | USER | +-----------+-----------+ | localhost | mysql.sys | | localhost | root | +-----------+-----------+ 2 rows in set (0.00 sec) 注意 : 'username'@'IP' 用户只能在该IP下才能访问 'username'@'127.0.0.1' 用户只能在该IP段下才能访问(通配符%表示任意) 'username'@'%' 用户可以再任意IP下访问(默认IP地址为%) 授权管理 🍀 SHOW GRANTS FOR 'username'@'IP'; 查看用户权限 GRANT 权限 ON dbname.表 TO 'username'@'IP'; 授权 REVOKE 权限 ON dbname.表 FROM 'username'@'IP'; 取消授权 实例 /* 创建用户lyon@%,密码为123 */ mysql> CREATE USER 'lyon'@'%' IDENTIFIED BY '123'; Query OK, 0 rows affected (0.00 sec) /* 查看用户lyon@%的权限 */ mysql> SHOW GRANTS FOR 'lyon'@'%'; +----------------------------------+ | Grants for lyon@% | +----------------------------------+ | GRANT USAGE ON *.* TO 'lyon'@'%' | +----------------------------------+ 1 row in set (0.00 sec) /* 授予用户lyon@% select权限,即将Select_priv改成Y */ mysql> GRANT SELECT ON *.* TO 'lyon'@'%'; Query OK, 0 rows affected (0.00 sec) /* 查看用户lyon@%的权限 */ mysql> SHOW GRANTS FOR 'lyon'@'%'; +-----------------------------------+ | Grants for lyon@% | +-----------------------------------+ | GRANT SELECT ON *.* TO 'lyon'@'%' | +-----------------------------------+ 1 row in set (0.00 sec) /* 取消对用户lyon@%的SELECT授权 */ mysql> REVOKE SELECT ON *.* FROM 'lyon'@'%'; Query OK, 0 rows affected (0.00 sec) /* 查看用户lyon@%的权限 */ mysql> SHOW GRANTS FOR 'lyon'@'%'; +----------------------------------+ | Grants for lyon@% | +----------------------------------+ | GRANT USAGE ON *.* TO 'lyon'@'%' | +----------------------------------+ 1 row in set (0.00 sec) 也可以用SELECT * FROM USER WHERE USER='lyon' AND HOST='%' \\G; 命令查看 , 具体如下 : *************************** 1. row *************************** Host: % User: lyon Select_priv: N ... *************************** 1. row *************************** Host: % User: lyon Select_priv: Y ... 权限介绍 all privileges 除grant外的所有权限 select 仅查权限 select,insert 查和插入权限 usage 无访问权限 alter 使用alter table alter routine 使用alter procedure和drop procedure create 使用create table create routine 使用create procedure create temporary tables 使用create temporary tables create user 使用create user,drop user,rename user和revoke all privileges create view 使用create view delete 使用delete drop 使用drop table execute 使用call和存储过程 file 使用select into outfile 和 load data infile grant option 使用grant 和 revoke index 使用index insert 使用insert lock tables 使用lock table process 使用show full processlist select 使用select show databases 使用show databases show view 使用show view update 使用update reload 使用flush shutdown 使用mysqladmin shutdown(关闭MySQL) super 使用change master,kill,logs,purge,master和set global,还允许 mysqladmin调试登陆 replication client 服务器位置的访问 replication slave 由复制从属使用 flush privileges　　　 　将数据读取到内存中,从而立即生效 PS : 代表所有 , \\.* 代表所有数据库中的所有表 "},"03-MySQL/02-MySQL - 数据类型.html":{"url":"03-MySQL/02-MySQL - 数据类型.html","title":"MySQL - 数据类型","keywords":"","body":"MySQL - 基本数据类型 介绍 🍀 MySQL中定义数据字段的类型对数据库的优化是非常重要的 MySQL支持多种数据类型 , 主要包括 : 数值类型 日期时间类型 字符串类型 本篇内容 , 以MySQL 5.0 版本为例 , 因为不同的版本可能有所差异 , 不过差异不大 数值类型 🍀 MySQL支持所有标准SQL中的数值类型 , 其中包括严格数值类型 , 以及近似数值数据类型 , 并在此基础上做了扩展 , 增加了TINYINT , MEDIUMINT , BIGINT 3种长度不同的整型 , 并增加了BIT类型 , 用来存放位数据 整数类型介绍 整数类型 字节 最小值 最大值 TINYINT 1 有符号 : -128 无符号 : 0 有符号 : 127无符号 : 255 SMALLINT 2 有符号 : -32768无符号 : 0 有符号 : 32767无符号 : 65535 MEDIUMINT 3 有符号 : -8388608无符号 : 0 有符号 : 8388607无符号 : 1677215 INT , INTEGER 4 有符号 : -2147483648无符号 : 0 有符号 : 2147483647无符号 : 4294967295 BIGINT 8 有符号 : -9223372036854775808无符号 : 0 有符号 : 9223372036854775807无符号 : 18446744073709551615 浮点数类型介绍 浮点数类型 字节 最小值 最大值 FLOAT 4 ±1.175494351E-38 ±3.402823466E+38 DOUBLE 8 ±2.2250738585072014E-308 ±1.7976931348623157E+308 定点数类型介绍 定点数类型 字节 描述 DEC (M , D) DECIMAL (M , D) M + 2 最大取值范围与DOUBLE相同 , 给定DECIMAL的有效取值范围由 M 和 D 决定 位类型介绍 位类型 字节 最小值 最大值 BIT (M) 1~8 BIT (1) BIT (64) 特别的 : MySQL中无布尔值 , 可以使用TINYINT(1)构造 , 0为假非0为真 , 如下 : mysql> SELECT IF(0, 'true', 'false'); +------------------------+ | IF(0, 'true', 'false') | +------------------------+ | false | +------------------------+ 1 row in set (0.00 sec) mysql> SELECT IF(1, 'true', 'false'); +------------------------+ | IF(1, 'true', 'false') | +------------------------+ | true | +------------------------+ 1 row in set (0.00 sec) 但是真假的值只有1和0 , 而不是非0的值都为真 , 如下 : mysql> SELECT IF(0 = FALSE, 'true', 'false'); +--------------------------------+ | IF(0 = FALSE, 'true', 'false') | +--------------------------------+ | true | +--------------------------------+ 1 row in set (0.01 sec) mysql> SELECT IF(1 = TRUE, 'true', 'false'); +-------------------------------+ | IF(1 = TRUE, 'true', 'false') | +-------------------------------+ | true | +-------------------------------+ 1 row in set (0.00 sec) mysql> SELECT IF(2 = TRUE, 'true', 'false'); +-------------------------------+ | IF(2 = TRUE, 'true', 'false') | +-------------------------------+ | false | +-------------------------------+ 1 row in set (0.00 sec) mysql> SELECT IF(2 = FALSE, 'true', 'false'); +--------------------------------+ | IF(2 = FALSE, 'true', 'false') | +--------------------------------+ | false | +--------------------------------+ 1 row in set (0.00 sec) 日期时间类型 🍀 MySQL中有多种数据类型可以用于日期和时间的表示 , 这些数据类型的主要区别如下 : 表示年月日 , 通常用DATE来表示 表示年月日时分秒 , 通常用DATETIME表示 只表示时分秒 , 通常用TIME来表示 日期和时间类型介绍 日期和时间类型 字节 最小值 最大值 DATE 4 1001-01-01 9999-12-31 DATETIME 8 1000-01-01 00 : 00 : 00 9999-12-31 23 : 59 : 59 TIMESTAMP 4 19700101080001 2038年的某个时刻 TIME 3 -838 : 59 : 59 838 : 59 : 59 YEAR 1 1901 2155 每种日期时间类型都有一个有效值范围 , 如果超出这个范围 , 在默认的SQLMode下 , 系统会进行错误提示 , 并将以零值来进行存储 , 不同日期类型零值的表示如下 : 日期和时间类型的零值表示 数据类型 零值表示 DATETIME 0000-00-00 00 : 00 : 00 DATE 0000-00-00 TIMESTAMP 00000000000000 TIME 00 : 00 : 00 YEAR 0000 字符串类型 🍀 MySQL包括了CHAR , VARCHAR , BINARY , VARBINARY , BLOB , TEXT , ENUM 和 SET等多种字符串类型 字符串类型介绍 字符串类型 字节 描述及存储需求 CHAR(M) M M为0~255之间的整数 VARCHAR(M) M为0~65535之间的整数 , 值的长度+1个字节 TINYBLOB 允许长度0~255字节 , 值的长度+1个字节 BLOB 允许长度0~65535字节 , 值的长度+2个字节 MEDIUMBLOB 允许长度0~167772150字节 , 值的长度+3个字节 LONGBLOB 允许长度0~4294967295字节 , 值的长度+4个字节 TINYTEXT 允许长度0~255字节 , 值的长度+2个字节 TEXT 允许长度0~65535字节 , 值的长度+2个字节 MEDIUMTEXT 允许长度0~167772150字节 , 值的长度+3个字节 LONGTEXT 允许长度0~4294967295字节 , 值的长度+4个字节 VARBINARY(M) 允许长度0~M个字节的变长字节字符串 , 值的长度+1个字节 BINARY(M) M 允许长度0~M个字节的定长字节字符串 CHAR 与 VARCHAR 两者类似 , 但保存和检索方式不同 CHAR长度固定 , VARCHAR长度可变 在检索时 , CHAR列删除了尾部的空格 , 而VARCHAR则保留这些空格 BINARY 与 VARBINARY BINARY 与 VARBINARY 类似于 CHAR 与 VARCHAR , 不同的是它们包含二进制字符串而不包含非二进制字符串 , 也就是说 , 它们包含字节字符串而不是字符字符串 , 它们没有字符集 , 并且排序和比较基于列值字节的数值值 ENUM ENUM中文名称叫枚举类型 , 它的值范围需要在创建表时通过枚举方式显示指定 , 意思就是字段的值只能在给定范围中选择 , 对1~255个成员的枚举需要1个字节存储 ; 对于255~65535个成员 , 需要2个字节存储 , 最多允许由65535个成员 使用ENUM时需注意 : ENUM类型是忽略大小写的 , 在存储时会将小写都转成大写 对于插入不在ENUM指定范围内的值时 , 并不会返回警告 , 而是插入enum()中的第一个值 ENUM类型只允许从值集合中选取单个值 , 而不能一次选取多个值 SET SET 和 ENUM类型非常类似 , 也是一个字符串对象 , 里面可以包含0~64个成员 1~8成员的集合 , 占1个字节 9~16成员的集合 , 占2个字节 17~24成员的集合 , 占3个字节 25~32成员的集合 , 占4个字节 33~64成员的集合 , 占8个字节 SET 和 ENUM除了存储之外 , 最主要的区别在于SET类型一次可以选取多个成员 , ENUM则只能选一个 mysql> CREATE TABLE myset(col SET('a','b','c','d')); Query OK, 0 rows affected (0.32 sec) mysql> INSERT INTO myset VALUES('a,b'),('a,d,a'),('a,b'),('a,c'),('a'); Query OK, 5 rows affected (0.12 sec) Records: 5 Duplicates: 0 Warnings: 0 mysql> SELECT * FROM myset; +------+ | col | +------+ | a,b | | a,d | | a,b | | a,c | | a | +------+ 5 rows in set (0.00 sec) 对于超出允许值范围的值 , 将不允许注入到设置的SET类型中 , 而对于包含重复成员的集合将只取一次 , 集合去重 "},"03-MySQL/03-MySQL - 存储引擎.html":{"url":"03-MySQL/03-MySQL - 存储引擎.html","title":"MySQL - 存储引擎","keywords":"","body":"MySQL - 存储引擎 介绍 🍀 插件式存储引擎是MySQL数据库最重要的特性之一 , 用户可以根据应用的需要选择如何存储和索引数据 , 是否使用实务等 , MySQL默认支持多种存储引擎(表类型) , 用户还可以按照自己的需要定制和使用自己的存储引擎 MySQL 5.0支持的存储引擎包括MyISAM , InnoDB , BDB , MEMORY , MERGE , EXAMPLE , NDB Cluster , ARCHIVE , CSV , BLACKHOLE 等 , 其中InnoDB 和 BDB提供事物安全表 , 其他存储引擎都是非安全事物安全表 创建新表时如果不指定存储引擎 , 那么系统就会使用默认存储引擎 , MySQL 5.5 之前的默认存储引擎是MyISAM , 5.5 之后改为了InnoDB , 如果修改默认的存储引擎 , 可以在参数文件中红设置 default-table-type 查看当前默认存储引擎 , 可以使用以下命令 : SHOW VARIABLES LIKE 'table_type'; 查询当前数据库支持的存储引擎 , 可以使用一下命令 : -- 第一种方法 SHOW ENGINES \\G -- 第二种方法 SHOW VARIABLES LIKE 'have%'; 常用存储引擎对比 特点 MyISAM InnoDB MEMORT MERGE NDB 存储限制 有 64TB 有 没有 有 事物安全 支持 锁机制 表锁 行锁 表锁 表锁 行锁 B树索引 支持 支持 支持 支持 支持 哈希索引 支持 支持 全文索引 支持 集群索引 支持 数据缓存 支持 支持 支持 索引缓存 支持 支持 支持 支持 支持 数据可压缩 支持 空间使用 低 高 N/A 低 低 内存使用 低 高 中等 低 高 批量插入的速度 高 低 高 高 高 支持外键 支持 下面重点介绍最常使用的4中存储引擎 : MyISAM , InnoDB , MEMORY 和 MERGE MyISAM 🍀 MyISAM不支持事务 , 也不支持外键 , 其优势是访问的速度快 , 对事务完整性没有要求或者以SELECT , INSERT为主的应用基本上都可以使用这个引擎来创建表 每个MyISAM在磁盘上存储成3个文件 , 其文件名都和表明相同 , 但扩展名分别是.frm(存储表定义) , .MYD(MYDate , 存储数据) , .MYI(MYIndex , 存储索引) ; MyISAM的表还支持3种不同的存储格式 , 分别是 : 静态表(固定长度) , 动态表 , 压缩表 数据文件和索引文件可以放置在不同的目录 , 平局分布IO , 获得更快的速度 ; 不同MyISAM表的索引文件和数据文件可以放置到不同的路经下 , 文件路经要是绝对路经 , 并且具有访问权限 MyISAM类型的表可能会损坏 , 原因可能是多种多样的 , 损坏后的表可能不能被访问 , 会提示需要修复或者访问返回错误的结果 ; MyISAM类型的表提供修复的工具 , 可以用CHECK TABLE语句来检查MyISAM表的健康 , 并用REPAIR TABLE语句修复一个损坏的MyISAM表 . MyISAM另一个与众不同的地方是 , 它的缓冲池只缓存(cache)索引文件 , 而不缓存数据文件 , 这与大多数的数据库都不相同 InnoDB 🍀 InnoDB存储引擎提供了具有提交 , 回滚和崩溃恢复能力的事务安全 , 但是对比MyISAM , InnoDB写的处理效率差一些 , 并且会占用更多的磁盘空间以保留数据和索引 InnoDB是MySQL数据库最为常用的存储引擎 , 其不同于其他存储引擎的表的特点如下 自动增长列 🍀 InnoDB表的自增列可以手工插入 , 但是插入的值如果是空或者0 , 则实际插入的将是自动增长后的值 自增实例 mysql> USE mydatabase; Database changed mysql> CREATE TABLE autoincre_demo( -> id int NOT NULL AUTO_INCREMENT, -- 设置id列自增 -> name varchar(10), -> PRIMARY KEY(id) -- 将id列设为主键 -> )ENGINE=InnoDB; Query OK, 0 rows affected (0.28 sec) /* 插入数据 */ mysql> INSERT INTO autoincre_demo VALUES(1,'lyon'),(0,'leon'),(NULL,'kenneth'); Query OK, 3 rows affected (0.11 sec) Records: 3 Duplicates: 0 Warnings: 0 /* 查看表 */ mysql> SELECT * FROM autoincre_demo; +----+---------+ | id | name | +----+---------+ | 1 | lyon | | 2 | leon | | 3 | kenneth | +----+---------+ 3 rows in set (0.00 sec) PS : 可以通过ALTER TABLE *** AUTO_INCREMENT = n; 语句强制设置自动增长列的初始值 , 默认从1开始 , 但是该强制的默认值是保留在内存中的 , 如果该值在使用之前数据库重新启动 , 那么这个强制的默认值就会丢失 , 就需要在数据库启动以后重新设置 可以使用LAST_INSERT_ID() 查询当前线程最后插入记录使用的值 , 如果一次插入多条记录 , 则返回第一条记录使用的自动增长值 LAST_INSERT_ID()实例 /* 从1开始,所以自增值为2 */ mysql> SELECT LAST_INSERT_ID(); +------------------+ | LAST_INSERT_ID() | +------------------+ | 2 | +------------------+ 1 row in set (0.00 sec) /* 再插3条 */ mysql> INSERT INTO autoincre_demo(name) VALUES('FIVE'),('SIX'),('SEVEN'); Query OK, 3 rows affected (0.12 sec) Records: 3 Duplicates: 0 Warnings: 0 /* 默认开始有3条,所以自增值为5 */ mysql> SELECT LAST_INSERT_ID(); +------------------+ | LAST_INSERT_ID() | +------------------+ | 5 | +------------------+ 1 row in set (0.00 sec) 对于InnoDB表 , 自动增长列必须是索引(主键) , 如果是组合索引 , 也必须是组合索引的第一列 但是对于MyISAM表 , 自增列可以是组合索引的其他列 外键约束 🍀 MySQL支持外键的存储引擎只有InnoDB , 在创建外键的时候 , 要求父表必须有对应的索引 , 子表在创建外键的时候也会自动创建对应的索引 实例 /* 创建父表country */ mysql> CREATE TABLE country( -> country_id SMALLINT UNSIGNED NOT NULL AUTO_INCREMENT, -- 创建自增列(索引) -> country VARCHAR(50) NOT NULL, -> last_update TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, -- 最后更新时间 -> PRIMARY KEY (country_id) -- 设置主键索引 -> )ENGINE=InnoDB DEFAULT CHARSET=utf8; Query OK, 0 rows affected (0.32 sec) /* 创建子表city */ mysql> CREATE TABLE city( -> city_id SMALLINT UNSIGNED NOT NULL AUTO_INCREMENT, -- 创建自增列 -> city VARCHAR(50) NOT NULL, -> country_id SMALLINT UNSIGNED NOT NULL, -- 外键 -> last_update TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, -> PRIMARY KEY (city_id), -- 设置主键索引 -> KEY idx_fk_country_id (country_id), -> CONSTRAINT fk_city_country FOREIGN KEY (country_id) REFERENCES country (country_id) ON DELETE RESTRICT ON UPDATE CASCADE -- 设置外键,对应country表的主键country_id -> )ENGINE=InnoDB DEFAULT CHARSET=utf8; Query OK, 0 rows affected (0.40 sec) 在创建索引时 , 可以指定在删除 , 更新父表时 , 对子表进行的相应操作 , 包括RESTRICT , CASCADE , SET NULL 和 NO ACTION . 其中RESETRICT 和 NO ACTION 相同 , 是指限制在子表有关联记录的情况下父表不能更新 ; CASCADE表示父表在更新或者删除时 , 更新或者删除子表对应记录 ; SET NULL 则表示父表在更新或者删除的时候 , 子表的对应字段被设置为NULL /* 子表的外键指定是 ON DELETE RESTRICT ON UPDATE CASCADE 方式,即主表删除记录时,如果子表有对应记录,则不允许删除,主表在更新记录时,如果子表有对应记录,则子表对应更新 */ -> CONSTRAINT fk_city_country FOREIGN KEY (country_id) REFERENCES country (country_id) ON DELETE RESTRICT ON UPDATE CASCADE 当某个表被其他表创建了外键参照 , 那么该表的对应索引或者主键禁止被删除 关闭外键 在导入多个表的数据时 , 如果需要忽略表之前的导入顺序 , 可以暂时关闭外键的检查 ; 在执行LOAD DATE 和 ALTER TABLE操作的时候 , 可以通过暂时关闭外键约束来加快处理的速度 关闭命令 : SET FOREIGN_KEY_CHECKS = 0; 打开外键则将0改为1即可 查看外键信息 命令 : SHOW CREATE TABLE或者SHOW TABLE STATUS 实例 : mysql> SHOW TABLE STATUS LIKE 'city' \\G; *************************** 1. row *************************** Name: city Engine: InnoDB Version: 10 Row_format: Dynamic Rows: 0 Avg_row_length: 0 Data_length: 16384 Max_data_length: 0 Index_length: 16384 Data_free: 0 Auto_increment: 1 Create_time: 2017-10-18 17:16:18 Update_time: NULL Check_time: NULL Collation: utf8_general_ci Checksum: NULL Create_options: Comment: 1 row in set (0.01 sec) ERROR: No query specified 存储方式 🍀 InnoDB存储表和索引有两种方式 : 使用共享表空间存储 使用多表空间存储 , 需要设置参数 innodb_file_per_table , 并且重新启动才生效 对于表中数据的存储 , InnoDB 存储引擎采用了聚集(clustered)的方式 , 每张表都是按主键的顺序进行存储的 , 如果没有显式地在表定义时指定主键 , InnoDB 存储引擎会为每一行生成一个 6 字节的 ROWID , 并以此作为主键 深入了解InnoDB存储引擎的工作 , 原理 , 实现和应用 , 可以参考《MySQL技术内幕 : InnoDB存储引擎》一书 MEMORY 🍀 MEMORY存储引擎使用存在于内存中的内容来创建表 每个MEMORY表只实际对应一个磁盘文件 , 格式是.frm , MEMORY类型的表访问非常地快 , 因为它的数据是存放在内存中的 , 并且默认使用HASH索引 , 但是一旦服务关闭 , 表中的数据就会丢失 给MEMORY创建索引的时候 , 可以指定使用HASH索引还是BTREE索引 实例 mysql> CREATE TABLE tab_memory ENGINE=MEMORY -> SELECT city_id,city,country_id -> FROM city GROUP BY city_id; Query OK, 0 rows affected (0.07 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql> CREATE INDEX mem_hash USING HASH ON tab_memory(city_id); Query OK, 0 rows affected (0.10 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql> SHOW INDEX FROM tab_memory \\G; *************************** 1. row *************************** Table: tab_memory Non_unique: 1 Key_name: mem_hash Seq_in_index: 1 Column_name: city_id Collation: NULL Cardinality: 0 Sub_part: NULL Packed: NULL Null: Index_type: HASH Comment: Index_comment: 1 row in set (0.00 sec) ERROR: No query specified 服务器需要足够内存来维持所有在同一时间使用的MEMORY表 , 当不再需要MEMOY表的内容之时 , 要释放被MEMORY表使用的内存 , 应该执行DELETE FROM 或TRUNCATE TABLE , 或者整个地删除(使用DROP TABLE操作) MEMORY类型的存储引擎主要用于那些内容变化不频繁的代码表 , 或者作为统计操作的中间结果表 , 便于高效地对中间结果进行分析并得到最终的统计结果 ; 对存储引擎为MEMORY的表进行更新操作要谨慎 , 因为数据并没有实际写入到磁盘中 , 所以一定要对下次重新启动服务后如何获得这些修改后的数据有所考虑 MERGE 🍀 MERGE存储是一组MyISAM表的组合 , 这些MyISAM表必须结构完全相同 , MERGE表本身并没有数据 , 对MERGE类型的表可以进行查询 , 更新 , 删除操作 , 这些操作实际上是对内部的MyISAM表进行的 可以对MERGE表进行DROP操作 , 这个操作只是删除MERGE的定义 , 对内部的表没有任何的影响 通常我们使用MERGE表来透明地对多个表进行查询和更新操作 , 而对按照时间记录的操作日志则可以透明地进行插入操作 TokuDB 🍀 前面的都是MySQL自带的存储引擎 , 除了这些之外 , 还有一些常见的第三方存储引擎 , 在某些特定应用中也有广泛使用 , 比如列式存储引擎Infobright , 高写性能高压缩的TokuDB就是其中非常有代表性的两种 TokuDB是一个高性能 , 支持事务处理的MySQL和MariaDB的存储引擎 , 具有高扩展性 , 高压缩率 , 高效的写入性能 , 支持大多数在线DDL操作 主要特性 : 使用Fractal树索引保证高效的插入性能 优秀的压缩特性 , 比InnoDB高近10倍 Hot Schema Changes 特性支持在线创建索引和添加 , 删除属性列等DDL操作 使用Bulk Loader达到快速加载大量数据 提供了主从延迟消除技术 支持ACID和MVCC 适用场景 : 日志数据 , 因为日志通常插入频繁切存储量大 历史数据 , 通常不会再有写操作 , 可以利用TokuDB的高压缩特性进行存储 在线DDL较频繁的场景 , 使用TokuDB可以大大增加系统的可用性 "},"03-MySQL/04-MySQL - 表操作.html":{"url":"03-MySQL/04-MySQL - 表操作.html","title":"MySQL - 表操作","keywords":"","body":"MySQL - 表操作 介绍 🍀 该部分语句属于DDL语句 , 对表的定义 , 结构的修改 与DML语句的区别在于 , DML语句仅对表内部数据进行操作 , 即数据的增删改查 DDL语句更多地由数据库管理员(DBA)使用 , 开发人员一般很少使用 创建表 🍀 -- 创建数据库 mysql> CREATE DATABASE mydatabase DEFAULT CHARSET utf8 COLLATE utf8_general_ci; Query OK, 1 row affected (0.00 sec) -- 使用数据库 mysql> USE mydatabase; Database changed -- 创建表tb mysql> CREATE TABLE tb( -> id int(5) NOT NULL AUTO_INCREMENT, -> name char(15) NOT NULL, -> alias varchar(10) DEFAULT NULL, -> email varchar(30) DEFAULT NULL, -> password varchar(20) NOT NULL, -> phone char(11) DEFAULT '00000000000', -> PRIMARY KEY(id,name) -> )ENGINE=InnoDB DEFAULT CHARSET=utf8; Query OK, 0 rows affected (0.24 sec) -- 查看表定义 mysql> DESC tb; +----------+-------------+------+-----+-------------+----------------+ | Field | Type | Null | Key | Default | Extra | +----------+-------------+------+-----+-------------+----------------+ | id | int(5) | NO | PRI | NULL | auto_increment | | name | char(15) | NO | PRI | NULL | | | alias | varchar(10) | YES | | NULL | | | email | varchar(30) | YES | | NULL | | | password | varchar(20) | NO | | NULL | | | phone | char(11) | YES | | 00000000000 | | +----------+-------------+------+-----+-------------+----------------+ 6 rows in set (0.00 sec) -- 查看表详细定义,\\G的含义是使记录按照字段竖向排列 mysql> SHOW CREATE TABLE tb \\G; *************************** 1. row *************************** Table: tb Create Table: CREATE TABLE `tb` ( `id` int(5) NOT NULL AUTO_INCREMENT, `name` char(15) NOT NULL, `alias` varchar(10) DEFAULT NULL, `email` varchar(30) DEFAULT NULL, `password` varchar(20) NOT NULL, `phone` char(11) DEFAULT '00000000000', PRIMARY KEY (`id`,`name`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 1 row in set (0.00 sec) ERROR: No query specified 删除表 🍀 mysql> DROP TABLE tb; Query OK, 0 rows affected (0.21 sec) 修改表 🍀 修改表类型 🍀 语法 : ALTER TABLE tablename MODIFY [COLUMN] column_name column_type [FIRST|AFTER col_name]; -- [...]表示中间的可以省略不写 实例 -- 创建emp表 mysql> CREATE TABLE emp( -> ename VARCHAR(10), -> hiredate DATE, -> sal DECIMAL(10,2), -> deptno INT(2) -> )ENGINE=InnoDB DEFAULT CHARSET=utf8; Query OK, 0 rows affected (0.27 sec) -- 修改emp表中ename字段的类型 mysql> ALTER TABLE emp MODIFY ename varchar(20); Query OK, 0 rows affected (0.08 sec) Records: 0 Duplicates: 0 Warnings: 0 -- 查看表定义 mysql> DESC emp; +----------+---------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------+---------------+------+-----+---------+-------+ | ename | varchar(20) | YES | | NULL | | | hiredate | date | YES | | NULL | | | sal | decimal(10,2) | YES | | NULL | | | deptno | int(2) | YES | | NULL | | +----------+---------------+------+-----+---------+-------+ 4 rows in set (0.00 sec) 增加表字段 🍀 语法 : ALTER TABLE tablename ADD [COLUMN] column_name column_type [FIRST|AFTER col_name]; ALTER TABLE tablename ADD PRIMARY KEY(column_name); ALTER TABLE slave_table ADD CONSTRAINT symbol(如:FK_slave_primary) FOREIGN KEY slave_table(foreign_name) REFERENCES primary_table(primary_name); 实例 : -- 增加age字段 mysql> ALTER TABLE emp ADD age int(3); Query OK, 0 rows affected (0.63 sec) Records: 0 Duplicates: 0 Warnings: 0 -- 增加id字段 mysql> ALTER TABLE emp ADD id int(5); Query OK, 0 rows affected (0.53 sec) Records: 0 Duplicates: 0 Warnings: 0 -- 将id字段设置为主键 mysql> ALTER TABLE emp ADD PRIMARY KEY(id); Query OK, 0 rows affected (0.41 sec) Records: 0 Duplicates: 0 Warnings: 0 -- 查看表定义 mysql> DESC emp; +----------+---------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------+---------------+------+-----+---------+-------+ | ename | varchar(20) | YES | | NULL | | | hiredate | date | YES | | NULL | | | sal | decimal(10,2) | YES | | NULL | | | deptno | int(2) | YES | | NULL | | | age | int(3) | YES | | NULL | | | id | int(5) | NO | PRI | NULL | | +----------+---------------+------+-----+---------+-------+ 6 rows in set (0.00 sec) 删除表字段 🍀 语法 : ALTER TABLE tablename DROP [COLUMN] column_name; ALTER TABLE DROP FOREIGN KEY foreign_key_name; ALTER TABLE DROP PRIMARY KEY; 实例 : -- 删除age字段 mysql> ALTER TABLE emp DROP age; Query OK, 0 rows affected (0.42 sec) Records: 0 Duplicates: 0 Warnings: 0 -- 删除主键 mysql> ALTER TABLE emp DROP PRIMARY KEY; Query OK, 0 rows affected (0.62 sec) Records: 0 Duplicates: 0 Warnings: 0 -- 查看表定义 mysql> DESC emp; +----------+---------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------+---------------+------+-----+---------+-------+ | ename | varchar(20) | YES | | NULL | | | hiredate | date | YES | | NULL | | | sal | decimal(10,2) | YES | | NULL | | | deptno | int(2) | YES | | NULL | | | id | int(5) | NO | | NULL | | +----------+---------------+------+-----+---------+-------+ 5 rows in set (0.00 sec) 字段改名 🍀 语法 : ALTER TABLE tablename CHANGE [COLUMN] old_col_name new_col_name column_type [FIRST|AFTER col_name]; 实例 : -- 将sal字段修改为salary mysql> ALTER TABLE emp CHANGE sal salary decimal(10,2); Query OK, 0 rows affected (0.09 sec) Records: 0 Duplicates: 0 Warnings: 0 -- 查看表定义 mysql> DESC emp; +----------+---------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------+---------------+------+-----+---------+-------+ | ename | varchar(20) | YES | | NULL | | | hiredate | date | YES | | NULL | | | salary | decimal(10,2) | YES | | NULL | | | deptno | int(2) | YES | | NULL | | | id | int(5) | NO | | NULL | | +----------+---------------+------+-----+---------+-------+ 5 rows in set (0.00 sec) PS : change 和 modify都可以修改表类型 , 不同的是change后面需要写两次列名 ; 并且change可以修改列名 , modify则不能 修改字段排列顺序 🍀 前面介绍的字段增加和修改语法(ADD/CHANGE/MODIFY)中, 都有一个可选项 [FIRST|AFTER col_name] ,这个选项可以用来修改字段在表中的位置 , ADD增加的新字段默认是加在表的最后位置 , 而CHANGE/MODIFY默认都不会改变字段的位置 将新增的字段birth date加在ename之后 mysql> DESC emp; +----------+---------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------+---------------+------+-----+---------+-------+ | ename | varchar(20) | YES | | NULL | | | hiredate | date | YES | | NULL | | | salary | decimal(10,2) | YES | | NULL | | | deptno | int(2) | YES | | NULL | | | id | int(5) | NO | | NULL | | +----------+---------------+------+-----+---------+-------+ 5 rows in set (0.00 sec) -- 新增birth date字段在ename之后 mysql> ALTER TABLE emp ADD birth date AFTER ename; Query OK, 0 rows affected (0.45 sec) Records: 0 Duplicates: 0 Warnings: 0 -- 查看表定义 mysql> DESC emp; +----------+---------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------+---------------+------+-----+---------+-------+ | ename | varchar(20) | YES | | NULL | | | birth | date | YES | | NULL | | | hiredate | date | YES | | NULL | | | salary | decimal(10,2) | YES | | NULL | | | deptno | int(2) | YES | | NULL | | | id | int(5) | NO | | NULL | | +----------+---------------+------+-----+---------+-------+ 6 rows in set (0.00 sec) 修改salary字段 , 将它放在最前面 mysql> ALTER TABLE emp MODIFY salary DECIMAL(10,2) FIRST; Query OK, 0 rows affected (0.55 sec) Records: 0 Duplicates: 0 Warnings: 0 -- 查看表定义 mysql> DESC emp; +----------+---------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------+---------------+------+-----+---------+-------+ | salary | decimal(10,2) | YES | | NULL | | | ename | varchar(20) | YES | | NULL | | | birth | date | YES | | NULL | | | hiredate | date | YES | | NULL | | | deptno | int(2) | YES | | NULL | | | id | int(5) | NO | | NULL | | +----------+---------------+------+-----+---------+-------+ 6 rows in set (0.00 sec) PS : CHANGE/FIRST|AFTER COLUMN 这些关键字都属于MySQL在标准SQL上的扩展 , 在其他数据库上不一定适用 更改表名 🍀 语法 : ALTER TABLE tablename RENAME [TO] new_tablename; 实例 : mysql> ALTER TABLE emp RENAME emp1; Query OK, 0 rows affected (0.16 sec) -- 表明改变 mysql> DESC emp1; +----------+---------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------+---------------+------+-----+---------+-------+ | salary | decimal(10,2) | YES | | NULL | | | ename | varchar(20) | YES | | NULL | | | birth | date | YES | | NULL | | | hiredate | date | YES | | NULL | | | deptno | int(2) | YES | | NULL | | | id | int(5) | NO | | NULL | | +----------+---------------+------+-----+---------+-------+ 6 rows in set (0.00 sec) 默认值 🍀 语法 : -- 修改默认值 ALTER TABLE tablename ALTER field_name SET DEFAULT v; -- 删除默认值 ALTER TABLE tablename ALTER field_name DROP DEFAULT; 实例 : -- 将salary字段默认值修改为2000 mysql> ALTER TABLE emp1 ALTER salary SET DEFAULT 2000; Query OK, 0 rows affected (0.12 sec) Records: 0 Duplicates: 0 Warnings: 0 -- 查看表定义 mysql> DESC emp1; +----------+---------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------+---------------+------+-----+---------+-------+ | salary | decimal(10,2) | YES | | 2000.00 | | | ename | varchar(20) | YES | | NULL | | | birth | date | YES | | NULL | | | hiredate | date | YES | | NULL | | | deptno | int(2) | YES | | NULL | | | id | int(5) | NO | | NULL | | +----------+---------------+------+-----+---------+-------+ 6 rows in set (0.00 sec) -- 删除salary的默认值 mysql> ALTER TABLE emp1 ALTER salary DROP DEFAULT; Query OK, 0 rows affected (0.09 sec) Records: 0 Duplicates: 0 Warnings: 0 -- 查看表定义 mysql> DESC emp1; +----------+---------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------+---------------+------+-----+---------+-------+ | salary | decimal(10,2) | YES | | NULL | | | ename | varchar(20) | YES | | NULL | | | birth | date | YES | | NULL | | | hiredate | date | YES | | NULL | | | deptno | int(2) | YES | | NULL | | | id | int(5) | NO | | NULL | | +----------+---------------+------+-----+---------+-------+ 6 rows in set (0.00 sec) 语句合集 🍀 创建表 /* 是否可空 */ CREATE TABLE tablename( column_name type NULL, /* 列名,类型,可为空 */ column_name type NOT NULL /* 列名,类型,不可为空 */ )ENGINE=InnoDB DEFAULT CHARSET=utf8 /* 默认值 */ CREATE TABLE tablename( column_name type DEFAULT NULL , /* 列名,类型,默认为空 */ 　column_name type NOT NULL DEFAULT 2 /* 列名,类型,默认为空 */ )ENGINE=InnoDB DEFAULT CHARSET=utf8 /* 自增 */ CREATE TABLE tablename( column_name type NOT NULL auto_increment PRIMARY KEY, )ENGINE=InnoDB DEFAULT CHARSET=utf8 或 CREATE TABLE tablename( column_name type NOT NULL auto_increment, INDEX(column_name) )ENGINE=InnoDB DEFAULT CHARSET=utf8 对于自增列,必须是索引(含主键) 对于自增可以设置步长和起始值 SHOW SESSION VARIABLES LIKE 'auto_inc%'; SET SESSION auto_increment_increment=2; SET SESSION auto_increment_offset=10; SHOW GLOBAL VARIABLES LIKE 'auto_inc%'; SET GLOBAL auto_increment_increment=2; SET GLOBAL auto_increment_offset=10; /* 主键 */ 主键,一种特殊的唯一索引,不允许有空值,如果主键使用单个列,则它的值必须唯一,如果是多列,则其组合必须唯一 CREATE TABLE tablename( column_name type NOT NULL auto_increment PRIMARY KEY, ) 或 CREATE TABLE tablename( column_name type NOT NULL, PRIMARY KEY(column_name) ) /* 外键 */ CREATE TABLE tablename( CONSTRAINT symbol FOREIGN KEY (id) REFERENCES table_child(id); ) 删除表 DROP TABLE tablename; 清空表 -- 如果清空的表又自增列,那么在清空之后会继续上次自增的值继续自增 DELETE FROM tablename; -- 如果清空的表又自增列,那么在清空之后再次添加数据自增的值会从新开始计算 TRUNCATE TABLE tablename; 修改表 -- 添加列 ALTER TABLE tablename ADD column_name column_type -- 删除列 ALTER TABLE tablename DROP COLUMN column_name -- 修改列 ALTER TABLE tablename MODIFY COLUMN column_name column_type; -- 修改类型 ALTER TABLE tablename CHANGE originalname newname column_type; -- 修改列名与类型 -- 添加主键 ALTER TABLE tablename ADD PRIMARY KEY(columnname); -- 删除主键 ALTER TABLE tablename DROP PRIMARY KEY; ALTER TABLE tablename MODIFY columnname INT, DROP PRIMARY KEY; -- 添加外键 ALTER TABLE slave_table ADD CONSTRAINT symbol(ex:FK_slave_primary) FOREIGN KEY slave_table(foreign_key_field) REFERENCES primary_table(primary_field); -- 删除外键 ALTER TABLE tablename DROP FOREIGN KEY foreign_key_field -- 修改默认值 ALTER TABLE testalter_tbl ALTER i SET DEFAULT 1000; -- 删除默认值 ALTER TABLE testalter_tbl ALTER i DROP DEFAULT; "},"03-MySQL/05-MySQL - 数据操作.html":{"url":"03-MySQL/05-MySQL - 数据操作.html","title":"MySQL - 数据操作","keywords":"","body":"MySQL - 数据操作 介绍 🍀 DML操作是指对数据库中表记录的操作 , 即数据操作 主要包括表记录的插入(insert) , 更新(update) , 删除(delete) 和查询(select) , 是开发人员日常使用最频繁的操作 插入记录 🍀 语法 : INSERT INTO tablename(field1,field2,...,fieldn) VALUES(value1,value2,...,valuen); 实例 : mysql> DESC emp; +----------+---------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------+---------------+------+-----+---------+-------+ | ename | varchar(10) | YES | | NULL | | | hiredate | date | YES | | NULL | | | sal | decimal(10,2) | YES | | NULL | | | deptno | int(2) | YES | | NULL | | +----------+---------------+------+-----+---------+-------+ 4 rows in set (0.00 sec) -- 插入数据,values中的顺序需排列一致 mysql> INSERT INTO emp(ename,hiredate,sal,deptno) VALUES('lyon','2000-01-01','2000',1); Query OK, 1 row affected (0.08 sec) -- 插入第二条数据 mysql> INSERT INTO emp(ename,hiredate,sal,deptno) VALUES('kenneth','2000-01-01','1000',2); Query OK, 1 row affected (0.10 sec) -- 没写的字段自动设置为NULL,默认值,自增的下一个数字 mysql> INSERT INTO emp(ename,sal) VALUES('alex',500); Query OK, 1 row affected (0.24 sec) -- 查看emp表中的所有记录 mysql> SELECT * FROM emp; +---------+------------+---------+--------+ | ename | hiredate | sal | deptno | +---------+------------+---------+--------+ | lyon | 2000-01-01 | 2000.00 | 1 | | kenneth | 2000-01-01 | 1000.00 | 2 | | alex | NULL | 500.00 | NULL | +---------+------------+---------+--------+ 3 rows in set (0.00 sec) 一次性插入多条 : INSERT INTO tablename(field1,field2,...,fieldn) VALUES (value1,value2,...,valuen), -- 以逗号分隔 (value1,value2,...,valuen), (value1,value2,...,valuen), (value1,value2,...,valuen); 更新记录 🍀 语法 : UPDATE tablename SET field1=value1,field2=value2,...,fieldn=valuen [WHERE CONDITION]; 实例 : mysql> UPDATE emp SET sal=100000 WHERE ename='lyon'; Query OK, 1 row affected (0.10 sec) Rows matched: 1 Changed: 1 Warnings: 0 同时更新多个表中数据 UPDATE t1,t2,...,tn SET t1.field1=expr1,tn.fieldn=exprn [WHERE CONDITION]; 删除记录 🍀 语法 : DELETE FROM tablename [WHERE CONDITION]; 实例 : mysql> DELETE FROM emp WHERE ename='alex'; Query OK, 1 row affected (0.06 sec) 一次删除多个表的数据 DELETE t1,t2,...,tn FROM t1,t2,...,tn [WHERE CONDITION]; 实例 : -- 查询记录 mysql> SELECT * FROM dept; +--------+----------+ | deptno | deptname | +--------+----------+ | 1 | tech | | 2 | sale | | 3 | hr | +--------+----------+ 3 rows in set (0.00 sec) -- 查询记录 mysql> SELECT * FROM emp; +---------+------------+-----------+--------+ | ename | hiredate | sal | deptno | +---------+------------+-----------+--------+ | lyon | 2000-01-01 | 100000.00 | 1 | | kenneth | 2000-01-01 | 1000.00 | 2 | +---------+------------+-----------+--------+ 2 rows in set (0.00 sec) -- 删除两个表中deptno为2的记录 mysql> DELETE a,b FROM emp a,dept b WHERE a.deptno=b.deptno and a.deptno=2; Query OK, 2 rows affected (0.11 sec) -- 查询记录 mysql> SELECT * FROM emp; +-------+------------+-----------+--------+ | ename | hiredate | sal | deptno | +-------+------------+-----------+--------+ | lyon | 2000-01-01 | 100000.00 | 1 | +-------+------------+-----------+--------+ 1 row in set (0.00 sec) -- 查询记录 mysql> SELECT * FROM dept; +--------+----------+ | deptno | deptname | +--------+----------+ | 1 | tech | | 3 | hr | +--------+----------+ 2 rows in set (0.00 sec) PS : 不管是单表还是多表 , 不加where条件会把表的所有记录删除 , 所以操作时一定要小心 查询记录 🍀 语法 : SELECT * FROM tablename [WHERE CONDITION]; \"*\"表示要将所有的记录都选出来 , 也可以用逗号分割所有的字段来代替 如上面例子中 mysql> SELECT ename,hiredate,sal,deptno FROM emp; 查询不重复的记录 🍀 mysql> SELECT DISTINCT deptno FROM emp; +--------+ | deptno | +--------+ | 1 | +--------+ 1 row in set (0.00 sec) 条件查询 🍀 mysql> SELECT * FROM emp WHERE deptno=1; +-------+------------+-----------+--------+ | ename | hiredate | sal | deptno | +-------+------------+-----------+--------+ | lyon | 2000-01-01 | 100000.00 | 1 | +-------+------------+-----------+--------+ 1 row in set (0.00 sec) 排序和限制 🍀 -- 按工资高低进行显示 mysql> SELECT * FROM emp order by sal; +---------+------------+-----------+--------+ | ename | hiredate | sal | deptno | +---------+------------+-----------+--------+ | kenneth | 2000-01-01 | 5000.00 | 2 | | alex | 2000-01-01 | 8000.00 | 3 | | lyon | 2000-01-01 | 100000.00 | 1 | +---------+------------+-----------+--------+ 3 rows in set (0.00 sec) 对于排序后的记录 , 如果希望只显示一部分 , 可以使用LIMIT关键字来实现 SELECT ...[LIMIT offset_start,row_count] -- offset_start表示记录的起始偏移量,默认为0;row_count表示显示的行数 实例 mysql> SELECT * FROM emp ORDER BY sal LIMIT 2; +---------+------------+---------+--------+ | ename | hiredate | sal | deptno | +---------+------------+---------+--------+ | kenneth | 2000-01-01 | 5000.00 | 2 | | alex | 2000-01-01 | 8000.00 | 3 | +---------+------------+---------+--------+ 2 rows in set (0.00 sec) PS : limit属于MySQL扩展SQL92后的语法 , 在其他数据库上并不能通用 聚合 🍀 用于进行汇总操作 语法 : SELECT [field1,field2,...,fieldn] fun_name FROM tablename [WHERE where_condition] [GROUP BY field1,dield2,,...,fieldn [WITH ROLLUP]] [HAVING where_contition] /* 参数说明 */ fun_name 表示要做的聚合操作,也就是聚合函数,常用的有 sum(求和),count(*)(记录表),max(最大值),min(最小值) GROUP BY 关键字表示要进行分类聚合的字段,比如要按照部门分类统计员工数量,部门就应该写在 group by后面 WITH ROLLUP 是可选语法,表明是否对分类聚合后的结果进行再汇总 HAVING 关键字表示对分类后的结果再进行条件的过滤 -- 注意 : having 和 where的区别在于,having是对聚合后的结果进行条件的过滤,而 where是在聚合前就对记录进行过滤,所以我们应该尽可能用 where先过滤记录,使结果集减小,会对聚合的效率大大提高 实例 : /* 统计emp表中公司的总人数 */ mysql> SELECT count(1) FROM emp; +----------+ | count(1) | +----------+ | 5 | +----------+ 1 row in set (0.00 sec) /* 统计个部门的总人数 */ mysql> SELECT count(1) FROM emp GROUP BY deptno; +----------+ | count(1) | +----------+ | 2 | | 2 | | 1 | +----------+ 3 rows in set (0.00 sec) /* 既统计各部门人数,又统计总人数 */ mysql> SELECT deptno,count(1) FROM emp GROUP BY deptno WITH ROLLUP; +--------+----------+ | deptno | count(1) | +--------+----------+ | 1 | 2 | | 2 | 2 | | 3 | 1 | | NULL | 5 | +--------+----------+ 4 rows in set (0.00 sec) /* 统计人数大于1的部门 */ mysql> SELECT deptno,count(1) FROM emp GROUP BY deptno HAVING count(1)>1; +--------+----------+ | deptno | count(1) | +--------+----------+ | 1 | 2 | | 2 | 2 | +--------+----------+ 2 rows in set (0.00 sec) /* 统计公司所有员工的薪水总额,最高和最低薪水 */ mysql> SELECT sum(sal),max(sal),min(sal) FROM emp; +-----------+-----------+----------+ | sum(sal) | max(sal) | min(sal) | +-----------+-----------+----------+ | 113000.00 | 100000.00 | 5000.00 | +-----------+-----------+----------+ 1 row in set (0.00 sec) 表连接 🍀 同时显示多个表中的字段 , 分为内连接和外连接 内连接仅选出两张表中互相匹配的记录 , 外连接会选出其他不匹配的记录 , 我们最常用的是内连接 外连接又分为左连接和右连接 内连接 : mysql> SELECT * FROM emp; +---------+------------+-----------+--------+ | ename | hiredate | sal | deptno | +---------+------------+-----------+--------+ | lyon | 2000-01-01 | 100000.00 | 1 | | kenneth | 2000-01-01 | 5000.00 | 2 | | alex | 2000-01-01 | 8000.00 | 3 | | egon | NULL | NULL | 1 | | eva | NULL | NULL | 2 | +---------+------------+-----------+--------+ 5 rows in set (0.00 sec) mysql> SELECT * FROM dept; +--------+----------+ | deptno | deptname | +--------+----------+ | 1 | tech | | 3 | hr | | 2 | sale | +--------+----------+ 3 rows in set (0.00 sec) mysql> SELECT ename,deptname FROM emp,dept WHERE emp.deptno=dept.deptno; +---------+----------+ | ename | deptname | +---------+----------+ | lyon | tech | | kenneth | sale | | alex | hr | | egon | tech | | eva | sale | +---------+----------+ 5 rows in set (0.00 sec) 外连接 : 根据上述实例 , 语句为 左连接 : SELECT ename,deptname FROM emp LEFT JOIN dept ON emp.deptno=dept.deptno; 右连接 : SELECT ename,deptname FROM emp RIGHT JOIN dept ON emp.deptno=dept.deptno; 子查询 🍀 查询时 , 需要的条件是另一个select语句的结果 mysql> SELECT * FROM emp WHERE deptno in(SELECT deptno FROM dept); +---------+------------+-----------+--------+ | ename | hiredate | sal | deptno | +---------+------------+-----------+--------+ | lyon | 2000-01-01 | 100000.00 | 1 | | kenneth | 2000-01-01 | 5000.00 | 2 | | alex | 2000-01-01 | 8000.00 | 3 | | egon | NULL | NULL | 1 | | eva | NULL | NULL | 2 | +---------+------------+-----------+--------+ 5 rows in set (0.00 sec) 如果子查询记录数唯一 , 可以用 = 代替 in , 即SELECT * FROM emp WHERE deptno = (SELECT deptno FROM dept); 某些情况下 , 子查询可以转化为表连接 , 如下 mysql> SELECT * FROM emp WHERE deptno in(SELECT deptno FROM dept); +---------+------------+-----------+--------+ | ename | hiredate | sal | deptno | +---------+------------+-----------+--------+ | lyon | 2000-01-01 | 100000.00 | 1 | | kenneth | 2000-01-01 | 5000.00 | 2 | | alex | 2000-01-01 | 8000.00 | 3 | | egon | NULL | NULL | 1 | | eva | NULL | NULL | 2 | +---------+------------+-----------+--------+ 5 rows in set (0.00 sec) PS : MySQL 4.1 以前的版本不支持子查询 , 需要用表连接来实现子查询 表连接在很多情况下用于优化子查询 记录联合 🍀 union 和union all 关键字可以实现 , 将多个表的数据按照一定的查询条件查询出来后 , 将结果合并到一起显示 语法 : SELECT * FROM t1 UNION\\UNION ALL SELECT * FROM t2 ... UNION\\UNION ALL SELECT * FROM tn; 实例 : mysql> SELECT deptno FROM emp -> UNION -> SELECT deptno FROM dept; +--------+ | deptno | +--------+ | 1 | | 2 | | 3 | +--------+ 3 rows in set (0.00 sec) PS : union all是把结果集直接合并在一起 , 而union是将union all后的结果进行一次distinct , 去除重复记录后的结果 "},"03-MySQL/06-MySQL - 索引.html":{"url":"03-MySQL/06-MySQL - 索引.html","title":"MySQL - 索引","keywords":"","body":"MySQL - 索引 介绍 🍀 索引是数据库中最常用也是最重要的手段之一 , 是数据库中专门用于帮助用户快速查询数据的一种数据结构 , 类似于字典中的目录 , 查找字典内容时可以根据目录查找到数据的存放位置 , 然后直接获取值即可 索引是在MySQL的存储引擎层中实现的 而不是在服务器层实现的 , 所以每种存储引擎的索引都不一定完全相同 , 也不是所有的存储引擎都支持所有的索引类型 三个常用引擎支持的索引类型比较 索引 MyISAM引擎 InnoDB引擎 Memory引擎 B-Tree索引 支持 支持 支持 HASH索引 不支持 不支持 支持 R-Tree索引 支持 不支持 不支持 Full-text索引 支持 5.6版本后支持 不支持 下面对比较常用的两个索引类型进行说明 B-Tree索引与HASH索引 🍀 B-Tree索引 B-Tree索引是最常见的索引 , 构造类似二叉树 , 所以可以根据键值进行快速的访问 , 通常只需要很少的读操作就可以找到正确的行 , 不过B-Tree中的B不代表二叉树 , 而是代表平衡树 , B-Tree并不是一棵二叉树 B-Tree索引适用于全关键字 , 关键字范围和关键字前缀查询 HASH索引 HASH索引相对简单 , 只有Memory/Heap引擎支持 HASH索引适用于 Key - Value查询 , 通过HASH索引要比通过B-Tree索引查询更迅速 , 但是HASH不适用范围查询 , 例如 : , =这类操作 ; 如果使用Memory/Heap引擎并且where条件中不使用 \"=\" 今夕in个索引列 , 那么不会用到索引 , Memory/Heap引擎只有在 \"=\" 的条件下才会使用索引 MySQL索引管理 🍀 索引的功能就是为了加速查找和约束 , 下面对常用索引进行介绍 查看索引 : SHOW INDEX FROM tablename \\G; 普通索引 🍀 普通索引仅有一个功能 , 就是加速查找 创建方式 方式一 : /* 创建索引 */ CREATE INDEX indexname ON tablename(column_name(length)); -- 注意如过是CHAR,VARCHAR类型,length可以小于字段长度 -- 如果是BLOB和TEXT类型,必须指定length 方式二 : /* 修改表结构 */ ALTER TABLE tablename ADD INDEX indexname (column_name); 方式三 : /* 创建表时直接指定 */ CREATE TABLE mytable( ID INT NOT NULL, name VARCHAR(16) NOT NULL, INDEX [indexname] (name(length)) -- indexname可不写 ); 删除索引 DROP INDEX indexname ON tablename; ALTER TABLE tablename DROP INDEX column_name; 唯一索引 🍀 唯一索引有两个功能 : 加速查找和唯一约束(可含NULL) 与普通索引类似 , 不同的就是 : 索引列的值必须唯一 , 但允许有空值 , 如果是组合索引 , 则列值的组合必须唯一 创建方式 方式一 : /* 创建索引 */ CREATE UNIQUE INDEX indexname ON tablename(column_name(length)); 方式二 : /* 修改表结构 */ ALTER TABLE tablename ADD UNIQUE [indexname] (column_name(length)); 方式三 : /* 创建表时指定 */ CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, UNIQUE [indexname] (username(length)) ); 删除索引 DROP INDEX indexname ON tablename; ALTER TABLE tablename DROP INDEX column_name; 主键索引 🍀 主键有两个功能 : 加速查找和唯一约束(不可NULL) 创建方式 方式一 : /* 修改表结构 */ ALTER TABLE tablename ADD PRIMARY KEY column_name; 方式二 : /* 创建表时指定 */ CREATE TABLE mytable( id INT NOT NULL AUTO_INCREMENT PRIMARY KEY, name VARCHAR(32) NOT NULL ); -- or CREATE TABLE mytable( id INT NOT NULL AUTO_INCREMENT, name VARCHAR(32) NOT NULL PRIMARY KEY(id) ); 删除主键 ALTER TABLE tablename DROP PRIMARY KEY; ALTER TABLE tablename MODIFY column_name column_type, drop primary key; 　组合索引 🍀 组合索引是将n个列组合成一个索引 , 专门用于组合搜索 , 其效率大于索引合并 应用场景 : 频繁的同时使用n列来进行查询 , 如 : where n1 = 'alex' and n2 = 666 创建索引 /* 创建表 */ CREATE TABLE mytable( nid INT NOT NULL AUTO_INCREMENT PRIMARY KEY, name VARCHAR(32) NOT NULL, email VARCHAR(64) NOT NULL, extra TEXT ); /* 创建组合索引 */ CREATE INDEX ix_name_email ON mytable(name,email); 如上创建索引后 , 查询 : name and email -- 使用索引 name -- 使用索引 email -- 不使用索引 PS : 对于同时搜索n个条件时 , 组合索引的性能好于多个单一索引合并 全文索引 : 对文本的内容进行分词 , 进行搜索 索引合并 : 使用多个单列索引组合搜索 覆盖索引 : MySQL只需要通过索引就可以返回查询所需要的数据 , 而不必在查到索引之后进行回表操作 , 减少IO , 提供效率 当你对一个sql 使用explain statement 查看一个sql的执行计划时 , 在EXPLAIN的Extra列出现Using Index提示时 , 就说明该select查询使用了覆盖索引 使用索引 🍀 使用索引可以加速查找 , 但是如果以错误的方式使用 , 即使建立索引也不会生效 以\"%\"开头的LIKE查询不走索引 mysql> EXPLAIN SELECT * FROM actor WHERE last_name LIKE '%NI' \\G; -- 不走索引 mysql> EXPLAIN SELECT * FROM actor WHERE last_name LIKE 'NI%' \\G; -- 走索引 数据类型出现隐式转换不走索引 , MySQL默认把输入的常量值进行转换后才进行检索 , 如下last_name列为字符串类型 mysql> EXPLAIN SELECT * FROM actor WHERE last_name = 1 \\G; -- 不走索引,全表扫描 mysql> EXPLAIN SELECT * FROM actor WHERE last_name = '1' \\G; -- 走索引 -- 一定记得在where条件中把字符常量值用引号引起来 组合索引情况下 , 查询条件不包含索引列最左边部分 , 不走索引 mysql> EXPLAIN SELECT * FROM mytable WHERE name='lyon' AND email='myemail' \\G; -- 使用索引 mysql> EXPLAIN SELECT * FROM mytable WHERE email='myemail' AND name='lyon' \\G; -- 不使用索引 -- 最左原则 如果MySQL估计使用索引比全表扫描更慢 , 不走索引 , MySQL 5.6版本中 , 能够通过Trace清晰地看到优化器选择的过程 用or分割开的条件中有未建立索引的列 , 不走索引 mysql> SELECT * FROM tb1 WHERE nid = 1 OR email = 'myemail'; -- 不使用索引,email列未建立 mysql> SELECT * FROM tb1 WHERE nid = 1 OR name = 'myemail'; -- 使用索引,两者都建立 普通索引的\"!=\"和\">\"不走索引 , 特别的走 -- != mysql> SELECT * FORM tb1 WHERE name != 'lyon'; -- 不走索引 mysql> SELECT * FORM tb1 WHERE nid != 123; -- 走索引,nid为主键 -- > mysql> SELECT * FORM tb1 WHERE name > 'lyon'; -- 不走索引 mysql> SELECT * FORM tb1 WHERE nid > 123; -- 走索引,nid为主键或索引是整数类型 排序条件为索引 , 选择的映射如果不是索引 , 则不走索引 mysql> SELECT email FROM tb1 ORDER BY name desc; -- 不走索引 mysql> SELECT * FROM tb1 ORDER BY nid desc; -- 走索引,如果对主键排序,则还是走 注意 : -- 避免使用select * -- count(1)或count(列) 代替 count(*) -- 创建表时尽量时 char 代替 varchar -- 表的字段顺序固定长度的字段优先 -- 组合索引代替多个单列索引（经常使用多个条件查询时） -- 尽量使用短索引 -- 使用连接（JOIN）来代替子查询(Sub-Queries) -- 连表时注意条件类型需一致 -- 索引散列值（重复少）不适合建索引，例：性别不适合 "},"03-MySQL/07-MySQL - 视图.html":{"url":"03-MySQL/07-MySQL - 视图.html","title":"MySQL - 视图","keywords":"","body":"MySQL - 视图 介绍 🍀 视图是一种虚拟存在的表 , 对于使用视图的用户来说基本上是透明的 视图并不在数据库中实际存在 , 行和列数据来自定义视图的查询中使用的表 , 并且是在使用视图时动态生成的 视图相对于普通的表的优势主要包括一下几点 : 简单 : 使用视图的用户完全不需要关心后面对应的表的结构 , 关联条件和筛选条件 , 对用户来说已经是过滤好的复杂条件的结果集 安全 : 使用视图的用户只能访问他们被允许查询的结果集 , 对表的权限管理并不能限制到某个行某个列 , 但是通过视图就可以简单的实现 数据独立 : 一旦视图的结构确定了 , 可以屏蔽表结构变化对用户的影响 , 源表增加列对视图没有影响 ; 源表修改列名 , 则可以通过修改视图来解决 , 不会造成对访问者的影响 视图操作 🍀 视图的操作包括创建或者修改视图 , 删除视图 , 以及查看视图定义 创建视图 🍀 创建视图需要有CREATE VIEW的权限 , 并且对于查询涉及的列有SELECT权限 ; 如果使用CREATE OR REPLACE或者ALTER修改视图 , 那么还需要该视图的DROP权限 语法 : -- 创建视图 CREATE VIWE 视图名称 AS SQL语句 -- 完整 CREATE [OR REPLACE] [ALGORITHM = {UNDEFINED|MERGE|TEMPTABLE}] VIEW view_name [(column_list)] AS select_statement [WITH [CASCADED|LOCAL] CHECK OPTION] 实例 mysql> CREATE VIEW lyon_view AS SELECT * FROM test; Query OK, 0 rows affected (0.08 sec) /* 注意 : MySQL视图的定义有一些限制,例如,在FROM关键字后面不能包含子查询,这和其他数据库是不同的 如果视图是从其他数据库迁移过来的,那么可能需要因此做一些改动,可以将子查询的内容先定义成 一个视图,然后对该视图再创建视图就可以实现类似的功能了 再次注意 : 使用视图后无需每次都重写子查询的sql , 但是这样效率并不高 , 还不如我们写子查询的效率高 一个致命的问题 : 视图是存放在数据库中的 , 如果我们程序中的sql过分依赖于数据库中存放的视图 , 那么意味着 , 一旦sql需要修改且涉及到视图的部分 , 则必须去数据库中进行修改 , 而通常在公司中数据库有专门的DBA负责 , 你要想完成修改 , 必须付出大量的沟通成本DBA可能才会帮你完成修改 , 极其的不方便 修改视图 🍀 语法 : -- 修改视图 ALTER VIEW 视图名称 AS SQL语句 -- 完整如下 ALTER [ALGORITHM = {UNDEFINED|MERGE|TEMPTABLE}] VIEW view_name [(column_list)] AS select_statement [WITH [CASCADED|LOCAL] CHECK OPTION] 实例 mysql> ALTER VIEW lyon_view AS SELECT * FROM test WHERE id > 4; Query OK, 0 rows affected (0.09 sec) 视图的可更新性 对于视图中的数据 , 由于视图是虚拟的 , 所以如果更新数据那么原始表也跟着被更新 , 即视图的可更新性 视图的可更新性和视图中查询的定义有关 , 一下类型的视图是不可更新的 : 包含一下关键字的SQL语句 : 聚合函数(SUM , MIN , MAX , COUNT等) , DISTINCT , GROUP BY , HAVING , UNION 或者 UNION ALL 常量视图 SELECT中包含子查询 JION FROM一个不能更新的视图 WHERE字句的子查询引用了FROM字句中的表 实例 -- 包含聚合函数 mysql> CREATE OR REPLACE VIEW payment_sum AS -> SELECT staff_id,SUM(count) FROM payment GROUP BY staff_id; Query OK, 0 rows affected(0.00 sec) -- 常量视图 mysql> CREATE OR REPLACE VIEW pi AS -> SELECT 3.1415926 AS pi; Query OK, 0 rows affected(0.00 sec) -- select中包含子查询 mysql> CREATE VIEW city_view AS -> SELECT (SELECT city FROM city WHERE city_id = 1); Query OK, 0 rows affected(0.00 sec) [WITH [CASCADED|LOCAL] CHECK OPTION] 该语句决定了是否允许更新数据使记录不再满足视图的条件 , 其中 : LOCAL只要满足本视图的条件就可以更新 CASCADED则必须满足所有针对该视图的所有视图的条件才可以更新 默认为CASCADED 实例 mysql> CREATE OR REPLACE VIEW payment_view AS -> SELECT payment_id,amount FROM payment -> WHERE amount CREATE OR REPLACE VIEW payment_view1 AS -> SELECT payment_id,amount FROM payment_view -> WHERE amount CREATE OR REPLACE VIEW payment_view2 AS -> SELECT payment_id,amount FROM payment_view -> WHERE amount > 5 WITH CASCADED CHECK OPTION; Query OK, 0 rows affected (0.00 sec) mysql> SELECT * FROM payment_view1 limit 1; +------------+--------+ | payment_id | amount | +------------+--------+ | 3 | 5.99 | +------------+--------+ 1 row in set (0.00 sec) mysql> UPDATE payment_view1 SET amount=10 -> WHERE payment_id = 3; Query OK, 1 row affected (0.03 sec) Rows matched: 1 changed: 1 warnings: 0 mysql> UPDATE payment_view2 SET amount=10 -> WHERE payment_id = 3; ERROR 1369 (HY000): CHECK OPTION failed 'sakila.payment_view2' 删除视图 🍀 用户可以一次删除一个或者多个视图 , 前提是必须有该视图的DROP权限 语法 : -- 删除视图 DROP VIEW view_name -- 完整如下 DROP VIEW [IF EXISTS] view_name [,view_name]...[RESTRICT|CASCADE]; 查看视图 🍀 从MySQL 5.1开始 , 使用SHOW TABLES命令的时候不仅显示表的名字 , 同时也会显示视图的名字 , 而不存在单独显示视图的SHOW VIEWS命令 , 如下 : mysql> SHOW TABLES; +----------------------+ | Tables_in_mydatabase | +----------------------+ | ... | | salary_view | | ... | +----------------------+ 11 rows in set (0.00 sec) 同样使用SHOW TABLE STATUS命令时 , 不但可以显示表的信息 , 同时也可以显示视图的信息 SHOW TABLE STATUS LIKE 'view_name' \\G; 查询某个视图的定义 SHOW CREATE VIEW view_name \\G; 通过查看系统表information_schema.views也可以查看视图的相关信息 SELECT * FROM VIEWS WHERE table_name = 'view_name' \\G; "},"03-MySQL/08-MySQL - 存储过程与函数.html":{"url":"03-MySQL/08-MySQL - 存储过程与函数.html","title":"MySQL - 存储过程与函数","keywords":"","body":"MySQL - 存储过程和函数 介绍 🍀 存储过程和函数是实现经过编译并存储在数据库中的一段SQL语句的集合 , 调用存储过程和函数可以简化应用开发人员的很多工作 , 减少数据在数据库和应用服务器之间的传输 , 对于提高数据处理的效率是有好处的 存储过程和函数的区别在于函数必须有返回值 , 而存储过程没有 , 存储过程的参数可以使用IN , OUT , INOUT类型 , 而函数的参数只能是IN类型的 , 如果有函数从其他类型的数据库迁移到MySQL , 那么就可能因此需要将函数改成成存储过程 参数介绍 : IN 仅用于传入参数用 OUT 仅用于返回值用 INOUT 既可以传入又可以当做返回值 在对存储过程或函数进行操作时 , 需要首先确认用户是否具有相应的权限 ' 例如 : 创建存储过程或者函数需要CREATE ROUTINE权限 , 修改或者删除存储过程或者函数需要ALTER ROUTINE权限 , 执行存储过程或者函数需要EXECUTE权限 创建存储过程或函数 🍀 语法 : /* 创建存储过程 */ CREATE PROCEDURE sp_name([proc_parameter[,...]]) [characteristic ...] routine_body /* 创建函数 */ CREATE FUNCTION sp_name([func_parameter[,...]]) RETURNS type [characteristic ...] routine_body -- 参数介绍 proc_parameter:[IN\\ OUT\\ INOUT] param_name type func_parameter:param_name type characteristic: LANGUAGE SQL |[NOT] DETERMINISTIC -- 修改SQL语句的结束符 |{CONTAINS SQL|NO SQL|READS SQL DATA|MODIFIES SQL DATA} |SQL SECURITY{DEFINER|INVOKER} -- SQL语句块 |COMMENT 'string' -- END 结束 实例 -- 修改SQL语句的结束符为$$ mysql> DELIMITER $$ -- 创建存储过程 mysql> CREATE PROCEDURE film_in_stock(IN p_film_id INT,IN p_store_id INT,OUT p_film_count INT) -> READS SQL DATA -> BEGIN -- 开始 -> SELECT inventory_id -- SQL语句块 -> FROM inventory -> WHERE film_id = p_film_id -> AND store_id = p_store_id -> AND inventory_in_stock(inventory_id); -> SELECT FOUND_ROWS() INTO p_film_count; -> END $$ -- 结束 Query OK, 0 rows affected (0.11 sec) -- 把SQL语句的结束符改为 ; mysql> DELIMITER ; characteristic特征值部分说明 特征值 说明 LANGUAGE SQL 说明下面过程的body是使用SQL语言编写 , 系统默认的 , 为今后MySQL会支持的除SQL外的其他语言做准备 [NOT] DETERMINISTIC DETERMINISTIC确定的 , 即每次输入一样输出也一样的程序 , NOT DETERMINISTIC非确定的 , 这个值当前还没有被优化程序使用 {CONTAINS SQL丨NO SQL丨READS SQL DATA丨MODIFIES SQL DATA} CONTAINS SQL表示子程序不包含读或写数据的语句NO SQL 表示子程序不包含SQL语句READS SQL DATA表示子程序包含读数据的语句 , 但不包含写数据的语句MODIFIES SQL DATA表示子程序包含写数据的语句默认值为CONTAINS SQL SQL SECURITY {DEFINER丨INVOKER} 可以用来指定子程序该用创建子程序者的许可来执行 , 还是使用调用者的许可来执行 , 默认为DEFINER(定义者) COMMENT 'string' 存储过程或者函数的注释信息 通过call调用存储过程 CALL sp_name([parameter[,...]]) 事务 修改存储过程或函数 🍀 语法 : ALTER {PRCEDURE|FUNCTION} sp_name [characteristic...] -- characteristic {CONTAINS SQL|NO SQL|READS SQL DATA|MODIFIES SQL DATA} |SQL SECURITY {DEFINER|INVOKER} |COMMENT 'string' 删除存储过程或函数 🍀 一次只能删除一个存储过程或者函数 , 删除过程或者函数需要有该过程或者函数的ALTER ROUTINE权限 语法 : DROP {PROCEDURE|FUNCTION} [IF EXISTS] sp_name 实例 mysql> DROP PROCEDURE film_in_stock; Query OK, 0 rows affected (0.00 sec) 查看存储过程或函数 🍀 查看状态 SHOW PROCEDURE STATUS LIKE 'film_in_stock' \\G; 查看定义 SHOW CREATE {PROCEDURE|FUNCTION} sp_name; 通过查看information_schema.Routines查看 SELECT * FROM ROUTINES WHERE ROUTINE_NAME = 'film_in_stock' \\G; 变量的使用 🍀 存储过程和和函数可以使用变量 , 而且在MySQL 5.1版本中 , 变量不区分大小写 变量的定义 通过DECLARE定义一个局部变量 , 该变量的作用域只能在BEGIN...END块中 , 可以用在嵌套的块中 ; 变量的定义必须卸载复合语句的开头 , 并且在任何其他语句的前面 , 可以一次声明多个相同类型的变量 , DEFAULT可以设置默认值 语法 : DECLARE var_name[,...] type [DEFAULT value]; 实例 DECLARE last_month_start DATE; 变量的赋值 变量可以直接赋值 , 或者通过查询赋值 ; 直接赋值使用SET , 可以赋厂里爱那个或者赋表达式 语法 : SET var_name = expr [,var_name = expr]... 给刚才定义的last_month_start复制 SET last_month_start = DATE_SUB(CURRENT_DATE(),INTERVAL 1 MONTH); 可以通过查询将结果赋给变量 , 但是结果必须只有一行 SELECT col_name [,...] INTO var_name [,...] table_expr; 实例如下 DECLARE v_payments DECIMAL(5,2); -- SUM OF PAYMENTS MADE PREVIOUSLY 条件处理 🍀 用于定义在处理过程中遇到问题时相应的处理步骤 定义条件 DECLARE condition_name CONDITION FOR condition_value condition_value: SQLSTATE [VALUE] sqlstate_value |mysql_error_code 处理条件 DECLARE handler_type HANDLER FOR condition_value [,...] sp_statement handler_type: CONTINUE |EXIT -- 执行终止 |UNDO -- 现在还不支持 condition_value: SQLSTATE [VALUE] sqlstate_value |condition_name |SQLWARNING |NOT FOUND |SQLEXCEPTION |mysql_error_code 实例 /* 事务 */ mysql> DELIMITER $$ mysql> CREATE PROCEDURE p1( -> OUT p_return_code TINYINT -> ) -> BEGIN -> DECLARE EXIT HANDLER FOR SQLEXCEPTION -> BEGIN -- ERROR -> SET p_return_code = 1; -> ROLLBACK; -- 回滚 -> END; -> DECLARE EXIT HANDLER FOR SQLWARNING -> BEGIN -- WARNING -> SET p_return_code = 2; -> ROLLBACK; -> END; -> START TRANSACTION; -- 开始事务 -> DELETE FROM tb1; -> INSERT INTO tb2(name) values('lyon'); -> COMMIT; -> SET p_return_code = 0; -- SUCCESS -> END $$ Query OK, 0 rows affected (0.10 sec) 光标 🍀 在存储过程或函数中 , 可以使用光标对结果集进行循环处理 声明光标 DECLARE curor_name CURSOR FOR select_statement OPEN光标 OPEN cursor_name FETCH光标 FETCH cursor_name INTO var_name [,var_name]... CLOSE光标 CLOSE cursor_name 实例 mysql> DELIMITER $$ mysql> CREATE PROCEDURE p3() -> BEGIN -> DECLARE ssid INT; -- 定义变量 -> DECLARE ssname VARCHAR(50); -> DECLARE done INT DEFAULT FALSE; -> DECLARE my_cursor CURSOR FOR SELECT sid,sname FROM student; -> DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE; -> OPEN my_cursor; -> ins:LOOP -> FETCH my_cursor INTO ssid,ssname; -> IF done THEN -> LEAVE ins; -> END IF; -> INSERT INTO teacher(tname) values(ssname); -> END LOOP ins; -> CLOSE my_cursor; -> END $$ Query OK, 0 rows affected (0.02 sec) 流程控制 🍀 IF语句 IF search_condition THEN statement_list [ELSEIF search_condition THEN statement_list]... [ELSE statement_list] END IF CASE语句 CASE case_value WHEN when_value THEN statement_list [WHEN when_value THEN statement_list]... [ELSE statement_list] END CASE -- or CASE WHEN search_condition THEN statement_list [WHEN search_codition THEN statement_list]... [ELSE statement_list] END CASE LOOP语句 [begin_label:] LOOP statement_list END LOOP [end_label] LEAVE语句 /* 用来从标注流程构造中退出,通常和BEGIN...END或者循环一起使用 */ BEGIN ... ins:LOOP ... LEAVE ins; ... ... END LOOP ins; END; ITERATE语句 /* 相当于continue */ BEGIN ... ins:LOOP IF ... THEN ITERATE ins; END LOOP ins; ... END; REPEAT语句 /* 满足条件退出循环 */ [begin_lable:] REPEAT statement_list UNTIL search_condition END REPEAT [end_late] WHILE语句 /* 满足条件才执行 */ [begin_lable:] WHILE search_condition DO statement_list END WHILE [end_label] 内置函数 🍀 对于一些内置函数 , 就直接看官方的吧 https://dev.mysql.com/doc/refman/5.7/en/functions.html 需要注意的是 , 上述为自定义函数的操作 , 而对于自定义函数 , 在功能块中不要写SQL语句 , 否则会报错 , 函数仅仅只是一个功能 , 一个在SQL中被应用的功能 , 如果要写SQL则应该使用存储过程 "},"03-MySQL/09-MySQL - 触发器与事务.html":{"url":"03-MySQL/09-MySQL - 触发器与事务.html","title":"MySQL - 触发器与事务","keywords":"","body":"MySQL - 触发器与事务 介绍 🍀 触发器是与表有关的数据库对象 , 在满足定义条件时触发 , 并执行触发器中定义的语句集合 创建触发器 🍀 语法 : CREATE TRIGGER trigger_name trigger_time trigger_event ON tbl_name FOR EACH ROW TRIGGER_stmt /* 触发器只能创建在永久性(Permanent Table)上,不能对临时表(Temporary Table)创建触发器 */ trigger_time: -- 触发器的触发时间 BEFORE|AFTER -- BEFORE:在检查约束前触发 -- AFTER:在检查约束后触发 trigger_event: -- 触发器触发的事件 INSERT|UPDATE|DELETE PS:对于同一个表相同触发时间的相同触发事件,只能定义一个触发器 详细如下 -- 插入前 CREATE TRIGGER tri_before_insert_tb1 BEFORE INSERT ON tb1 FOR EACH ROW BEGIN ... END -- 插入后 CREATE TRIGGER tri_after_insert_tb1 AFTER INSERT ON tb1 FOR EACH ROW BEGIN ... END -- 删除前 CREATE TRIGGER tri_before_delete_tb1 BEFORE DELETE ON tb1 FOR EACH ROW BEGIN ... END -- 删除后 CREATE TRIGGER tri_after_delete_tb1 AFTER DELETE ON tb1 FOR EACH ROW BEGIN ... END -- 更新前 CREATE TRIGGER tri_before_update_tb1 BEFORE UPDATE ON tb1 FOR EACH ROW BEGIN ... END -- 更新后 CREATE TRIGGER tri_after_update_tb1 AFTER UPDATE ON tb1 FOR EACH ROW BEGIN ... END 实例 -- 插入前触发 DELIMITER $$ CREATE TRIGGER tri_before_insert_tb1 BEFORE INSERT ON tb1 FOR EACH ROW BEGIN IF NEW.NAME == 'LYON' THEN INSERT INTO tb2 (NAME) VALUES ('aa') END END $$ 删除触发器 🍀 语法 : DROP TRIGGER [schema_name.]trigger_name -- 如果没有指定schema_name,默认为当前数据库 实例 mysql> DROP TRIGGER ins_film Query OK, 0 rows affected (0.00 sec) 查看触发器 🍀 可通过执行SHOW TRIGGERS \\G; 命令查看触发器的状态 , 语法等信息 , 但是因为不能查询指定的触发器 , 所以每次都返回所有的触发器信息 , 使用不方便 查询系统表information_schema.triggers表 , 该方式可以查询指定触发器的指定信息 DESC TRIGGERS; SELECT * FROM TRIGGERS WHERE trigger_name = '...' \\G; 使用触发器 🍀 触发器的语句有以下两个限制 触发程序不能调用将数据返回客户端的存储程序 , 也不能采用CALL语句的动态SQL语句 , 但是允许存储程序通过参数将数据返回触发程序 , 也就是存储过程或者函数通过OUT或者INOUT类型的参数将数据返回触发器是可以的 , 但是不能调用直接返回数据的过程 不能在触发器中使用以显示或隐式方式开始或结束事务的语句 , 如START TRANSACTION , COMMIT或ROLLBACK 总之触发器无法由用户直接调用 事务 🍀 事务用于将某些操作的多个SQL作为原子性操作 , 一旦有某一个出现错误 , 即可回滚到原来的状态 , 从而保证数据库数据完整性 MySQL通过SET AUTOCOMIT , START TRANSACTION , COMMIT 和 ROLLBACK 等语句支持本地事务 语法 : START TRANSACTION|BEGIN[WORK] COMMIT [WORK] [AND [NO] CHAIN] [[NO] RELEASE] ROLLBACK [WORK] [AND [NO] CHAIN] [[NO] RELEASE] SET AUTOCOMMIT = {0/1} -- 特征值介绍: START TRANSACTION 或 BEGIN 语句可以开始一项新的事务 COMMIT 和 ROLLBACK 用来提交或者回滚事务 CHAIN 和 RELEASE子句分别用来定义在事务提交或者回滚之后的操作,CHAIN会立即启动一个新事务,宾且和刚才的事务具有相同的隔离级别,RELEASE则会断开和客户端的连接 SET AUTOCOMMIT可以修改当前连接的提交方式,如果设置了 SET AUTOCOMMIT=0,则设置之后的所有事务都需要通过明确的命令进行提交或者回滚 默认情况下 , MySQL是自动提交(Autocommt)的 , 如果需要通过明确的Commit和Rollback来提交和回滚事务 , 那么就需要通过明确的事务控制命令来开始事务 , 这是和Oracle的事务管理明显不同的地方 实例 mysql> DELIMITER $$ mysql> CREATE PROCEDURE p1( -> OUT p_return_code TINYINT -> ) -> BEGIN -> DECLARE EXIT HANDLER FOR SQLEXCEPTION -> BEGIN -- ERROR -> SET p_return_code = 1; -> ROLLBACK; -- 回滚 -> END; -> DECLARE EXIT HANDLER FOR SQLWARNING -> BEGIN -- WARNING -> SET p_return_code = 2; -> ROLLBACK; -> END; -> START TRANSACTION; -- 开始事务 -> DELETE FROM tb1; -> INSERT INTO tb2(name) values('lyon'); -> COMMIT; -> SET p_return_code = 0; -- SUCCESS -> END $$ Query OK, 0 rows affected (0.10 sec) -- 调用 SET @i = 0; CALL p1(@i); SELECT @i; "},"03-MySQL/10-MySQL - SQL注入.html":{"url":"03-MySQL/10-MySQL - SQL注入.html","title":"MySQL - SQL注入","keywords":"","body":"MySQL - SQL注入 介绍 🍀 SQL注入(SQL Injection)就是利用某些数据的外部接口将用户数据插入到实际的数据库操作语言(SQL)当中 , 从而达到入侵数据库乃至操作系统的目的 , 它的产生主要是由于程序对用户输入的数据没有进行严格的过滤 , 导致非法数据库查询语句的执行 SQL注入攻击具有很大的危害 , 攻击者可以利用它读取 , 修改或者删除数据库内的数据 , 获取数据库中的用户名和密码等敏感信息 , 甚至可以获得数据库管理原的权限 , 而且 , SQL注入也很难防范 , 网站管理员无法通过安装系统补丁或者进行简单的安全配置进行自我保护 , 一般的防火墙也无法拦截SQl注入攻击 SQL注入实例(PHP程序实例) 创建用户表user CREATE TABLE user( userid INT(11) NOT NULL AUTO_INCREMENT, username VARCHAR(20) NOT NULL DEFAULT '', password VARCHAR(20) NOT NULL DEFAULT '', PRIMARY KEY(userid) )TYPE=MyISAM AUTO_INCREMENT=3; 添加一条用户记录 INSERT INTO 'user' VALUES(1,'angel','mypass'); 验证用户root登录localhost服务器 SQL Query:$sql\"; ?> 提交URL http://127.0.0.1/injection/user.php?username=angel' or '1=1 结果发现 , 这个URL可以成功登录系统 , 显然这并不是我们预期的结果 ; 溶氧也可以利用SQL的注释语句实现SQL注入 , 如下 : http://127.0.0.1/injection/user.php?username=angel'/* http://127.0.0.1/injection/user.php?username=angel'# 因为在SQL语句中 , \"/*\" 或者 \"#\" 都可以将后面的语句注释掉 这样上述语句就可以通过这两个注释符中的任意一个将后面的语句给注释掉 结果导致只根据用户名而没有密码的URL都成功进行了登录 \"or\" 是利用逻辑运算 , 注释符是根据MySQL的特性 , 这个比逻辑运算简单多了 , 两者都实现了SQL注入效果 应对措施 🍀 对于SQL注入隐患 , 后果可想而知 , 轻则获得数据信息 , 重则可以将数据进行非法更改 , 一下则是常用的防范方法 PrepareStatemen + Bind - Variable 🍀 MySQL服务器端并不存在共享池的概念 , 所以在MySQL上使用绑定变量(Bind Variable) , 最大的好处主要是为了避免SQL注入 , 增加安全性 即使用PrepareStatement语句(如Java)来实现 , 输入的参数中的单引号会被正常转义 , 导致后续的\"or 1=1\" 作为username条件内容出现 , 而不会作为SQL的一个单独条件被解析 , 避免了SQL注入的风险 ; 同样的 , 在使用绑定变量的情况下 , 企图通过注释 \"/*\" 或 \"#\" 让后续条件失效也是会失败的 需要注意 , PrepareStatement语句是由JDBC驱动来支持的 , 他仅仅做了简单的替换和转义 , 斌不是MySQL提供了PreparedStatement的特性 使用应用程序提供的转换函数 🍀 很多应用程序接口都提供了对特殊字符进行转换的函数 , 恰当地使用这些函数 , 可以防止应用程序用户输入使应用程序生成不期望的语句 MySQL C API : 使用mysql_real_escape_string() API调用 MySQL++ : 使用escape 和quote修饰符 PHP : 使用mysql_real_escape_string()函数 Perl DBI : 使用placeholders 或者quote()方法 Ruby DBI : 使用paceholders 或者quote()方法 自己定义函数进行检验 🍀 如果现有的转换函数任然不能满足要求 , 则需要自己编写函数进行输入校验 目前最好的解决方法就是 , 对用用户提交或者可能改变的数据进行简单分类 , 分别应用正则表达式来对用户提供的输入数据进行严格的检测和验证 Python中的pymysql模块 🍀 通过Python的pymysql模块来进行SQL的执行 , 在pymysql模块内部会自动把 \" ' \"(单引号做一个特殊的处理 , 来预防上述的错误) ...... effect_row = cursor.execute(\"select username from user_info where username='%s' and password = '%s'\", (username, pwd)) ...... "},"03-MySQL/SQL优化.html":{"url":"03-MySQL/SQL优化.html","title":"SQL优化","keywords":"","body":"SQL优化 一般步骤 MySQL 客户端连接成功后 , 通过 mysql> show [session|global]status 可以提供服务器状态信息 , 也可以在操作系统上使用 mysqladmin extended-status 命令获得这些消息 对于 session 与 global 参数 : session : 显示当前连接的统计结果 , 默认使用session global : 显示自数据库上次启动至今的统计结果 示例 mysql> show status like 'Com_%'; +-----------------------------+-------+ | Variable_name | Value | +-----------------------------+-------+ | Com_admin_commands | 0 | | Com_assign_to_keycache | 0 | | Com_alter_db | 0 | | Com_alter_db_upgrade | 0 | | Com_alter_event | 0 | | Com_alter_function | 0 | | Com_alter_instance | 0 | | Com_alter_procedure | 0 | | Com_alter_server | 0 | | Com_alter_table | 0 | ... Com_xxx 表示每个 xxx 语句执行的次数 , 我们通常比较关心以下几个统计参数 : Com_select : 执行 SELECT 操作的次数 , 一次查询只累加 1 Com_insert : 执行 INSERT 操作的次数 , 对于批量插入的 INSERT 操作 , 只累加一次 Com_update : 执行 UPDATE 操作的次数 Com_delete : 执行 DELETE 操作的次数 以上 4 个参数对于所有存储引擎的表操作都会进行累加 , 下面这几个参数只是针对 InnoDB 存储引擎的 , 累加的算法也略有不同 : Innodb_rows_read : SELECT 查询返回的行数 Innodb_rows_inserted : 执行 INSERT 操作插入的行数 Innodb_rows_upddated : 执行 UPDATE 操作更新的行数 Innodb_rows_deleted : 执行 DELETE 操作删除的行数 通过以上几个参数 , 可以容易地了解当前数据库的应用是以插入更新为主还是以查询操作为主 , 以及各种类型的 SQL 大致的执行比例是多少 ; 对于更新操作的技术 , 是对执行次数的技术 , 不论提交还是回滚都会进行累加 对于事务型的应用 , 通过 Com_commit 和 Com_rollback 可以了解事务提交和回滚的情况 , 对于回滚操作非常频繁的数据 , 可能意味着应用编写存在问题 , 此外还有几个参数便于用户了解数据库的基本情况 : Connections : 视图连接 MySQL 服务器的次数 Uptime : 服务器工作时间 Slow_queries : 慢查询的次数 定位低效SQL 有两种方式定位执行效率较低的 SQL : 通过慢查询日志定位那些执行效率较低的 SQL 语句 , 用 --log-slow-queries[= file_name] 选项启动时 , mysqld 写一个包含所有执行时间超过 long_query_time 秒的 SQL 语句的日志文件 慢查询日志在查询结束以后才记录 , 所以在应用反映执行效率出现问题的时候查询慢查询日志并不能定位问题 , 可以使用 show processlist 命令查看当前 MySQL 在进行的线程 , 包括线程的状态 , 是否锁表等 , 可以实时地查看 SQL 的执行情况 , 同时对一些锁表操作进行优化 EXPLAIN分析低效SQL 通过上一步定位效率低的 SQL 语句后 , 可以通过 EXPLAIN 或者DESC 命令获取 MySQL 如何执行 SELECT 语句的信息 , 包括在 SELECT 语句执行过程中表如何连接和连接的顺序 , 比如想统计某个 email 为租赁电影拷贝所支付的总金额 , 需要关联客户表 customer 和付款表 payment , 并且对付款金额 amount 字段做求和 (sum) 操作 , 相应的 SQL 执行计划如下 : mysql>explain select sum(amount) from custoer a, payment b where l=l and a.customer_id = b.customer_id and email = 'lyon.yang@qq.com'\\G; *************************** 1. row *************************** id: 1 select_type: SIMPLE table: a type: ALL possible_keys: PRIMARY key: NULL key_len: NULL ref: NULL rows: 583 Extra: Using where *************************** 2. row *************************** id: 1 select_type: SIMPLE table: b type: ref possible_keys: idx_fk_customer_id key: idx_fk_customer_id key_len: 2 ref: sakila.a.customer_id rows: 12 Extra: 2 rows in set (0.00 sec) 参数说明 : select_type : 表示 SELECT 的类型 , 常见的取值有 SIMPLE (简单表 , 即不使用表连接或者子查询) , PRIMARY (主查询 , 即外层的查询) , UNION (UNION 中的第二个或者后面的查询语句) , SUBQUERY (子查询中的第一个 SELECT ) 等 table : 输出结果集的表 type : 表示 MySQL 在表中找到所需行的方式 , 或者叫访问类型 , 常见类型有 : # 从左至右,性能由最差到最好 +------+--------+-------+-----+--------+--------------+------+ | ALL | index | range | ref | eq_ref | const,system | NULL | +------+--------+-------+-----+--------+--------------+------+ ALL : 全表扫描 , MySQL 遍历全表来找到匹配的行 # type=ALL explain select * from film where rating > 9\\G; index : 索引全扫描 , MySQL 遍历整个索引来查询匹配的行 # type=index explain select title from film\\G; range : 索引范围扫描 , 常见与 , >= , between 等操作符 # type=range explain select * from payment where customer_id >= 300 and customer_id ref : 使用非唯一索引扫描或唯一索引的前缀扫描 , 返回匹配某个单独值的记录行 # type=ref explain select * from payment where customer_id = 350\\G; eq_ref : 类似 ref , 区别就在使用的索引是唯一索引 , 对于每个索引键值 , 表中只有一条记录匹配 ; 简单来说 , 就是多表连接中使用主键或者联合索引作为关联条件 # type=eq_ref explain select * from film a, film_text b where a.film_id = b.film_id\\G; const/system : 单表中最多有一个匹配行 , 查询起来非常迅速 , 所以这个匹配行中的其他列的值可以被优化器在当前查询中当做常量来处理 , 如 , 根据主键或唯一索引进行的查询 # type=const/system explain select * from (select * from customer where email='lyon.yang@qq.com')a\\G; NULL : MySQL 不用访问表或者索引 , 直接就能得到结果 # type=NULL explain select 1 from dual where 1\\G; type 还有其他值 , 如 ref_or_null (与 ref 类似 , 区别在于条件中包含对 NULL 的查询) , index_merge (索引合并优化) , unique_subquery (in 的后面是一个查询主键字段的子查询) , index_subquery (与 unique_subquery 类似 , 区别在于 in 的后面是查询非唯一索引字段的子查询) possible_keys : 表示查询时可能使用的索引 key : 表示实际使用的索引 key_len : 使用到索引字段的长度 rows : 扫描行的数量 Extra : 执行情况的说明和描述 , 包含不适合在其他列中显示但是对执行计划非常重要的额外信息 show profile分析SQL 查看是否支持 profile mysql> select @@have_profiling; +------------------+ | @@have_profiling | +------------------+ | YES | +------------------+ 1 row in set, 1 warning (0.00 sec) 默认 profiling 是关闭的 , 在 Session 级别开启 profiling : mysql> select @@profiling; +-------------+ | @@profiling | +-------------+ | 0 | +-------------+ 1 row in set, 1 warning (0.00 sec) mysql> set profiling=1; Query OK, 0 rows affected, 1 warning (0.05 sec) mysql> select @@profiling; +-------------+ | @@profiling | +-------------+ | 1 | +-------------+ 1 row in set, 1 warning (0.00 sec) 通过 show profiles 语句可以查看 SQL 的 Query ID : mysql> show profiles; +----------+------------+--------------------+ | Query_ID | Duration | Query | +----------+------------+--------------------+ | 1 | 0.00050550 | select @@profiling | +----------+------------+--------------------+ 1 row in set, 1 warning (0.00 sec) 通过 show profile for query 语句查看执行过程中线程的每个状态和消耗的时间 mysql> show profile for query 1; +----------------------+----------+ | Status | Duration | +----------------------+----------+ | starting | 0.000081 | | checking permissions | 0.000005 | | Opening tables | 0.000004 | | init | 0.000009 | | optimizing | 0.000336 | | executing | 0.000012 | | end | 0.000004 | | query end | 0.000004 | | closing tables | 0.000003 | | freeing items | 0.000036 | | cleaning up | 0.000013 | +----------------------+----------+ 11 rows in set, 1 warning (0.03 sec) "},"04-前端/":{"url":"04-前端/","title":"前端","keywords":"","body":"Web development 介绍 本目录为Web开发前端部分整理 整理路线如下 : - HTML - CSS - JavaScirpt - BOM - DOM - jQuery - Ajax 更多等待后期扩展添加...... "},"04-前端/02-Web开发 - HTML-head.html":{"url":"04-前端/02-Web开发 - HTML-head.html","title":"Web开发 - HTML-head","keywords":"","body":"Web开发之路 - HTML-head 介绍 🍀 HTML是什么 ? 超文本标记语言(Hyper Text Markup Language , HTML) , 是一种用于创建网页的标准标记语言 HTML使用一套标记标签来描述网页 , HTML文档 = 网页 , Web浏览器的作用是读取HTML文档 , 并以网页的形式显示出来 , 浏览器不会显示HTML标签 , 而是使用标签来解释页面的内容 HTML标签 HTML标签是由尖括号包围的关键字 , Content \"HTML 标签\" 和 \"HTML 元素\" 通常都是描述同样的意思 , 但是严格来讲 , 一个HTML元素包含了开始标签与结束标签 HTML元素 HTML元素以开始标签起始(起始标签) , 以结束标签终止(闭合标签) , 元素的内容是开始标签与结束标签之间的内容 HTML元素分为块级元素和内联元素 , 块级元素在浏览器显示时 , 通常会以新的行来开始(和结束) , 而内联元素显示时通常就在行内开始(和结束) , 如下 : 块级元素 : , , , 等 内联元素 : , , , 等 HTML属性 HTML标签可以拥有属性 , 属性提供了有关HTML元素的更多信息 , 属性是以键/值对的形式出现 , 如 : name=\"Lyon\" ; 属性在HTML元素的起始标签中规定 , 如 :点我进百度 HTML中有很多标准属性 , 当然也可以自定义属性 , 适用于大多数HTML元素的属性如下 : class , 为html元素定义一个或多个类名(类名从样式文件引入) id , 定义元素的id style , 规定元素的行内样式 title , 描述了元素的额外信息 HTML文档 file.html ├── └── ├── │ ├── │ ├── │ ├── │ ├── │ ├── │ └── └── 🍀 DOCTYPE告诉浏览器使用什么样的html或xhtml规范来解析html文档 如果html文档没有DOCTYPE声明 , 那么compatMode 默认为BackCompat(标准兼容模式未开启,称为怪异模式或混杂模式) , 使用该模式时 , 浏览器会按照自己的方式解析渲染页面 , 并且在不同的浏览器就会显示不同的样式 如果html文档添加了声明 , 那么compatMode就是CSS1Compat(标准兼容模式已开启,称为严格模式) , 即按照W3C的标准解析渲染页面 , 这样所有的浏览器显示的就是一个样子了 🍀 元素是HTML页面的根元素 , HTML文档由嵌套的HTML元素构成 一般包括与 , 如下 🍀 元素包含了所有的头部标签元素 , 在元素中可以插入脚本(Script) , 样式(CSS) , 及各种meta信息 🍀 meta标签描述了一些基本的元数据 页面编码 刷新和跳转 关键词 描述 X-UA-Compatible 🍀 定义网页头部信息 , 在HTML/XHTML文档中是必须的 title元素 : 定义了浏览器工具栏的标题 当网页添加收藏夹时 , 显示在收藏夹中的标题 显示在搜索引擎结果页面的标题 Lyon 🍀 标签描述了基本的链接地址/链接目标 , 该标签作为HTML文档中所有的链接默认链接 🍀 标签定义了文档与外部资源之间的关系 , 通常用于链接到样式表 : 🍀 标签定义HTML文档的样式文件引用地址 , 在 元素中也可以直接添加样式来渲染HTML文档 Lyon body { background-color: yellowgreen; font-size: inherit; } I am Lyon!! 🍀 标签用于加载脚本文件 , 也可直接写脚本代码 🍀 body元素是html文档中的主体 , 表示网页的主题部分 , 也就是用户可以看到的内容 , 可以包含文本 , 图片 , 音频 , 视频等各种内容 为避免篇幅过长 , body部分请看下一篇 "},"04-前端/03-Web开发 - HTML-body.html":{"url":"04-前端/03-Web开发 - HTML-body.html","title":"Web开发 - HTML-body","keywords":"","body":"Web开发之路 - HTML-body 前言 🍀 为避免上一篇篇幅过长 , body部分在这一篇进行整理 , 主要介绍常用标签 🍀 定义标题 , ~ , 标题从大到小 标题一 标题二 标题三 标题四 标题五 标题六 and 🍀 标签用于定义段落 , 默认段落之间是有间隔的 , 并且浏览器会自动地在段落前后添加空行(块级标签) 标签用于换行 , 即不产生一个新段落的情况下进行换行 这是第一个段落 这是第二个段落 这是第三个段落 and 🍀 定义文本粗体和斜体 我是粗体 我是斜体 更多 我是下划线 我是删除线 🍀 定义列表 , 区别如下 : ul , 无序列表 ol , 有序列表 li , 定义列表项 dl , 自定义列表 dt , 自定义列表项 dd , 自定义列表项的描述 Coffee Milk Coffee Milk Coffee - black hot drink Milk - white cold drink 🍀 定义下拉列表 , 元素中的 标签定义了列表中的可用选项 上海 北京 广州 上海 北京 广州 武汉 上海 北京 广州 武汉 武汉 湖里 石家庄 河里 🍀 插入图像 是空标签 , 只包含属性 , 没有闭合标签 , 属性如下 : src , 源属性(source) , 值为图像的url地址 alt , 定义图像的预备可替换文本 , 即无法载入图像时显示 🍀 定义表格 , 每个表格均有若干行( 标签定义) , 每行分为若干单元格( 标签定义) , 以及表格的标头(由 标签定义) 标签也可以用于页面的布局 , 用法与 一样 row 1, cell 1 row 1, cell 2 row 2, cell 1 row 2, cell 2 and 🍀 HTML可以通过 和 将元素组合起来 为块级标签 ; 为内联标签 , 可以作文本的容器 块级标签与内联标签的区别 : 块级标签是另起一行开始渲染 , 而行内联标签则不需要另起一行 单独在页面中插入这两个标签, 不会对页面产生任何影响 , 这两个标签是专门为定义CSS样式而生的 关于标签嵌套 : 通常块级标签可以包含内联标签或某些块级标签 ; 但是内联标签不能包含块级标签 , 它只能包含其他内联标签 Welcome To Lyon's Blog 菜单 HTML CSS JavaScript Welcom to lyon's blog! 版权 © Lyon.com 🍀 为表单标签 , 表单是一个包含表单元素的区域 表单元素允许用户在表单中输入内容 , 比如 : 文本域(textarea) , 下拉列表 , 单选框(radio-buttons) , 复选框(checkboxes)等 , 格式如下 : . input 元素 . 实例 username: password: 🍀 标签规定了用户可以在其中输入数据的输入字段 , 输入字段可以通过多种方式改变 , 取决于type属性 湖北 湖南 北京 男 女 男 女 password: 以上简单的介绍了几个属性 , 更多input元素属性可以通过访问W3school进行学习 🍀 标签为input元素定义标注(标记) lable元素不会向用户呈现任何特殊效果 , 不过当鼠标点击时 , 浏览器会自动将焦点转到和标签相关的表单控件上 标签的for属性应当与相关元素的id属性相同 姓名： 婚否： 姓名： 婚否： 🍀 用于定义多行文本 可以通过cols和rows属性来规定textarea的尺寸 , 不过更好的办法是使用CSS的 height和width属性 如果需要启动自动换行功能 , 可以通过设置wrap属性为virtual或physical 🍀 标签用于将表单内容的一部分打包 , 生成一组相关表单的字段 , 浏览器会以特殊方式来显示 , 它们可能有特殊的边界 , 3D效果 , 或者甚至可创建一个子表单来处理这些元素 标签为fieldset元素定义标题 登录 用户名： 密码： 更多:dash: "},"04-前端/05-Web开发 - CSS.html":{"url":"04-前端/05-Web开发 - CSS.html","title":"Web开发 - CSS","keywords":"","body":"Web开发之路 - CSS 介绍 🍀 CSS指的是层叠样式表(Cascading Style Sheets) , 用于定义如何显示HTML元素 CSS是在HTML 4 开始使用的 , 是为了更好的渲染HTML元素而引入的 , CSS可以通过以下方式加到HTML中 : 内联样式 : 在HTML元素中使用 \"style\" 属性 内部样式表 : 在HTML文档头部区域使用 元素来包含CSS 外部引用 : 是用外部CSS文件 最好的方式就是通过外部引用CSS文件 , 三种方式如下 : 内联样式 标题 段落 内部样式表 body {background-color:yellow;} p {color:blue;} 外部引用 选择器 🍀 CSS规则由两个主要的部分构成 : 选择器 , 以及一条或多条声明 , 如下 : selector {declaration1;declaration2;... declarationN} 选择器的种类有很多 , 下面就开始介绍各种选择器 元素选择器 🍀 元素选择器又称标签选择器 文档的元素就是最基本的选择器 div {background-color:red;} Class选择器 🍀 class选择器用于描述一组元素的样式 , class可以在多个元素中使用 class选择器在HTML中以class属性表示 , 在CSS中 , 类选择器以一个点 \".\" 号显示 .center {text-align:center;} p.center {text-align:center;} 类名的第一个字符不能使用数字 , 它无法在Mozilla或Firefox中起作用/ ID选择器 🍀 ID选择器可以为标有特定id的HTML元素指定特定的样式 CSS中ID选择器以\"#\"来定义 #para1 { color:red; } ID属性不要以数字开头 , 数字开头的ID在Mozilla/Firefox浏览器中不起作用 属性选择器 🍀 选择拥有某些属性的元素 , 也可设置特定属性 *[title] {color:red;} a[href][title] {color:red;} p[class=\"important warning\"] {color: red;} p[class~=\"important\"] {color: red;} 后代选择器 🍀 后代选择器又称包含选择器 , 后代选择器可以选择作为某元素后代的元素 h1 em {color:red;} 子元素选择器 🍀 与后代选择器相比 , 子元素选择器只能选择作为某元素子元素中的元素 h1 > strong {color:red;} 相邻兄弟选择器 🍀 相邻兄弟选择器可以选择紧接在另一元素后的元素 , 且二者有相同父元素 h1 + p {margin-top:50px;} 伪类 🍀 伪类用于向某些选择器添加特殊的效果 伪类的语法 : selector : pseudo-class {property:value} selector.class : pseduo-class {property:value} 实例 a.red : visited {color: #FF0000} CSS Syntax 伪元素 🍀 伪元素用于向某些选择器设置特殊效果 伪元素的语法 : selector:pseudo-element {property:value;} selector.class:pseudo-element {property:value;} p:first-line { color:#ff0000; font-variant:small-caps; } 组合选择器 : input,div,p { background-color:red; } 关联选择器 : idselect p { background-color:red; } 常用属性 🍀 background 🍀 背景色 background-color属性可以为元素设置背景色 /* 把元素背景设置为灰色 */ p {background-color: gray;} background-color属性默认值为transparent , 即\"透明\" 背景图像 background-image属性可以把图像作为背景 /* 设置图像时,必须为该属性设置一个url值 */ body {background-image: url(/i/eg_bg_04.gif);} background-image属性默认值为none , 表示背景上没有放置任何图像 背景重复 background-repeat属性可以将背景图像在页面上进行平铺 属性repeat导致图像在水平垂直方向都平铺 , repeat-x和repeat-y分别导致图像只在水平或垂直方向上重复 , no-repeat则不允许图像在任何方向上平铺 /* 默认从左上角开始,垂直方向上平铺 */ body { background-image: url(/i/eg_bg_03.gif); background-repeat: repeat-y; } 背景定位 background-position属性可以改变图像在背景中的位置 body { background-image:url('/i/eg_bg_03.gif'); background-repeat:no-repeat; background-position:center; } background-position有以下关键字 : top , bottom , left , right 和center , 这些关键字通常成对出现 , 也可以使用长度值 , 如 : 100px或5cm(长度值是元素边距区左上角的便宜偏移) , 以及使用百分数 body { background-image:url('/i/eg_bg_03.gif'); background-repeat:no-repeat; background-position:50% 50%; } 背景关联 background-attachment属性可以使图像相对于可视区固定 , 即不会受到滚动的影响 body { background-image:url(/i/eg_bg_02.gif); background-repeat:no-repeat; background-attachment:fixed } border 🍀 border属性允许规定元素边框的样式 , 宽度和颜色 元素的边框是围绕元素内容和内边距的一条或多条线 /* 一个边框定义多个样式 */ p.aside {border-style: solid dotted dashed double;} 看看我的边框 更多边框样式及边框相关 , 在我这里 margin 🍀 margin属性可以用来设置外边距 , 接受任何长度单位 , 百分数甚至负值 围绕在元素边框的空白区域就是外边距 , 设置外边距会在元素外创建额外的\"空白\" /* h1元素的各个边上设置了1/4英寸的空白 */ h1 {margin : 0.25in;} h1 {margin : 10px 0px 15px 5px;} /* margin: top right bottom left */ 值复制 如果缺少左外边距的值 , 则使用右外边距的值 如果缺少下外边距的值 , 则使用上外边距的值 如果缺少右外边距的值 , 则使用上外边距的值 h1 {margin: 0.25em 1em 0.5em;} /* 等价于 0.25em 1em 0.5em 1em */ h2 {margin: 0.5em 1em;} /* 等价于 0.5em 1em 0.5em 1em */ p {margin: 1px;} /* 等价于 1px 1px 1px 1px */ 单边外边距 margin-top margin-right margin-bottom margin-left padding 🍀 padding属性可以设置内边距 , 接受长度值或百分比值 , 但不允许使用负值 元素的内边距在边框和内容区之间 /* 同样具有值复制规则,与margin一样 */ h1 {padding: 10px;} h1 {padding: 10px 0.25em 2ex 20%;} 单边内边距 padding-top padding-right padding-bottom padding-left display 🍀 display属性规定元素应该生成的框的类型 /* 使段落生出行内框 */ p.inline { display:inline; } display属性常用的值 : none , 此元素不会被显示 block , 此元素将显示为块级元素 , 此元素前后会带有换行符 inline , 默认 , 此元素会被显示为内联元素 , 元素前后没有换行符 inline-block , 行内块元素 更多display属性 cursor 🍀 cursor属性规定要显示的光标的类型 该属性定义了鼠标指针放在一个元素边界范围内时锁用的光标形状 值 描述 url 需使用的自定义光标的 URL , 末端始终定义一种普通的光标 , 以防没有由 URL 定义的可用光标 default 默认光标(通常是一个箭头) auto 默认 , 浏览器设置的光标 crosshair 光标呈现为十字线 pointer 光标呈现为指示链接的指针(一只手) move 此光标指示某对象可被移动 e-resize 此光标指示矩形框的边缘可被向右(东)移动 ne-resize 此光标指示矩形框的边缘可被向上及向右移动(北/东) nw-resize 此光标指示矩形框的边缘可被向上及向左移动北(西) n-resize 此光标指示矩形框的边缘可被向上(北)移动。 se-resize 此光标指示矩形框的边缘可被向下及向右移动(南/东) sw-resize 此光标指示矩形框的边缘可被向下及向左移动(南/西) s-resize 此光标指示矩形框的边缘可被向下移动(南) w-resize 此光标指示矩形框的边缘可被向左移动(西) text 此光标指示文本 wait 此光标指示程序正忙(通常是一只表或沙漏) help 此光标指示可用的帮助(通常是一个问号或一个气球) 请把鼠标移动到单词上，可以看到鼠标指针发生变化： Auto Crosshair Default Pointer Move e-resize ne-resize nw-resize n-resize se-resize sw-resize s-resize w-resize text wait help position 🍀 CSS有三种基本的定位机制 : 普通流 , 浮动和绝对定位 ; 除非专门指定 , 否则所有框都在普通流中定位 position属性有以下属性值 : static , 默认值 , 元素没有被定位 , 而且在文档中出现在它应该在的位置 , 一般不用指定 , 除非需要覆盖之前设置的定位 relative , 元素框偏移某个距离 , 元素实际上依然占据文档中的原有位置 , 只是视觉上相对于它在文档中的原有位置移动了 , 相对定位 absolute , 元素在文档中不占据位置 , 定位后生成一个块级框 , 不论原来它在正常流中生成何种类型的框 , 绝对定位 fixed , 是特殊的absolute , 即fixed总是以body为定位对象的 , 按照浏览器的窗口进行定位 相对定位 h2.pos_left { position:relative; left:-20px } h2.pos_right { position:relative; left:20px } 这是位于正常位置的标题 这个标题相对于其正常位置向左移动 这个标题相对于其正常位置向右移动 相对定位会按照元素的原始位置对该元素进行移动。 样式 \"left:-20px\" 从元素的原始左侧位置减去 20 像素。 样式 \"left:20px\" 向元素的原始左侧位置增加 20 像素。 绝对定位 h2.pos_abs { position:absolute; left:100px; top:150px } 这是带有绝对定位的标题 通过绝对定位，元素可以放置到页面上的任何位置。下面的标题距离页面左侧 100px，距离页面顶部 150px。 固定定位 p.one { position:fixed; left:5px; top:5px; } p.two { position:fixed; top:30px; right:5px; } 一些文本。 更多的文本。 float 🍀 float属性可以实现浮动的框 /* 图像向右浮动 */ img { float:right; } float属性值 : left , 元素向左浮动 right , 元素向右浮动 none , 默认值 , 元素不浮动 inherit , 规定应该从父元素继承float属性的值 注意 : 假如在一行之上只有极少的空间可供浮动元素，那么这个元素会跳至下一行，这个过程会持续到某一行拥有足够的空间为止。 clear属性可以阻止框围绕浮动框 , clear属性值 : left , 在左侧不允许浮动元素 right , 在右侧不允许浮动元素 both , 在左右两侧均不允许浮动元素 none , 默认值 , 允许浮动元素出现在两侧 inherit , 规定应该从父元素继承 clear 属性的值 /* 图像左侧和右侧均不允许出现浮动元素 */ img { float:left; clear:both; } opacity 🍀 opacity属性用于定义透明效果 , opacity属性能设置的值从0.0到1.0 , 值越小则越透明 img { opacity:0.4; filter:alpha(opacity=40); /* 针对 IE8 以及更早的版本 */ } 更过CSS内容 , CSS教程 "},"04-前端/06-Web开发 - JavaScript.html":{"url":"04-前端/06-Web开发 - JavaScript.html","title":"Web开发 - JavaScript","keywords":"","body":"Web开发之路 - JavaScript 介绍 🍀 JavaScript是属于网络的脚本语言 , 是因特网上最流行的脚本语言 JavaScript被数百万计的网页用来改进设计 , 验证表单 , 检测浏览器 , 创建cookies , 以及更多的应用 浏览器内置了JavaScript语言的解释器 , 所以浏览器上按照JavaScript的规则编写相应代码 , 浏览器可以解释并作出相应的处理 完整的JavaScript实现是由一下三个不同部分组成的 : 核心 , ECMAScript 文档对象模型 (DOM) , Document Object Model (整合JS , CSS , HTML) 浏览器对象模型 (BOM) , Broswer Object Model (整合JS和浏览器) 简单的说 , ECMAScript描述了JavsScript语言本身的相关内容 存在形式 js代码内容 存放位置 HTML的head中 HTML的body代码块底部 由于HTML代码是从上到下执行的 , 如果Head中的JS代码耗时严重 , 会导致用户长时间无法看到页面 , 所以将JS代码防止HTML的body代码块底部是最好的 , 因为不会影响用户看到页面效果 , 只是JS实现特效慢而已 JavaScript注释 单行注释 : // 多行注释 : /* ... */ , (CSS注释也是如此) 变量 🍀 在JavaScript中 , 变量的声明默认表示声明的全局变量 , 局部变量必须以var开头 生命周期 : JavaScript变量的声明周期从它们被声明的时间开始 局部变量会在函数运行以后被删除 全局变量会在页面关闭后被删除 // 全局变量 name = 'Lyon'; function func(){ // 局部变量 var age = 18; // 全局变量 gender = \"男\" } 注意 : JavaScript中严格区分大小写 , 并且以 \";\" 号结束 数据类型 🍀 JavaScript中的数据类型有字符串 , 数字 , 布尔 , 数组 , 对象 , Null , Undefined 其中Null是JavaScript语言的关键字 , 它表示一个特殊的值 , 常用来描述\"空值\" , Undefined是一个特殊值 , 表示变量未定义 , 即声明后若不定义则变量的值为Undefined 数字(Number) JavaScript中不区分整数值和浮点数值 , 所有数字均用浮点数值表示 , 还有两个特殊值NaN和Infinity , 如下 123; // 整数 0.456; //浮点数 1.2345e3; // 科学计数法表示1.2345x1000，等同于1234.5 NaN; // NaN表示Not a Number，当无法计算结果时用NaN表示 Infinity; // Infinity表示无限大，当数值超过了JavaScript的Number所能表示的最大值时，就表示为Infinity Number可以直接做四则运算 , 规则和数学一致 : 1 + 2; // 3 (1 + 2) * 5 / 2; // 7.5 2 / 0; // Infinity 0 / 0; // NaN 10 % 3; // 取余,1 10.5 % 3; // 1.5 如果要执行常见的算数任务 , 可以使用Math对象进行计算 , Math对象 字符串(String) 字符串是由字符组成的数组 , 在JavaScript中字符串不可变的 常见功能 string.length // 长度 string.trim() //移除空白 string.trimLeft() string.trimRight) string.charAt(n) //返回字符串中的第n个字符 string.concat(value, ...) //拼接 string.indexOf(substring,start) //子序列位置 string.lastIndexOf(substring,start) //子序列位置 string.substring(from, to) //根据索引获取子序列 string.slice(start, end) //切片 string.toLowerCase() //大写 string.toUpperCase() //小写 string.split(delimiter, limit) //分割 string.search(regexp) //从头开始匹配,返回匹配成功的第一个位置(g无效) string.match(regexp) //全局搜索,如果正则中有g表示找到全部，否则只找到第一个。 string.replace(regexp, replacement) //替换,正则中有g则替换所有,否则只替换第一个匹配项 布尔 布尔类型即true和false 比较运算符 == //比较值相等 != //不等于 === //比较值和类型相等 !=== //不等于 || //或 && //且 数组 JavaScript中的数组与Python中的列表类似 , 是一组按顺序排列的集合 , 集合的每个值称为元素 [1, 2, 3.14, 'Hello', null, true]; // 通过Array()函数创建 new Array(1, 2, 3); 常用功能 array.length //数组的大小 array.push(ele) //尾部追加元素 array.pop() //尾部获取一个元素 array.unshift(ele) //头部插入元素 array.shift() //头部移除元素 array.splice(start, deleteCount, value, ...) //插入,删除或替换数组的元素 array.splice(n,0,val) //指定位置插入元素 array.splice(n,1,val) //指定位置替换元素 array.splice(n,1) //指定位置删除元素 array.slice( ) //切片 array.reverse( ) //反转 array.join(sep) //将数组元素连接起来以构建一个字符串 array.concat(val,..) //连接数组 array.sort( ) //对数组元素进行排序 对象 对象由花括号分隔 , 在括号内部 , 对象的属性以名称和值对的形式定义 , 属性由逗号分隔 var person={ name:\"Lyon\", age:20 } 要获取对象的属性 , 只需用对象变量.属性名即可 , 也可对象变量[属性名] 语句与异常 🍀 条件语句 JavaScript中支持两个条件语句 , 分别是if和switch // if语句 if(条件){ } else if(条件){ } else{ } // switch语句,选择要执行的多个代码块之一 switch(n){ case 1: 执行代码块 1 break; case 2: 执行代码块 2 break; default: n 与 case 1 和 case 2 不同时执行的代码 } 注意 : 使用switch语句时 , 如果不使用break , 那么程序将继续往下执行 循环语句 与Python一样 , for循环和while循环 // for循环 var names = [\"Lyon\", \"Kenneth\", \"Eva\"]; for(var i=0;i 异常处理 try { // 捕获异常 } catch (e) { // 如果try代码块中捕获到了异常，catch代码块中的代码就会被执行。 //e是一个局部变量，用来指向Error对象或者其他抛出的对象 } finally { //无论发生啥,最后都要执行,即使遇到return } // throw Error(e) 主动抛出异常,如Python中的raise 函数 🍀 基本函数 JavaScript中函数基本上可以分为以下三类 // 普通函数 function func(arg){ return true; } // 匿名函数 var func = function(arg){ return \"Lyon\"; } // 自执行函数 (function(arg){ console.log(arg); })('123') 上例中函数的参数都属于显示参数(Parameters) , 显示参数在函数定义时列出 ; 还有隐式参数(Arguments) , 其在函数调用时传递给函数真正的值 , 如果函数在调用时未提供隐式参数 , 参数会默认设置为undefined JavaScript函数有个内置的对象arguments对象 , 包含了函数调用的参数数组 , 通过这种方式可以方便的找到最大的参数的值 , 或者创建一个函数用来统计所有数值的和 x = findMax(1, 123, 500, 115, 44, 88); function findMax() { var i, max = arguments[0]; if(arguments.length max) { max = arguments[i]; } } return max; } 对于Python来讲 , 显示与隐式不过就是实参与形参而已 ; 在JavaScript中都是按照位置参数进行传递的 , 特殊对象arguments的存在 , 使得JavaScript中实际参数可能小于形式参数的个数 作用域 JavaScript中每个函数都有自己的作用域 , 当出现函数嵌套时 , 就出现了作用域链 , 即函数使用变量时 , 会随着作用域链从内而外的一层层寻找 , 找不到就异常 function f2(){ var arg= 111; function f3(){ console.log(arg); } return f3; } ret = f2(); ret(); PS1 : 所有的作用域在创建函数且未执行时就已经存在 PS2 : JavaScript函数在被执行之前 , 所有的变量都已经声明 , 但是却不会赋值 , 所以即使你在使用参数的后面再定义变量也不会报错 , 因为它是存在的并且值为undefined function Mytest(){ console.log(name); var name = \"Lyon\"; } Mytest(); // 输出结果:undefined 闭包 闭包在很多语言中都可以看到 , 就像Python中 , 闭包必须是内部定义的函数(嵌套函数) , 该函数包含对外部作用域而不是全局作用域名字的引用 , JavaScript中也一样 闭包是一个函数 , 它记住了周围发生了什么 由于作用域链只能从内而外的找 , 默认外部无法获取函数内部变量 , 闭包则实现了在外部获取函数内部的变量 function f2(){ var arg= [11,22]; function f3(){ return arg; } return f3; } ret = f2(); ret(); 面向对象 function Foo (name,age) { this.Name = name; this.Age = age; this.Func = function(arg){ return this.Name + arg; } } var obj = new Foo('Lyon', 18); var ret = obj.Func(\"Kenneth\"); console.log(ret); 上述代码中 : Foo充当构造函数 this代指对象 创建对象时需要使用new 但是在上述代码中每个对象中均保存了一个相同的Func函数 , 可以使用原型优化处理 function Foo (name,age) { this.Name = name; this.Age = age; } Foo.prototype = { GetInfo: function(){ return this.Name + this.Age }, Func : function(arg){ return this.Name + arg; } } 其他 🍀 序列化 - JSON.stringify(obj) 序列化 - JSON.parse(str) 反序列化 转义 - decodeURI( ) URl中未转义的字符 - decodeURIComponent( ) URI组件中的未转义字符 - encodeURI( ) URI中的转义字符 - encodeURIComponent( ) 转义URI组件中的字符 - escape( ) 对字符串转义 - unescape( ) 给转义字符串解码 - URIError 由URl的编码和解码方法抛出 eval // JavaScript中的eval是Python中eval和exec的合集,既可以编译代码也可以获取返回值 -eval() -EvalError // 执行字符串中的JavaScript代码 正则表达式 定义正则表达式 /.../ 用于定义正则表达式 /.../g 表示全局匹配 /.../i 表示不区分大小写 /.../m 表示多行匹配 // JS正则匹配时本身就是支持多行,此处多行匹配只是影响正则表达式^和$,m模式也会使用^$来匹配换行的内容 实例 var pattern = /^Java\\w*/gm; var text = \"JavaScript is more fun than \\nJavaEE or JavaBeans!\"; result = pattern.exec(text) result = pattern.exec(text) result = pattern.exec(text) // 定义正则表达式也可以使用RegExp对象 匹配 JavaScript中主要提供了以下两个功能 : test(string) 检查字符串中是否和正则匹配 n = 'uui99sdf' reg = /\\d+/ reg.test(n) ---> true // 只要正则在字符串中存在就匹配,如果想要开头和结尾匹配的话,就需要在正则前后加^和$ exec(string) 获取正则表达式匹配的内容 , 如果未匹配 , 值为null , 否则 , 获取匹配成功的数组 非全局模式 // 获取匹配结果数组，注意：第一个元素是第一个匹配的结果，后面元素是正则子匹配（正则内容分组匹配） var pattern = /\\bJava\\w*\\b/; var text = \"JavaScript is more fun than Java or JavaBeans!\"; result = pattern.exec(text) var pattern = /\\b(Java)\\w*\\b/; var text = \"JavaScript is more fun than Java or JavaBeans!\"; result = pattern.exec(text) 全局模式 // 需要反复调用exec方法，来一个一个获取结果,直到匹配获取结果为null表示获取完毕 var pattern = /\\bJava\\w*\\b/g; var text = \"JavaScript is more fun than Java or JavaBeans!\"; result = pattern.exec(text) var pattern = /\\b(Java)\\w*\\b/g; var text = \"JavaScript is more fun than Java or JavaBeans!\"; result = pattern.exec(text) 字符串中相关方法 obj.search(regexp) // 获取索引位置,搜索整个字符串,返回匹配成功的第一个位置(g模式无效) obj.match(regexp) // 获取匹配内容,搜索整个字符串,获取找到第一个匹配内容,如果正则是g模式找到全部 obj.replace(regexp, replacement) //替换匹配替换,正则中有g则替换所有,否则只替换第一个匹配项 // $数字：匹配的第n个组内容； // $&：当前匹配的内容； // $`：位于匹配子串左侧的文本； // $'：位于匹配子串右侧的文本 // $$：直接量$符号 时间处理 Date对象用于处理日期和时间 获取系统当前时间 var now = new Date(); now; // Wed Jun 24 2015 19:49:22 GMT+0800 (CST) now.getFullYear(); // 2015, 年份 now.getMonth(); // 5, 月份，注意月份范围是0~11，5表示六月 now.getDate(); // 24, 表示24号 now.getDay(); // 3, 表示星期三 now.getHours(); // 19, 24小时制 now.getMinutes(); // 49, 分钟 now.getSeconds(); // 22, 秒 now.getMilliseconds(); // 875, 毫秒数 now.getTime(); // 1435146562875, 以number形式表示的时间戳 // 注意当前时间是浏览器从本机操作系统获取的时间,所以不一定准确 创建一个指定日期和时间的Date对象 var d = new Date(2015, 5, 19, 20, 15, 30, 123); d; // Fri Jun 19 2015 20:15:30 GMT+0800 (CST) 第二中创建方式 var d = Date.parse('2015-06-24T19:49:22.875+08:00'); d; // 1435146562875 PS : Date对象表示的时间总是按浏览器所在的时区显示的 , 我们可以进行调整 var d = new Date(1435146562875); d.toLocaleString(); // '2015/6/24 下午7:49:22'，本地时间（北京时区+8:00），显示的字符串与操作系统设定的格式有关 d.toUTCString(); // 'Wed, 24 Jun 2015 11:49:22 GMT'，UTC时间，与本地时间相差8小时 更多JavaScript内容可以通过 , 以下链接学习 , 菜鸟教程 , 廖雪峰官网教程 , w3school "},"04-前端/07-Web开发 - BOM.html":{"url":"04-前端/07-Web开发 - BOM.html","title":"Web开发 - BOM","keywords":"","body":"Web开发之路 - BOM 介绍 🍀 由于JavaScript的出现就是为了能在浏览器中运行 , BOM , 即浏览器对象模型(Browser Object Model) , BOM使JavaScript有能力与浏览器进行\"对话\" 由于现代浏览器已经(几乎) 实现了JavaScript交互性方面的相同方法和属性 , 因此常被认为是BOM的方法和属性 BOM是为了控制浏览器的行为而出现的接口 , 不同浏览器之间定义与实现存在差异 下面就开始介绍浏览器对象啦 Window 🍀 所有的浏览器都支持window对象 , 它表示浏览器窗口 , 所有JavaScript全局对象 , 函数以及变量均自动成为window对象的成员 , 也就是说Window对象是客户端JavaScript最高层对象之一 由于window对象是全局对象 , 所有的表达式都在当前的环境中计算 , 所以要引用当前窗口不需要特殊的语法 , 可以直接把窗口的属性作为全局变量来使用 , 如 : window.document可以直接写document Window对象属性 属性 描述 closed 返回窗口是否已被关闭 defaultStatus 设置或返回窗口状态栏中的默认文本 document 文档对象 history 包含窗口的浏览历史 innerheight 返回窗口的文档显示区的高度 innerwidth 返回窗口的文档显示区的宽度 length 设置或返回窗口中的框架数量 location 包含有关当前URL的信息 name 设置或返回窗口的名称 navigator 包含有关浏览器的信息 opener 返回对创建此窗口的窗口的引用 outerheight 返回窗口的外部高度 outerwidth 返回窗口的外部宽度 pageXOffset 设置或返回当前页面相对于窗口显示区左上角的 X 位置 pageYOffset 设置或返回当前页面相对于窗口显示区左上角的 Y 位置 parent 返回父窗口。 screen 包含有关显示浏览器屏幕的信息 self 返回对当前窗口的引用 , 等价于 Window 属性 status 设置窗口状态栏的文本 top 返回最顶层的先辈窗口 window window 属性等价于 self 属性 , 它包含了对窗口自身的引用 screenLeftscreenTopscreenXscreenY 只读整数 , 声明了窗口的左上角在屏幕上的的 x 坐标和 y 坐标 , IE、Safari 和 Opera 支持 screenLeft 和 screenTop , 而 Firefox 和 Safari 支持 screenX 和 screenY Window对象方法 方法 描述 alert() 显示带有一段消息和一个确认按钮的警告框 blur() 把键盘焦点从顶层窗口移开 clearInterval() 取消由 setInterval() 设置的 timeout clearTimeout() 取消由 setTimeout() 方法设置的 timeout close() 关闭浏览器窗口 confirm() 显示带有一段消息以及确认按钮和取消按钮的对话框 createPopup() 创建一个 pop-up 窗口 focus() 把键盘焦点给予一个窗口 moveBy() 可相对窗口的当前坐标把它移动指定的像素 moveTo() 把窗口的左上角移动到一个指定的坐标 open() 打开一个新的浏览器窗口或查找一个已命名的窗口 print() 打印当前窗口的内容 prompt() 显示可提示用户输入的对话框 resizeBy() 按照指定的像素调整窗口的大小 resizeTo() 把窗口的大小调整到指定的宽度和高度 scrollBy() 按照指定的像素值来滚动内容 scrollTo() 把内容滚动到指定的坐标 setInterval() 按照指定的周期（以毫秒计）来调用函数或计算表达式 setTimeout() 在指定的毫秒数后调用函数或计算表达式 实例 // 返回窗口尺寸 alert('window inner size:' + window.innerWidth + 'x' + window.innerHeight); // 直接在浏览器中consle下执行 document 🍀 每个载入浏览器的HTML文档都会成为document对象 , document对象使我们可以从脚本中对HTML页面中的所有元素进行访问 document对象是Window对象的一部分 , 可通过window.document属性对其进行访问 , 或直接使用document document对象属性 属性 描述 body 提供对 元素的直接访问 , 对于定义了框架集的文档 , 该属性引用最外层的 cookie 设置或返回与当前文档有关的所有 cookie domain 返回当前文档的域名 lastModified 返回文档被最后修改的日期和时间 referrer 返回载入当前文档的文档的 URL title 返回当前文档的标题 URL 返回当前文档的 URL document对象方法 方法 描述 close() 关闭用 document.open() 方法打开的输出流 , 并显示选定的数据 getElementById() 返回对拥有指定 id 的第一个对象的引用 getElementsByName() 返回带有指定名称的对象集合 getElementsByTagName() 返回带有指定标签名的对象集合 open() 打开一个流 , 以收集来自任何 document.write() 或 document.writeln() 方法的输出 write() 向文档写 HTML 表达式 或 JavaScript 代码 writeln() 等同于 write() 方法 , 不同的是在每个表达式之后写一个换行符 实例 // 改变title document.title = '努力学习JavaScript!'; navigator 🍀 navigator对象包含有关浏览器的信息 , 所有浏览器中都支持 , navigator对象的实例是唯一的 , 它是Window对象的子对象 , 所以可以用Window对象的navigator属性来引用它 , 即window.navigator , 当然也可以直接navigator navigator对象属性 属性 描述 appCodeName 返回浏览器的代码名 appMinorVersion 返回浏览器的次级版本 appName 返回浏览器的名称 appVersion 返回浏览器的平台和版本信息 browserLanguage 返回当前浏览器的语言 cookieEnabled 返回指明浏览器中是否启用 cookie 的布尔值 cpuClass 返回浏览器系统的 CPU 等级 onLine 返回指明系统是否处于脱机模式的布尔值 platform 返回运行浏览器的操作系统平台 systemLanguage 返回 OS 使用的默认语言 userAgent 返回由客户机发送服务器的 user-agent 头部的值 userLanguage 返回 OS 的自然语言设置 navigator对象方法 方法 描述 javaEnabled() 规定浏览器是否启用 Java taintEnabled() 规定浏览器是否启用数据污点 (data tainting) 实例 alert('appName = ' + navigator.appName + '\\n' + 'appVersion = ' + navigator.appVersion + '\\n' + 'language = ' + navigator.language + '\\n' + 'platform = ' + navigator.platform + '\\n' + 'userAgent = ' + navigator.userAgent); screen 🍀 screen对象中存放着有关显示浏览器屏幕的信息 , 可用Window对象中的screen属性直接引用 , 即window.screen , 或者screen , 所有浏览器都支持 screen对象属性 属性 描述 availHeight 返回显示屏幕的高度 (除 Windows 任务栏之外) availWidth 返回显示屏幕的宽度 (除 Windows 任务栏之外) bufferDepth 设置或返回调色板的比特深度 colorDepth 返回目标设备或缓冲器上的调色板的比特深度 deviceXDPI 返回显示屏幕的每英寸水平点数 deviceYDPI 返回显示屏幕的每英寸垂直点数 fontSmoothingEnabled 返回用户是否在显示控制面板中启用了字体平滑 height 返回显示屏幕的高度 logicalXDPI 返回显示屏幕每英寸的水平方向的常规点数 logicalYDPI 返回显示屏幕每英寸的垂直方向的常规点数 pixelDepth 返回显示屏幕的颜色分辨率(比特每像素) updateInterval 设置或返回屏幕的刷新率 width 返回显示器屏幕的宽度 实例 alert('screen size = ' + screen.width + ' x ' + screen.height); history 🍀 history对象最初设计来表示窗口的浏览历史 , 但出于隐私方面的原因 , history对象不在允许脚本访问已经访问过的实际URL , 唯一保持使用的功能只有back()、forward() 和 go() 方法 可通过window.history或者history进行访问 history对象属性 属性 描述 length 返回浏览器历史列表中的 URL 数量 history对象方法 方法 描述 back() 加载 history 列表中的前一个 URL forward() 加载 history 列表中的下一个 URL go() 加载 history 列表中的某个具体页面 实例 // 该操作与单击后退按钮执行的操作一样 history.back() // 返回结果:undefined location 🍀 location对象包含有关当前URL的信息 , location对象是Window对象的一部分 , 可通过window.location属性来访问 , 或者location location对象属性 属性 描述 hash 设置或返回从井号 (#) 开始的 URL（锚） host 设置或返回主机名和当前 URL 的端口号 hostname 设置或返回当前 URL 的主机名 href 设置或返回完整的 URL pathname 设置或返回当前 URL 的路径部分 port 设置或返回当前 URL 的端口号 protocol 设置或返回当前 URL 的协议 search 设置或返回从问号 (?) 开始的 URL（查询部分） location 对象方法 属性 描述 assign() 加载新的文档 reload() 重新加载当前文档 replace() 用新的文档替换当前文档 实例 function currLocation() { alert(window.location) } function newLocation() { window.location=\"/index.html\" } "},"04-前端/08-Web开发 - DOM.html":{"url":"04-前端/08-Web开发 - DOM.html","title":"Web开发 - DOM","keywords":"","body":"Web开发之路 - DOM 介绍 🍀 上一篇中了解了BOM , 其存在是为了控制浏览器的行为 , 而这一篇所说的DOM则是为了操作HTML和XML文档出现的接口 DOM全称为Document Object Model , 也就是文档对象模型 , DOM是W3C(万维网联盟)的标准 , 所有浏览器公共遵守的标准 当网页被加载时 , 浏览器会创建页面的DOM ; DOM是一个树形结构 , 在HTML DOM中 , 每一个元素都是节点 同样的 , 通过JavaScript可以来操作DOM DOM查找 🍀 直接查找 document.getElementById() // 获取指定ID节点 document.getElementsByName() // 获取指定name属性节点 document.getElementsByClassName() // 获取指定class属性节点 document.getElementsByTagName() // 获取指定标签节点 间接查找 parentNode // 父节点 childNodes // 所有子节点 firstChild // 第一个子节点 lastChild // 最后一个子节点 nextSibling // 下一个兄弟节点 previousSibling // 上一个兄弟节点 parentElement // 父节点标签元素 children // 所有子标签 firstElementChild // 第一个子标签元素 lastElementChild // 最后一个子标签元素 nextElementtSibling // 下一个兄弟标签元素 previousElementSibling // 上一个兄弟标签元素 实例 // 返回ID为'test'的节点： var test = document.getElementById('test'); // 先定位ID为'test-table'的节点，再返回其内部所有tr节点： var trs = document.getElementById('test-table').getElementsByTagName('tr'); // 先定位ID为'test-div'的节点，再返回其内部所有class包含red的节点： var reds = document.getElementById('test-div').getElementsByClassName('red'); // 获取节点test下的所有直属子节点: var cs = test.children; // 获取节点test下第一个、最后一个子节点： var first = test.firstElementChild; var last = test.lastElementChild; DOM修改 🍀 对于DOM的修改操作有很多, 比如内容 , 样式 , 属性等等 , 都是可以用DOM进行修改的 内容 🍀 innerHTML // 设置或获取位于对象起始和结束标签内的HTML,符合W3C标准 innerText // 设置或获取位于对象起始和结束标签内的文本 outerHTML // 设置或获取对象及其内容的HTML形式 outerText // 设置(包括标签)或获取(不包括标签)对象的文本 value // 设置或返回隐藏输入域的value属性的值 实例 // 获取... var p = document.getElementById('p-id'); // 设置文本为abc: p.innerHTML = 'ABC'; // ABC // 设置HTML: p.innerHTML = 'ABC RED XYZ'; // ...的内部结构已修改 属性 🍀 attribute // 获取所有标签属性 setAttribute(key,value) // 设置标签属性 getAttribute(key) // 获取指定标签属性 实例 // 创建class属性 var atr = document.createAttribute(\"class\"); // 设置属性值 atr.nodeValue=\"democlass\"; // 设置属性节点 document.getElementById('n1').setAttributeNode(atr); Class 🍀 className // 获取所有类名 classList.remove(cls) // 删除指定类 classList.add(cls) // 添加类 标签 🍀 创建标签 // 方式一 var tag = document.createElement('a') tag.innerText = \"baidu\" tag.className = \"c1\" tag.href = \"http://www.baidu.com/\" // 方式二 var tag = \"baidu\" 插入标签 // 方式一 var obj = \"\"; xxx.insertAdjacentHTML(\"beforeEnd\",obj); xxx.insertAdjacentElement('afterBegin',document.createElement('p')) //注意：第一个参数只能是'beforeBegin'、 'afterBegin'、 'beforeEnd'、 'afterEnd' // 方式二 var tag = document.createElement('a') xxx.appendChild(tag) xxx.insertBefore(tag,xxx[1]) 样式 🍀 var obj = document.getElementById('i1') obj.style.fontSize = \"32px\"; obj.style.backgroundColor = \"red\"; 实例 function Focus(ths){ ths.style.color = \"black\"; if(ths.value == '请输入关键字' || ths.value.trim() == \"\"){ ths.value = \"\"; } } function Blur(ths){ if(ths.value.trim() == \"\"){ ths.value = '请输入关键字'; ths.style.color = 'gray'; }else{ ths.style.color = \"black\"; } } 位置 🍀 document.documentElement.offsetHeight // 总文档高度 document.documentElement.clientHeight // 当前文档占屏幕高度 tag.offsetHeight // 自身高度 tag.offsetTop // 距离上级定位高度 tag.offsetParent // 父定位标签 tag.scrollTop // 滚动高度 /* clientHeight -> 可见区域：height + padding clientTop -> border高度 offsetHeight -> 可见区域：height + padding + border scrollHeight -> 全文高：height + padding 特别的： document.documentElement代指文档根节点 */ 实例 var i1 = document.getElementById('i1'); console.log(i1.clientHeight); // 可见区域：height + padding console.log(i1.clientTop); // border高度 console.log('====='); console.log(i1.offsetHeight); // 可见区域：height + padding + border console.log(i1.offsetTop); // 上级定位标签的高度 console.log('====='); console.log(i1.scrollHeight); //全文高：height + padding console.log(i1.scrollTop); // 滚动高度 console.log('====='); 表单 🍀 document.geElementById('form').submit() 其他 🍀 console.log // 输出框 alert // 弹出框 confirm // 确认框 // URL和刷新 location.href // 获取URL location.href = \"url\" // 重定向 location.reload() // 重新加载 // 定时器 setInterval // 多次定时器 clearInterval // 清除多次定时器 setTimeout // 单次定时器 clearTimeout // 清除单次定时器 DOM事件 🍀 鼠标事件 属性 描述 DOM onclick 当用户点击某个对象时调用的事件句柄 2 oncontextmenu 在用户点击鼠标右键打开上下文菜单时触发 ondblclick 当用户双击某个对象时调用的事件句柄 2 onmousedown 鼠标按钮被按下 2 onmouseenter 当鼠标指针移动到元素上时触发 2 onmouseleave 当鼠标指针移出元素时触发 2 onmousemove 鼠标被移动 2 onmouseover 鼠标移到某元素之上 2 onmouseout 鼠标从某元素移开 2 onmouseup 鼠标按键被松开 2 键盘事件 属性 描述 DOM onkeydown 某个键盘按键被按下 2 onkeypress 某个键盘按键被按下并松开 2 onkeyup 某个键盘按键被松开 2 更多DOM事件 , HTML DOM事件对象 搜索框实例 Title .gray{ color:gray; } .black{ color:black; } function Enter(){ var id= document.getElementById(\"tip\") id.className = 'black'; if(id.value=='请输入关键字'||id.value.trim()==''){ id.value = '' } } function Leave(){ var id= document.getElementById(\"tip\") var val = id.value; if(val.length==0||id.value.trim()==''){ id.value = '请输入关键字' id.className = 'gray'; }else{ id.className = 'black'; } } 跑马灯实例 欢迎blue shit莅临指导&nbsp;&nbsp; function Go(){ var content = document.title; var firstChar = content.charAt(0) var sub = content.substring(1,content.length) document.title = sub + firstChar; } setInterval('Go()',1000); "},"04-前端/09-Web开发 - jQuery.html":{"url":"04-前端/09-Web开发 - jQuery.html","title":"Web开发 - jQuery","keywords":"","body":"Web开发之路 - jQuery 介绍 🍀 为了使写更少的代码完成更多的功能 , JavaScript (helper) 库应运而生 , 这些JavaScript库常被成为JavaScript框架 广受欢迎的JavaScript框架如下 : jQuery Prototype MooTools jQuery是目前最受欢迎的JavaScript框架 , jQuery库包含以下功能 : HTML元素选取 HTML元素操作 CSS操作 HTML事件函数 JavaScript特效和动画 HTML DOM 遍历和修改 AJAX Utilities 除此之外 , jQuery还提供了大量的插件 , jQuery受欢迎与其兼容性是密不可分的 下载jQuery http://jquery.com/download/ jQuery库是一个JavaScript文件 , 所以可以直接使用 标签引用 也可通过CDN (内容分发网络) 进行引用 $符号 🍀 $是jQuery符号 , jQuery把所有功能全部封装在一个全局变量jQuery中 , 而$也是一个合法的变量名 , 它是变量jQuery的别名 window.jQuery; // jQuery(selector, context) window.$; // jQuery(selector, context) $ === jQuery; // true typeof($); // 'function' $本质上就是一个函数 , 但是函数也是对象 , 于是$除了可以直接调用外 , 也可以有很多其他属性 PS : 如果$变量被占用了 , 那么我们就只能使用jQuery这个变量了 jQuery对象 jQuery对象就是通过jQuery包装DOM对象后产生的对象 , jQuery对象是jQuery独有的 , 如果一个对象是jQuery对象 , 那么它就可以使用jQuery里面的方法 , 如 : $(\"test\").html(); 约定 : 如果获取的是jQuery对象 , 那么要在变量前面加上$ var $variable = jQuery对象 var variable = DOM对象 PS : 虽然jQuery对象是包含DOM对象后产生的 , 但是jQuery无法使用DOM对象的任何方法 , 同理DOM对象也不能使用jQuery里的方法 jQuery语法 语法 : $(selector).action() 美元符号定义 jQuery 选择符(selector)\"查询\"和\"查找\" HTML 元素 jQuery 的 action() 执行对元素的操作 jQuery查找 🍀 选择器 🍀 ID $('#test') // id=\"test\" Class $(\".c1\") // class=\"c1\" 标签 $('p') // 所有p标签 组合 $('a') $('.c2') $('a,.c2,#i10') 层级 $(\".outer div\") //后代,子子孙孙 $(\".outer>div\") //子元素 $(\".outer+div\") //相邻,同一父元素 $(\".outer~div\") //包含 基本 :first //第一行 :last //最后一行 :eq() //匹配一个给定索引值的元素 属性 $('[Lyon]') //具有Lyon属性的所有标签 $('[Lyon=\"123\"]') //Lyon属性等于123的标签 左侧菜单实例 left_menu function show(self){ //console.log($(self).text()) $(self).next().removeClass(\"hide\") $(self).parent().siblings().children(\".con\").addClass(\"hide\") } .menu{ height: 500px; width: 30%; background-color: gainsboro; float: left; } .content{ height: 500px; width: 70%; background-color: rebeccapurple; float: left; } .title{ line-height: 50px; background-color: #425a66; color: forestgreen;} .hide{ display: none; } 菜单一 111 111 111 菜单二 111 111 111 菜单三 111 111 111 筛选器 🍀 $('#i1').next() // 下一个同级标签 $('#i1').nextAll() // 下面的所有同级标签 $('#i1').nextUntil('#ii1') // 往下找,直到找到为止 $('#i1').prev() // 上一个同级标签 $('#i1').prevAll() // 上面所有同级标签 $('#i1').prevUntil('#ii1') // 往上找,直到找到为止 $('#i1').parent() // 父级标签 $('#i1').parents() // 所有父级标签 $('#i1').parentsUntil() // 找所有父级标签,直到找到为止 $('#i1').children() // 找子标签 $('#i1').siblings() // 找兄弟标签 $('#i1').find() // 搜索指定的元素 $('li:eq(1)') // li标签中索引为1的元素 $('li').eq(1) // 索引为1的li标签 first() // 匹配找到的第一个元素 last() // 匹配找到的最后一个元素 hasClass(class) // 是否含有指定的类 jQuery操作 🍀 属性 🍀 // 专门用于做自定义属性 $(..).attr('n') // 查找属性 $(..).attr('n','v') // 设置属性 $(..).removeAttr('n') // 删除属性 // 专门用于chekbox,radio $(..).prop('checked') $(..).prop('checked', true) CSS 🍀 $('t1').css('样式名称', '样式值') //位置 $(window).scrollTop() // 获取 $(window).scrollTop(0) // 设置 scrollLeft([val]) offset().left // 指定标签在html中的坐标 offset().top // 指定标签在html中的坐标 position() // 指定标签相对父标签(relative)标签的坐标 $('i1').height() // 获取标签的高度 纯高度 $('i1').innerHeight() // 获取边框 + 纯高度 + ？ $('i1').outerHeight() // 获取边框 + 纯高度 + ？ $('i1').outerHeight(true) // 获取边框 + 纯高度 + ？ 文本操作 🍀 $(..).text() // 获取文本内容 $(..).text(\"1\") // 设置文本内容 $(..).html() // 获取html内容 $(..).html(\"1\") // 设置html内容 $(..).val() // 获取值 $(..).val(..) // 设置值 文档处理 🍀 // 内部插入 $(\"#c1\").append(\"hello\") // 追加到内容后面 $(\"p\").appendTo(\"div\") // 追加到指定位置后面 prepend() // 追加到内容前面 prependTo() // 追加到指定位置前面 // 外部插入 before() // 插入到元素之前 insertBefore() // 插入到指定元素之前 after // 插入到元素之后 insertAfter() // 插入到指定元素之后 replaceWith() // 替换 remove() // 删除 empty() // 匹配空元素 clone() // 克隆 事件 🍀 jQuery： $('.c1').click() $('.c1').bind('click',function(){}) $('.c1').unbind('click',function(){}) $('.c').delegate('a', 'click', function(){}) $('.c').undelegate('a', 'click', function(){}) $('.c1').on('click', function(){}) $('.c1').off('click', function(){}) // 阻止事件发生 return false // 当页面框架加载完成之后，自动执行 $(function(){ $(...) }) 拖动面板实例 标题 内容 $(function(){ // 页面加载完成之后自动执行 $('#title').mouseover(function(){ $(this).css('cursor','move'); }).mousedown(function(e){ //console.log($(this).offset()); var _event = e || window.event; // 原始鼠标横纵坐标位置 var ord_x = _event.clientX; var ord_y = _event.clientY; var parent_left = $(this).parent().offset().left; var parent_top = $(this).parent().offset().top; $(this).bind('mousemove', function(e){ var _new_event = e || window.event; var new_x = _new_event.clientX; var new_y = _new_event.clientY; var x = parent_left + (new_x - ord_x); var y = parent_top + (new_y - ord_y); $(this).parent().css('left',x+'px'); $(this).parent().css('top',y+'px'); }) }).mouseup(function(){ $(this).unbind('mousemove'); }); }) 效果 🍀 // 基本 show([s,[e],[fn]]) hide([s,[e],[fn]]) toggle([s],[e],[fn]) // 滑动 slideDown([s],[e],[fn]) slideUp([s,[e],[fn]]) slideToggle([s],[e],[fn]) // 淡入淡出 fadeIn([s],[e],[fn]) fadeOut([s],[e],[fn]) fadeTo([[s],o,[e],[fn]]) fadeToggle([s,[e],[fn]]) // 自定义 animate(p,[s],[e],[fn])1.8* stop([c],[j])1.7* delay(d,[q]) finish([queue])1.9+ // 设置 jQuery.fx.off jQuery.fx.interval 回调函数实例 Title $(document).ready(function(){ $(\"button\").click(function(){ $(\"p\").hide(1000,function(){ alert('动画结束') }) //$(\"p\").css('color','red').slideUp(1000).slideDown(2000) }) }); 隐藏 helloworld helloworld helloworld 扩展 🍀 jQuery.fn.extend(object) jQuery.extend(object) 更多详细内容 jQuery API中文文档 "},"04-前端/11-Web开发 - Ajax.html":{"url":"04-前端/11-Web开发 - Ajax.html","title":"Web开发 - Ajax","keywords":"","body":"Web开发之路 - Ajax 介绍 🍀 Ajax : Asynchronous JavaScript and XML , 意思就是用JavaScript执行异步网络请求 Ajax是一种用于创建快速动态网页的技术 , 通过在后台与服务器进行少量数据交换 , Ajax可以使网页实现异步更新 , 这意味着可以在不重新加载整个网页的情况下 , 对网页的某部分进行更新 2005年 , Google通过其Google Suggest使用Ajax创造出动态性极强的Web界面 , 于是Ajax开始流行起来 Ajax是基于现有的Internet标准 , 并且联合使用它们 : XMLHttpRequest对象 (异步的与服务器交换数据) JavaScript/DOM (信息显示/交互) CSS (给数据定义样式) XML (作为转换数据的格式) AJAX应用程序与浏览器和平台无关的 XHR创建对象 🍀 XMLHttpRequest是Ajax的基础 , 所有现代浏览器均支持XMLHttpRequest对象 (IE5 和 IE6使用ActiveXObject) XMLHttpRequest用于在后台与服务器交换数据 , 也就是完成不重新加载整个页面实现某部分进行更新 创建XMLHttpRequest对象 variable=new XMLHttpRequest(); variable=new ActiveXObject(\"Microsoft.XMLHTTP\"); // IE5和IE6使用ActiveX对象 应对所有浏览器 var xmlhttp; if (window.XMLHttpRequest) { // IE7+, Firefox, Chrome, Opera, Safari 浏览器执行代码 xmlhttp=new XMLHttpRequest(); } else { // IE6, IE5 浏览器执行代码 xmlhttp=new ActiveXObject(\"Microsoft.XMLHTTP\"); } XHR请求 🍀 将请求发送到服务器 , 使用XMLHttpRequest对象的open() 和 send() 方法 描述 open(method,url,async) 规定请求的类型 , URL 以及是否异步处理请求 method : 请求的类型 , GET 或 POSTurl : 文件在服务器上的位置async : true(异步)或 false(同步) send(string) 将请求发送到服务器 , string : 仅用于 POST 请求 GET 与 POST 与 POST 相比 , GET 更简单也更快 , 并且在大部分情况下都能用 然而 , 在以下情况中 , 请使用 POST 请求 : 无法使用缓存文件 (更新服务器上的文件或数据库) 向服务器发送大量数据 (POST 没有数据量限制) 发送包含未知字符的用户输入时 , POST 比 GET 更稳定也更可靠 GET请求 xmlhttp.open(\"GET\",\"/try/ajax/demo_get.php\",true); // url-服务器上的文件 xmlhttp.send(); POST请求 xmlhttp.open(\"POST\",\"/try/ajax/demo_post.php\",true); xmlhttp.send(); HTML表单POST数据使用setRequestHeader(header,value) 来添加HTTP头 xmlhttp.open(\"POST\",\"/try/ajax/demo_post2.php\",true); xmlhttp.setRequestHeader(\"Content-type\",\"application/x-www-form-urlencoded\"); xmlhttp.send(\"fname=Henry&lname=Ford\"); XHR响应 🍀 获取服务器的响应 , 可以使用XMLHttpRequest对象的responseText或responseXML属性 属性 描述 responseText 获得字符串形式的响应数据 responseXML 获得 XML 形式的响应数据 responseText document.getElementById(\"myDiv\").innerHTML=xmlhttp.responseText; responseXML xmlDoc=xmlhttp.responseXML; txt=\"\"; x=xmlDoc.getElementsByTagName(\"ARTIST\"); for (i=0;i\"; } document.getElementById(\"myDiv\").innerHTML=txt; XHR readyState 🍀 onreadystatechange 事件 当请求被发送到服务器时 , 我们需要执行一些基于响应的任务 ; 每当readyState改变时 , 就会触发onreadystatechange事件 XMLHttpRequest对象的三个重要属性 : 属性 描述 onreadystatechange 存储函数(或函数名) , 每当 readyState 属性改变时 , 就会调用该函数 readyState 存有 XMLHttpRequest 的状态 , 从 0 到 4 发生变化0: 请求未初始化1: 服务器连接已建立2: 请求已接收3: 请求处理中4: 请求已完成 , 且响应已就绪 status 200 : \"OK\"404 : 未找到页面 在onreadystatechange事件中 , 我们规定当服务器响应已做好被处理的准备时所执行的任务 xmlhttp.onreadystatechange=function() { if (xmlhttp.readyState==4 && xmlhttp.status==200) { document.getElementById(\"myDiv\").innerHTML=xmlhttp.responseText; } } // onreadystatechange 事件被触发 5 次(0-4),对应着 readyState 的每个变化 回调函数 function myFunction() { loadXMLDoc(\"/try/ajax/ajax_info.txt\",function() { if (xmlhttp.readyState==4 && xmlhttp.status==200) { document.getElementById(\"myDiv\").innerHTML=xmlhttp.responseText; } }); } Ajax数据库 🍀 Ajax可用来与数据库进行动态通信 , 使用showCustomer()函数 showCustomer() 函数执行以下任务 : 检查是否已选择某个客户 创建 XMLHttpRequest 对象 当服务器响应就绪时执行所创建的函数 把请求发送到服务器上的文件 请注意我们向 URL 添加了一个参数 q (带有输入域中的内容) 实例 function showCustomer(str) { var xmlhttp; if (str==\"\") { document.getElementById(\"txtHint\").innerHTML=\"\"; return; } if (window.XMLHttpRequest) { // IE7+, Firefox, Chrome, Opera, Safari 浏览器执行代码 xmlhttp=new XMLHttpRequest(); } else { // IE6, IE5 浏览器执行代码 xmlhttp=new ActiveXObject(\"Microsoft.XMLHTTP\"); } xmlhttp.onreadystatechange=function() { if (xmlhttp.readyState==4 && xmlhttp.status==200) { document.getElementById(\"txtHint\").innerHTML=xmlhttp.responseText; } } xmlhttp.open(\"GET\",\"/try/ajax/getcustomer.php?q=\"+str,true); xmlhttp.send(); } jQuery Ajax方法 🍀 在jQuery中我们为我们封装了有关Ajax的操作 , 方法如下 : 方法 描述 $.ajax() 执行异步 AJAX 请求 $.ajaxPrefilter() 在每个请求发送之前且被 $.ajax() 处理之前 , 处理自定义 Ajax 选项或修改已存在选项 $.ajaxSetup() 为将来的 AJAX 请求设置默认值 $.ajaxTransport() 创建处理 Ajax 数据实际传送的对象 $.get() 使用 AJAX 的 HTTP GET 请求从服务器加载数据 $.getJSON() 使用 HTTP GET 请求从服务器加载 JSON 编码的数据 $.getScript() 使用 AJAX 的 HTTP GET 请求从服务器加载并执行 JavaScript $.param() 创建数组或对象的序列化表示形式（可用于 AJAX 请求的 URL 查询字符串） $.post() 使用 AJAX 的 HTTP POST 请求从服务器加载数据 ajaxComplete() 规定 AJAX 请求完成时运行的函数 ajaxError() 规定 AJAX 请求失败时运行的函数 ajaxSend() 规定 AJAX 请求发送之前运行的函数 ajaxStart() 规定第一个 AJAX 请求开始时运行的函数 ajaxStop() 规定所有的 AJAX 请求完成时运行的函数 ajaxSuccess() 规定 AJAX 请求成功完成时运行的函数 load() 从服务器加载数据，并把返回的数据放置到指定的元素中 serialize() 编码表单元素集为字符串以便提交 serializeArray() 编码表单元素集为 names 和 values 的数组 GET var jqxhr = $.get('/path/to/resource', { name: 'Bob Lee', check: 1 }); POST var jqxhr = $.post('/path/to/resource', { name: 'Bob Lee', check: 1 }); JSON var jqxhr = $.getJSON('/path/to/resource', { name: 'Bob Lee', check: 1 }).done(function (data) { // data已经被解析为JSON对象了 }); "},"04-前端/Vue/":{"url":"04-前端/Vue/","title":"Vue","keywords":"","body":"Vue "},"04-前端/Vue/01-Vue - 介绍.html":{"url":"04-前端/Vue/01-Vue - 介绍.html","title":"Vue - 介绍","keywords":"","body":" Vue - 介绍 Vue.js是什么 🍀 Vue 是一套用于构建用户界面的渐进式框架 , 与其它大型框架不同的是 , Vue 被设计为可以自底向上逐层应用 , Vue 的和核心库只关注视图层 , 不仅易于上手 , 还便于与第三方库或已有项目整合 , 另一方面 , 当与现代化的工具链以及各种支持类库结合使用时 , Vue 也完全能够为复杂的单页应用提供驱动 起步 🍀 尝试 Vue.js 最简单的方法是使用 Jsfiddle 的 Vue 工具 , 可以直接从官网提供的 Hello World 例子开始 我们也可以自己创建一个 .html 文件 , 然后在里面引入 Vue : 或者 : 这里我们就自己创建一个 index.html 来完成教程 , 为了将 Javascript 与 HTML 分离 , 我们再创建一个 index.js 存放 Javascript 代码 , 以下不再说明 声明式渲染 🍀 Vue.js 的核心是一个允许采用简介的模板语法来声明式地将数据渲染进 DOM 的系统 : 我们只截取重要代码 , index.html 如下 : {{ message }} 在 index.js 中 var app = new Vue({ el: '#app', data: { message: 'Hello Vue!' } }); 浏览器页面效果如下 : {{ message }} 我们已经成功创建了第一个 Vue 应用 , 看起来这跟渲染一个字符串模板非常类似 , 但是 Vue 在背后做了大量工作 , 现在数据和 DOM 已经被建立了关联 , 所有东西都是响应式的 , 我们可以就在当前页面打开浏览器的 Javascript控制台 , 并修改 app.message 的值 , 你将看到上面的例子会相应地更新 除了文本插值 , 我们还可以像这样来绑定元素特性 : 鼠标悬停几秒钟查看此处动态绑定的提示信息！ var app2 = new Vue({ el: '#app-2', data: { message: '页面加载于 ' + new Date().toLocaleString() } }) 鼠标悬停几秒钟查看此处动态绑定的提示信息 ! 这里我们遇到了一点新东西 , 你看到的 v-bind 特性被成为指令 , 指令带有前缀 v- , 以表示它们是 Vue 提供的特殊特性 , 这与 AngularJS 的 ng- 很相似 . 它们会在渲染的 DOM 上应用特殊的响应式行为 , 在这里 , 该指令的意思是 : \"将这个元素节点的 title 特性和 Vue 实例的 message 属性保持一致\" 如果你再次打开浏览器的 JavaScript 控制台 , 输入 app2.message = '新消息' , 就会再一次看到这个绑定了 title 特性的 HTML 已经进行了更新 条件与循环 🍀 像其他模板语言语法一样 , Vue 当然有条件与循环 现在你看到我了 var app3 = new Vue({ el: '#app-3', data: { seen: true } }) 现在你看到我了 继续在控制台输入 app3.seen = false , 你会发现之前显示的消息消失了 这个例子演示了我们不仅可以把数据绑定到 DOM 文本或特性 , 还可以绑定到 DOM 结构 此外 , Vue 也提供了一个强大的过渡效果系统 , 可以在 Vue 插入/更新/移除元素时自动应用过渡效果 还有其它很多指令 , 每个都有特殊的功能 , 例如 , v-for 指令可以绑定数组的数据来渲染一个项目列表 : {{ todo.text }} var app4 = new Vue({ el: '#app-4', data: { todos: [ { text: '学习 JavaScript' }, { text: '学习 Vue' }, { text: '整个牛项目' } ] } }) {{ todo.text }} 在控制台里 , 输入 app4.todos.push({text:'新项目'}) , 你会发现列表最后添加了一个新项目 处理用户输入 🍀 为了让用户和你的应用进行交互 , 我们可以用 v-on 指令添加一个事件监听器 , 通过它调用在 Vue 实例中定义的方法 : {{ message }} 逆转消息 var app5 = new Vue({ el: '#app-5', data: { message: 'Hello Vue.js!' }, methods: { reverseMessage: function () { this.message = this.message.split('').reverse().join('') } } }) {{ message }} 逆转消息 注意在 reverseMessage 方法中 , 我们更新了应用的状态 , 但没有触碰 DOM ——所有的 DOM 操作都有 Vue 来处理 , 你编写的代码只需要关注逻辑层面即可 Vue 还提供了 v-model 指令 , 它能轻松实现表单输入和应用状态之间的双向绑定 {{ message }} var app6 = new Vue({ el: '#app-6', data: { message: 'Hello Vue!' } }) {{ message }} 组件化应用构建 🍀 组件系统是 Vue 的另一个重要概念 , 因为它是一种抽象 , 允许我们是使用小型 , 独立和通常可复用的组件构建大型应用 , 仔细想想 , 几乎任意类型的应用界面都可以抽象为一个组件树 : 在 Vue 里 , 一个组件本质上是一个拥有预定义选项的一个 Vue 实例 , 在 Vue 中注册组件很简单 : // 定义名为 todo-item 的新组件 Vue.component('todo-item', { template: '这是个待办项' }) 现在你可以用它构建另一个组件模板 : 但是这样会为每个代办项渲染同样的文本 , 为了使其更加酷炫 , 我们应用从父作用域将数据传到子组件才对 , 我们修改一下组件定义 , 使之能够接受一个 prop : Vue.component('todo-item', { // todo-item 组件现在接受一个 // \"prop\"，类似于一个自定义特性。 // 这个 prop 名为 todo。 props: ['todo'], template: '{{ todo.text }}' }) 现在 , 我们可以使用 v-bind 指令将代办项传到循环输出的每个组件中 : Vue.component('todo-item', { props: ['todo'], template: '{{ todo.text }}' }) var app7 = new Vue({ el: '#app-7', data: { groceryList: [ { id: 0, text: '蔬菜' }, { id: 1, text: '奶酪' }, { id: 2, text: '随便其它什么人吃的东西' } ] } }) 尽管这只是一个刻意设计的例子 , 但是我们已经设法将应用分割成两个更小的单元 , 子单元通过 prop 接口与父单元进行了良好的解藕 , 我们现在可以进一步改进 组件 , 提供更为复杂的模板和逻辑 , 而不会影响到父单元 在一个大型应用中 , 有必要将整个应用程序划分为组件 , 以使开发更易管理 , 在后续教程中我们将详述组件 , 不过这里有一个假想的例子 , 以展示使用了组件的应用模板是什么样的 : 与自定义元素的关系 🍀 你可能已经注意到 Vue 组件非常类似于自定义元素——它是 Web 组件规范的一部分 , 这是因为 Vue 的组件语法部分参考了该规范 , 例如 Vue 组件实现了 Slot API 与 is 特性 , 但是 , 还是有几个关键差别 : Web 组件规范仍然处于草案阶段 , 并且未被所有浏览器原生实现 , 相比之下 , Vue 组件不需要任何 polyfill , 并且在所有支持的浏览器 (IE9 及更高版本) 之下表现一致 , 必要时 , Vue 组件也可以包装于原生自定义元素之内 Vue 组件提供了纯自定义元素所不具备的一些重要功能 , 最突出的是跨组件数据流 , 自定义事件通信以及构建工具集成 下一步 🍀 我们刚才简单介绍了 Vue 核心最基本的功能——本教程的其余部分将涵盖这些功能以及其它高级功能更详细的细节 , 所以请务必读完整个教程 ! var app = new Vue({ el: '#app', data: { message: 'Hello Vue!' } }); var app2 = new Vue({ el: '#app-2', data: { message: '页面加载于 ' + new Date().toLocaleString() } }); var app3 = new Vue({ el: '#app-3', data: { seen: true } }); var app4 = new Vue({ el: '#app-4', data: { todos: [ {text: '学习 JavaScript'}, {text: '学习 Vue'}, {text: '整个牛项目'} ] } }); var app5 = new Vue({ el: '#app-5', data: { message: 'Hello Vue.js!' }, methods: { reverseMessage: function () { this.message = this.message.split('').reverse().join('') } } }); var app6 = new Vue({ el: '#app-6', data: { message: 'Hello Vue!' } }); Vue.component('todo-item', { props: ['todo'], template: '{{ todo.text }}' }); var app7 = new Vue({ el: '#app-7', data: { groceryList: [ {id: 0, text: '蔬菜'}, {id: 1, text: '奶酪'}, {id: 2, text: '随便其它什么人吃的东西'} ] } }); "},"04-前端/Vue/02-Vue - 实例.html":{"url":"04-前端/Vue/02-Vue - 实例.html","title":"Vue - 实例","keywords":"","body":"Vue - 实例 创建一个Vue实例 🍀 每个 Vue 应用都是通过用 Vue 函数创建一个新的 Vue 实例开始的 : var vm = new Vue({ // 选项 }) 虽然没有完全遵循 MVVM 模型 , 但是 Vue 的设计也受到了它的启发 , 因此在文档中经常会使用 vm (ViewModel 的缩写) 这个变量名表示 Vue 实例 当创建一个 Vue 实例时 , 你可以传入一个选项对象 , 这篇教程主要描述的就是如何使用这些选项来创建你想要的行为 , 作为参考 , 你也可以在 API 文档中浏览完整的选项列表 一个 Vue 应用由一个通过 new Vue 创建的根 Vue 实例 , 以及可选的嵌套的 , 可复用的组件树组成 , 举个例子 , 一个 todo 应用的组件树可以是这样的 : 根实例 └─ TodoList ├─ TodoItem │ ├─ DeleteTodoButton │ └─ EditTodoButton └─ TodoListFooter ├─ ClearTodosButton └─ TodoListStatistics 我们会在稍后的组件系统章节具体展开 , 不过现在 , 你只需要明白所有的 Vue 组件都是 Vue 实例 , 并且接受相同的选项对象 (一些根实例特有的选项除外) 数据与方法 🍀 当一个 Vue 实例被创建时 , 它向 Vue 的响应式系统中加入了其 data 对象中能找到的所有的属性 , 当这些属性的值发生改变时 , 视图将会产生 \"响应\" , 即匹配更新为新的值 // 我们的数据对象 var data = { a: 1 } // 该对象被加入到一个 Vue 实例中 var vm = new Vue({ data: data }) // 获得这个实例上的属性 // 返回源数据中对应的字段 vm.a == data.a // => true // 设置属性也会影响到原始数据 vm.a = 2 data.a // => 2 // 反之亦然 data.a = 3 vm.a // => 3 当这些数据改变时 , 视图会进行重新渲染 , 值得注意的是只有当实例被创建时 data 中存在的属性才是响应式的 , 也就是说如果你添加一个新的属性 , 比如 : vm.b = 'hi' 那么对 b 的改动将不会触发任何视图的更新 , 如果你知道你会在晚些时候需要一个属性 , 但是一开始它为空或者不存在 , 那么你仅需要设置一些初始值 , 比如 : data: { newTodoText: '', visitCount: 0, hideCompletedTodos: false, todos: [], error: null } 这里唯一的例外是使用 Object.freeze() , 这会组织修改现有的属性 , 也意味着响应系统无法再追踪变化 var obj = { foo: 'bar' } Object.freeze(obj) new Vue({ el: '#app', data: obj }) {{ foo }} Change it 除了数据属性 , Vue 实例还暴露了一些有用的实例属性与方法 , 它们都有前缀 $ , 以便与用户定义的属性区分开来 , 例如 : var data = { a: 1 } var vm = new Vue({ el: '#example', data: data }) vm.$data === data // => true vm.$el === document.getElementById('example') // => true // $watch 是一个实例方法 vm.$watch('a', function (newValue, oldValue) { // 这个回调将在 `vm.a` 改变后调用 }) 以后你可以在 API 参考中查阅到完整的实例属性和方法的列表 实例生命周期钩子 🍀 每个 Vue 实例在被创建时都要经过一系列的初始化过程——例如 , 需要设置数据监听 , 编译模板 , 将实例挂载到 DOM 并在数据变化时更新 DOM 等 , 同时在这个过程中也会运行一些叫做生命周期钩子的函数 , 这给了用户在不同阶段添加自己的代码的机会 比如 created 钩子可以用来在一个实例被创建之后执行代码 : new Vue({ data: { a: 1 }, created: function () { // `this` 指向 vm 实例 console.log('a is: ' + this.a) } }) // => \"a is: 1\" 也有一些其它的钩子 , 在实例生命周期的不同阶段被调用 , 如 mounted , updated 和destroyed , 生命周期钩子的 this 上下文指向调用它的 Vue 实例 不要在选项属性或回调上使用箭头函数 , 比如created: () => console.log(this.a) 或vm.$watch('a', newValue => this.myMethod()) , 因为箭头函数是和父级上下文绑定在一起的 , this 不会是如你所预期的 Vue 实例 , 经常导致Uncaught TypeError: Cannot read property of undefined 或Uncaught TypeError: this.myMethod is not a function 之类的错误 生命周期图示 🍀 下图展示了实例的生命周期 , 你不需要立马弄明白所有的东西 , 不过随着你的不断学习和使用，它的参考价值会越来越高 "},"04-前端/Vue/03-Vue - 模板语法.html":{"url":"04-前端/Vue/03-Vue - 模板语法.html","title":"Vue - 模板语法","keywords":"","body":"Vue - 模板语法 介绍 🍀 Vue.js 使用了基于 HTML 的模板语法 , 允许开发者声明式地将 DOM 绑定至底层 Vue 实例的数据 , 所有 Vue.js 的模板都是合法的 HTML , 所以能被遵循规范的浏览器和 HTML 解析器解析 在底层的实现上 , Vue 将模板编译成虚拟 DOM 渲染函数 , 结合响应系统 , Vue 能够智能地计算出最少需要重新渲染多少组件 , 并把 DOM 操作次数减到最少 如果你熟悉虚拟 DOM 并且偏爱 JavaScript 的原始力量 , 你也可以不用模板 , 直接写渲染 (render) 函数 , 使用可选的 JSX 语法。 插值 🍀 文本 🍀 数据绑定最常见的形式就是使用 Mustache 语法 (双大括号) 的文本插值 : Message: {{ msg }} Mustache 标签将会被替代为对应数据对象上 msg 属性的值 , 无论何时 , 绑定的数据对象上 msg 属性发生了改变 , 插值处的内容都会更新 通过使用 v-once 指令 , 你也能执行一次性地插值 , 当数据改变时 , 插值处的内容不会更新 , 但请留心这会影响到该节点上的其它数据绑定 : 这个将不会改变: {{ msg }} 原始HTML 🍀 双大括号会将数据解释为普通文本 , 而非 HTML 代码 , 为了输出真正的 HTML , 你需要使用 v-html 指令 : Using mustaches: {{ rawHtml }} Using v-html directive: Using mustaches: Using v-html directive: 这个 span 的内容将会被替换成为属性值 rawHtml , 直接作为 HTML——会忽略解析属性值中的数据绑定 , 注意 , 你不能使用 v-html 来复合局部模板 , 因为 Vue 不是基于字符串的模板引擎 ; 反之 , 对于用户界面 (UI) , 组件更适合作为可重用和可组合的基本单位 你的站点上动态渲染的任意 HTML 可能会非常危险 , 因为它很容易导致 XSS 攻击。请只对可信内容使用 HTML 插值 , 绝不要对用户提供的内容使用插值 特性 🍀 Mustache 语法不能作用在 HTML 特性上 , 遇到这种情况应该使用 v-bind 指令 : 在布尔特性的情况下 , 它们的存在即暗示为 true , v-bind 工作起来略有不同 , 在这个例子中 : Button 如果 isButtonDisabled 的值是 null、undefined 或 false , 则 disabled 特性甚至不会被包含在渲染出来的 元素中 使用JavaScript表达式 🍀 迄今为止 , 在我们的模板中 , 我们一直都只绑定简单的属性键值 ; 但实际上 , 对于所有的数据绑定 , Vue.js 都提供了完全的 JavaScript 表达式支持 {{ number + 1 }} {{ ok ? 'YES' : 'NO' }} {{ message.split('').reverse().join('') }} 这些表达式会在所属 Vue 实例的数据作用域下作为 JavaScript 被解析 , 有个限制就是 , 每个绑定都只能包含单个表达式 , 所以下面的例子都不会生效 {{ var a = 1 }} {{ if (ok) { return message } }} 模板表达式都被放在沙盒中 , 只能访问全局变量的一个白名单 , 如 Math 和 Date , 你不应该在模板表达式中试图访问用户定义的全局变量 指令 🍀 指令 (Directives) 是带有 v- 前缀的特殊特性 , 指令特性的值预期是单个 JavaScript 表达式(v-for 是例外情况)。指令的职责是 , 当表达式的值改变时 , 将其产生的连带影响 , 响应式地作用于 DOM , 如 : 现在你看到我了 这里 , v-if 指令将根据表达式 seen 的值的真假来插入/移除 元素 参数 🍀 一些指令能够接收一个“参数” , 在指令名称之后以冒号表示 , 例如 , v-bind 指令可以用于响应式地更新 HTML 特性 : ... 在这里 href 是参数 , 告知 v-bind 指令将该元素的 href 特性与表达式 url 的值绑定 另一个例子是 v-on 指令 , 它用于监听 DOM 事件 : ... 在这里参数是监听的事件名。我们也会更详细地讨论事件处理。 修饰符 🍀 修饰符 (Modifiers) 是以半角句号 . 指明的特殊后缀 , 用于指出一个指令应该以特殊方式绑定 , 例如 , .prevent 修饰符告诉 v-on 指令对于触发的事件调用 event.preventDefault() : ... 在接下来对 v-on 和 v-for 等功能的探索中 , 你会看到修饰符的其它例子 缩写 🍀 v- 前缀作为一种视觉提示 , 用来识别模板中 Vue 特定的特性 ; 当你在使用 Vue.js 为现有标签添加动态行为 (dynamic behavior) 时 , v- 前缀很有帮助 , 然而 , 对于一些频繁用到的指令来说 , 就会感到使用繁琐 . 同时 , 在构建由 Vue.js 管理所有模板的单页面应用程序 (SPA - single page application) 时 , v- 前缀也变得没那么重要了 , 因此 , Vue.js 为 v-bind 和 v-on 这两个最常用的指令 , 提供了特定简写 : v-bind 缩写如下 : ... ... v-on 缩写如下 : ... ... 它们看起来可能与普通的 HTML 略有不同 , 但 : 与 @ 对于特性名来说都是合法字符 , 在所有支持 Vue.js 的浏览器都能被正确地解析 , 而且 , 它们不会出现在最终渲染的标记中 . 缩写语法是完全可选的 , 但随着你更深入地了解它们的作用 , 你会庆幸拥有它们 "},"04-前端/Vue/04-Vue - 计算属性和侦听器.html":{"url":"04-前端/Vue/04-Vue - 计算属性和侦听器.html","title":"Vue - 计算属性和侦听器","keywords":"","body":"Vue - 计算属性和侦听器 计算属性 🍀 模板内的表达式非常便利 , 但是设计它们的初衷是用于简单运算的 , 在模板中放入太多的逻辑会让模板过重且难以维护 , 例如 : {{ message.split('').reverse().join('') }} 在这个地方 , 模板不再是简单的声明式逻辑 , 你必须看一段时间才能意识到 , 这里是想要显示变量 message 的翻转字符串 , 当你想要在模板中多次引用此处的翻转字符串时 , 就会更加难以处理 所以 , 对于任何复杂逻辑 , 你都应当使用计算属性 基础例子 🍀 Original message: \"{{ message }}\" Computed reversed message: \"{{ reversedMessage }}\" var vm = new Vue({ el: '#example', data: { message: 'Hello' }, computed: { // 计算属性的 getter reversedMessage: function () { // `this` 指向 vm 实例 return this.message.split('').reverse().join('') } } }) 结果 : Original message: \"{{ message }}\" Computed reversed message: \"{{ reversedMessage }}\" 这里我们声明了一个计算属性 reversedMessage , 我们提供的函数将用作属性 vm.reversedMessage 的 getter 函数 : console.log(vm.reversedMessage) // => 'olleH' vm.message = 'Goodbye' console.log(vm.reversedMessage) // => 'eybdooG' 你可以打开浏览器的控制台 , 自行修改例子中的 vm , vm.reversedMessage 的值始终取决于 vm.message 的值 你可以像绑定普通属性一样在模板中绑定计算属性 , Vue 知道 vm.reversedMessage 依赖于 vm.message , 因此当 vm.message 发生改变时 , 所有依赖 vm.reversedMessage 的绑定也会更新 , 而且最妙的是我们已经以声明的方式创建了这种依赖关系 : 计算属性的 getter 函数是没有副作用 (side effect) 的 , 这使它更易于测试和理解 计算属性缓存与方法 🍀 你可能已经注意到我们可以通过在表达式中调用方法来达到同样的效果 : Reversed message: \"{{ reversedMessage() }}\" // 在组件中 methods: { reversedMessage: function () { return this.message.split('').reverse().join('') } } 我们可以将同一函数定义为一个方法而不是一个计算属性 , 两种方式的最终结果确实是完全相同的 , 然而 , 不同的是计算属性是基于它们的依赖进行缓存的 , 计算属性只有在它的相关依赖发生改变时才会重新求值 , 这就意味着只要 message 还没有发生改变 , 多次访问 reversedMessage 计算属性会立即返回之前的计算结果 , 而不必再次执行函数 这也同样意味着下面的计算属性将不再更新 , 因为 Date.now() 不是响应式依赖 : computed: { now: function () { return Date.now() } } 相比之下 , 每当触发重新渲染时 , 调用方法将总会再次执行函数 我们为什么需要缓存 ? 假设我们有一个性能开销比较大的计算属性 A , 它需要遍历一个巨大的数组并做大量的计算 , 然后我们可能有其他的计算属性依赖于 A , 如果没有缓存 , 我们将不可避免的多次执行 A 的 getter ! 如果你不希望有缓存 , 可以使用方法来替代计算属性 计算属性和侦听属性 🍀 Vue 提供了一种更通用的方式来观察和响应 Vue 实例上的数据变动 : 侦听属性 ; 当你有一些数据需要随着其它数据变动而变动时 , 你很容易滥用 watch——特别是如果你之前使用过 AngularJS , 然而 , 通常更好的做法是使用计算属性而不是命令式的 watch 回调 , 看看如下例子 : {{ fullName }} // 侦听器版本 var vm = new Vue({ el: '#demo', data: { firstName: 'Foo', lastName: 'Bar', fullName: 'Foo Bar' }, watch: { firstName: function (val) { this.fullName = val + ' ' + this.lastName }, lastName: function (val) { this.fullName = this.firstName + ' ' + val } } }) 上面代码是命令式且重复的 , 将它与计算属性的版本进行比较 : // 计算属性版本 var vm = new Vue({ el: '#demo', data: { firstName: 'Foo', lastName: 'Bar' }, computed: { fullName: function () { return this.firstName + ' ' + this.lastName } } }) 明显 , 计算属性版本更加简洁 计算属性的setter 🍀 计算属性默认只有 getter , 不过在需要时你也可以提供一个 setter : // ... computed: { fullName: { // getter get: function () { return this.firstName + ' ' + this.lastName }, // setter set: function (newValue) { var names = newValue.split(' ') this.firstName = names[0] this.lastName = names[names.length - 1] } } } // ... 现在再运行 vm.fullName = 'John Doe' 时 , setter 会被调用 , vm.firstName 和 vm.lastName 也会相应地被更新 侦听器 🍀 虽然计算属性在大多数情况下更合适 , 但有时也需要一个自定义的侦听器 , 这就是为什么 Vue 通过 watch 选项提供了一个更通用的方法 , 来响应数据的变化 , 当需要在数据变化时执行异步或开销较大的操作时 , 这个方式是最有用的 例如 : Ask a yes/no question: {{ answer }} // 因为 AJAX 库和通用工具的生态已经相当丰富, Vue 核心代码没有重复 // 提供这些功能以保持精简, 这也可以让你自由选择自己更熟悉的工具 var watchExampleVM = new Vue({ el: '#watch-example', data: { question: '', answer: 'I cannot give you an answer until you ask a question!' }, watch: { // 如果 `question` 发生改变 , 这个函数就会运行 question: function (newQuestion, oldQuestion) { this.answer = 'Waiting for you to stop typing...' this.debouncedGetAnswer() } }, created: function () { // `_.debounce` 是一个通过 Lodash 限制操作频率的函数 // 在这个例子中, 我们希望限制访问 yesno.wtf/api 的频率 // AJAX 请求直到用户输入完毕才会发出. 更多关于 // `_.debounce` 函数, 请参考 : https://lodash.com/docs#debounce this.debouncedGetAnswer = _.debounce(this.getAnswer, 500) }, methods: { getAnswer: function () { if (this.question.indexOf('?') === -1) { this.answer = 'Questions usually contain a question mark. ;-)' return } this.answer = 'Thinking...' var vm = this axios.get('https://yesno.wtf/api') .then(function (response) { vm.answer = _.capitalize(response.data.answer) }) .catch(function (error) { vm.answer = 'Error! Could not reach the API. ' + error }) } } }) 结果 : Ask a yes/no question: {{ answer }} 在这个示例中 , 使用 watch 选项允许我们执行异步操作 (访问一个 API) , 限制我们执行该操作的频率 , 并在我们得到最终结果前 , 设置中间状态。这些都是计算属性无法做到的。 除了 watch 选项之外 , 您还可以使用命令式的 vm.$watch API var watchExampleVM = new Vue({ el: '#watch-example', data: { question: '', answer: 'I cannot give you an answer until you ask a question!' }, watch: { // 如果 `question` 发生改变 , 这个函数就会运行 question: function (newQuestion, oldQuestion) { this.answer = 'Waiting for you to stop typing...' this.debouncedGetAnswer() } }, created: function () { this.debouncedGetAnswer = _.debounce(this.getAnswer, 500) }, methods: { getAnswer: function () { if (this.question.indexOf('?') === -1) { this.answer = 'Questions usually contain a question mark. ;-)' return } this.answer = 'Thinking...' var vm = this axios.get('https://yesno.wtf/api') .then(function (response) { vm.answer = _.capitalize(response.data.answer) }) .catch(function (error) { vm.answer = 'Error! Could not reach the API. ' + error }) } } }); var vm = new Vue({ el: '#example', data: { message: 'Hello' }, computed: { // 计算属性的 getter reversedMessage: function () { // `this` 指向 vm 实例 return this.message.split('').reverse().join('') } } }); "},"04-前端/Vue/05-Vue - Class与Style 绑定.html":{"url":"04-前端/Vue/05-Vue - Class与Style 绑定.html","title":"Vue - Class与Style 绑定","keywords":"","body":"Vue - Class与Style绑定 介绍 🍀 操作元素的 class 列表和内联样式是数据绑定的一个常见需求 , 因为它们都是属性 , 所以我们可以用 v-bind 处理它们 : 只需要通过表达式计算出字符串结果即可 , 不过 , 字符串拼接麻烦且易错 , 因此 , 在将 v-bind 用于 class 和 style 时 , Vue.js 做了专门的增强 , 表达式结果的类型除了字符串之外 , 还可以是对象或数组 绑定Class 🍀 对象语法 🍀 我们可以传给 v-bind:class 一个对象 , 以动态地切换 class : 上面的语法表示 active 这个 class 存在与否将取决于数据属性 isActive 的 truthiness 你可以在对象中传入更多属性来动态切换多个 class , 此外 , v-bind:class 指令也可以与普通的 class 属性共存 , 当有如下模板 : 和如下 data : data: { isActive: true, hasError: false } 结果渲染为 : 当 isActive 或者 hasError 变化时 , class 列表将相应地更新 , 例如 , 如果 hasError的值为 true , class 列表将变为 \"static active text-danger\" 绑定的数据对象不必内联定义在模板里 : data: { classObject: { active: true, 'text-danger': false } } 渲染的结果和上面一样 , 我们也可以在这里绑定一个返回对象的计算属性 , 这是一个常用且强大的模式 : data: { isActive: true, error: null }, computed: { classObject: function () { return { active: this.isActive && !this.error, 'text-danger': this.error && this.error.type === 'fatal' } } } 数组语法 🍀 我们可以把一个数组传给 v-bind:class , 以应用一个 class 列表 : data: { activeClass: 'active', errorClass: 'text-danger' } 渲染为 : 如果你也想根据条件切换列表中的 class , 可以用三元表达式 : 这样写将始终添加 errorClass , 但是只有在 isActive 是 truthy 时才添加 activeClass 不过 , 当有多个条件 class 时这样写有些繁琐 , 所以在数组语法中也可以使用对象语法 : 组件上使用 🍀 这个章节假设你已经对 Vue 组件有一定的了解 , 当然你也可以先跳过这里 , 稍后再回过头来看 当在一个自定义组件上使用 class 属性时 , 这些类将被添加到该组件的根元素上面 , 这个元素上已经存在的类不会被覆盖 例如 , 如果你声明了这个组件 : Vue.component('my-component', { template: 'Hi' }) 然后在使用它的时候添加一些 class : HTML 将被渲染为: Hi 对于带数据绑定 class 也同样适用 : 当 isActive 为 truthy 时 , HTML 将被渲染成为 : Hi 绑定内联样式 🍀 对象语法 🍀 v-bind:style 的对象语法十分直观——看着非常像 CSS , 但其实是一个 JavaScript 对象。CSS 属性名可以用驼峰式 (camelCase) 或短横线分隔 (kebab-case , 记得用单引号括起来) 来命名 : data: { activeColor: 'red', fontSize: 30 } 直接绑定到一个样式对象通常更好 , 这会让模板更清晰 : data: { styleObject: { color: 'red', fontSize: '13px' } } 同样的 , 对象语法常常结合返回对象的计算属性使用 数组语法 🍀 v-bind:style 的数组语法可以将多个样式对象应用到同一个元素上 : 自动添加前缀 🍀 当 v-bind:style 使用需要添加浏览器引擎前缀的 CSS 属性时 , 如 transform , Vue.js 会自动侦测并添加相应的前缀 多重值 🍀 2.3.0+ 从 2.3.0 起你可以为 style 绑定中的属性提供一个包含多个值的数组 , 常用于提供多个带前缀的值 , 例如 : 这样写只会渲染数组中最后一个被浏览器支持的值。在本例中 , 如果浏览器支持不带浏览器前缀的 flexbox , 那么就只会渲染 display: flex "},"04-前端/Vue/06-Vue - 条件渲染.html":{"url":"04-前端/Vue/06-Vue - 条件渲染.html","title":"Vue - 条件渲染","keywords":"","body":"Vue - 条件渲染 v-if 🍀 在字符串模板中 , 比如 Handlebars , 我们得像这样写一个条件块 : {{#if ok}} Yes {{/if}} 在 Vue 中 , 我们使用 v-if 指令实现同样的功能 : Yes 也可以用 v-else 添加一个“else 块” : Yes No 在template元素上使用v-if条件渲染分组 🍀 因为 v-if 是一个指令 , 所以必须将它添加到一个元素上 , 但是如果想切换多个元素呢 ? 此时可以把一个 元素当做不可见的包裹元素 , 并在上面使用 v-if , 最终的渲染结果将不包含 元素 Title Paragraph 1 Paragraph 2 v-else 🍀 你可以使用 v-else 指令来表示 v-if 的“else 块” : 0.5\"> Now you see me Now you don't v-else 元素必须紧跟在带 v-if 或者 v-else-if 的元素的后面 , 否则它将不会被识别 v-else-if 🍀 2.1.0 新增 v-else-if , 顾名思义 , 充当 v-if 的“else-if 块” , 可以连续使用 : A B C Not A/B/C 类似于 v-else , v-else-if 也必须紧跟在带 v-if 或者 v-else-if 的元素之后 用key管理可复用的元素 🍀 Vue 会尽可能高效地渲染元素 , 通常会复用已有元素而不是从头开始渲染 , 这么做除了使 Vue 变得非常快之外 , 还有其它一些好处 , 例如 , 如果你允许用户在不同的登录方式之间切换 : Username Email 那么在上面的代码中切换 loginType 将不会清除用户已经输入的内容 , 因为两个模板使用了相同的元素 , 不会被替换掉——仅仅是替换了它的 placeholder 自己动手试一试 , 在输入框中输入一些文本 , 然后按下切换按钮 : Username Email Toggle login type 这样也不总是符合实际需求 , 所以 Vue 为你提供了一种方式来表达“这两个元素是完全独立的 , 不要复用它们” , 只需添加一个具有唯一值的 key 属性即可 : Username Email 现在 , 每次切换时 , 输入框都将被重新渲染 , 请看 : Username Email Toggle login type 注意 , 元素仍然会被高效地复用 , 因为它们没有添加 key 属性 v-show 🍀 另一个用于根据条件展示元素的选项是 v-show 指令 , 用法大致一样 : Hello! 不同的是带有 v-show 的元素始终会被渲染并保留在 DOM 中 , v-show 只是简单地切换元素的 CSS 属性 display 注意 , v-show 不支持 元素 , 也不支持 v-else v-if与v-show 🍀 v-if 是“真正”的条件渲染 , 因为它会确保在切换过程中条件块内的事件监听器和子组件适当地被销毁和重建 v-if 也是惰性的 : 如果在初始渲染时条件为假 , 则什么也不做——直到条件第一次变为真时 , 才会开始渲染条件块 相比之下 , v-show 就简单得多——不管初始条件是什么 , 元素总是会被渲染 , 并且只是简单地基于 CSS 进行切换 一般来说 , v-if 有更高的切换开销 , 而 v-show 有更高的初始渲染开销 , 因此 , 如果需要非常频繁地切换 , 则使用 v-show 较好 ; 如果在运行时条件很少改变 , 则使用 v-if 较好 v-if与v-for一起使用 🍀 当 v-if 与 v-for 一起使用时 , v-for 具有比 v-if 更高的优先级。 new Vue({ el: '#no-key-example', data: { loginType: 'username' }, methods: { toggleLoginType: function () { return this.loginType = this.loginType === 'username' ? 'email' : 'username' } } }); new Vue({ el: '#key-example', data: { loginType: 'username' }, methods: { toggleLoginType: function () { return this.loginType = this.loginType === 'username' ? 'email' : 'username' } } }); "},"04-前端/Vue/07-Vue - 列表渲染.html":{"url":"04-前端/Vue/07-Vue - 列表渲染.html","title":"Vue - 列表渲染","keywords":"","body":"Vue - 列表渲染 v-for迭代列表 🍀 我们用 v-for 指令根据一组数组的选项列表进行渲染 , v-for 指令需要使用 item in items 形式的特殊语法 , items 是源数据数组并且 item 是数组元素迭代的别名 {{ item.message }} var example1 = new Vue({ el: '#example-1', data: { items: [ { message: 'Foo' }, { message: 'Bar' } ] } }) 结果 : {{ item.message }} 在 v-for 块中 , 我们拥有对父作用域属性的完全访问权限 , v-for 还支持一个可选的第二个参数为当前项的索引 {{ parentMessage }} - {{ index }} - {{ item.message }} var example2 = new Vue({ el: '#example-2', data: { parentMessage: 'Parent', items: [ { message: 'Foo' }, { message: 'Bar' } ] } }) 结果 : {{ parentMessage }} - {{ index }} - {{ item.message }} 你也可以用 of 替代 in 作为分隔符 , 因为它是最接近 JavaScript 迭代器的语法 : v-for迭代对象 🍀 你也可以用 v-for 通过一个对象的属性来迭代 {{ value }} new Vue({ el: '#v-for-object', data: { object: { firstName: 'John', lastName: 'Doe', age: 30 } } }) 结果 : {{ value }} 你也可以提供第二个参数为键名 : {{ key }}: {{ value }} : 第三个参数为索引 : {{ index }}. {{ key }}: {{ value }} . : 在遍历对象时 , 是按 Object.keys() 的结果遍历 , 但是不能保证它的结果在不同的 JavaScript 引擎下是一致的 key 🍀 当 Vue.js 用 v-for 正在更新已渲染过的元素列表时 , 它默认用 “就地复用” 策略 , 如果数据项的顺序被改变 , Vue 将不会移动 DOM 元素来匹配数据项的顺序 , 而是简单复用此处每个元素 , 并且确保它在特定索引下显示已被渲染过的每个元素 , 这个类似 Vue 1.x 的 track-by=\"$index\" 这个默认的模式是高效的 , 但是只适用于不依赖子组件状态或临时 DOM 状态 (例如 : 表单输入值) 的列表渲染输出 为了给 Vue 一个提示 , 以便它能跟踪每个节点的身份 , 从而重用和重新排序现有元素 , 你需要为每项提供一个唯一 key 属性 , 理想的 key 值是每项都有的且唯一的 id , 这个特殊的属性相当于 Vue 1.x 的 track-by , 但它的工作方式类似于一个属性 , 所以你需要用 v-bind 来绑定动态值 (在这里使用简写) : 建议尽可能在使用 v-for 时提供 key , 除非遍历输出的 DOM 内容非常简单 , 或者是刻意依赖默认行为以获取性能上的提升 因为它是 Vue 识别节点的一个通用机制 , key 并不与 v-for 特别关联 , key 还具有其他用途 , 我们将在后面的指南中看到其他用途 数组更新检测 🍀 变异方法 🍀 Vue 包含一组观察数组的变异方法 , 所以它们也将会触发视图更新 , 这些方法如下 : push() , 从末尾添加 pop() , 从某位删除 shift() , 从头部添加 unshift() , 从头部删除 splice() , 删除元素 , 删除索引为 1 的元素 : splice(index, 1) sort() , 排序 reverse() , 反转 你可以打开控制台 , 然后用前面例子的 items 数组调用变异方法 : example1.items.push({ message: 'Baz' }) 替换数组 🍀 变异方法 (mutation method) , 顾名思义 , 会改变被这些方法调用的原始数组 , 相比之下 , 也有非变异 (non-mutating method) 方法 , 例如 : filter(), concat() 和 slice() , 这些不会改变原始数组 , 但总是返回一个新数组 , 当使用非变异方法时 , 可以用新数组替换旧数组 : example1.items = example1.items.filter(function (item) { return item.message.match(/Foo/) }) 你可能认为这将导致 Vue 丢弃现有 DOM 并重新渲染整个列表 , 幸运的是 , 事实并非如此 , Vue 为了使得 DOM 元素得到最大范围的重用而实现了一些智能的、启发式的方法 , 所以用一个含有相同元素的数组去替换原来的数组是非常高效的操作 注意事项 🍀 由于 JavaScript 的限制 , Vue 不能检测以下变动的数组 : 当你利用索引直接设置一个项时 , 例如 : vm.items[indexOfItem] = newValue 当你修改数组的长度时 , 例如 : vm.items.length = newLength 举个例子 : var vm = new Vue({ data: { items: ['a', 'b', 'c'] } }) vm.items[1] = 'x' // 不是响应性的 vm.items.length = 2 // 不是响应性的 为了解决第一类问题 , 以下两种方式都可以实现和 vm.items[indexOfItem] = newValue 相同的效果 , 同时也将触发状态更新 : // Vue.set Vue.set(vm.items, indexOfItem, newValue) // Array.prototype.splice vm.items.splice(indexOfItem, 1, newValue) 你也可以使用 vm.$set 实例方法 , 该方法是全局方法 Vue.set 的一个别名 : vm.$set(vm.items, indexOfItem, newValue) 为了解决第二类问题 , 你可以使用 splice : vm.items.splice(newLength) 对象更改检测 🍀 还是由于 JavaScript 的限制 , Vue 不能检测对象属性的添加或删除 : var vm = new Vue({ data: { a: 1 } }) // `vm.a` 现在是响应式的 vm.b = 2 // `vm.b` 不是响应式的 对于已经创建的实例 , Vue 不能动态添加根级别的响应式属性 , 但是 , 可以使用 Vue.set(object, key, value) 方法向嵌套对象添加响应式属性 , 例如 , 对于 : var vm = new Vue({ data: { userProfile: { name: 'Anika' } } }) 你可以添加一个新的 age 属性到嵌套的 userProfile 对象 : Vue.set(vm.userProfile, 'age', 27) 你还可以使用 vm.$set 实例方法 , 它只是全局 Vue.set 的别名 : vm.$set(vm.userProfile, 'age', 27) 有时你可能需要为已有对象赋予多个新属性 , 比如使用 Object.assign() 或 _.extend() , 在这种情况下 , 你应该用两个对象的属性创建一个新的对象。所以 , 如果你想添加新的响应式属性 , 不要像这样 : Object.assign(vm.userProfile, { age: 27, favoriteColor: 'Vue Green' }) 你应该这样做 : vm.userProfile = Object.assign({}, vm.userProfile, { age: 27, favoriteColor: 'Vue Green' }) 显示过滤/排序结果 🍀 有时 , 我们想要显示一个数组的过滤或排序副本 , 而不实际改变或重置原始数据 , 在这种情况下 , 可以创建返回过滤或排序数组的计算属性 例如 : {{ n }} data: { numbers: [ 1, 2, 3, 4, 5 ] }, computed: { evenNumbers: function () { return this.numbers.filter(function (number) { return number % 2 === 0 }) } } 在计算属性不适用的情况下 (例如 , 在嵌套 v-for 循环中) 你可以使用一个 method 方法 : {{ n }} data: { numbers: [ 1, 2, 3, 4, 5 ] }, methods: { even: function (numbers) { return numbers.filter(function (number) { return number % 2 === 0 }) } } v-for取值范围 🍀 v-for 也可以取整数 , 在这种情况下 , 它将重复多次模板 {{ n }} 结果 : template里使用v-for 🍀 类似于 v-if , 你也可以利用带有 v-for 的 渲染多个元素 , 比如 : {{ item.msg }} v-for与v-if 🍀 当它们处于同一节点 , v-for 的优先级比 v-if 更高 , 这意味着 v-if 将分别重复运行于每个 v-for 循环中 , 当你想为仅有的一些项渲染节点时 , 这种优先级的机制会十分有用 , 如下 : {{ todo }} 上面的代码只传递了未完成的 todos 而如果你的目的是有条件地跳过循环的执行 , 那么可以将 v-if 置于外层元素 (或 )上 , 如 : {{ todo }} No todos left! 组件中使用v-for 🍀 在自定义组件里 , 你可以像任何普通元素一样用 v-for 2.2.0+ 的版本里 , 当在组件中使用 v-for 时 , key 现在是必须的 然而 , 任何数据都不会被自动传递到组件里 , 因为组件有自己独立的作用域 , 为了把迭代数据传递到组件里 , 我们要用 props : 不自动将 item 注入到组件里的原因是 , 这会使得组件与 v-for 的运作紧密耦合 , 明确组件数据的来源能够使组件在其他场合重复使用 下面是一个简单的 todo list 的完整例子 : Add a todo Add 注意这里的 is=\"todo-item\" 属性 , 这种做法在使用 DOM 模板时是十分必要的 , 因为在 元素内只有 元素会被看作有效内容。这样做实现的效果与 相同 , 但是可以避开一些潜在的浏览器解析错误。查看 DOM 模板解析说明 来了解更多信息 Vue.component('todo-item', { template: '\\ \\ {{ title }}\\ Remove\\ \\ ', props: ['title'] }) new Vue({ el: '#todo-list-example', data: { newTodoText: '', todos: [ { id: 1, title: 'Do the dishes', }, { id: 2, title: 'Take out the trash', }, { id: 3, title: 'Mow the lawn' } ], nextTodoId: 4 }, methods: { addNewTodo: function () { this.todos.push({ id: this.nextTodoId++, title: this.newTodoText }) this.newTodoText = '' } } }) Add a todo Add Vue.component('todo-item', { template: '\\ \\ \\ Remove\\ \\ ', props: ['title'] }); new Vue({ el: '#todo-list-example', data: { newTodoText: '', todos: [ { id: 1, title: 'Do the dishes', }, { id: 2, title: 'Take out the trash', }, { id: 3, title: 'Mow the lawn' } ], nextTodoId: 4 }, methods: { addNewTodo: function () { this.todos.push({ id: this.nextTodoId++, title: this.newTodoText }) this.newTodoText = '' } } }); new Vue({ el: '#v-for-object', data: { object: { firstName: 'John', lastName: 'Doe', age: 30 } } }); var example2 = new Vue({ el: '#example-2', data: { parentMessage: 'Parent', items: [ { message: 'Foo' }, { message: 'Bar' } ] } }); var example1 = new Vue({ el: '#example-1', data: { items: [ { message: 'Foo' }, { message: 'Bar' } ] } }); "},"04-前端/Vue/08-Vue - 事件处理.html":{"url":"04-前端/Vue/08-Vue - 事件处理.html","title":"Vue - 事件处理","keywords":"","body":"Vue - 事件处理 监听事件 🍀 可以用 v-on 指令监听 DOM 事件 , 并在触发时运行一些 JavaScript 代码 示例 : Add 1 The button above has been clicked {{ counter }} times. var example1 = new Vue({ el: '#example-1', data: { counter: 0 } }) 结果 : Add 1 The button above has been clicked {{ counter }} times. 事件处理 🍀 然而许多事件处理逻辑会更为复杂 , 所以直接把 JavaScript 代码写在 v-on 指令中是不可行的 , 因此 v-on 还可以接收一个需要调用的方法名称 示例 : Greet var example2 = new Vue({ el: '#example-2', data: { name: 'Vue.js' }, // 在 `methods` 对象中定义方法 methods: { greet: function (event) { // `this` 在方法里指向当前 Vue 实例 alert('Hello ' + this.name + '!') // `event` 是原生 DOM 事件 if (event) { alert(event.target.tagName) } } } }) // 也可以用 JavaScript 直接调用方法 example2.greet() // => 'Hello Vue.js!' 结果 : Greet 内联处理 🍀 除了直接绑定到一个方法 , 也可以在内联 JavaScript 语句中调用方法 : Say hi Say what new Vue({ el: '#example-3', methods: { say: function (message) { alert(message) } } }) 结果 : Say hi Say what 有时也需要在内联语句处理器中访问原始的 DOM 事件 , 可以用特殊变量 $event 把它传入方法 : Submit // ... methods: { warn: function (message, event) { // 现在我们可以访问原生事件对象 if (event) event.preventDefault() alert(message) } } 事件修饰符 🍀 在事件处理程序中调用 event.preventDefault() 或 event.stopPropagation() 是非常常见的需求 , 尽管我们可以在方法中轻松实现这点 , 但更好的方式是 : 方法只有纯粹的数据逻辑 , 而不是去处理 DOM 事件细节 为了解决这个问题 , Vue.js 为 v-on 提供了事件修饰符 , 之前提过 , 修饰符是由点开头的指令后缀来表示的 : .stop .prevent .capture .self .once .passive 用法实例如下 : ... ... 使用修饰符时 , 顺序很重要 ; 相应的代码会以同样的顺序产生 , 因此 , 用 v-on:click.prevent.self 会阻止所有的点击 , 而 v-on:click.self.prevent 只会阻止对元素自身的点击 2.1.4 新增 不像其它只能对原生的 DOM 事件起作用的修饰符 , .once 修饰符还能被用到自定义的组件事件上 , 如果你还没有阅读关于组件的文档 , 现在大可不必担心 2.3.0 新增 Vue 还对应 addEventListener 中的 passive 选项提供了 .passive 修饰符 ... 这个 .passive 修饰符尤其能够提升移动端的性能 不要把 .passive 和 .prevent 一起使用 , 因为 .prevent 将会被忽略 , 同时浏览器可能会向你展示一个警告 , 请记住 , .passive 会告诉浏览器你不想阻止事件的默认行为 按键修饰符 🍀 在监听键盘事件时 , 我们经常需要检查常见的键值 , Vue 允许为 v-on 在监听键盘事件时添加按键修饰符 : 记住所有的 keyCode 比较困难 , 所以 Vue 为最常用的按键提供了别名 : 全部的按键别名 : .enter .tab .delete .esc .space .up .down .left .right 可以通过全局 config.keyCodes 对象自定义按键修饰符别名 : // 可以使用 `v-on:keyup.f1` Vue.config.keyCodes.f1 = 112 自动匹配按键修饰符 🍀 2.5.0 新增 你也可直接将 KeyboardEvent.key 暴露的任意有效按键名转换为 kebab-case 来作为修饰符 : 在上面的例子中 , 处理函数仅在 $event.key === 'PageDown' 时被调用 有一些按键 (.esc 以及所有的方向键) 在 IE9 中有不同的 key 值 , 如果你想支持 IE9 , 它们的内置别名应该是首选 系统修饰键 🍀 2.1.0 新增 可以用如下修饰符来实现仅在按下相应按键时才触发鼠标或键盘事件的监听器 .ctrl .alt .shift .meta 注意 : 在 Mac 系统键盘上 , meta 对应 command 键 (⌘) ; 在 Windows 系统键盘 meta 对应 Windows 徽标键 (⊞) ; 在 Sun 操作系统键盘上 , meta 对应实心宝石键 (◆) ; 在其他特定键盘上 , 尤其在 MIT 和 Lisp 机器的键盘、以及其后继产品 , 比如 Knight 键盘、space-cadet 键盘 , meta 被标记为“META” ; 在 Symbolics 键盘上 , meta 被标记为“META”或者“Meta” 例如 : Do something 请注意修饰键与常规按键不同 , 在和 keyup 事件一起用时 , 事件触发时修饰键必须处于按下状态 , 换句话说 , 只有在按住 ctrl 的情况下释放其它按键 , 才能触发 keyup.ctrl , 而单单释放 ctrl 也不会触发事件 , 如果你想要这样的行为 , 请为 ctrl 换用 keyCode : keyup.17 .exact修饰符 🍀 2.5.0 新增 .exact 修饰符允许你控制由精确的系统修饰符组合触发的事件 A A A 鼠标按钮修饰符 🍀 2.2.0 新增 .left .right .middle 这些修饰符会限制处理函数仅响应特定的鼠标按钮 HTML中监听事件 🍀 你可能注意到这种事件监听的方式违背了关注点分离 (separation of concern) 这个长期以来的优良传统 , 但不必担心 , 因为所有的 Vue.js 事件处理方法和表达式都严格绑定在当前视图的 ViewModel 上 , 它不会导致任何维护上的困难 , 实际上 , 使用 v-on 有几个好处 : 扫一眼 HTML 模板便能轻松定位在 JavaScript 代码里对应的方法 因为你无须在 JavaScript 里手动绑定事件 , 你的 ViewModel 代码可以是非常纯粹的逻辑 , 和 DOM 完全解耦 , 更易于测试 当一个 ViewModel 被销毁时 , 所有的事件处理器都会自动被删除 , 你无须担心如何自己清理它们 var example1 = new Vue({ el: '#example-1', data: { counter: 0 } }); var example2 = new Vue({ el: '#example-2', data: { name: 'Vue.js' }, // 在 `methods` 对象中定义方法 methods: { greet: function (event) { // `this` 在方法里指向当前 Vue 实例 alert('Hello ' + this.name + '!') // `event` 是原生 DOM 事件 if (event) { alert(event.target.tagName) } } } }); new Vue({ el: '#example-3', methods: { say: function (message) { alert(message) } } }); "},"04-前端/Vue/09-Vue - 组件基础.html":{"url":"04-前端/Vue/09-Vue - 组件基础.html","title":"Vue - 组件基础","keywords":"","body":"Vue - 组件基础 基本示例 🍀 这里有一个 Vue 组件的示例 : // 定义一个名为 button-counter 的新组件 Vue.component('button-counter', { data: function () { return { count: 0 } }, template: 'You clicked me {{ count }} times.' }) 组件是可复用的 Vue 实例 , 且带有一个名字 : 在这个例子中是 , 我们可以在一个通过 new Vue 创建的 Vue 根实例中 , 把这个组件作为自定义元素来使用 : new Vue({ el: '#components-demo' }) 因为组件是可复用的 Vue 实例 , 所以它们与 new Vue 接收相同的选项 , 例如 data、computed、watch、methods 以及生命周期钩子等 , 仅有的例外是像 el 这样根实例特有的选项 组件的复用 🍀 你可以将组件进行任意次数的复用 : 注意当点击按钮时 , 每个组件都会各自独立维护它的 count , 因为你每用一次组件 , 就会有一个它的新实例被创建 组件的data 🍀 当我们定义这个 组件时 , 你可能会发现它的 data 并不是像这样直接提供一个对象 : data: { count: 0 } 取而代之的是 , 一个组件的 data 选项必须是一个函数 , 因此每个实例可以维护一份被返回对象的独立的拷贝 : data: function () { return { count: 0 } } 组件的组织 🍀 通常一个应用会以一棵嵌套的组件树的形式来组织 : 例如 , 你可能会有页头、侧边栏、内容区等组件 , 每个组件又包含了其它的像导航链接、博文之类的组件 为了能在模板中使用 , 这些组件必须先注册以便 Vue 能够识别 , 这里有两种组件的注册类型 : 全局注册和局部注册 , 至此 , 我们的组件都只是通过 Vue.component 全局注册的 : Vue.component('my-component-name', { // ... options ... }) 全局注册的组件可以用在其被注册之后的任何 (通过 new Vue) 新创建的 Vue 根实例 , 也包括其组件树中的所有子组件的模板中 Prop 🍀 早些时候 , 我们提到了创建一个博文组件的事情 , 问题是如果你不能向这个组件传递某一篇博文的标题或内容之类的我们想展示的数据的话 , 它是没有办法使用的 , 这也正是 prop 的由来 Prop 是你可以在组件上注册的一些自定义特性 , 当一个值传递给一个 prop 特性的时候 , 它就变成了那个组件实例的一个属性 , 为了给博文组件传递一个标题 , 我们可以用一个 props 选项将其包含在该组件可接受的 prop 列表中 : Vue.component('blog-post', { props: ['title'], template: '{{ title }}' }) 一个组件默认可以拥有任意数量的 prop , 任何值都可以传递给任何 prop , 在上述模板中 , 你会发现我们能够在组件实例中访问这个值 , 就像访问 data 中的值一样 一个 prop 被注册之后 , 你就可以像这样把数据作为一个自定义特性传递进来 : 然而在一个典型的应用中 , 你可能在 data 里有一个博文的数组 : new Vue({ el: '#blog-post-demo', data: { posts: [ { id: 1, title: 'My journey with Vue' }, { id: 2, title: 'Blogging with Vue' }, { id: 3, title: 'Why Vue is so fun' } ] } }) 并想要为每篇博文渲染一个组件 : 如上所示 , 你会发现我们可以使用 v-bind 来动态传递 prop , 这在你一开始不清楚要渲染的具体内容 , 比如从一个 API 获取博文列表的时候 , 是非常有用的 Prop详细 单个根元素 🍀 当构建一个 组件时 , 你的模板最终会包含的东西远不止一个标题 : {{ title }} 最最起码 , 你会包含这篇博文的正文 : {{ title }} 然而如果你在模板中尝试这样写 , Vue 会显示一个错误 , 并解释道 every component must have a single root element (每个组件必须只有一个根元素) , 你可以将模板的内容包裹在一个父元素内 , 来修复这个问题 , 例如 : {{ title }} 看起来当组件变得越来越复杂的时候 , 我们的博文不只需要标题和内容 , 还需要发布日期、评论等等 , 为每个相关的信息定义一个 prop 会变得很麻烦 : 所以是时候重构一下这个 组件了 , 让它变成接受一个单独的 post prop : Vue.component('blog-post', { props: ['post'], template: ` {{ post.title }} ` }) 上述的这个和一些接下来的示例使用了 JavaScript 的模板字符串来让多行的模板更易读 , 它们在 IE 下并没有被支持 , 所以如果你需要在不 (经过 Babel 或 TypeScript 之类的工具) 编译的情况下支持 IE , 请使用折行转义字符取而代之 现在 , 不论何时为 post 对象添加一个新的属性 , 它都会自动地在 内可用。 通过事件向父级组件发送消息 🍀 在我们开发 组件时 , 它的一些功能可能要求我们和父级组件进行沟通 , 例如我们可能会引入一个可访问性的功能来放大博文的字号 , 同时让页面的其它部分保持默认的字号 在其父组件中 , 我们可以通过添加一个 postFontSize 数据属性来支持这个功能 : new Vue({ el: '#blog-posts-events-demo', data: { posts: [/* ... */], postFontSize: 1 } }) 它可以在模板中用来控制所有博文的字号 : 现在我们在每篇博文正文之前添加一个按钮来放大字号 : Vue.component('blog-post', { props: ['post'], template: ` {{ post.title }} Enlarge text ` }) 问题是这个按钮不会做任何事 : Enlarge text 当点击这个按钮时 , 我们需要告诉父级组件放大所有博文的文本 , 幸好 Vue 实例提供了一个自定义事件的系统来解决这个问题 , 我们可以调用内建的 $emit 并传入事件的名字 , 来向父级组件触发一个事件 : Enlarge text 然后我们可以用 v-on 在博文组件上监听这个事件 , 就像监听一个原生 DOM 事件一样 : 使用事件抛出一个值 🍀 有的时候用一个事件来抛出一个特定的值是非常有用的 , 例如我们可能想让 组件决定它的文本要放大多少 , 这时可以使用 $emit 的第二个参数来提供这个值 : Enlarge text 然后当在父级组件监听这个事件的时候 , 我们可以通过 $event 访问到被抛出的这个值 : 或者 , 如果这个事件处理函数是一个方法 : 那么这个值将会作为第一个参数传入这个方法 : methods: { onEnlargeText: function (enlargeAmount) { this.postFontSize += enlargeAmount } } 组件上使用 v-model 🍀 自定义事件也可以用于创建支持 v-model 的自定义输入组件 , 记住 : 等价于 : 当用在组件上时 , v-model 则会这样 : 为了让它正常工作 , 这个组件内的 必须 : 将其 value 特性绑定到一个名叫 value 的 prop 上 在其 input 事件被触发时 , 将新的值通过自定义的 input 事件抛出 写成代码之后是这样的 : Vue.component('custom-input', { props: ['value'], template: ` ` }) 现在 v-model 就应该可以在这个组件上完美地工作起来了 : 通过插槽分发内容 🍀 和 HTML 元素一样 , 我们经常需要向一个组件传递内容 , 像这样 : Something bad happened. 幸好 , Vue 自定义的 元素让这变得非常简单 : Vue.component('alert-box', { template: ` Error! ` }) 如你所见 , 我们只要在需要的地方加入插槽就行了——就这么简单 ! 更多插槽相关 : 插槽 动态组件 🍀 有的时候 , 在不同组件之间进行动态切换是非常有用的 , 比如在一个多标签的界面里 : Home component 上述内容可以通过 Vue 的 元素加一个特殊的 is 特性来实现 : 在上述示例中 , currentTabComponent 可以包括 已注册组件的名字 , 或 一个组件的选项对象 解析 DOM 模板时的注意事项 🍀 有些 HTML 元素 , 诸如 、、 和 , 对于哪些元素可以出现在其内部是有严格限制的 , 而有些元素 , 诸如 、 和 , 只能出现在其它某些特定的元素内部 这会导致我们使用这些有约束条件的元素时遇到一些问题 , 例如 : 这个自定义组件 会被作为无效的内容提升到外部 , 并导致最终渲染结果出错。幸好这个特殊的 is 特性给了我们一个变通的办法 : 需要注意的是 , 如果我们从以下来源使用模板的话 , 这条限制是不存在的 : 字符串 (例如 : template: '...') 单文件组件 (.vue) `` "},"04-前端/Vue/10-Vue - Vue-cli.html":{"url":"04-前端/Vue/10-Vue - Vue-cli.html","title":"Vue - Vue-cli","keywords":"","body":"Vue - Vue-cli 介绍 🍀 Vue CLI 是一个用于 vue.js 快速开发的系统 , 提供 : 交互式工程脚手架 @vue/cli 零配置快速成型 @vue/cli + @vue/cli-service-global 运行时依赖项 @vue/cli-service : 可升级 建立在 WebPack 之上 , 有合理的默认设置 可通过项目内配置文件进行配置 可扩展的插件 丰富的官方插件 , 集成了前端生态系统中最好的工具 Vue CLI 旨在成为 VUE 生态系统的标准工具基线 , 它确保各种构建工具与合理的缺省值一起顺利工作 , 这样你就可以专注于编写应用程序 , 而不是花费数天时间与配置进行争论 , 同时 , 它仍然可以灵活地调整每个工具的配置 使用 vue-cli 可以快速构建我们的 Vue 项目 快速开始 🍀 安装 Node.js 🍀 在安装 vue-cli 之前 , 我们需要安装 Node 环境 , 因为我们需要使用 npm 包管理器 官网下载安装 安装 vue-cli 🍀 安装好 node 之后 , 我们就可以安装 vue-cli 了 : npm install -g vue-cli 待安装完成后 , 在中断使用 vue -help 出现以下信息说明安装成功 : C:\\Users\\Lyon>vue -help Usage: vue [options] Options: -V, --version output the version number -h, --help output usage information Commands: init generate a new project from a template list list available official templates build prototype a new project create (for v3 warning only) help [cmd] display help for [cmd] 可用的官方模板如下 : C:\\Users\\Lyon>vue list Available official templates: ★ browserify - A full-featured Browserify + vueify setup with hot-reload, linting & unit testing. ★ browserify-simple - A simple Browserify + vueify setup for quick prototyping. ★ pwa - PWA template for vue-cli based on the webpack template ★ simple - The simplest possible Vue setup in a single HTML file ★ webpack - A full-featured Webpack + vue-loader setup with hot reload, linting, testing & css extraction. ★ webpack-simple - A simple Webpack + vue-loader setup for quick prototyping. 初始化项目 🍀 使用 webpack 模块初始化 my-project 项目 $ vue init webpack my-project ? Project name my-project ? Project description A Vue.js project ? Author lyonyang ? Vue build standalone ? Install vue-router? Yes ? Use ESLint to lint your code? No ? Set up unit tests No ? Setup e2e tests with Nightwatch? No ? Should we run `npm install` for you after the project has been created? (recommended) npm vue-cli · Generated \"my-project\". # Installing project dependencies ... # ======================== ..... # Project initialization finished! # ======================== To get started: cd my-project npm run dev Documentation can be found at https://vuejs-templates.github.io/webpack 切换到项目目录 🍀 $ cd my-project 下载项目依赖包 🍀 $ npm install 启动当前项目 🍀 $ npm run dev > my-project@1.0.0 dev D:\\my-project > webpack-dev-server --inline --progress --config build/webpack.dev.conf.js 95% emitting DONE Compiled successfully in 4755ms 10:39:13 I Your application is running here: http://localhost:8080 访问 http://localhost:8000 项目结构 🍀 注释部分为未启用功能部分 . ├── build/ # webpack config files │ └── ... ├── config/ │ ├── index.js # main project config │ └── ... ├── node_modules/ # library root ├── src/ │ ├── main.js # app entry file │ ├── App.vue # main app component │ ├── components/ # ui components │ │ └── ... │ └── assets/ # module assets (processed by webpack) │ └── ... ├── static/ # pure static assets (directly copied) # ├── test/ # │ └── unit/ # unit tests # │ │ ├── specs/ # test spec files # │ │ ├── eslintrc # config file for eslint with extra settings only for unit tests # # │ │ ├── index.js # test build entry file # │ │ ├── jest.conf.js # Config file when using Jest for unit tests # │ │ └── karma.conf.js # test runner config file when using Karma for unit tests # │ │ ├── setup.js # file that runs before Jest runs your unit tests # │ └── e2e/ # e2e tests # │ │ ├── specs/ # test spec files # │ │ ├── custom-assertions/ # custom assertions for e2e tests # │ │ ├── runner.js # test runner script # │ │ └── nightwatch.conf.js # test runner config file ├── .babelrc # babel config ├── .editorconfig # indentation, spaces/tabs and similar settings for your editor # ├── .eslintrc.js # eslint config # ├── .eslintignore # eslint ignore rules ├── .gitignore # sensible defaults for gitignore ├── .postcssrc.js # postcss config ├── index.html # index.html template ├── package.json # build scripts and dependencies └── README.md # Default README file 构建命令 🍀 所有的构建命令都是通过 NPM 脚本执行的 npm run dev 开启一个本地 Node.js 开发服务器 npm run build 打包生产资源 , 如 JavaScript , HTML , CSS 等 npm run unit 在 JSDOM 中运行单元测试 npm run e2e 运行端到端的测试 npm run lint 运行 eslint 并报告错误链接 "},"05-Web框架/":{"url":"05-Web框架/","title":"Web框架","keywords":"","body":"Web框架介绍 主流Web框架 🍀 Django 🍀 Django 是当前 Python 世界中最负盛名且最成熟的网络框架 , 最初用来制作在线新闻的 Web 站点 , 目前已经发展为应用最广泛的 Python 网络框架 Django 的各模块之间结合得比较紧密 , 所以在功能强大的同时又是一个相对封闭的系统 , 但是它提供了非常齐备的官方文档 , 提供了译站式的解决方案 , 其中包含缓存 , ORM , 管理后台 , 验证 , 表单处理等 , 使得开发复杂的数据库驱动的网站变得很简单 ; 当然也因为系统耦合度太高 , 替换掉内置的功能往往需要花费一些功夫 , 所以学习曲线也相当陡峭 Flask 🍀 Flask 是一个轻量级 Web 应用框架 , 它基于 Werkzeug 实现的 WSGI 和 Jinjia2 模板引擎 Flask 的作者是 Armin Ronacher , 本来这只是作者愚人节开的一个玩笑 , 但是开源之后却受到 Python 程序员的喜爱 , 目前在 GitHub 上的 Star 数量已经超过了 Django . 设计上 , 它只保留核心 , 通过扩展机制来增加其他功能 , Flask 用到的依赖都是 Pocoo 团队开发的 , Pocoo 团队其他的项目还有 Pygments , Sphinx , 以及 lodgeit . Flask 的扩展环境非常繁荣 , 基本上 Web 应用的每个环节都有对应的扩展供选择 , 就算没有对应的扩展也能很方便的自己实现一个 Pyramid 🍀 Pyramid 在国内知名度并不高 , 主要原因是中文文档匮乏 , 其高级用法需要通过阅读源代码获取灵感 , 尽管被 Django 和 Flask 的光芒遮蔽 , 但是它的性能要比 Flask 高 . Pyramid 的灵感来源于 Zope , Pylons 1.0 和 Django . Pyramid 在努力朝着胜任不同级别应用的框架的方向在走 , 虽然它默认使用 Chameleon 和 Mako 模块 , 但很容易切换成 Jinja2 , 甚至可以让多种模板引擎共存 , 通过文件后缀名来识别 豆瓣赞赏和豆瓣钱包等产品就是基于此框架实现的 , 代码量级和 Flask 相同 , 性能比 Flask 要略高 Bottle 🍀 Bottle 也是一个轻量级的 Web 框架 , 它的特点是单文件 , 代码只使用了 Python 标准库 , 而不需要额外依赖其他的第三方库 , 它更符合微框架的定义 , 截止到今天只有 4100 多行的代码 Tornado 🍀 Tornado 全称 Tornado Web Server , 最初是由 FriendFeed 开发的非阻塞式 Web 服务器 , 现在我们看到的是被 Fackbook 收购后开源出来的版本 , 它和其他主流框架有个明显的区别 : 它是非阻塞式服务器 , 而且速度相当快 , 得益于其非阻塞的方式和对 epoll 的运用 , Tornado 每秒可以处理数以千计的连接 , 这意味着对于长轮询 , WebSocket 等实时 Web 服务来说 , Tornado 是一个理想的 Web 框架 Web.py 🍀 Web.py 也是一个微框架 , 由 Reddit 联合创始人 , RSS 规格合作创造者 , 著名计算机黑客 Aaron Swartz 开发 , Web.py 使用基于类的视图 , 简单易学却功能强大 Twisted 🍀 Twisted 是一个有着十多年历史的开源事件驱动框架 , 它适用于从传输层到自定义应用协议的所有类型的网络程序的开发 , 而不着眼于网络 HTTP 应用开发 , 并且它能在不同的操作系统上提供很高的运行效率 小众的Web框架 🍀 Quixote 🍀 Quixote 是由美国全国研究创新联合会的工程师 A.M.Kuchling , Neil Schemenauer 和 Greg Ward 开发的一个轻量级 Web 框架 , 它简单 , 高校 , 代码简洁 , 豆瓣的大部分用户产品都使用定制版的 Quixote 作为 Web 框架 它使用目录式的 URL 分发规则 , 用 Python 来写模板 , PTL 模板更适合程序员 , 但是并不适合美工参与前端代码的编写和修改 , 豆瓣在开发中使用了 Mako 替代 PTL ; 不建议在生产环境中选用 Quixote Klein 🍀 Klein 是 Twisted 组织开源出来的基于 werkzeug 和 twisted.web 的为框架 , Flask 很不错 , 但是不能使用异步非阻塞的方式编程 , 根本原因是它和 Django , Pyramid 一样 , 都基于 WSGI , 而WSGI 的接口是同步阻塞的 , Klein 用法非常像 Flask , 却可以使用异步的方式开发 Web 应用 选择 Web 框架时应遵循的原则 🍀 选择更主流的 Web 框架 , 因为他们文档齐全 , 技术积累更多 , 社区更繁盛 , 能得到更好的支持 关注框架的活跃情况 , 如果一个框架长时间没有更新 , 或者有一堆的问题需要解决但是没有得到回应 , 就不应该将这样的框架放在生产环境中 确认框架是否足够满足需求 , 没有最好的框架 , 只有最合适的框架 "},"05-Web框架/01-HTTP基础.html":{"url":"05-Web框架/01-HTTP基础.html","title":"HTTP基础","keywords":"","body":"HTTP基础 HTTP常用头字段 🍀 字段名 方向 解释 可能的值 Accept Request 接受什么介质类型 type/sub-type*/* 表示任何类型 , type/* 表示该类型下的所有子类型 Accept-Charset Request 接收的字符集 ISO-8859-1 Accept-Encoding Request 接收的编码方法 , 通常指定压缩方法 , 是否支持压缩 , 支持什么压缩方法 Gzip , deflate , UTF8 Accept-Language Request 接收的语言 En , cn Cache-Control Request 对服务器的缓存控制 no-cache : 不要从缓存中去取 , 要求现在从Web服务器中去取 Connection Request 连接状态通知 Close : 告诉Web服务器在完成本次请求的响应后 , 断开连接 , 不要等待本次连接的后续请求了Keepalive : 告诉Web服务器在完成本次请求的响应后 , 保持连接 , 等待本次连接的后续请求 Host Request 客户端指定自己想访问的Web服务器的域名 , IP 地址和端口号 IP : port Proxy-Authenticate Request 提供自己在代理服务器中的身份信息 Username : password range Request 需要获取对象的哪一部分内容 bytes=1024- : 获取从第1024个字节到最后的内容 Referer Request 浏览器向 Web 服务器表明自己是从哪个 URL 获得当前请求中的 URL 的 http://www.baidu.com User-Agent Request 指明浏览器的软件类型及版本 Mozilla/x.x: Windows浏览器Firefox/xx.x.x: Fiefox浏览器 Age Response 用该头部表示该实体从产生到现在经过多长时间 Authorization Response 当客户端接收到来 自 Web 服务器的WWW-Authenticate响应时 , 该头部回应自己的身份验证信息给Web服务器 Username : password Cache-Control Response 对客户端的缓存控制 Public : 可以用缓存内容回应任何用户Private : 只能用缓存内容回应先前请求该内容的那个用户 Connection Response 连接状态通知 Close : 连接已经关闭Keepalive : 连接保持 , 等待本次连接的后续请求 Expired Response Web服务器表明该实体将在什么时候过期 YYYY-MM-DD HH:MM:SS Location Response 访问的对象已经被转移到别的位置了 , 应该到本头字段指向的地址获取 http://mysite.com/another_url Proxy-Authenticate Response 代理服务器响应浏览器 , 要求其提供代理身份验证信息 Server Response 指明服务器的软件类型及版本 Nginx/1.14 Etag Both 内容唯一标识 , 服务端要把服务器传来的Etage保留 , 在下次请求相同的 URL 时提交给服务器 . 服务器用 Etag值判断同一个 URL 的内容是否有变化 , 如果有变化则发送更新的内容给客户端 任何值 Via Both 列出从客户端到服务器或者相反方向的响应经过了哪些代理服务器 , 它们用什么协议 (和版本) 发送的请求 HTTP常见错误代码 🍀 在每个 Response 的第1行中有一个整数状态码用于表达其对应 Request 的结果 , HTTP 除了约定该状态的表达方式 , 还约定了该状态的取值范围 , 约定的 5 类状态码如下 : 1xx : 信息 ; 表明服务器已经收到 Request , 但需要进一步处理 , 请客户端等待 2xx : 成功 ; 处理成功 3xx : 重定向 ; 请求的地址已被重定向 , 需要客户端重新发起请求 4xx : 客户端错误 ; 请求中提交的参数或内容有错误 5xx : 服务器错误 ; 服务器处理请求时出错 , 一般本类错误需要联系服务器管理员处理 注意 : 1xx~5xx 的错误为 HTTP 标准错误 , 在网站开发中如需要定义自己的错误代码 , 则需要避开该范围 常见 HTTP 错误代码表如下 : 代码 解释 代码 解释 代码 解释 100 继续等待 200 正常完成并返回 204 无内容 206 部分内容被返回 301 已移动 304 未修改 305 必须使用代理 400 语法错误 401 未授权 402 需要付费访问 403 禁止访问 500 服务器异常错误 501 未执行 502 上游的其他来源错误 503 临时过载或维护中 HTTP请求方法 🍀 HTTP 中常用的访问方式及其意义 访问方式的名称 意义 DELETE 从给定的地址中删除信息 GET 从访问的地址中获取信息 , 即获取信息头 , 也获取信息体 . 这是互联网上最主要的一种 HTTP 访问方式 HEAD 从访问的地址中获取信息 , 它与 GET 的区别是 : HEAD 只获取信息头 , 不获取信息体 . 在 Flask 路由中如果声明了 GET 访问方式 , 则无需显式地声明 HEAD 访问方式 OPTIONS 为客户端提供一种查询 \"本URL地址中有哪些可用的访问方式\" 的方法 POST 客户端通过 POST 方法向服务器提交新数据 , 服务器必须保证数据被完整地保存 , 并且服务器不允许出现重复的 POST 数据提交 , 这是 HTML 中通过表单提交数据所使用的 URL 访问方式 PUT 与 POST 访问方法类似 , POST 也是一种使客户端可以向服务器提交数据的方式 , 但是 PUT 允许客户端提交重复主键的数据 , 当通过 PUT 访问方式在服务器中发现重复主键的数据时 , 它会用新提交的数据覆盖服务器中已有的数据 "},"05-Web框架/02-REST.html":{"url":"05-Web框架/02-REST.html","title":"REST","keywords":"","body":"REST 介绍 🍀 REST 是 Representational State Transfer (表征状态转移) 的缩写 表征实际上指的是资源的表现特征 , 而资源指的是 Web 上一切可识别 , 可命名 , 可找到并被处理的实体 , 比如 HTML 页面 , 音频文件 , 图片等 用一个 URI (统一资源定位符) 指向资源 , 使用 HTTP 请求方法操作资源 , URL 可进一步划分为统一资源名 (URN , 代表资源的名字) 和统一资源定位符 (URL , 代表资源的地址) , 其中 URL 可以定位 HTTP 网址 , FTP 服务器和文件路径等 , 符合绝大多数场景 , 所以一般都可以用 URL 代替 URI REST架构约束 🍀 REST 架构风格最重要的架构约束有如下 5 个 : 客户端-服务端 , 这种 Client/Server 的架构形式提供了基本的分布式 , 客户端发起请求 , 服务端决定响应或者拒绝请求 , 如果出错则返回错误信息 , 由客户端处理异常 无状态 , 通信的会话状态应该全部由客户端负责维护 , 也就是请求中包含了全部必要的信息 . 如果使用基于服务端的会话 , 要么需要保证指定会话会使用同一个服务端响应所有请求 , 要么得创建一个可供所有服务器访问的公用的会话存储区 , 对每个请求都额外访问这个几种式的数据存储区获得会话状态 缓存 , 无状态就表示可能出现重复的请求 , 事实上这些请求只需要第一次真正的执行 , 其余的请求都可以享用这个已完成的记过而直接响应 , 所以缓存可以抵消一部分无状态带来的影响 统一接口 , 统一接口意味着每个 REST 应用都共享一种通用架构 , 那么熟悉这种架构的人一眼就能看明白接口的意义 , 并会继续延承下去 分层系统 , 将系统划分为几个部分 , 每个部分负责一部分相对单一的职责 , 然后通过上层对下层的依赖和调用组成一个完整的系统 , 通常可以划分为如下三层 : 应用层 : 负责返回 JSON 数据和其他业务逻辑 服务层 : 为应用层提供服务支持 , 如全站的账号系统 , 以及文件托管服务等 数据访问层 : 提供数据访问和存储的服务 , 如数据库 , 缓存系统 , 文件系统 , 搜索引擎等 如果一个架构符合 REST 原则 , 就称它为 RESTful 架构 RESTful API设计指南 🍀 使用名词表示资源 🍀 URI 不应该包含动词 , 动词应该通过不同的 HTTP 方法来体现 错误用法 : GET /getusers/1 POST /users/1/delete POST /users/1/create 正确用法 : GET /users/1 DELETE /users/1 PUT /users/1 关注请求头 🍀 一定要看请求头信息 , 并给予正确的状态码 , 例如 , 假设服务端只能返回 JSON 格式 , 如果客户端的头信息的 Accept 字段要求返回 application/xml , 这个时候就不应该返回 application/json 类型的数据 , 而应该返回 406 错误 合理使用请求方法和状态码 🍀 方法语义说明 方法 语义 OPTIONS 用于获取资源支持的所有 HTTP 方法 HEAD 用于只获取请求某个资源返回的头信息 GET 用于从服务器获取某个资源的信息 : 1. 完成请求后 , 返回状态码 200 OK2. 完成请求后 , 需要返回被请求的资源详细信息 POST 用于创建新资源 : 1. 创建完成后 , 返回状态码 201 Created2. 完成请求后 , 需要返回被创建的资源详细信息 PUT 用于完整的替换资源后者创建指定身份的资源 , 比如创建 id 为 123的某个资源 : 1. 如果是创建了资源 , 则返回 201 Created2. 如果是替换了资源 , 则返回 200 OK PATCH 用于局部更新资源 :1. 完成请求后 , 返回状态码 200 OK2. 完成请求后 , 需要返回被修改的资源详细信息 DELETE 用于删除某个资源 , 完成请求后返回状态码 204 NO Content 使用嵌套对象序列化 🍀 对象应该合理地嵌套 , 不应该都在一个层次上 , 如下的格式是不正确的 : { 'id': 1, 'post_id': '10001', 'post_name': 'Post1', 'post_content': 'this is a post' } 尽可能把相关联的资源信息内联在一起 , 应该把 post 作为一个键 : { 'id': 1, 'post': { 'id' : '10001', 'name': 'Post1', 'content': 'this is a post' } } 版本 🍀 常见的区分版本方法有三种 : 保存在 URI 中 , 比如 \"https://api.lyonyang.com/api/v2\" 放在请求头中 , 比如 GitHub 的用于 : \"Accept:application/vnd.github.v3+json\" 自定义请求头 , 比如 , \"X-Api-Version:1\" 推荐使用第一种方法 URI失效和迁移 🍀 随着业务发展 , 会出现一些 API 失效或者迁移 , 对失效的 API , 应该返回 \"404 not found\" 或 \"401 gone\" ; 对迁移的 API , 返回 301 重定向 速度限制 🍀 为了避免请求泛滥 , 给 API 设置速度限制很重要 , 为此 RFC 6585 引入了 HTTP 状态码 429 (too many requests) 加入限制功能后 , 应该提示用户 , 参照 GitHub 如下 : X-RateLimit-Limit : 当前时间段允许的并发请求书 X-RateLimit-Remaining : 当前时间段保留的请求数 X-RateLimit-Reset : 当前时间段剩余的秒数 我们使用 httpie 或者 curl 来访问 https://api.github.com/users/whatever : >curl -i https://api.github.com/users/whatever HTTP/1.1 200 OK Date: Mon, 01 Jun 2013 17:27:06 GMT Content-Type: application/json; charset=utf-8 Content-Length: 1350 Server: GitHub.com Status: 200 OK X-RateLimit-Limit: 60 X-RateLimit-Remaining: 59 X-RateLimit-Reset: 1530220396 ... 缓存 🍀 数据内容在一段时间不会变动 , 这个时候我们就可以合理地减少 HTTP 响应内容 , 应该在响应头中携带 Last-Modified , ETag , Vary , Date 等信息 , 客户端可以在随后请求这些资源时 , 在请求头中使用 If-Modified-Since , If-None-Match 等来确认资源是否进过修改 , 如果资源没有做过修改 , 那么就可以响应 \"304 Not Modified\" , 并且不在响应实体中返回任何内容 GitHub 用法如下 (隐藏了无关的自定义头) : >http https://api.github.com/users/lyonyang --headers HTTP/1.1 200 OK Access-Control-Allow-Origin: * Access-Control-Expose-Headers: ETag, Link, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval Cache-Control: public, max-age=60, s-maxage=60 Content-Encoding: gzip Content-Security-Policy: default-src 'none' Content-Type: application/json; charset=utf-8 Date: Thu, 04 Feb 2016 14:05:03 GMT ETag: W/\"02742979edf9240e6ea171ac41914d44\" Last-Modified: Mon, 25 Jun 2018 08:15:42 GMT Referrer-Policy: origin-when-cross-origin, strict-origin-when-cross-origin Server: GitHub.com Status: 200 OK Strict-Transport-Security: max-age=31536000; includeSubdomains; preload Transfer-Encoding: chunked Vary: Accept Vary: Accept-Encoding ... 通过 If-Modified-Since 实现缓存 : >http https://api.github.com/users/lyonyang \"If-Modified-Since: Thu, 04 Feb 2016 14:05:03 GMT\" --headers 并发控制 🍀 缺少并发控制的 PUT 和 PATCH 请求可能导致 \"更新丢失\" , 这个时候可以使用 Last-Modified 和 ETag 头来实现条件请求 , 具体原则如下 : 客户端发起的请求如果没有包含 If-Unmodified-Since 或者 If-Match 头 , 就返回 \"403 Forbidden\" , 在响应正文中解释为何返回该状态码 客户端发起的请求所提供的 If-Unmodified-Since 或者 If-Match 头与服务器记录的实际修改时间或 ETag 值不匹配时 , 返回状态码 \"412 Precondition Failed\" 客户端发起的请求所提供的 If-Unmodified-Since 或者 If-Match 头与服务器记录的实际修改时间或 ETag 的历史值匹配 , 但资源已经被修改过事 , 返回状态码 \"409 Conflict\" 客户端发起的请求所提供的条件服务实际值 就更新资源 , 响应 \"200 Ok\" 或者 \"204 No Content\" , 并且包含更新过的 Last-Modified 和 / 或 ETag 头 , 同时包含 Content-Location 头 , 其值为更新后的资源 URI "},"05-Web框架/03-ORM简介.html":{"url":"05-Web框架/03-ORM简介.html","title":"ORM简介","keywords":"","body":"ORM简介 介绍 🍀 ORM在开发者和数据库之间建立了一个中间层 , 把数据库中的数据转换成了 Python 中的对象实体 , 这样既屏蔽了不同数据库之间的差异性 , 又使开发者可以非常方便地操作数据库中的数据 , 而且可以使用面向对象的高级特性 ORM 为我们做了如下操作 : 将调用转换成 SQL 语句 通过数据库引擎发送给数据库执行 将数据库返回的结果记录用 ORM 映射技术转换成类对象 ORM 优点 : 向开发者屏蔽了数据库的细节 , 使开发者无需与 SQL 语句打交道 , 提高了开发小懒虫 便于数据库迁移 , 由于每种数据库的 SQL 语法有细微差别 , 所以基于 SQL 的数据访问层在更换数据库时通常需要花费大量的时间调试 SQL 语句 , 而 ORM 提供了独立于 SQL 的接口 , ORM 引擎会处理不同数据库之间的差异 , 所以迁移数据库时无须更改代码 应用缓存优化等技术有时可以提高数据库操作的效率 Python ORM 库介绍 🍀 Python 中提供 ORM 支持的组件有很多 , 每个组件的应用领域稍有区别 , 但是数据库操作的理论原理是相同的 , 下面对比较著名的 Python 数据库的 ORM 框架介绍 : SQLAlchemy : 是 Python 中最成熟的 ORM 框架 , 资源和文档都很丰富 , 大多数 Python Web 框架对其都有很好的支持 , 能够胜任大多数应用场合 ; SQLAlchemy 被认为是 Python 事实上的 ORM 标准 Django ORM : 是 Python 世界中大名鼎鼎的 Django Web 框架独用的 ORM 技术 , Django是一个大而全的框架 , 这使得其灵活性大大降低 , 其他 Python Web 框架可以随意更换 ORM , 但在 Django 中不能这样做 , 因为 Django 内置的很多 model 是用 Django 内置 ORM 实现的 Peewee : 小巧灵活 , 是一个轻量级的 ORM , Peewee 是基于 SQLAlchemy 内核开发的 , 整个框架只由一个文件构成 , Peewee 提供了对多种数据库的访问方式 , 如 SQLite , MySQL , PostgreSQL , 适用于功能简单的小型网站 Storm : 是一个中型的 ORM 库 ,比 SQLAlchemy 和 Django 等轻量 , 比 Peewee 的功能更丰富 , Storm 要求开发者编写数据表的 DDL 代码 , 而不能直接从数据表类定义中自动生成表定义 SQLObject : 与 SQLAlchemy 相似 , 也是一套大而全的 ORM , SQLObject 的特点是其设计借鉴了 Ruby on Rails 的 ActiveRecord 模型 , 是的熟悉 Ruby 的开发者上手非常容易 Peewee库使用 🍀 示例 : # 引入Peewee包的所有内容 from peewee import * # 建立一个SQLite数据库引擎对象,该引擎打开数据库文件sampleDB.db db = SqliteDatabase(\"sampleDB.db\") # 定义一个ORM的基类,在基类中指定本ORM所使用的数据库 # 这样在之后所有的子类中就不用重复声明数据库了 class BaseModel(Model): class Meta: database = db # 定义course表,继承自BaseModel class Course(BaseModel): id = PrimaryKeyField() title = CharField(null=false) period = IntegerField() description = CharField() class Meta: order_by = ('title',) db_table = 'course' # 定义teacher表,继承自BaseModel class Teacher(BaseModel): id = PrimaryKeyField() name = CharField(null=false) gender = BooleanField() description = CharField() course_id = ForeignKeyField(Course, to_field=\"id\", related_name=\"course\") class Meta: order_by = ('name',) db_table = 'course' 使用 ORM 映射对数据内容进行增 , 删 , 改 , 查 : # 建表,进需创建一次 Course.create_table() Teacher.craete_table() # 新增行 Course.create(id=1, title='经济学', period=320, description='文理科学生均可选修') Teacher.create(name='Lyon', gender=True, address='...', course_id=1) # 查询一行 record = Course.get(Course.title='经济学') print(\"课程:%s, 学时:%d\" % (record.titel, record.period)) # 更新 record.period = 200 record.save() # 删除 record.delete_instance() # 查询所有记录 courses = Course.select() # 带条件查询,并将结果按period字段倒序排序 courses = Course.select().where(Course.id100).execute() # 多表连接操作,Peewee会自动根据ForeignKeyField的外键定义进行连接 Record = Course.select().join(Teacher).where(Teacher.gender=True) "},"05-Web框架/Django/":{"url":"05-Web框架/Django/","title":"Django","keywords":"","body":"Django 介绍 本目录下为Django框架整理文章 , 内容概述如下 暂时内容不全 , 待后期更新修改 "},"05-Web框架/Django/01-Web框架简介.html":{"url":"05-Web框架/Django/01-Web框架简介.html","title":"Web框架简介","keywords":"","body":"Web框架简介 介绍 🍀 框架 (Framework) , 特指为解决一个开发性问题而设计的具有一定约束性的支撑结构 , 使用框架可以帮助我们快速开发特定的系统 , 简单说就是使用别人搭好的舞台 , 你来做表演 对于Web应用 , 本质其实就是一个socket服务端 , 而我们使用的浏览器就是一个socket客户端 , 如下 : # 服务端 import socket def handle_request(client): \"\"\"处理请求函数\"\"\" buf = client.recv(1024) print(buf) client.send(b\"HTTP/1.1 200 OK\\r\\n\\r\\n\") client.send(b\"Hello,Lyon\") def main(): \"\"\"主函数\"\"\" sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) sock.bind(('localhost', 8000)) sock.listen(5) while True: connection, address = sock.accept() # 连接成功后直接处理请求 handle_request(connection) connection.close() if __name__ == '__main__': main() ''' 说明: 执行该脚本后,用浏览器(客户端)访问 127.0.0.1:8000 连接成功后服务端直接应答以及发送 Hello,Lyon 于是网页就直接显示出了Hello,Lyon的标题 ''' 上述通过socket实现了其本质 , 而对于真是开发中的Python Web程序来说 , 一般会分为两部分 : 服务器程序和应用程序 服务器程序负责对socket服务器进行封装 , 并在请求到来时 , 对请求的各种数据进行整理 , 如上述代码 应用程序负责具体的逻辑处理 为了方便应用程序的开发 , 就出现了众多的Web框架 , 常见的Python Web框架如下 : Django : 全能型Web框架 Flask : 一个轻量级的Web框架 web.py : 一个小巧的Web框架 Bottle : 和Flask类似的Web框架 Tornado : Facebook的开源异步Web框架 不同的框架有不同的开发方式 , 但是无论如何 , 开发出的应用程序都要和服务器程序配合 , 才能为用户提供服务 也就是说框架和Web服务器之间进行通信 , 那么首先就需要两者互相支持 , 所以为了使Web服务器能够匹配多个不同的Web框架 , 就需要设立一个标准 , 在Python中这个标准就是WSGI WSGI 🍀 WSGI : WSGI (Web Server Gateway Interface , Web服务器网关接口) 它定义了使用Python编写Web应用与Web服务端之间的接口格式 , 实现了Web应用与Web服务器间的解藕 Python标准库提供的独立WSGI服务器称为wsgiref , 所以我们可以使用wsgiref模块开发一个自己的Web框架 关于wsgiref模块的更多内容请可以阅读Python之路 - wsgiref模块 > , 这也是完成下面内容的前提 自定义Web框架 🍀 框架 🍀 通过Python标准库提供的wsgiref模块开发 # 从simple_server模块中导入make_server函数 from wsgiref.simple_server import make_server # 处理函数 def index(): return 'index' # 处理函数 def login(): return 'login' # 路由管理函数 def routers(): urlpatterns = ( ('/index/',index), ('/login/',login), ) return urlpatterns # 该函数就是simple_server模块中的demo_app函数,即创建一个app def RunServer(environ, start_response): \"\"\" 符合WSGI标准的一个HTTP处理函数 environ:一个包含所有HTTP请求信息的dict对象 start_response:一个发送HTTP响应的函数 注:该函数会在内部调用start_response函数 \"\"\" # start_response接收两个参数,一个是HTTP响应码,如下\"200 OK\";另一个是一组list表示的HTTP Header,每个Header用一个包含两个str的tuple表示 start_response('200 OK', [('Content-Type', 'text/html')]) # 获取路径信息,即url url = environ['PATH_INFO'] urlpatterns = routers() func = None # 查看路径是否存在 for item in urlpatterns: if item[0] == url: func = item[1] break if func: return func() else: return '404 not found' if __name__ == '__main__': # 创建一个WSGI服务器 httpd = make_server('', 8000, RunServer) print(\"Serving HTTP on port 8000...\") # 开始监听HTTP请求 httpd.serve_forever() 模板引擎 🍀 在上一步中 , 对于处理函数login以及index仅仅做了最简单的处理 , 在现实的Web请求中一般会返回一个复杂的符合HTML规则的字符串 , 所以我们一般会将要返回给用户HTML写在指定文件中 , 然后再返回 , 进一步优化如下 : # 通过文件处理发送HTML信息 def index(): # return 'index' f = open('index.html') data = f.read() return data def login(): # return 'login' f = open('login.html') data = f.read() return data 如上我们实现了静态的页面处理 , 要使其能够给用户返回动态内容 , 我们有两种方法 : 自定义一套特殊的语法 , 进行替换 使用开源工具jinja2 , 遵循其指定语法 Jinja2介绍 : Jinja2是Python下一个被广泛应用的模板引擎 , 他的设计思想来源于Django的模板引擎 , 并扩展了其语法和一系列强大的功能 , 他基于unicode并能在python2.4之后的版本运行 , 包括python3 于是我们可以再进一步 from jinja2 import Template def index(): # return 'index' # template = Template('Hello !') # result = template.render(name='John Doe') f = open('index.html') result = f.read() template = Template(result) data = template.render(name='John Doe', user_list=['Lyon', 'Kenneth']) return data.encode('utf-8') def login(): # return 'login' f = open('login.html') data = f.read() return data 以上就完成了一个最简单的Web框架 MVC和MTV 🍀 MVC MVC (Model View Controller , 模型-视图-控制器) 是一种Web架构的模式 , 它把业务逻辑 , 模型数据 , 用户界面分离开来 , 让开发者将数据与表现解藕 , 前端工程师可以只改页面效果部分而不用接触后端代码 , DBA(数据库管理员) 可以重新命名数据表并且只需要更改一个地方 , 无序从一大堆文件中进行查找和替换 MVC模式甚至还可以提高代码复用能力 , 现在MVC模式依然是主流 MVC三要素 : Model表示应用程序核心(比如数据库记录列表) , 是应用程序中用于处理应用程序数据逻辑的部分 , 通常模型对象负责在数据库中存取数据 View显示数据(数据库记录) , 是应用程序中处理数据显示的部分 , 通常视图是依据模型数据创建的 Controller处理输入(写入数据库记录) , 是应用程序中处理用户交互的部分 , 通常控制器负责从视图读取数据 , 控制用户输入 , 并向模型发送数据 MVC模式同时提供了对HTML , CSS和JavaScript的完全控制 MVC的特点是通信单向的 : 浏览器发送请求 Contorller和Model交互获取数据 Contorller调用View View渲染数据返回 MTV 在Python的世界中 , 基本都使用了MVC的变种MTV (Model Templates View , 模型-模板-视图) MTV三要素 : Model , 和MVC的Model一样 , 处理与数据相关的所有事务 : 如何存取 , 如何确认有效性 , 包含哪些行为以及数据之间的关系等 Template , 处理与表现相关的决定 : 如何在页面或其他类型文档中进行显示出来 View , 处理业务逻辑 , 视图就是一个特定URL的回调函数 , 回调函数中描述数据 : 从Model取出对应的数据 , 调用相关的模板 . 它就是Contorller要调用的那个用来做Model和View之间的沟通函数 , 从而完成控制 两者的区别在于 : MVC中的View的目的是「呈现哪一个数据」 , 而MTV的View的目的是「数据如何呈现」 下一篇就开始学习Django啦 "},"05-Web框架/Django/02-Django - Django初识.html":{"url":"05-Web框架/Django/02-Django - Django初识.html","title":"Django - Django初识","keywords":"","body":"Django - Django初识 介绍 🍀 通过上一篇整理 , 对于Web框架应该清晰了很多 , 当然上一篇仅仅是自定义了一个最low , 最底端的Web框架 , 基本仅能处理特定的HTTP请求 , 那么这一章就开始学习Python Web框架中的王牌——Django Django本身集成了ORM , 模型绑定 , 模板引擎 , 缓存 , Session等诸多功能 Django是一个基于MVC模式构造的框架 , 但是在Django中 , 控制器接受用户输入的部分由框架自行处理 , 所以 Django 里更关注的是模型 (Model) , 模板 (Template) 和视图 (Views) , 即MTV模式 , 它们各自的职责如下 层次 职责 模型 (Model) , 即数据存取层 处理与数据相关的所有事务 : 如何存取、如何验证有效性、包含哪些行为以及数据之间的关系等 视图 (View) , 即表现层 处理与表现相关的决定 : 如何在页面或其他类型文档中进行显示 模板 (Template) , 即业务逻辑层 存取模型及调取恰当模板的相关逻辑 , 模型与模板的桥梁 安装 $pip install django 获取版本 >>> import django >>> django.get_version() '1.10.8' 添加环境变量 C:\\Python3.5\\Scripts - 具体路径自行添加 创建一个Django项目 🍀 我们使用命令行来进行创建 , 命令如下 django-admin startproject mysite - 当前目录下创建 # IDE创建Django程序时本质上都是自动执行了该命令 创建成功后可见 mysite ├── mysite # 对整个程序进行配置 │ ├── __init__.py │ ├── settings.py # 配置文件 │ ├── urls.py # URL对应关系 │ └── wsgi.py # 一个WSGI兼容的Web服务器入口,以便运行你的项目,上线uwsgi + nginx ├── db.sqlite3 # 默认使用sqlite └── manage.py # 用户管理Django的工具 PS : 如果我们使用Pycharm 来完成这项操作 , 那么其还会为我们自动创建一个templates 文件夹 , 用于存放模板 启动Django项目 🍀 创建完成后我们就可以通过以下命令启动Django项目了 python manage.py runserver 0.0.0.0:8000 ''' 0.0.0.0:让其他电脑可连接到开发服务器 8000:端口,如果不说明,默认为8000 ''' 启动项目后我们就可以在浏览器输入服务器的IP及端口进行访问了 , 即在浏览器输入http://127.0.0.1:8000 创建一个Django模型 🍀 Django规定 , 如果要使用应用模型 , 必须要创建一个app 执行如下命令创建app python manage.py startapp blog - 同样在manage.py所在目录下执行 创建完成后就可以看到如下文件了 blog ├── migrations # 数据库相关目录 | └── __init__.py ├── __init__.py ├── admin.py # admin后台管理文件 ├── apps.py # 应用文件 ├── models.py # 模型文件 ├── tests.py # 测试文件 └── views.py # 对整个程序进行配置 PS : 我们每创建一个模型 , 都需要在settings.py 中添加配置 , 如下所示 # mysite\\settings.py \"\"\"截取文件中的片段\"\"\" # Application definition INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'blog', # 此行为添加的配置 ] 同步数据库 🍀 在同步数据库之前需要先生成同步数据库的脚本 , 一般我们创建一个模型时这一步都自动为我们生成了 , 如果没有 , 则可以使用如下命令生成同步数据库的脚本 python manage.py makemigrations 而后进行同步数据库 python manage.py migrate 访问admin 🍀 django admin是django提供的一个后台管理页面 , 如果我们使用django admin则需要提前创建好后台管理员 (超级用户) , 以及url的配置 创建后台管理员 python manage.py createsuperuser 配置后台管理url # mysite\\urls.py urlpatterns = [ url(r'^admin/', admin.site.urls), ] '''当然这一步实际上我们创建Django项目时就为我们自动完成了''' 于是我们就可以访问admin了 , 即浏览器中访问http://127.0.0.0:8000/admin/ 其他命令如下 python manage.py flush - 清空数据库 django-admin.py help startapp - 查询某个命令的详细信息 python manage.py shell - 启动交互界面 本篇仅仅对Django做一个简单的介绍 , 详细内容见后续文章 "},"05-Web框架/Django/03-Django - Settings.html":{"url":"05-Web框架/Django/03-Django - Settings.html","title":"Django - Settings","keywords":"","body":"Django - Settings 介绍 🍀 Django项目的配置信息在Django项目建立时就已经为我们创建完成 , 也就是目录下的settings.py 文件 由 python manage.py startproject 命令生成 , 每个设置都有默认值 , 这些默认值定义在django/conf/global_settings.py中 如需查看修改了哪些设置 , 可使用命令python manage.py diffsettings 显示当前settings文件与django默认设置的不同之处 本章配置文件根据Django 1.11x 描述 , 并仅为初始基本配置 SECRET_KEY 🍀 SECRET_KEY 为一个特定的Django安装密钥 , 用于提供加密签名 使用django-admin startproject 命令时为每一个项目随机生成 , 如果SECRET_KEY 没有设置 , Django将拒绝启动 DEBUG 🍀 DEBUG 配置默认为True , 在此状态下会暴露出一些错误信息或者配置信息以方便调试 , 但是上线后应该将其关掉 , 防止配置信息或者敏感错误信息泄漏 DEBUG = False ALLOWED_HOSTS 🍀 ALLOWED_HOSTS 是为了限定请求中的host值 , 以防止黑客构造包来发送请求 , 只有在列表中的host才能访问 , 建议不要使用通配符去配置 注意 : 当DEBUG设置为False时 , 该配置必须配置 , 否则会抛出异常 默认配置为空 , 配置模板如下 : ALLOWED_HOSTS = [ '.example.com', # 允许是域名或子域名 '.example.com.', # 也允许是FQDN或子域名 ] INSTALLED_APPS 🍀 INSTALLED_APPS 是一个列表 , 里面是应用中需要加载的自带或者自定义的app包路经列表 , 所以我们每创建一个应用都需要在这里进行添加 , 如下 : INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'blog', ] MIDDLEWARE 🍀 MIDDLEWARE 是一个列表 , 里面为要使用的中间件列表 , 默认如下 : MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', ] ROOT_URLCONF 🍀 ROOT_URLCONF 为一个字符串 , 代表你的根URLconf的模块名 , 如下 : ROOT_URLCONF = 'mydjango.urls' TEMPLATES 🍀 TEMPLATES 为一个包含所有模板引擎设置的列表 , 列表中的每一项都是一个包含单个引擎选项的字典 , 如下 : TEMPLATES = [ { # 要使用的模板后端,内置的模板后端如下,还有django.template.backends.jinja2.Jinja2, 'BACKEND': 'django.template.backends.django.DjangoTemplates', # 在搜索顺序中引擎应该寻找模板源文件的目录,即绝对路径 'DIRS': [os.path.join(BASE_DIR, 'templates')] , # 设置引擎是否应该在安装的应用程序中查找模板源文件 'APP_DIRS': True, # 额外的参数传递给模板后端,可用参数因模板后端而异 'OPTIONS': { 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, }, ] WSGI_APPLICATION 🍀 WSGI_APPLICATION 为Django内置服务器 (如runserver) 的应用程序对象的完整Python路径 django-admin startproject 执行会创建一个简单的wsgi.py 应用程序 , 并将此设置指向该应用程序 WSGI_APPLICATION = 'mydjango.wsgi.application' DATABASES 🍀 DATABASES 为一个包含所有数据库配置的字典 , 它是一个嵌套的字典 , 其内容将数据库别名映射到包含单个数据库选项的字典 数据库设置必须配置一个默认数据库 , 还可以指定任意数量的附加数据库 DATABASES = { 'default': { 'ENGINE': 'django.db.backends.sqlite3', 'NAME': os.path.join(BASE_DIR, 'db.sqlite3'), 'USER': 'mydatabaseuser', 'PASSWORD': 'mypassword', 'HOST': '127.0.0.1', 'PORT': '5432', } } AUTH_PASSWORD_VALIDATORS 🍀 AUTH_PASSWORD_VALIDATORS 是一个列表 , 用于检查用户密码强度验证程序的列表 AUTH_PASSWORD_VALIDATORS = [ { 'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator', }, { 'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator', }, { 'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator', }, { 'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator', }, ] LANGUAGE_CODE 🍀 LANGEUAGE_CODE 是一个字符串 , 默认为 'en-us' , 即一个表示安装的语言代码的字符串 , 为标准语言ID格式 , 美国英语是 'en-us' USE_I18N 必须激活此设置才能起作用 LANGUAGE_CODE = 'en-us' TIME_ZONE 🍀 TIME_ZONE 表示此安装时区的字符串 , 新版本默认为'UTC' , 这不一定是服务器的时区 , 因为一个服务器可以服务多个Django支持的站点 , 每个站点都有一个单独的时区设置 如果USE_TZ 是False , 这是Django存储所有日期时间的时区 , 如果为True , 这是Django会使用显示模板日期时间的默认时区 TIME_ZONE = 'UTC' USE_I18N 🍀 USE_I18N 为一个bool值 , 指定Django的翻译系统是否应该启动 , 如果设置为False , Django将进行一些优化 , 以避免加载翻译器 USE_I18N = True USE_L10N 🍀 USE_L10N 为一个bool值 , 它指定了默认的数据的本地化格式是否可以在默认情况下使用 , 如果为True , Django将用当前的语言环境来显示数字和日期 USE_L10N = True USE_TZ 🍀 USE_TZ 为一个bool值 , 指定日期时间默认情况下是否是时区感知的 , 如果设置为True , Django将在内部使用时区感知的日期时间 USE_TZ = True STATIC_URL 🍀 STATIC_URL 为一个引用名 , 引用位于STATIC_ROOT的静态文件 , STATIC_ROOT 如下 : STATICFILES_DIRS = ( os.path.join(BASE_DIR,'static'), # 实际名,即实际文件夹的名字 ) 注意 : 引用时 , 只能按照引用名找 , 不能按实际名 静态文件 (static) 主要指 , CSS , JavaScript , Images这样的文件 更多管理静态文件 : https://docs.djangoproject.com/en/1.11/howto/static-files/ 更多settings相关 : https://docs.djangoproject.com/en/1.11/ref/settings/ "},"05-Web框架/Django/04-Django - Urls.html":{"url":"05-Web框架/Django/04-Django - Urls.html","title":"Django - Urls","keywords":"","body":"Django - Urls 介绍 🍀 如settings.py 一样 , django-admin startproject 或者python manage.py startproject 执行创建时 , 会为我们自动创建其一个名为URLconf (URL配置) 的Python模块 , 即urls.py 通常把它称为路由系统 url.py 是纯Python代码 , 是一个简单的Python模式 (简单的正则表达式) 到Python函数 (你的视图) 之间的映射 如默认下已经有了admin这一条 from django.conf.urls import url urlpatterns = [ # 由正则表达是到urls视图函数之间的一个映射 url(r'^admin/', admin.site.urls), ] ''' urlpatterns是一个列表 列表中是一个个url()实例 ''' url参数介绍 def url(regex, view, kwargs=None, name=None): \"\"\" regex:一个正则表达式字符串 view:一个可调用对象,通常为一个视图函数或一个指定视图函数路径的字符串 kwargs:可选的要传给视图函数的默认参数,字典形式 name:可选参数name,具体可以查看源码 \"\"\" 请求处理 🍀 Django如何处理一个请求 当用户从Django支持的站点请求页面时 , 系统会遵循以下的算法来确定要执行的Python代码 : Django决定是否使用ROOT_URLCONF配置 ; 如果传入HttpRequest对象具有一个urlconf属性(由中间件设置) , 则将使用其值代替ROOT_URLCONF设置 Django加载Python模块并查找变量urlpatterns , 即urls.py中的django.conf.urls.url()实例列表 Django按顺序遍历每个URL模式 , 并停在与请求的URL匹配的第一个URL模式 , 这意味着找到一个后就不会继续往下找了 , 也就会出现覆盖现象(前面的pattern覆盖后面的pattern) 一旦一个正则表达式匹配 , Django就会导入并调用给定的视图 (视图函数) , 该函数参数如下 : 一个HttpRequest实例 如果匹配的正则表达式没有返回任何命名组 , 则将正则表达式的匹配作为位置参数提供 关键字参数由任何与正则表达式匹配的命名组组成 , 在可选的kwargs参数中指定的任何参数覆盖到django.url.urls.url() 如果没有正则表达式匹配 , 或者在这个过程中的任何一点引发异常 , Django就会调用一个合适的错误处理视图进行处理 基本示例 🍀 # 导入url函数 from django.conf.urls import url # 导入视图模块 from . import views # url()实例列表 urlpatterns = [ # r表示Python原生字符串 url(r'^articles/2003/$', views.special_case_2003), url(r'^articles/([0-9]{4})/$', views.year_archive), url(r'^articles/([0-9]{4})/([0-9]{2})/$', views.month_archive), url(r'^articles/([0-9]{4})/([0-9]{2})/([0-9]+)/$', views.article_detail), ] 说明 请求/articles/2005/03/匹配列表中的第三个条目 , Django会调用函数views.month_archive(request, '2005', '03') /articles/2005/3/ 不匹配任何URL模式 , 因为列表中的第三个条目需要两位数的月份 /articles/2003/将匹配列表中的第一个模式 , 而不是第二个模式 , 因为模式是按顺序测试的 , 而第一个模式是第一个要传递的测试 ; 你可以随意地使用这种排序来插入一些特殊的例子 , 在这里 , Django将调用函数views.special_case_2003(request) /articles/2003 将不匹配任何这些模式 , 因为每个模式都要求URL以斜杠 \"/\" 结尾 /articles/2003/03/03/将匹配最终模式 , Django会调用函数views.article_detail(request, '2003', '03', '03') 注意 : 捕获的值是作为位置参数 分组命名 🍀 # 导入url函数 from django.conf.urls import url # 导入视图函数 from . import views # url()实例列表 urlpatterns = [ url(r'^articles/2003/$', views.special_case_2003), url(r'^articles/(?P[0-9]{4})/$', views.year_archive), url(r'^articles/(?P[0-9]{4})/(?P[0-9]{2})/$', views.month_archive), url(r'^articles/(?P[0-9]{4})/(?P[0-9]{2})/(?P[0-9]{2})/$', views.article_detail), ] 说明 请求/articles/2005/03/将调用函数views.month_archive(request, year='2005',month='03') 而不是 views.month_archive(request, '2005', '03') 请求/articles/2003/03/03/调用函数 views.article_detail(request, year='2003', month='03',day='03') 注意 : 捕获的值将作为关键字参数传递 , 而不是位置参数 匹配/分组算法 如果有命名参数 , 则使用命名参数 , 忽略非命名参数 否则 , 它将传递所有非命名参数作为位置参数 额外参数 🍀 django.conf.urls.url() 函数可以接收一个可选的第三个参数 (kwargs) , 它应该是一个额外的关键字参数的字典 , 如下 : from django.conf.urls import url from . import views urlpatterns = [ # 传递额外的参数foo url(r'^blog/(?P[0-9]{4})/$', views.year_archive, {'foo': 'bar'}), ] 在上述例子中 , 对于请求/blog/2005/ , Django将调用函数views.year_archive(request, year='2005', foo='bar') 处理冲突 : 可能有一个URL模式捕获命名的关键字参数 , 并且还在其额外参数的字典中传递具有相同名称的参数 , 发生这种情况时 , 将使用字典中的参数 , 而不是在URL中捕获的参数 反向解析 🍀 django.conf.urls.url() 函数中的第四个可选参数name , 我们可以利用该参数进行反向解析 , 相当于为我们配置的第一个参数 (regex) 取一个别名 实例 from django.conf.urls import url from . import views urlpatterns = [ # 为home取别名为h1 url(r'^home', views.home, name='h1'), # 为index取别名为h2 url(r'^index/(\\d*)', views.index, name='h2'), ] 设置名称之后 , 可以在不同的地方进行反向解析 , 如 : 模板中使用生成URL 用户: 密码: 函数中使用生成URL , django.urls.reverse('h2', args=(2012,)) model中使用获取URL , 自定义get_absoulte_url() 方法 class NewType(models.Model): caption = models.CharField(max_length=16) def get_absolute_url(self): \"\"\" 为每个对象生成一个URL应用, 在对象列表中生成查看详细的URL,使用此方法即可 \"\"\" # return '/%s/%s' % (self._meta.db_table, self.id) # 或 from django.urls import reverse return reverse('NewType.Detail', kwargs={'nid': self.id}) 路由分发 🍀 如果所有应用的url都放在urls.py 这一个文件中 , 这无疑会对我们管理url造成麻烦 , Django中提供了一个django.conf.urls.include() 函数 , 可以为我们提供一个url之间的映射 , 我们把这叫做路由分发 , 如下 : myapp/urls.py # 导入url函数 from django.conf.urls import url # 从应用视图导入homepage函数 from myapp.views import homePage urlpatterns = [ url(r'homepage', homePage), ] mydjango/urls.py # 导入url函数 from django.conf.urls import url # 导入include函数 from django.conf.urls import include # 导入admin函数 from django.contrib import admin urlpatterns = [ url(r'^admin/', admin.site.urls), # 引用myapp下的urls.py url(r'^myapp/', include(\"myapp.urls\")) ] 命名空间 🍀 mydjango.urls.py from django.conf.urls import url,include urlpatterns = [ url(r'^a/', include('app01.urls', namespace='author-polls')), url(r'^b/', include('app01.urls', namespace='publisher-polls')), ] app01.urls.py from django.conf.urls import url from app01 import views app_name = 'app01' urlpatterns = [ url(r'^(?P\\d+)/$', views.detail, name='detail') ] app01.views.py def detail(request, pk): print(request.resolver_match) return HttpResponse(pk) 以上定义带命名空间的url之后 , 使用name参数生成URL时 , 应该如下 : v = reverse('app01:detail', kwargs={'pk':11}) {% url 'app01:detail' pk=12 pp=99 %} Django中的路由系统和其他语言的框架有所不同 , 在Django中每一个请求的url都要有一条路由映射 ; 其他大部分的Web框架则是对一类的url请求做一条路由映射 , 从而使路由系统变得简洁 更多URL调度相关 : https://docs.djangoproject.com/en/1.11/topics/http/urls/ "},"05-Web框架/Django/05-Django - Views.html":{"url":"05-Web框架/Django/05-Django - Views.html","title":"Django - Views","keywords":"","body":"Django - Views 介绍 🍀 在前面的文章中已经整理了关于URLconf 的相关内容 , 我们知道url() 的第二个位置参数是一个视图函数 , 简称视图 , 视图函数其实就是一个简单的Python函数 , 它的作用就是接收Web请求并且返回Web响应 URLconf 就像是Django所支撑网站的目录 , 它的本质是URL模式以及要为该URL模式调用的视图函数之间的映射表 , 也就是每一个URL都有相对应的视图进行处理 在Django中当我们创建一个应用时 , 也就是执行命令python manage.py startapp app_name , Django会自动创建一个views.py 文件 , 用来存放我们的视图函数 Django对于views.py 的文件命名没有特别的要求 , 不在乎这个文件叫什么 , 但是根据约定 , 把它命名成views.py 是个好主意 , 这样有利于其他开发者读懂你的代码 一个简单视图 🍀 我们编写一个简单的视图 , Hello视图 blog\\views.py from django.http import HttpResponse def hello(request): # 视图中必须实现响应 return HttpResponse(\"Hello Lyon\") mysite\\urls.py from blog import views urlpatterns = [ url(r'^hello/', views.hello), ] 编写完成后我们就可以通过浏览器进行访问了 , 访问http://127.0.0.1:8000/hello/ 获取结果 这样我们就完成了一个非常简单的视图 , 接下来分析一下上面的代码 : 每个视图至少要有一个参数 , 通常被叫做request , 这是一个触发这个视图 , 包含当前Web请求信息的对象 , 是django.http.HttpRequest 的一个实例 这个视图会返回一个HttpResponse 对象 , 其中包含生成的响应 . 每个视图函数都负责返回一个HttpResponse对象 在urls.py 中我们需要导入视图模块 , 并配置好URL模式 注意 : 当访问URL/hello/ 时 , Django根据settings.py中的ROOT_URLCONF 的设置装载URLconf , 然后按顺序逐个匹配URLconf里的URLpatterns , 直到找到一个匹配的 HttpRequest 🍀 Django使用请求和响应对象来通过系统传递状态 当请求页面时 , Django创建一个HttpRequest 包含关于请求的元数据的对象 , 然后Django加载响应的视图 , 将HttpRequest 作为视图函数的第一个参数传递 , 而视图则负责返回一个HttpResponse 对象 , 这点在上节中已经有说明 HttpRequest对象的属性如果没有特别说明 , 都被认为是只读的 , 下面对HttpRequest对象的属性进行说明 HttpRequest属性 🍀 class HttpRequest [source] 属性 说明 HttpRequest.scheme 表示请求方案的字符串(通常为http或https) HttpRequest.body 原始Http请求的字节字符串 , 这对于处理数据的方式与传统的HTML表单很有用 ; 对于处理传统表单数据 , 请使用HttpRequest.POST ; 可以利用HttpRequest.read() 进行查看 HttpRequest.path 表示请求页面的完整路径的字符串 , 不包括scheme和 domain HttpRequest.path_info 在某些Web服务器配置下 , 主机名后的URL部分被分成脚本前缀部分和路径信息部分 , 该path_info属性始终包含路径的路径信息部分 , 无论使用何种Web服务器 HttpRequest.method 表示请求中使用的HTTP方法的字符串 , 必须为大写 , 即('GET'或'POST') HttpRequest.encoding 表示当前编码 HttpRequest.content_type 表示请求的MIME类型的字符串 , 从CONTENT_TYPE头部解析 HttpRequest.content_params 包含在CONTENT_TYPE头部的键/值参数的字典 HttpRequest.GET 一个包含所有给定的HTTP GET 参数的字典对象 , 详情阅读 QueryDict HttpRequest.POST 一个包含所有给定HTTP POST参数的字典对象 , 前提是请求包含表单数据 , 详情阅读 QueryDict HttpRequest.COOKIES 包含所有cookies的标准Python字典对象 ; keys和values都是字符串 HttpRequest.FILES 包含所有上传文件的类字典对象 , FILES中的每一个Key都是标签中name属性的值 , FILES中的每一个value同时也是一个标准的Python字典对象 , 包含下面三个Keys : filename , 上传文件名，用字符串表示 content_type , 上传文件的Content Typecontent , 上传文件的原始内容 HttpRequest.META 包含所有可用HTTP标头的字典 HttpRequest.resolver_match 一个ResolverMatch的实例 , 它表示已解析的URL 这个属性只在URL解析发生之后才被设置 , 这意味着它在所有的视图中都可用 , 但在解析发生之前执行的中间件中是不可用的 应用程序设置的属性 🍀 Django本身没有设置这些属性 , 但是如果你的应用程序设置了这些属性 , 就可以使用它们 属性 说明 HttpRequest.current_app url模板标签将使用它的值作为reverse() 的current_app参数 HttpRequest.urlconf 这将用作当前请求的根URLconf , 会覆盖ROOT_URLCONF设置 urlconf可以设置为None恢复以前中间件所做的任何更改并返回到使用ROOT_URLCONF 中间件设置的属性 🍀 包含在Django的contrib应用程序中的一些中间件在请求中设置了属性 , 如果在请求中看不到该属性，请确保列出了相应的中间件类MIDDLEWARE 属性 说明 HttpRequest.session 来自 SessionMiddleware : 唯一可读写的属性 , 代表当前会话的字典对象 ; 只有激活Django中的session支持时该属性才可用 HttpRequest.site 来自CurrentSiteMiddleware : 代表当前网站的实例Site或 RequestSite通过 get_current_site() 获取 HttpRequest.user 来自AuthenticationMiddleware : AUTH_USER_MODEL代表当前登录用户的一个实例。如果用户当前没有登录，user将被设置为一个AnonymousUser 实例 , 可以用 is_authenticated 进行区分 HttpRequest对象的方法点这里 : Methods 常用 get_full_path() , 返回path , 加上一个附加的查询字符串(如果使用) \"/music/bands/the_beatles/?print=true\" HttpResponse 🍀 HttpRequest对象是由Django自动创建的 , 而HttpResponse 对象是由我们自己来创建的 , 我们写的视图负责实例化 , 填充和返回一个HttpResponse 对象 这个HttpResponse 类定义在 django.http模块中 用法 🍀 传递字符串 典型的用法是将页面内容作为字符串传递给HttpResponse构造函数 >>> from django.http import HttpResponse >>> response = HttpResponse(\"Here's the text of the Web page.\") >>> response = HttpResponse(\"Text only, please.\", content_type=\"text/plain\") 如果想增加内容 , 可以将其当做类似文件对象使用 >>> response = HttpResponse() >>> response.write(\"Here's the text of the Web page.\") >>> response.write(\"Here's another paragraph.\") 传递迭代器 除了传递字符串 , 还可以传递一个迭代器对象 ; 它会立即使用迭代器 , 将其内容存储为字符串 , 然后丢弃 如果需要将响应以迭代器对象传输到客户端 , 则必须使用StreamingHttpResponse 类 设置标题栏 要设置或删除响应中的标题字段 , 可以将其视为字典 >>> response = HttpResponse() >>> response['Age'] = 120 >>> del response['Age'] 注意 : 如果标题字段不存在 , del 不会引发KeyError , 这一点与字典不同 告诉浏览器对待响应作为文件附件 要告诉浏览器将响应当做文件附件处理 , 可以使用content_type 参数并设置Content-Disposition 标题 返回一个Excel电子表格 >>> response = HttpResponse(my_data, content_type='application/vnd.ms-excel') >>> response['Content-Disposition'] = 'attachment; filename=\"foo.xls\"' 属性 🍀 HttpResponse属性 属性 说明 HttpResponse.content 表示内容的字符串 HttpResponse.charset 表示响应将被编码的字符串的字符串 , 如果在HttpResponse实例化的时候没有给出 , 则会从中提取 content_type , 如果不成功 , DEFAULT_CHARSET将使用该 设置 HttpResponse.status_code 该响应的 HTTP状态码 , 除非reason_phrase明确设置 , 否则修改 status_code构造函数外部的值也会修改值 reason_phrase HttpResponse.reason_phrase 响应的HTTP原因短语 , 它使用的HTTP标准的默认原因短语。 除非明确规定 , reason_phrase由价值决定status_code HttpResponse.streaming 此属性存在使中间件可以以不同于常规响应的方式处理流响应 , 一直为False HttpResponse.closed 如果响应已经结束则为True HttpResponse对象方法可见 : Method HttpResponse子类 🍀 Django包含许多HttpResponse处理不同类型HTTP响应的子类 , 这些子类都在django.http 中 , 子类如下 : class HttpResponseRedirect [source] class HttpResponsePermanentRedirect [source] class HttpResponseNotModified [source] class HttpResponseBadRequest [source] class HttpResponseNotFound [source] class HttpResponseForbidden [source] class HttpResponseNotAllowed [source] class HttpResponseGone [source] class HttpResponseServerError [source] 更多子类相关 : HttpResponse相关 https://docs.djangoproject.com/en/1.11/_modules/django/http/response/ render 🍀 为了方便 , Django中有一个shortcuts模块 , 其中收集了跨越多个级别的MVC的帮助函数和类 这里介绍一下其中的render()和redirect() : render , 对html进行渲染 redirect , 从当前页面进行跳转 def render(request, template_name, context=None, content_type=None, status=None, using=None): \"\"\" Returns a HttpResponse whose content is filled with the result of calling django.template.loader.render_to_string() with the passed arguments. \"\"\" content = loader.render_to_string(template_name, context, request, using=using) return HttpResponse(content, content_type, status) 必要参数 : request : 用于生成此响应的请求对象 template_name : 要使用的模板的全名或模板名称的序列 , 如果给出了一个序列 , 将使用存在的第一个模板 可选参数 : context : 要添加到模板上下文的值的字典 content_type : 用于生成文档的MIME类型 , 默认为DEFAULT_CONTENT_TYPE设置的值 status : 响应的状态码 , 默认为200 using : settings.py中NAME配置的模板引擎使用加载的模板 实例 from django.shortcuts import render def my_view(request): # View code here... return render(request, 'myapp/index.html', {'foo': 'bar',}, content_type='application/xhtml+xml') 上述实例相当于 from django.http import HttpResponse from django.template import loader def my_view(request): # View code here... t = loader.get_template('myapp/index.html') c = {'foo': 'bar'} return HttpResponse(t.render(c, request), content_type='application/xhtml+xml') redirect 🍀 def redirect(to, *args, **kwargs): \"\"\" Returns an HttpResponseRedirect to the appropriate URL for the arguments passed. The arguments could be: * A model: the model's `get_absolute_url()` function will be called. * A view name, possibly with arguments: `urls.reverse()` will be used to reverse-resolve the name. * A URL, which will be used as-is for the redirect location. By default issues a temporary redirect; pass permanent=True to issue a permanent redirect \"\"\" if kwargs.pop('permanent', False): redirect_class = HttpResponsePermanentRedirect else: redirect_class = HttpResponseRedirect return redirect_class(resolve_url(to, *args, **kwargs)) 默认返回一个临时的重定向 ; 传递permanent=True 可以返回一个永久的重定向 参数 : A model: the model’s get_absolute_url() function will be called. A view name, possibly with arguments: reverse() will be used to reverse-resolve the name. An absolute or relative URL, which will be used as-is for the redirect location. 实例 通过传递一些对象 , 该对象的get_absolute_url() 方法将被调用来找出重定向URL from django.shortcuts import redirect def my_view(request): ... object = MyModel.objects.get(...) return redirect(object) 通过传递一个视图的名称和可选的一些参数 , 该URL将通过reverse()` 方法反向解析 def my_view(request): ... return redirect('some-view-name', foo='bar') 通过传递一个硬编码的URL进行重定向 def my_view(request): ... return redirect('/some/url/') 也适用于完整的网址 def my_view(request): ... return redirect('https://example.com/') 默认情况下，redirect()返回一个临时重定向 , 所有上述形式都接受permanent参数 ; 如果设置为True永久重定向将被返回 def my_view(request): ... object = MyModel.objects.get(...) return redirect(object, permanent=True) 更多shortcuts内容 : Django shortcut functions The Django Book : http://docs.30c.org/djangobook2/index.html "},"05-Web框架/Django/06-Django - Model.html":{"url":"05-Web框架/Django/06-Django - Model.html","title":"Django - Model","keywords":"","body":"Django - Model 介绍 🍀 在我们的Web应用中 , 与数据库的交互不可避免 ; 数据库驱动网站在后台链接数据库服务器 , 从中取出一些数据 , 然后在Web页面用漂亮的格式展示这些数据 , 这就是我们需要的模型(Model) 我们知道Python中的sqlalchemy 是一个第三方的ORM框架 , Django中的Model也是通过ORM来进行数据库管理的 特点 : 每个模型都是django.db.models.Molde 的一个Python子类 模型的每个属性都表示为数据库中的一个字段 一旦我们创建一个数据模型 , Django会自动为我们提供一个数据抽象API , Making queries 当我们执行python manage.py startapp app_name 命令时 , Django就已经为我们自动创建了一个models.py 文件 , 就是用来存放我们的模型定义的 注意 : 我们创建模型前 , 需要将数据库相关配置完成 , 方法见settings整理文章 简单示例 🍀 首先创建一个应用 python manage.py startapp myapp 安装应用 # settings.py INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'myapp', # 此行为添加项 ] 定义模型 # myapp/models.py # 导入models from django.db import models # 必须继承models.Model class Userinfo(models.Model): username = models.CharField(max_length=30) password = models.CharField(max_length=20) 生成模型 # Django 1.6.x 及以下 python manage.py syncdb # Django 1.7.x 及以上 python manage.py makemigrations # 生成同步记录 python manage.py migrate # 开始同步 这里我使用的是Django 1.7.x 及以上版本 , 可见信息如下 : # 生成同步记录 mysite>python manage.py makemigrations No changes detected # 开始同步 mysite>python manage.py migrate Operations to perform: Apply all migrations: admin, auth, contenttypes, sessions Running migrations: Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying auth.0008_alter_user_username_max_length... OK Applying sessions.0001_initial... OK # 默认使用sqlite 以上的Person模型会在数据库中创建这样一张表 : CREATE TABLE myapp_userinfo ( \"id\" serial NOT NULL PRIMARY KEY, \"username\" varchar(30) NOT NULL, \"password\" varchar(20) NOT NULL ); 注意 : 表名称是根据模型中的某些元数据自动生成的 , 也可以重写 , Table names id字段是Django自动为我们添加的一个主键 , 也可以重写 , Automatic primary key fields Django会根据settings.py 中指定的数据库类型来使用相应的SQL语句 如果我们使用的数据库为MySQL : Django对于MySQL默认使用的是MySQLdb模块 , 而Python 3 中是没有MySQLdb的 , 使用的是pymsql , 所以我们需要添加以下内容 # mysite/__init__.py import pymysql pymysql.install_as_MySQLdb()　 # settings DATABASES = { 'default': { 'ENGINE': 'django.db.backends.mysql', 'NAME':'dbname', 'USER': 'root', 'PASSWORD': 'xxx', 'HOST': '', 'PORT': '', } } 添加数据 🍀 添加数据需要先创建对象 , 然后再执行save函数 , 相当于SQL中的INSERT myapp/views.py # 一步完成:使用create函数 from django.http import HttpResponse from myapp import models def add_user(request): models.Userinfo.objects.create(username='Lyon', password='123456') # models.Userinfo.objects.create(**user1) user1={'username':'Lyon','password':'123465'} return HttpResponse('数据添加成功!') # 先创建对象后执行操作:使用save函数 from django.http import HttpResponse from myapp import models def add_user(request): user1 = models.Userinfo(username='Lyon', password='123456') user1.save() return HttpResponse('数据添加成功!') mysite/urls.py from myapp import views urlpatterns = [ url(r'^add_user/', views.add_user), ] 访问http://127.0.0.1:8000/testdb/ 完成添加 查询数据 🍀 myapp/views.py from myapp import models def select_user(request): # 通过objects这个模型管理器的all()获得所有数据行,相当于SQL中的SELECT * FROM result = models.Userinfo.objects.all() # filter相当于SQL中的WHERE,可设置条件过滤结果 response1 = models.Userinfo.objects.filter(id=1) # 获取单个对象 response2 = models.Userinfo.objects.get(id=1) # 限制返回的数据,相当于SQL中的OFFSET 0 LIMIT 2; models.Userinfo.objects.order_by('username')[0:2] # 数据排序 models.Userinfo.objects.order_by(\"id\") # 上面的方法可以连锁使用 models.Userinfo.objects.filter(username=\"Lyon\").order_by(\"id\") # all()返回的是一个QuerySet对象,即封装了一行数据的所有属性的对象 for var in result: print(var.id,var.username,var.password) print(response1) print(response2) return HttpResponse('查询成功!') mysite/urls.py from myapp import views urlpatterns = [ url(r'^select_user/', views.select_user), ] 删除数据 🍀 myapp/views.py from myapp import models def delete_user(request): models.Userinfo.objects.filter(username='Lyon').delete() models.Userinfo.objects.all().delete() return HttpResponse('删除成功!') mysite/urls.py from myapp import views urlpatterns = [ url(r'^delete_user/', views.delete_user), ] 更新数据 🍀 myapp/views.py from myapp import models def update_user(request): models.Userinfo.objects.filter(username='Lyon').update(username='Kenneth') models.Userinfo.objects.all().update(password='456789') return HttpResponse('更新成功!') mysite/urls.py from myapp import views urlpatterns = [ url(r'^update_user/', views.update_user), ] 本章仅对Model进行简单的操作介绍 详细参考 : Model instance reference "},"05-Web框架/Django/07-Django - Model Fields.html":{"url":"05-Web框架/Django/07-Django - Model Fields.html","title":"Django - Model Fields","keywords":"","body":"Django - Model Fields 介绍 🍀 对于一个模型来说 , 最重要的和不可或缺的是列出该模型在数据库中定义的字段 字段由属性指定 , 但是选择的字段名称不要和models API 冲突 , 比如 save , clean 或者 delete , 如下 : from django.db import models class Musician(models.Model): first_name = models.CharField(max_length=50) last_name = models.CharField(max_length=50) instrument = models.CharField(max_length=100) class Album(models.Model): artist = models.ForeignKey(Musician, on_delete=models.CASCADE) name = models.CharField(max_length=100) release_date = models.DateField() num_stars = models.IntegerField() 字段类型 🍀 模型中的每个字段都是 Field 子类的某个实例 , Djnaog根据字段的类型确定以下信息 : 列类型 , 它告知数据库要存储哪种数据 (如 , INTEGER , VARCHAR , TEXT) 渲染表单时使用的默认HTML widget , 例如 : , ). 即使用select小部件 最低限度的验证需求 , 它被用在Django管理站点和自动生成的表单中 Django拥有数十种内置的字段类型 ; 你可以在 model field reference 中找到完整列表 , 如果Django内置的字段不能满足我们的要求 , 那么我们可以进行自定义模型字段 : Writing custom model fields 字段选项 🍀 每个字段都接受一组与字段有关的参数 , 例如 , CharField (和它的派生类) 需要max_length 参数来指定VARCHAR 数据库字段的大小 而对于所有的字段类型 , 都有一组通用的参数可供使用 , 以下介绍一些最常用的 : 参数 说明 null 如果为True , Django将会把数据库中的空值保存为NULL ; 默认为False blank 如果为True , 该字段允许为空值 ; 默认为False choices 一个二元组组成的可迭代对象 (list或tuple) , 用来给字段提供选择项 ; 如果设置了choices , 默认的表单将是一个选择框而不是标准的文本框 , 而且这个选择框的选项就是choices中的选项choices实例见表格补充 default 默认值 , 可以是一个值或可调用对象 , 如果是可调用对象 , 那么每个新对象被创建它都会被调用 help_text 表单部件额外显示的帮助内容 , 即使字段不在表单中使用 , 它对生成文档也很有用 primary_key 如果为True , 那么这个字段就是模型的主键如果没有指定任何一个字段的primary_key=True , Django就会自动添加一个IntegerField字段作为主键 , 也就是字段 id主键字段是只读的 , 如果你在一个已存在的对象上面更改主键的值并且保存 , 那么就会在原有对象之外创建出一个新的对象 unique 如果True , 则这个字段在整张表中必须是唯一的 表格补充 : choices实例 YEAR_IN_SCHOOL_CHOICES = ( ('FR', 'Freshman'), ('SO', 'Sophomore'), ('JR', 'Junior'), ('SR', 'Senior'), ('GR', 'Graduate'), ) ''' 元组中的第一个元素是将被存储在数据库中的值,第二个元素将由默认窗体小部件或ModelChoiceField显示 给定一个模型实例,可以使用get_FOO_display()方法来访问选项字段的显示值 ''' 访问选项字段的显示值 from django.db import models class Person(models.Model): SHIRT_SIZES = ( ('S', 'Small'), ('M', 'Medium'), ('L', 'Large'), ) name = models.CharField(max_length=60) shirt_size = models.CharField(max_length=1, choices=SHIRT_SIZES) # 创建Person对象 >>> p = Person(name=\"Fred Flintstone\", shirt_size=\"L\") # 保存到数据库 >>> p.save() # 查看shirt_size属性 >>> p.shirt_size 'L' # 查看shirt_size显示值 >>> p.get_shirt_size_display() 'Large' 注 : 上述仅仅对最常见的字段选项进行说明 , 完整查看 common model field option reference 自增主键字段 🍀 默认 , Django给了每个模型一个主键字段 : id = models.AutoField(primary_key=True) 这是一个自增主键 当我们想指定一个自定义主键字段时 , 只需要在某个字段上指定primary_key=True 即可 , 因为Django看到你显示地设置了Field.primary_key 就不会自动添加id 列 每个模型只能有一个字段指定primary_key=True 字段的自述名 🍀 除了ForeignKey , ManyToManyField 和 OneToOneField 之外 , 每个字段类型都接受一个可选的位置参数 , 即字段的自述名 (在第一的位置) ; 如果没有给定自述名 , Django将根据字段的属性名称自动创建自述名 , 即将属性名称的下划线替换成空格 实例 # 自述名为person's first name first_name = models.CharField(\"person's first name\", max_length=30) # 自述名为first name first_name = models.CharField(max_length=30) ForeignKey , ManyToManyField 和OneToOneField都要求第一个参数是一个模型类 , 所以要使用verbose_name 关键字参数才能指定自述名 : poll = models.ForeignKey( Poll, on_delete=models.CASCADE, verbose_name=\"the related poll\", ) sites = models.ManyToManyField(Site, verbose_name=\"list of sites\") place = models.OneToOneField( Place, on_delete=models.CASCADE, verbose_name=\"related place\", ) 习惯上 , verbose_name 的首字母不用大写 , Djnaog在必要的时候会自动大写首字母 数据库关系 🍀 关系型数据库的威力体现在表之间的相互关联 , 而Django提供了三种最常见的数据库关系 : 多对一 , many - to - one 多对多 , many - to - many 一对一 , ont - to - one 多对一 🍀 Django使用django.db.models.ForeignKey 定义多对以关系 和使用其它字段类型一样 , 在模型当中把它作为一个类属性使用 class ForeignKey(to, on_delete, **options): \"\"\" ForeignKey需要两个位置参数,模型相关联的类和on_delete选项 更多详细内容:https://docs.djangoproject.com/en/1.11/ref/models/fields/#foreignkey \"\"\" 实例 from django.db import models # 制造商可以生产很多汽车 class Manufacturer(models.Model): # ... pass # 每一辆汽车只能有一个制造商 class Car(models.Model): manufacturer = models.ForeignKey(Manufacturer, on_delete=models.CASCADE) # ... 若要创建递归关联关系 , 即具有多对一关系的对象需要使用 models.ForeignKey('self' , on_delete=models.CASCADE) 如果需要在尚未定义的模型上创建关系 , 可以使用模型的名称 , 而不是模型对象本身 : from django.db import models class Car(models.Model): manufacturer = models.ForeignKey( 'Manufacturer', on_delete=models.CASCADE, ) # ... class Manufacturer(models.Model): # ... pass # 更多说明:https://docs.djangoproject.com/en/1.11/ref/models/fields/#ref-foreignkey ForeignKey字段还接受许多别的参数 , 更多 : the model field reference 多对一更多示例 : Many-to-one relationship model example 多对多 🍀 ManyToManyField 字段是用来定义多对多关系的 , 同使用其他字段类型一样 class ManyToManyField(to, **options): \"\"\" 多对多关系,需要一个位置参数:模型相关联的类 它与ForeignKey的工作方式完全相同,包括递归和延迟(未定义)关系 \"\"\" 实例 from django.db import models # 一种装饰可以在多个Pizza上 class Topping(models.Model): # ... pass # 一个Pizza上可以有多种装饰 class Pizza(models.Model): # ... toppings = models.ManyToManyField(Topping) 官方文档中建议以被关联模型名称的复数形式作为ManyToManyField 的名字 , 如上实例中为toppings 对于多对多关系 , 在哪个模型中设置ManyToManyField 都可以 , 但是不要两个模型都设置 完整示例 : Many-to-many relationship model example 中介模型 🍀 对与上一节中Pizza和Topping搭配这样简单的多对多关系时 , 使用标准的ManyToManyField 就可以了 , 但是有时我们可能需要关联数据到两个模型之间的上 例如 , 有这样一个应用 , 它记录音乐家所属的音乐小组 , 我们可以用一个ManyToManyField 表示小组和成员之间的多对多关系 , 但是 , 有时你可能想知道更多成员关系的细节 , 比如成员是何时加入小组的 , 对于这些情况 , Django允许你指定一个中介模型 来定义多对多关系 , 你可以将其他字段放在中介模型里面 源模型的ManyToManyField 字段将使用through参数指向中介模型 , 实例 : from django.db import models # 音乐家,目标模型 class Person(models.Model): name = models.CharField(max_length=128) def __str__(self): # __unicode__ on Python 2 return self.name # 音乐小组,源模型 class Group(models.Model): name = models.CharField(max_length=128) # 通过through参数指向中介模型Membership members = models.ManyToManyField(Person, through='Membership') def __str__(self): # __unicode__ on Python 2 return self.name # 中介模型 class Membership(models.Model): person = models.ForeignKey(Person, on_delete=models.CASCADE) group = models.ForeignKey(Group, on_delete=models.CASCADE) date_joined = models.DateField() invite_reason = models.CharField(max_length=64) 中介模型的一些限制 : 中介模型必须有且只有一个外键到源模型 , 或者必须使用ManyToManyField.through_fields 显示指定Django应该在关系中使用的外键 ; 如果你的模型中存在不止一个外键 , 并且through_fields 没有指定 , 将会触发一个无效的错误 . 对目标模型的外键有相同的限制(Person) 对于通过中介模型与自己进行多对多关联的模型 , 允许存在到同一个模型有两个外键 , 但他们将被当做多对多关联中一个关系的两边 ; 如果有超过两个外键 , 同样你必须像上面一样指定through_fields , 否则将引发一个验证错误 使用中介模型定义与自身的多对多关系时 , 你必须设置symmetrical=False , 详细见the model field reference 设置好中介模型(Membership)后 , 接下来要开始创建多对多关系 , 首先创建中介模型的实例 : >>> ringo = Person.objects.create(name=\"Ringo Starr\") >>> paul = Person.objects.create(name=\"Paul McCartney\") >>> beatles = Group.objects.create(name=\"The Beatles\") >>> m1 = Membership(person=ringo, group=beatles, ... date_joined=date(1962, 8, 16), ... invite_reason=\"Needed a new drummer.\") >>> m1.save() >>> beatles.members.all() ]> >>> ringo.group_set.all() ]> >>> m2 = Membership.objects.create(person=paul, group=beatles, ... date_joined=date(1960, 8, 1), ... invite_reason=\"Wanted to form a band.\") >>> beatles.members.all() , ]> 与普通的多对多字段不同 , 不能使用add() , create() 和 set() 来建立关系 : >>> # The following statements will not work >>> beatles.members.add(john) >>> beatles.members.create(name=\"George Harrison\") >>> beatles.members.set([john, paul, ringo, george]) 因为你不能只创建Membership 和Group 之间的关联关系 , 你还要指定Person模型中所需要的所有信息 , 而简单的add() , create() 和复制语句是做不到这一点的 ; 所以它们不能在使用中介模型的多对多关系中使用 , 唯一的办法就是创建中介实例 同上remove() 也被禁用 , 但是clear()方法是可以用的 , 因为它会清空某个实例所有的多对多关系 >>> # Beatles have broken up >>> beatles.members.clear() >>> # Note that this deletes the intermediate model instances >>> Membership.objects.all() 建立好关系之后 , 就可以执行查询了 '''直接使用被关联模型的属性进行查询''' # Find all the groups with a member whose name starts with 'Paul' >>> Group.objects.filter(members__name__startswith='Paul') ]> '''利用中介模型的属性进行查询''' # Find all the members of the Beatles that joined after 1 Jan 1961 >>> Person.objects.filter( ... group__name='The Beatles', ... membership__date_joined__gt=date(1961,1,1)) '''直接获取Membership模型''' >>> ringos_membership = Membership.objects.get(group=beatles, person=ringo) >>> ringos_membership.date_joined datetime.date(1962, 8, 16) >>> ringos_membership.invite_reason 'Needed a new drummer.' '''还有一种方法是在Person对象查询多对多反向关系''' # 详细见https://docs.djangoproject.com/en/1.11/topics/db/queries/#m2m-reverse-relationships >>> ringos_membership = ringo.membership_set.get(group=beatles) >>> ringos_membership.date_joined datetime.date(1962, 8, 16) >>> ringos_membership.invite_reason 'Needed a new drummer.' 一对一 🍀 OneToOneField 用来定义一对一关系 , 和使用其它字段类型一样 当某个对象想扩展自另一个对象时 , 最常用的方式就是这个对象的主键上添加一对一关系 class OneToOneField(to, on_delete, parent_link=False, **options): \"\"\" OneToOneField和ForeignKey以及ManyToManyField一样 它有两个位置参数:相关联的类以及on_delete选项 parent_link:该参数为True且使用从另一个具体模型继承的模型时,表明该字段应该作为返回到父类的链接,而 而不是通常由子类隐式创建的额外的OneToOneField \"\"\" 如果你正在建立一个\"places\" 的数据库 , 那么你将建立一个非常标准的地址 , 电话号码等 , 在数据库中; 接下来 , 如果你想在places数据库的基础上建立一个restaurant数据库 , 而不想将已有的字段复制到Restaurant模型 , 那么你可以在Restaurant添加一个OneToOneField字段 , 这个字段指向Place (因为Restaurant本身就是一个Place) , 事实上 , 在处理这个问题时 , 我们应该使用一个典型的inheritance , 因为它隐含一个一对一关系 示例 : https://docs.djangoproject.com/en/1.11/topics/db/examples/one_to_one/ 与ForeignKey一样 , 可以定义 recursive relationship 和 references to as-yet undefined models Meta选项 🍀 使用内部的class Meta 可以定义模型的元数据 , 如下 : from django.db import models class Ox(models.Model): horn_length = models.IntegerField() class Meta: ordering = [\"horn_length\"] verbose_name_plural = \"oxen\" 模型元数据是任何不是字段的数据 , 比如排序选项 (ordering) , 数据库表名 (db_table) 或者可读的单复数名称 (verbose_name和verbose_name_plural) 所有Meta选项的完整列表见 : model option reference 更多相关内容 : https://docs.djangoproject.com/en/1.11/topics/db/models/ "},"05-Web框架/Django/08-Django - Model Field Options.html":{"url":"05-Web框架/Django/08-Django - Model Field Options.html","title":"Django - Model Field Options","keywords":"","body":"Django - Model Field Options 介绍 🍀 本篇文章为\"工具\"笔记 , 适合用于翻阅查找 , 对于字段元选项的总结 以下字段选项对于所有字段类型都是可选的 null 🍀 说明 如果为 True , 则Django将在数据库中将空值存储为NULL , 也意味着该字段可填可不填 , 默认为 False 示例 class Student(models.Model): name = models.CharField(null=True) 特别的 : 应该避免在基于字符串的字段中字段中使用 null=True , 例 : CharField 和 TextField ; 因为空字符串值会存储为空字符串而不是NULL , 而如果使用该选项 , 则意味着 \"无数据\" 可能有两种状态 , NULL 和空字符串 , 并且在大多数情况下 , Django中惯例使用空字符串而不是 NULL 如果在 CharField 中同时拥有两个选项 , unique=True 与 blank=True , 那么需要设置 null=True 来防止在保存多个空白值 (blank=True的结果)时违反 unique=True 唯一约束 null 选项是纯粹的数据库范畴 , 针对数据库的选项 , 即数据库中 , 数据是否能为空值 如果我们需要在BooleanField 字段中设置 null , 我们应该使用 NullBooleanField 字段来代替 blank 🍀 说明 与上面的 null 不同 , blank 针对的是数据验证的范畴 , 如在使用 admin 录入数据时 , 默认不允许输入空值 , 通过设置 blank=True 即可输入空值 在设计表时 , 如果仅设置 null=True , 那么在使用 admin 录入数据时 , 是不可输入空值的 示例 class Student(models.Model): name = models.CharField(blank=True) choices 🍀 说明 设置 choices 后 , 该字段就为一个选择框 (设置 max_length 选项指定可选数) , 设置值为一个可迭代的结构 , 如上示例中 : 每个元组中的第一个元素 , 是存储在数据库中的值 ; 第二个元素是该选项的描述值 示例 class Student(models.Model): YEAR_IN_SCHOOL_CHOICES = ( ('FR', 'Freshman'), ('SO', 'Sophomore'), ('JR', 'Junior'), ('SR', 'Senior'), ) # default为默认选择项 year_in_school = models.CharField(max_length=2, choices=YEAR_IN_SCHOOL_CHOICES, default='FR') 除了单层的二元元组 , 还可以设置成多成二元元组 : MEDIA_CHOICES = ( ('Audio', ( ('vinyl', 'Vinyl'), ('cd', 'CD'), ) ), ('Video', ( ('vhs', 'VHS Tape'), ('dvd', 'DVD'), ) ), ('unknown', 'Unknown'), ) 同样的 , 第一个元素为组的名字 , 第二个元素为描述值 , 并且每个二元元组的第一个元素是不可选的 , 可选选项为最里层的二元元组的第二个元素 , 例如 : 'Vinyl' , 'CD' Django中 , 对于每一个选择框 , 都有一个 get_fieldname_display() 方法以获取描述值 (二元元组的第二个元素) , 如下 : >>> stu = Student(year_in_school=\"FR\") >>> stu.save() >>> stu.year_in_school 'FR' >>> stu.get_year_in_school_display() 'Freshman' PS : 如果不指定默认选项 , 那么选择菜单默认为 \"-----------\" , 如果我们要进行重写 , 只需在元组添加一项包含None的元组到 choices 中 , 如 : (None, 'Your Choices') db_column 🍀 说明 指定在数据库中的字段名 , 默认使用 Field 名 (即示例中的 name ) 示例 class Student(models.Model): name = models.CharField(max_length=32, db_column=\"姓名\") # 数据库表 +----+---------+ | id | 姓名 | +----+---------+ | 1 | lyon | +----+---------+ db_index 🍀 说明 为字段创建索引 , 默认为 False , 设置为 True Django会为该字段创建数据库索引 示例 class Student(models.Model): name = models.CharField(max_length=32, db_index=True) db_tablespace 🍀 待整理 default 🍀 说明 设置字段的默认值 , 该值可为一个值或一个可调用对象 , 但是不可为可变对象 (dict , list , ...) ; 如果为一个可调用对象 , 那么每次创建实例时都会被调用一次 示例 def contact_default(): return {\"email\": \"to1@example.com\"} class Student(models.Model): name = models.CharField(max_length=32, default=\"未知\") # 默认值为可调用对象 contact_info = JSONField(\"ContactInfo\", default=contact_default) PS : 可调用对象不可使用 lambdas 函数 , 因为这类参数无法被 migrations 命令进行序列化 editable 🍀 说明 默认为 True , 如果设置为 False , 那么这个字段将不会出现 admin (本质使用了ModelForm) 或者其他 ModelForm 中 示例 class Student(models.Model): role = models.CharField(max_length=32, editable=False) error_messages 🍀 说明 指定 error_messages 选项可以更改该字段将引发的默认错误信息 , error_messages 为一个字典 , 其中 key 包括 : null , blank , invalid , invalid_choice , unique 以及 unique_for_data (Django 1.7以上版本后添加) 示例 class Student(models.Model): name = models.CharField(max_length=32, db_column=\"姓名\", error_messages={ 'null':\"不能为空\", }) 它们的默认错误信息如下 : default_error_messages = { 'invalid_choice': _('Value %(value)r is not a valid choice.'), 'null': _('This field cannot be null.'), 'blank': _('This field cannot be blank.'), 'unique': _('%(model_name)s with this %(field_label)s ' 'already exists.'), # Translators: The 'lookup_type' is one of 'date', 'year' or 'month'. # Eg: \"Title must be unique for pub_date year\" 'unique_for_date': _(\"%(field_label)s must be unique for \" \"%(date_field_label)s %(lookup_type)s.\"), # 特殊的,在Field的派生类中定义,以DateField为例 'invalid': \"'%(value)s' value has an invalid date format. It must be \" \"in YYYY-MM-DD format.\" } help_text 🍀 说明 该选项会在表单控件form中 , 添加一些文档 , 文档会出现在 input 框下方 示例 class Student(models.Model): name = models.CharField(max_length=32, help_text='这里填名字') PS : 默认会对文档进行HTML转换 , 所以为了避免任何HTML特定的字符 , 我们可以使用简单文本或 django.utils.html.escape() 进行转换 , 以防止用户进行的跨站点脚本攻击 primary_key 🍀 说明 指定该字段为主键 , 默认情况下 , 如果在model中没有指定 primary_key=True , Django会自动添加一个 AutoField 来作为主键 , 即默认创建的 id 字段 示例 class Student(models.Model): sid = models.AutoField(primary_key=True) PS : 主键字段是只读的 , 如果你更改现有对象的主键的值 , 然后将其保存 , 该结果并不是更改原对象的值 , 而是创建一个新对象 unique 🍀 说明 唯一约束 , 如果为True , 该字段在表中必须是唯一的 示例 class Student(models.Model): name = models.CharField(max_length=32, unique=True) PS : 这个选项同 null 一样 , 是一个在数据库级别与Form验证级别的强制性动作 ; 该选项对于 ManyToManyField 和 OneToOneField 是无效的 只要设置 unique=True , 意味着创建唯一索引 , 所以不需要再次指定 db_index 选项 版本区别 : 在Django 1.11 中 , 为了版本支持 , unique=True 不可以使用 FileField unique_for_date 🍀 说明 用于设置时间相关字段的值唯一 , 即针对 DateField 和 DateTimeField 字段 示例 class Student(models.Model): opening_date = models.DateField(unique_for_date=True) PS : 该选项是在Form验证期间通过 Model.validate_unique() 强制执行的 , 而不是在数据库级别进行的 , 所以这就意味着 , 如果字段中有 editable=True , 那么 Model.validate_unique() 将忽略该约束 unique_for_month 🍀 类似于 unique_for_date , 只是要求字段对于月份是唯一的 unique_for_year 🍀 类似于 unique_for_date , 只是要求字段对于年份是唯一的 verbose_name 🍀 说明 为字段设置一个可读性更高的名称 , 如果未设置该选项 , 那么Django在Form中默认会使用字段名 , 并会将字段名中的 \"_\" 转换成空格显示以及自动首字母大写 示例 class Student(models.Model): name = models.CharField(max_length=32, verbose_name=\"学生姓名\") validators 🍀 说明 可以自定制验证器 , 即验证值是否符合要求 , 它的值为一个列表 , 列表中为可调用对象 示例 from django.core.exceptions import ValidationError from django.utils.translation import ugettext_lazy as _ def validate_even(value): if value % 2 != 0: raise ValidationError( _('%(value)s is not an even number'), params={'value': value}, ) from django.db import models class MyModel(models.Model): even_field = models.IntegerField(validators=[validate_even]) 除了我们自定制之外 , Django为我们提供了很多的内置验证器 , 我们可从 django.core.validators 中进行导入 本文参考 : https://docs.djangoproject.com/en/1.11/ref/models/fields "},"05-Web框架/Django/09-Django - Model QuerySet API.html":{"url":"05-Web框架/Django/09-Django - Model QuerySet API.html","title":"Django - Model QuerySet API","keywords":"","body":"Django - Model QuerySet API 介绍 🍀 我们知道Django中存在着大量的接口 , 而跟QuerySet 就是一个Model相关的接口 , 它建立在 model 和 database query 指南的基础上 , 而这两个指南已经在前面的文章整理完成了 , 但是对于QuerySet API的整理还不完全 本篇中依然会使用在上一篇中使用的例子 上一篇中我们已经知道 , 当我们不对QuerySet 进行求值时 , 它会像生成器一样 , 不做任何反应 QuerySet 求值有以下方法 : 迭代 , QuerySet 是可迭代的 , 它在首次迭代查询集时会对数据库进行查询 , 实例如下 : for e in Entry.objects.all(): print(e.headline) ''' 这两条语句虽然可以验证在数据库中是否至少存在一条记录,但是使用exists()方法会更高效 ''' 切片 , 如 Limiting QuerySets 中说的那样 , 可以使用Python的序列切片语法对一个QuerySet 进行切片 ; 一个未求值的QuerySet 进行切片通常返回另一个未求值的QuerySet , 但是如果使用\"step\"参数 , Django 将执行数据库查询并返回一个列表 ; 对一个已经求值的QuerySet 进行切片将返回一个列表 注意 : 虽然对未求值的QuerySet 进行切片返回另一个未求值的QuerySet , 但是却不可以进一步修改它 , 比如添加更多的filter , 或者修改排序的方式 , 因为这将不太好翻译成SQL而且含义也不清晰 Pickling/Caching , 序列化将读取数据库 , 下节介绍 repr() , 当对QuerySet 调用repr() 时 , 将对它求值 ; 这是为了在Python交互式解释器中方便显示结果 len() , 当对QuerySet 调用len() 时 , 将对它求值 , 返回一个查询集的长度 注意 : 如果确定集合中记录的数量 , 而不需要实际的数据对象 , 那么使用SQL语句的SELECT COUNT(*)效率会更高 , 为此Django提供了一个count() 方法 list() , 当对QuerySet 调用list() 将强制对它求值 bool() , 测试布尔值 , 例如使用bool() , and , or 或者if语句将导致查询集的执行 Pickling QuerySet 🍀 如果你pickle一个QuerySet , 它将在pickle之前强制将所有的结果加载到内存中 ; pickle通常用于缓存之前 , 并且当缓存的查询集重新加载时 , 你希望结果已经存在随时准备使用 ; 不过注意 , pickle的数据只是pickle时的 , 也就是说pickle的数据不是即时的 如果此后你只想pickle必要的信息来重新创建QuerySet , 可以使用如下方式 : import pickle query = pickle.loads(s) # Assuming 's' is the pickled string. qs = MyModel.objects.all() qs.query = query # Restore the original 'query'. query是一个不透明的对象 , 它表示查询的内部构造 , 不属于公开的API 注意 : QuerySet 的pickle在不同的Django版本中是不保证兼容的 , 所以pickle不可用于归档的长期策略 QuerySet API 🍀 class QuerySet(model=None, query=None, using=None): \"\"\" 通常,当你与QuerySet交互时,都是通过链接过滤器来使用它 为了实现这一功能,大多数QuerySet方法都返回新的QuerySet QuerySet类有两个公共属性: ordered:如果QuerySet是排好序的则为True,如有一个order_by()子句或者模型有默认的排序;否则为False db:如果现在执行,则返回将使用的数据库 \"\"\" QuerySet 存在query参数是为了让具有特殊查询用途的子类如GeoQuerySet 可以重新构造内部的查询状态 , 这个参数的值是查询状态的不透明的表示 , 不是一个公开的API QuerySet API 中有非常多的方法供我们使用 , 分为如下几种 : 返回新的QuerySet 不返回新的QuerySet field查找 聚合函数 返回QuerySet 🍀 Django提供了一系列的QuerySet筛选方法 , 用于改变QuerySet返回的结果类型或者SQL查询执行的方式 filter() filter(**kwargs): \"\"\" 返回一个新的QuerySet,它包含满足查询参数的对象 **kwargs:应该满足字段查询中的格式,在底层的SQL语句中,多个参数通过AND连接 \"\"\" exclude() exclude(**kwargs): \"\"\" 返回一个新的QuerySet,它包含不满足给定查询参数的对象 **kwargs:应该满足字段查询中的格式,在底层的SQL语句中,多个参数通过AND连接,然后所有的内容放入NOT()中 \"\"\" 实例 Entry.objects.exclude(pub_date__gt=datetime.date(2005, 1, 3)).exclude(headline='Hello') # 对应的SQL SELECT ... WHERE NOT pub_date > '2005-1-3' AND NOT headline = 'Hello' annotate() annotate(*args,**kwargs): \"\"\" 使用提供的查询表达式注释QuerySet中的每个对象,表达式可以是简单的值,对模型上字段的应用, 对与QuerySet中对象相关的对象进行计算的聚合表达式 *args,**kwargs:每个参数都是一个注释,它将添加到返回的QuerySet中的每个对象 \"\"\" 实例 '''我们正在操作一个Blog对象列表,你可能想知道每个Blog有多少Entry''' >>> from django.db.models import Count >>> q = Blog.objects.annotate(Count('entry')) # The name of the first blog >>> q[0].name 'Blogasaurus' # The number of entries on the first blog >>> q[0].entry__count # Blog模型本身没有定义entry__count属性 42 控制Annotation的名称 >>> q = Blog.objects.annotate(number_of_entries=Count('entry')) # The number of entries on the first blog, using the name provided >>> q[0].number_of_entries 42 order_by() order_by(*fields): \"\"\" 对QuerySet进行指定排序;默认情况下,QuerySet返回的结果是由模型的元数据中的排序选项指定的 *fields:指定排序的字段 \"\"\" 实例 # 先按照pub_date降序排列,然后再按照headline升序排序 Entry.objects.filter(pub_date__year=2005).order_by('-pub_date', 'headline') ''' \"-\",负号表示降序;升序是隐含的,随机可以使用\"?\" ''' # 这种方式查询可能耗费资源而且很慢,取决于使用的数据库 Entry.objects.order_by('?') 使用跨表 , 即双下划线 : Entry.objects.order_by('blog__name', 'headline') 如果排序的字段与另外一个模型关联 , Django将使用关联的模型的默认排序 , 或者如果没有指定Meta.ordering 将通过关联的模型的主键排序 , 如下 : Entry.objects.order_by('blog') # 与上面相同 Entry.objects.order_by('blog__id') # Blog设置ordering=['name'],第一个QuerySet等同于 Entry.objects.order_by('blog__name') reverse() reverse(): \"\"\"翻转,即反向排序\"\"\" 实例 # 获取QuerySet中最后五个元素 my_queryset.reverse()[:5] # 注意QuerySet应该已经定义排序,否则reverse将无效 distinct() distinct(*fields): \"\"\" 返回一个在SQL查询中使用SELECT DISTINCT的新QuerySet,它将去除查询结果中重复的行 \"\"\" 默认情况下 , QuerySet不会去除重复的行 ; 在实际应用中这一般不是个问题 , 但是如果查询跨越多张表 , 当对QuerySet求值时就可能得到重复的结果 , 这时候我们就应该使用distinct() 注意 : order_by() 调用中的任何字段都将包含在SQL的SELECT列中 , 与distinct() 一起使用时可能导致无法预料的后果 ; 总之使用distiinct() 时 , 一定要注意相关模型的排序 values() values(*fields,**expressinos): \"\"\" 返回一个QuerySet字典,每个字典表示一个对象,键对应于模型对象的属性名称 \"\"\" 实例 # This list contains a Blog object. >>> Blog.objects.filter(name__startswith='Beatles') ]> # This list contains a dictionary. >>> Blog.objects.filter(name__startswith='Beatles').values() SELECT接收可选的位置参数*fields , 它指定values()应该限制哪些字段 ; 如果指定字段 , 每个字典将只包含指定字典的键/值 , 如果没有指定字段 , 每个字典将包含数据库中所有字段的键和值 , 如下 : >>> Blog.objects.values() >>> Blog.objects.values('id', 'name') 采用关键字参数**expressions , 这些参数传递给annotate() : >>> from django.db.models.functions import Lower >>> Blog.objects.values(lower_name=Lower('name')) values_list() value_list(*fields,flat=False): \"\"\" 与values()类似,只是在迭代时返回的是元组而不是字典 flat:如果为True表示返回的结果是单个值而不是元组 如果有多个字段,传递flat将发生错误 \"\"\" 实例 >>> Entry.objects.values_list('id').order_by('id') >>> Entry.objects.values_list('id', flat=True).order_by('id') dates() dates(field,kind,order='ASC'): \"\"\" 返回一个QuerySet,其为一个包含datetime.date对象的列表;date对象在QuerySet中表示特定类型的所有可用时间 field:DateField名称 kind:应为year,month,day -year,返回对应该字段的所有不同年份值的list -month,返回字段的所有不同年/月值的list -day,返回字段的所有不同年/月/日值的list order:指定排序方式,默认为ASC,即升序还可设置为DESC,即为降序 \"\"\" 实例 >>> Entry.objects.dates('pub_date', 'year') [datetime.date(2005, 1, 1)] >>> Entry.objects.dates('pub_date', 'month') [datetime.date(2005, 2, 1), datetime.date(2005, 3, 1)] >>> Entry.objects.dates('pub_date', 'day') [datetime.date(2005, 2, 20), datetime.date(2005, 3, 20)] >>> Entry.objects.dates('pub_date', 'day', order='DESC') [datetime.date(2005, 3, 20), datetime.date(2005, 2, 20)] >>> Entry.objects.filter(headline__contains='Lennon').dates('pub_date', 'day') [datetime.date(2005, 3, 20)] datetimes() datetimes(field_name,kind,order='ASC',tzinfo=None): \"\"\" 与dates()相同 field_name:为DateField的名称 kind:应为hour,minute,month,year,second,day order:同dates() tzinfo:定义在阶段之前将数据时间转换到的时区 \"\"\" none() 调用none() 将创建一个从不返回任何对象的queryset , 并且在访问结果时不会执行任何查询 ; qs.name() 查询集是EmptyQuerySet 的一个实例 实例 >>> Entry.objects.none() >>> from django.db.models.query import EmptyQuerySet >>> isinstance(Entry.objects.none(), EmptyQuerySet) True all() 返回当前QuerySet 或QuerySet 子类的副本 , 它可以用于在你希望传递一个模型管理器或QuerySet 并对结果做进一步过滤的情况 当对QuerySet 进行求值时 , 会缓存其结果 ; 如果数据库中的数据在QuerySet 求值之后可能已经改变 , 你可以通过在以前求值过的all() 上调用相同的QuerySet 查询以获得更新后的结果 union() union(*other_qs,all=False): \"\"\" 使用SQL的UNION运算符组合两个或多个Queryset的结果 all:为False表示不允许重复值,True即允许重复值 \"\"\" 实例 >>> qs1.union(qs2, qs3) intersection() intersection(*other_qs): \"\"\"使用SQL的INTERSECT运算符返回两个或多个QuerySet的共享元素\"\"\" 实例 >>> qs1.intersection(qs2, qs3) difference() difference(*other_qs): \"\"\"使用SQL的EXCEPT运算符只保留QuerySet中的元素,而不是在其他QuerySet中保存\"\"\" 实例 >>> qs1.difference(qs2, qs3) select_related() select_related(*fields): \"\"\" 返回一个QuerySet,当执行它的查询时它沿着外键关系查询关联的对象的数据 它会生成一个复杂的查询并引起性能的损耗,但是在以后使用外键关系时将不需要数据库查询 简单说,在对QuerySet使用select_related()函数后,Django会获取相应外键对应的对象,从而在之后需要的时候不必再查询数据库了 \"\"\" 普通查询 # Hits the database. e = Entry.objects.get(id=5) # Hits the database again to get the related Blog object. b = e.blog select_related() 查询 # Hits the database. e = Entry.objects.select_related('blog').get(id=5) # Doesn't hit the database, because e.blog has been prepopulated # in the previous query. b = e.blog select_related() 可用于objects的查询集 from django.utils import timezone # Find all the blogs with entries scheduled to be published in the future. blogs = set() for e in Entry.objects.filter(pub_date__gt=timezone.now()).select_related('blog'): # Without select_related(), this would make a database query for each # loop iteration in order to fetch the related blog for each entry. blogs.add(e.blog) 注 : select_related('foo', 'bar') 等同 select_related('foo').select_related('bar') prefetch_related() prefetch_related(*lookups): \"\"\" 返回一个QuerySet,它将在单个批处理中自动检索每个指定查找的相关对象 \"\"\" 这具有与select_related类似的目的 , 两者都被设计为阻止由访问相关对象而导致的数据库查询的泛滥 , 但是策略是完全不同的 select_related通过创建SQL连接并在SELECT语句中包括相关对象的字段来工作 ; 因此 , select_related在同一数据库查询中获取相关对象 , 然而 , 为了避免由于跨越\"多个\"关系而导致的大得多的结果集 , select_related限于单值关系 - 外键和一对一关系 prefetch_related , 另一方面 , 为每个关系单独查找 , 并在Python中\"加入\" , 这允许它预取多对多和多对一对象 , 除了外键和一对一关系 , 它们不能使用select_related来完成 extra() extra(select=None,where=None,params=None,tables=None,order_by=None,select_params=None): \"\"\" 有些情况下,Django的查询语法难以简单的表达复杂的WHERE子句,对于这种情况, Django提供了extra()修改机制,它能在QuerySet生成的SQL从句中注入新子句 \"\"\" extra()可以指定一个或多个WHERE , 如下 : select , 该参数可以让你在SELECT从句中添加其他字段信息,它应该是一个字典,存放着属性名到SQL从句的映射 Entry.objects.extra(select={'is_recent': \"pub_date > '2006-01-01'\"}) # 对应的SQL SELECT blog_entry.*, (pub_date > '2006-01-01') AS is_recent FROM blog_entry; where/tables , 你可以使用WHERE定义显示SQL where子句 , 也许执行非显示连接 ; 你可以使用FROM手动将表添加到SQL tables子句 ; where和tables都接受字符串列表 , 所有where参数均为\"与\"任何其他搜索条件 Entry.objects.extra(where=[\"foo='a' OR bar = 'a'\", \"baz = 'a'\"]) # SQL如下 SELECT * FROM blog_entry WHERE (foo='a' OR bar='a') AND (baz='a') order_by , 如果你需要使用通过extra()包含的一些新字段或表来对结果查询进行排序 , 可以使用order_by参数传入一个字符串序列 , 这些字符串应该是模型字段 , 如下 : q = Entry.objects.extra(select={'is_recent': \"pub_date > '2006-01-01'\"}) q = q.extra(order_by = ['-is_recent']) ''' 同前面的order_by参数 ''' params , 上述where参数可以使用标准Python数据库字符串占位符%s , 来指示数据库引擎应自动引用的参数 ; params参数是要替换的任何额外参数的列表 # 引号被正确转义 Entry.objects.extra(where=['headline=%s'], params=['Lennon']) # 始终使用params而不是将值直接嵌入where,因为params会确保根据你的特定后端正确引用值 defer() defer(*fields): \"\"\"用于延迟字段的查询集\"\"\" 在一些复杂的数据建模情况下 , 你的模型可能包含大量字段 , 其中一些可能包含大量数据 (例如文本字段) , 或者需要昂贵的处理来将他们转换为Python对象 ; 当你最初获取数据时不知道是否需要这些特定字段的情况下 , 如果你正在使用查询集的结果 , 你可以告诉Django不要从数据库中检索它们 # 通过传递字段名称到defer()实现不加载 Entry.objects.defer(\"headline\", \"body\") 具有延迟字段的查询集仍将返回模型实例 , 每个延迟字段将在你访问该字段时从数据库中检索 , 并且每次只检索一个 , 而不是一次检索所有的延迟字段 还可以多次调用 # Defers both the body and headline fields. Entry.objects.defer(\"body\").filter(rating=5).defer(\"headline\") only() only(*fields): \"\"\"与defer相反,仅让这些字段立即加载,其余的被延迟\"\"\" 对only()的连续调用的结果是只有最后一次调用的字段被考虑 # This will defer all fields except the headline. Entry.objects.only(\"body\", \"rating\").only(\"headline\") 由于defer() 以递增方式动作 (想延迟列表中添加字段) , 因此你可以结合only() 和 defer() , 它们将合乎逻辑地工作 : # Final result is that everything except \"headline\" is deferred. Entry.objects.only(\"headline\", \"body\").defer(\"body\") # Final result loads headline and body immediately (only() replaces any # existing set of fields). Entry.objects.defer(\"body\").only(\"headline\", \"body\") using() using(alias): \"\"\" 控制QuerySet在哪个数据库上求值 alias:数据库的别名,定义在DATABASES \"\"\" 实例 # queries the database with the 'default' alias. >>> Entry.objects.all() # queries the database with the 'backup' alias >>> Entry.objects.using('backup') select_for_update() select_for_update(nowait=False,skip_locked=False): \"\"\" 返回一个锁住行直到事务结束的查询集,如果数据库支持, 它将生成一个SELECT ... FOR UPDATE语句 nowait:默认如果其他事务锁定了相关行,那么本查询将被阻塞,直到锁被释放;改为True使查询不阻塞 skip_locked:如果其他事务持有冲突的锁,可以改为Trye忽略锁定的行 nowait与skip_locked是互斥的,同时启用会导致ValueError \"\"\" raw() raw(raw_query,params=None,translations=None): \"\"\" 接收一个原始的SQL查询,执行并返回一个django.db.models.query.RawQuereySet实例 这个RawQuerySet实例可以迭代以提供实例对象,就像普通的QuerySet一样 \"\"\" raw() 永远触发一个新的查询 , 而与之前的filter无关 ; 因此 , 它通常应该从Manager或一个全新的QuerySet实例调用 不返回QuerySet 🍀 以下方法对QuerySet进行求值并返回 , 返回结果不是QuerySet 这些方法不使用高速缓存 , 并且每次被调用的时候都会查询数据库 get() 返回按照查询参数匹配到的对象 , 如果匹配到的对象个数不止一个 , get()将会触发MultipleObjectReturned异常 实例 entry = Entry.objects.filter(...).exclude(...).get() create() 快捷创建对象并保存 , 如下 : p = Person.objects.create(first_name=\"Bruce\", last_name=\"Springsteen\") # 等同如下 p = Person(first_name=\"Bruce\", last_name=\"Springsteen\") p.save(force_insert=True) get_or_create() get_or_create(defaults=None,**kwargs): \"\"\" 通过给出的kwargs来查询对象的便捷方法,需要的话创建一个对象, 返回一个由(object,created)组成的元组,object是一个查询到的或者是被创建的对象,created是一个表示是否创建了新的对象的布尔值 \"\"\" 实例 obj, created = Person.objects.get_or_create( first_name='John', last_name='Lennon', defaults={'birthday': date(1940, 10, 9)}, ) 任何传递给 get_or_create() 的关键字参数 , 除了一个可选的defaults, 都将传递给get() 调用 ; 如果查找到一个对象 , get_or_create() 返回一个包含匹配到的对象以及False 组成的元组 , 如果查找到的对象超过一个以上 , get_or_create 将引发MultipleObjectsReturned异常 , 如果查找不到对象 , get_or_create() 将会实例化并保存一个新的对象 , 返回一个由新的对象以及True 组成的元组 , 新的对象将会大概按照以下的逻辑创建 : params = {k: v for k, v in kwargs.items() if '__' not in k} params.update({k: v() if callable(v) else v for k, v in defaults.items()}) obj = self.model(**params) obj.save() update_or_create() update_or_create(defaults=None,**kwargs): \"\"\" 返回一个由(object,created)组成的元组, 元组中的object是一个创建的或者是被更新的对象, created是一个标识是否创建了心得额对象的布尔值 \"\"\" 实例 obj, created = Person.objects.update_or_create( first_name='John', last_name='Lennon', defaults={'first_name': 'Bob'}, ) bulk_create() bulk_create(objs,batch_size=None): \"\"\" 以高效的方式(通常只有1个查询,无论多少对象)将提供的对象列表插入到数据库中 obj:插入的对象 batch_size:控制在单个查询中创建的对象数;默认值是在一个批处理中创建所有的对象,除了SQLite,其中默认值为每个查询最多使用999个变量 \"\"\" 实例 >>> Entry.objects.bulk_create([ ... Entry(headline='This is a test'), ... Entry(headline='This is only a test'), ... ]) 该方法需要注意以下 : 将不会调用模型的sava()方法 , 并且不会发送pre_save 和 post_save 信号 它不适用于多表继承场景中的子模型 如果模型的主键是AutoField , 则不会像save() 那样检索并设置主键属性 , 除非数据库后端支持(当前是PostgreSQL) 它不适用于多对多关系 count() 返回在数据中对应的QuerySet 对象的个数 , count() 永远不会引发异常 # Returns the total number of entries in the database. Entry.objects.count() # Returns the number of entries whose headline contains 'Lennon' Entry.objects.filter(headline__contains='Lennon').count() in_bulk() in_bulk(id_list=None): \"\"\" 获取主键值的列表,并返回将每个主键值映射到具有给定ID的对象的实例的字典, 如果未提供列表,则会返回查询集中的所有对象 \"\"\" 实例 >>> Blog.objects.in_bulk([1]) {1: } >>> Blog.objects.in_bulk([1, 2]) {1: , 2: } >>> Blog.objects.in_bulk([]) {} >>> Blog.objects.in_bulk() {1: , 2: , 3: } iterator() 对QuerySet进行求值并返回一个迭代器 , 其不会在QuerySet级别执行任何缓存 (内部 , 默认迭代器调用iterator() 并高速缓存返回值) latest() latest(field_name=None): \"\"\" 按日期返回表中的最新对象 field_name:日期字段 \"\"\" 实例 Entry.objects.latest('pub_date') earliest() 除非方向更改 , 否则像latest() first() 返回结果集的第一个对象 , 当没有找到时返回None ; 如果QuerySet没有设置排序 , 则将会自动按主键进行排序 , 如下 : p = Article.objects.order_by('title', 'pub_date').first() last() 工作方式类似first() , 只是返回的是查询集中最后一个对象 aggregate() aggregate(*args,**kwargs): \"\"\" 返回汇总值的字典(平均值,总和等),通过QuerySet进行计算 每个参数指定返回的字典中将要包含的值 \"\"\" 实例 >>> from django.db.models import Count >>> q = Blog.objects.aggregate(Count('entry')) {'entry__count': 16} >>> q = Blog.objects.aggregate(number_of_entries=Count('entry')) {'number_of_entries': 16} exists() 如果QuerySet包含任何结果 , 则返回True , 否则返回False 它视图用最简单和最快的方法完成查询 , 但它执行的方法与普通的QuerySet查询几乎一样 , exists()用于搜寻对象是都在QuerySet中以及QuerySet受否存在任何对象 , 特别是QuerySet比较大的时候 entry = Entry.objects.get(pk=123) if some_queryset.filter(pk=entry.pk).exists(): print(\"Entry contained in queryset\") update() 对指定的字段执行SQL更新查询 , 并返回匹配的行数 (如果某些行已具有新值 , 则可能不等于已更新的行数) >>> Entry.objects.filter(pub_date__year=2010).update(comments_on=False, headline='This is old') delete() 对QuerySet中的所有行执行SQL删除查询 , 并返回删除的对象数和每个对象类型的删除次数的字典 >>> b = Blog.objects.get(pk=1) # Delete all the entries belonging to this Blog. >>> Entry.objects.filter(blog=b).delete() (4, {'weblog.Entry': 2, 'weblog.Entry_authors': 2}) as_manager() classmethod as_manager() 类方法 , 返回Manager的实例与QuerySet的方法的副本 Field查询 🍀 字段查询是指如何指定SQL WHERE子句的内容 , 它通过QuerySet的filter() , exclude() 和 get() 的关键字参数指定 , 即使用双下划线时后的参数 exact 精确匹配 , 如果为比较提供的值为NULL , 它将被解释SQL None Entry.objects.get(id__exact=14) Entry.objects.get(id__exact=None) # 等价的SQL SELECT ... WHERE id = 14; SELECT ... WHERE id IS NULL; iexact 不区分大小写的精确匹配 , 如果为比较提供的值为NULL , 它将被解释为SQL None Blog.objects.get(name__iexact='beatles blog') Blog.objects.get(name__iexact=None) # 等价的SQL SELECT ... WHERE name ILIKE 'beatles blog'; SELECT ... WHERE name IS NULL; contains 大小写敏感的包含关系测试 Entry.objects.get(headline__contains='Lennon') # 等价SQL SELECT ... WHERE headline LIKE '%Lennon%'; icontains 与contains相反 , 大小写不敏感的包含关系测试 Entry.objects.get(headline__icontains='Lennon') # 等价SQL SELECT ... WHERE headline ILIKE '%Lennon%'; in 在给定的列表 Entry.objects.filter(id__in=[1, 3, 4]) # 等价SQL SELECT ... WHERE id IN (1, 3, 4); gt 大于 Entry.objects.filter(id__gt=4) # 等价SQL SELECT ... WHERE id > 4; gte 大于或等于 lt 小于 lte 小于或等于 startswith 区分大小写 , 开始位置匹配 Entry.objects.filter(headline__startswith='Lennon') # 等价SQL SELECT ... WHERE headline LIKE 'Lennon%'; istartswith 不区分大小写 , 开始位置匹配 Entry.objects.filter(headline__istartswith='Lennon') # 等价SQL SELECT ... WHERE headline ILIKE 'Lennon%'; endswith 区分大小写 , 结尾位置匹配 Entry.objects.filter(headline__endswith='Lennon') # 等价SQL SELECT ... WHERE headline LIKE '%Lennon'; iendswith 不区分大小写 , 结尾位置匹配 Entry.objects.filter(headline__iendswith='Lennon') # 等价SQL SELECT ... WHERE headline ILIKE '%Lennon' range 范围测试 import datetime start_date = datetime.date(2005, 1, 1) end_date = datetime.date(2005, 3, 31) Entry.objects.filter(pub_date__range=(start_date, end_date)) # 等价SQL SELECT ... WHERE pub_date BETWEEN '2005-01-01' and '2005-03-31'; date 对于datetime字段 , 将值作为日期转换 ; 允许链接附加字段查找 , 获取日起值 Entry.objects.filter(pub_date__date=datetime.date(2005, 1, 1)) Entry.objects.filter(pub_date__date__gt=datetime.date(2005, 1, 1)) year 对于日期和时间字段 , 确切的年匹配 , 循序链接附加字段查找 Entry.objects.filter(pub_date__year=2005) Entry.objects.filter(pub_date__year__gte=2005) # 等价SQL SELECT ... WHERE pub_date BETWEEN '2005-01-01' AND '2005-12-31'; SELECT ... WHERE pub_date >= '2005-01-01'; month 对于日期和日期时间字段 , 确切的月份匹配 , 允许链接附加字段查找 Entry.objects.filter(pub_date__month=12) Entry.objects.filter(pub_date__month__gte=6) # 等价SQL SELECT ... WHERE EXTRACT('month' FROM pub_date) = '12'; SELECT ... WHERE EXTRACT('month' FROM pub_date) >= '6'; day 对于日期和日期时间字段 , 具体到某一天的匹配 , 允许链接附加字段查找 Entry.objects.filter(pub_date__day=3) Entry.objects.filter(pub_date__day__gte=3) # 等价SQL SELECT ... WHERE EXTRACT('day' FROM pub_date) = '3'; SELECT ... WHERE EXTRACT('day' FROM pub_date) >= '3'; week 对于日期和日期时间字段 , 根据 ISO-8601 返回周号 , 即星期一开始的星期 Entry.objects.filter(pub_date__week=52) Entry.objects.filter(pub_date__week__gte=32, pub_date__week__lte=38) week_day 对于日期和日期时间字段 , 周号匹配 , 允许链接附加字段查找 Entry.objects.filter(pub_date__week_day=2) Entry.objects.filter(pub_date__week_day__gte=2) time 对于datetime字段 , 将值转换为时间 , 允许链接附加字段查找 , 获取datetime.time的值 Entry.objects.filter(pub_date__time=datetime.time(14, 30)) Entry.objects.filter(pub_date__time__between=(datetime.time(8), datetime.time(17))) hour 对于日期时间和时间字段 , 确切的时间匹配 , 允许链接附加字段查找 Event.objects.filter(timestamp__hour=23) Event.objects.filter(time__hour=5) Event.objects.filter(timestamp__hour__gte=12) # 等价SQL SELECT ... WHERE EXTRACT('hour' FROM timestamp) = '23'; SELECT ... WHERE EXTRACT('hour' FROM time) = '5'; SELECT ... WHERE EXTRACT('hour' FROM timestamp) >= '12'; minute 对于日期时间和时间字段 , 确切的分钟匹配 , 允许链接附加字段查找 Event.objects.filter(timestamp__minute=29) Event.objects.filter(time__minute=46) Event.objects.filter(timestamp__minute__gte=29) # 等价SQL SELECT ... WHERE EXTRACT('minute' FROM timestamp) = '29'; SELECT ... WHERE EXTRACT('minute' FROM time) = '46'; SELECT ... WHERE EXTRACT('minute' FROM timestamp) >= '29'; second 对于日期时间和时间字段 , 确切的第二个匹配 , 允许链接附加字段查询 Event.objects.filter(timestamp__second=31) Event.objects.filter(time__second=2) Event.objects.filter(timestamp__second__gte=31) # 等价SQL SELECT ... WHERE EXTRACT('second' FROM timestamp) = '31'; SELECT ... WHERE EXTRACT('second' FROM time) = '2'; SELECT ... WHERE EXTRACT('second' FROM timestamp) >= '31'; isnull 值为False或True , 相当于SQL语句IS NULL 和IS NOT NULL Entry.objects.filter(pub_date__isnull=True) # 等价SQL SELECT ... WHERE pub_date IS NULL; search 一个Boolean类型的全文搜索 , 以全文搜索的优势 ; 这个很像contains , 但是由于全文索引的优势 , 以使它更显著的块 Entry.objects.filter(headline__search=\"+Django -jazz Python\") # 等价SQL SELECT ... WHERE MATCH(tablename, headline) AGAINST (+Django -jazz Python IN BOOLEAN MODE); regex 区分大小写的正则表达式匹配 Entry.objects.get(title__regex=r'^(An?|The) +') # 等价SQL SELECT ... WHERE title REGEXP BINARY '^(An?|The) +'; -- MySQL SELECT ... WHERE REGEXP_LIKE(title, '^(An?|The) +', 'c'); -- Oracle SELECT ... WHERE title ~ '^(An?|The) +'; -- PostgreSQL SELECT ... WHERE title REGEXP '^(An?|The) +'; -- SQLite iregex 不区分大小写的正则表达式匹配 Entry.objects.get(title__iregex=r'^(an?|the) +') # 等价SQL SELECT ... WHERE title REGEXP '^(an?|the) +'; -- MySQL SELECT ... WHERE REGEXP_LIKE(title, '^(an?|the) +', 'i'); -- Oracle SELECT ... WHERE title ~* '^(an?|the) +'; -- PostgreSQL SELECT ... WHERE title REGEXP '(?i)^(an?|the) +'; -- SQLite 聚合函数 🍀 Django的django.db.models 模块提供以下聚合函数 , 关于如果使用这些聚合函数的细节 , 参考 the topic guide on aggregation , 如何创建聚合函数 , 参考 Aggregate 所有聚合函数都具有以下共同的参数 : expression 引用模型字段的一个字符串 , 或者一个查询表达式 output_field 用来表示返回的模型字段 , 它是一个可选的参数 **extra 这些关键字参数可以给聚合函数生成的SQL提供额外的信息 Avg class Avg(expression, output_field=FloatField(), **extra*) 返回给定表达式的平均值 , 它必须是数值 , 除非你指定不同的output_field 默认别名为 : __avg 返回类型 : float(或指定output_field的类型) Count 返回表达式相关的对象的个数 默认别名 :__count 返回类型 : int 有一个可选的参数 : distinct , 如果为True , Count将只计算唯一的实例 , 它等同于CONUT(DISTINCT ) SQL语句 , 默认为False Max class Max(expression,output_field=None,**extra) 返回expression 的最大值。 默认的别名 : __max 返回类型 : 与输入字段的类型相同 , 如果提供则为 output_field 类型 Min class Min(expression,output_field=None, **extra) 返回expression 的最小值 默认的别名 : __min 返回类型 : 与输入字段的类型相同 , 如果提供则为 output_field 类型 StdDev class StdDev(expression, sample=False, **extra) 返回expression 的标准差 默认的别名 : __stddev 返回类型 : float 有一个可选的参数 : sample , 默认情况下 , StdDev 返回群体的标准差 ; 但是 , 如果sample=True , 返回的值将是样本的标准差 Sum class Sum(expression, output_field=None, **extra) 计算expression 的所有值的和。 默认的别名 : __sum 返回类型 : 与输入字段的类型相同 , 如果提供则为 output_field 类型 Variance class Variance(expression,sample=False, **extra*) 返回expression 的方差。 默认的别名 : __variance 返回类型 : float 有一个可选的参数 : sample , 默认情况下 , Variance 返回群体的方差 ; 但是 , 如果sample=True , 返回的值将是样本的方差 在QuerySet API中还有几个查询相关的工具 : Q() 对象 Prefetch() 对象 prefetch_related_objects() 详细内容见 : Query-related tools 更多QuerySet API 详细内容 : https://docs.djangoproject.com/en/1.11/ref/models/querysets/ "},"05-Web框架/Django/10-Django - Model Making queries.html":{"url":"05-Web框架/Django/10-Django - Model Making queries.html","title":"Django - Model Making queries","keywords":"","body":"Django - Model Making queries 介绍 🍀 一旦我们建立好模型 , Django就会自动为我们生成一套数据库抽象的API , 可以让我们进行创建 , 检索 , 更新和删除对象 , 这篇文章主要阐述怎么去使用这些API 关于模型接口的完整细节见 , data model reference 我们首先建立好模型 , 该模型构成一个博客应用 : from django.db import models class Blog(models.Model): name = models.CharField(max_length=100) tagline = models.TextField() def __str__(self): # __unicode__ on Python 2 return self.name class Author(models.Model): name = models.CharField(max_length=200) email = models.EmailField() def __str__(self): # __unicode__ on Python 2 return self.name class Entry(models.Model): blog = models.ForeignKey(Blog) headline = models.CharField(max_length=255) body_text = models.TextField() pub_date = models.DateField() mod_date = models.DateField() authors = models.ManyToManyField(Author) n_comments = models.IntegerField() n_pingbacks = models.IntegerField() rating = models.IntegerField() def __str__(self): # __unicode__ on Python 2 return self.headline 获取对象 🍀 从数据库获取对象 , 是通过模型中的Manager 构造出一个QuerySet ; QuerySet表示从数据库中取出来的对象的集合 , 从SQL的角度来讲 , QuerySet与WHERE语句等价 Manager则是Django模型提供数据库查询操作的接口 , 在一个Django应用中 , 每个模型至少存在一个Manager , 默认情况下命名为objects , 也就是说我们的模型Manager就是我们所使用的objects , 例如 : models.Blog.objects.all() ''' models.Blog:model class objects:Manager all:QuerySet API ''' 注意 : Manager只能通过模型类访问 , 而不能通过模型的实例访问 , 目的是为了强制区分\"表级别\" 的操作和\"记录级别\" 的操作 ; 对于一个模型来说 , Manager是QuerySet的主要来源 获取所有对象 🍀 可以使用Manager的all() 方法将一个表中的所有对象全部获取 # all()方法返回一个包含数据库表中的所有对象的QuerySet all_entries = Entry.objects.all() 过滤器获取对象 🍀 all() 方法返回了一个包含数据库表中的所有记录的QuerySet , 但是通常情况下我们往往需要获取完整数据集的一个子集 , 即我们需要使用过滤器 filter(**kwargs): \"\"\"返回一个新的QuerySet,它包含满足查询参数的对象\"\"\" exclude(**kwargs): \"\"\"返回一个新的QuerySet,它包含不满足查询参数的对象\"\"\" 实例 # 获取年份为2006的所有文章的QuerySet Entry.objects.filter(pub_date_year=2006) # 相当于 Entry.objects.all().filter(pub_date_year=2006) 链接过滤器 🍀 QuerySet的筛选结果本身还是QuerySet , 所以可以将筛选语句链接在一起 , 如下 : Entry.objects.filter( headline__startswith='What' ).exclude( pub_date__gte=datetime.date.today() ).filter( pub_date__gte=datetime(2005, 1, 30) ) QuerySet唯一性 🍀 每次筛选一个QuerySet , 得到的都是全新的另一个QuerySet , 它和之前的QuerySet没有任何绑定关系 , 每次筛选都会创建一个独立的QuerySet , 它可以被存储及反复使用 , 如下 : # 所有标题包含\"what\"开头的记录 q1 = Entry.objects.filter(headline__startswith=\"What\") # q1的子集,排除pub_date为今天的记录 q2 = q1.exclude(pub_date__gte=datetime.date.today()) # q1的子集,只选择pub_date为今天的记录 q3 = q1.filter(pub_date__gte=datetime.date.today()) ''' q1不会受筛选过程的影响 ''' QuerySet惰性 🍀 QuerySet是惰性执行的 , 创建QuerySet不会带来任何数据的访问 , 类似于Python中的生成器 , 你可以将过滤器保持一整天 , 知道QuerySet需要取值时 , Django才会真正执行这个查询 , 如下 : q = Entry.objects.filter(headline__startswith=\"What\") q = q.filter(pub_date__lte=datetime.date.today()) q = q.exclude(body_text__icontains=\"food\") # 此时才真正访问数据库 print(q) QuerySet切片 🍀 QuerySet是支持切片的 , 它等同于SQL的OFFSET和LIMIT语句 # LIMIT 5,返回前5个对象 Entry.objects.all()[:5] # OFFSET 5 LIMIT 5,返回第6至第10个 Entry.objects.all()[5:10] 但是QuerySet不支持负的索引 , 如 : Entry.objects.all()[-1] 通常QuerySet的切片返回一个新的QuerySet , 它不会执行查询 , 但是如果使用Python切片语法中的step 参数 , 即步长 , 那么它将执行查询 获取单个对象 🍀 如需获取单个对象 , 可以使用Manager的get() 方法 one_entry = Entry.objects.get(pk=1) 字段查询 🍀 字段查询是指如何指定SQL WHERE 子句的内容 , 通常使用过滤器的关键字参数指定 查询的关键字参数的基本形式是field__lookuptype=value , 如下 : Entry.objects.filter(pub_date__lte='2006-01-01') # 翻译成SQL大体如下 SELECT * FROM blog_entry WHERE pub_date 查询条件中指定的字段必须是模型字段的名称 ; 有一个例外 , 对于ForeignKey 你可以使用字段名加上_id 后缀 , 在这种情况下 , 该参数的值应该是外键的原始值 , 如下 : Entry.objects.filter(blog_id=4) 数据库API支持大约二十种lookuptype , 完整参考见 : field lookup reference 下面介绍几个常用的 : exact , 精确匹配 Entry.objects.get(headline__exact=\"Cat bites dog\") # 对应SQL SELECT ... WHERE headline = 'Cat bites dog'; # 如果关键字参数不包含双下划线,默认假定查询类型是exact,以下两条语句相等 Blog.objects.get(id__exact=14) # Explicit form Blog.objects.get(id=14) # __exact is implied iexact , 大小写不敏感的匹配 # 将匹配标题为\"Beatles Blog\",\"beatles blog\"甚至\"BeAtlES blOG\"的Blog Blog.objects.get(name__iexact=\"beatles blog\") contains , 大小写敏感的包含关系测试 Entry.objects.get(headline__contains='Lennon') # 翻译成SQL SELECT ... WHERE headline LIKE '%Lennon%'; ''' 这将匹配'Today Lennon honored',但不能匹配'today lennon honored' 还有一个大小写不敏感版本,icontains ''' startswith , endswith , 以 ... 开头 , 以 ... 结尾 更多详细字段类型会在下一篇文章中整理 跨表查询 🍀 Django提供了一种强大又直观的方式来\"处理\"查询中的关联关系 , 它在后台自动帮你处理JOIN 如果要进行跨表查询 , 只需要使用关联的模型字段的名称 , 并使用双下划线分隔 , 直至你想要的字段 , 如下 : # 获取所有Blog表中name为'Beatles Blog'的Entry对象 Entry.objects.filter(blog__name='Beatles Blog') 这种跨越可以是任意深度的 , 它还可以反向工作 , 若要引用一个\"反向\"的关系 , 只需要使用该模型的小写的名称 , 如下 : # 获取所有Entry表中headline包含'Lennon'的Blog对象 Blog.objects.filter(entry__headline__contains='Lennon') 如果在多个关联关系过滤而且其中某个中介模型没有满足过滤条件的值 , Django将把它当做一个空的(所有的值都为NULL) 但是合法的对象 , 这意味着不会有错误引发 Blog.objects.filter(entry__authors__name='Lennon') 更多实例 models.Tb1.objects.filter(id__lt=10, id__gt=1) # 获取id大于1 且 小于10的值 models.Tb1.objects.filter(id__in=[11, 22, 33]) # 获取id等于11、22、33的数据 models.Tb1.objects.exclude(id__in=[11, 22, 33]) # not in models.Tb1.objects.filter(id__range=[1, 2]) # 范围bettwen and F expressions 🍀 如果我们想将模型的一个字段与同一个模型的另外一个字段进行比较 , 可以使用F() 表达式 F() 返回的实例用作查询内部对模型字段的引用 , 然后可以在过滤器中使用这些引用来比较同一模型实例中两个不同字段的值 , 如下 : from django.db.models import F # 获取所有comments数目大于pingbacks的Entry对象,gt表示大于,将在下一篇QuerySet API中详细介绍 Entry.objects.filter(n_comments__gt=F('n_pingbacks')) Django支持对F()对象使用加法 , 减法 , 乘法 , 除法 , 取模以及幂运算等算数操作 , 两个操作数可以都是常数和其他F() 对象 , 如下 : # 查找comments数目比pingbacks两倍还多的Entry对象 Entry.objects.filter(n_comments__gt=F('n_pingbacks') * 2) F() 对象同样可以使用双下划线进行跨表 # 获取author的名字与blog名字相同的Entry对象 Entry.objects.filter(authors_name=F('blog__name')) 对于date和date/time字段 , 可以给它们加上或减去一个timedalta对象 # 获取发布超过3天后被修改的所有Entry对象 from datetime import timedelta Entry.objects.filter(mod_date__gt=F('pub_date') + timedelta(days=3)) F() 对象支持位操作bitand() , bitor() , bitrightshift() 和 bitleftshift() F('somefield').bitand(16) 更多F表达式相关 : F expressions 缓存与QuerySet 🍀 每个QuerySet都包含一个缓存来最小化对数据的访问 , 在一个新创建的QuerySet中 , 缓存为空 ; 首次对QuerySet进行求值 , 同时发生数据库查询 , Django将保存查询的结果到QuerySet的缓存中并返回明确请求的结果 , 我们需要考虑的是对QuerySet重用缓存的问题 如果QuerySet使用不当 , 它是会坑你的 , 如下 : # 查询后就释放缓存 print([e.headline for e in Entry.objects.all()]) # 查询后就释放缓存 print([e.pub_date for e in Entry.objects.all()]) ''' 这两条语句意味着相同的数据库查询将执行两次, 显然倍增了数据库负载, 同时,还有可能两个结果列表并不一样, 因为两次请求期间有可能有新的Entry对象被添加进来或删除掉 ''' 为了避免这个问题 , 我们只需保存QuerySet并重新使用它 queryset = Entry.objects.all() print([p.headline for p in queryset]) # Evaluate the query set. print([p.pub_date for p in queryset]) # Re-use the cache from the evaluation. QuerySet不缓存 QuerySet并不总是缓存它们的结果 , 当只对查询集的部分进行求值时会检查缓存 , 但是如果这部分不在缓存中 , 那么接下来查询返回的记录都将不会被缓存 ; 具体的说 , 这意味着使用切片或索引来约束查询集将不会进行缓存 实例1 # 重复获取查询集对象中一个特定的索引将每次都查询数据库,不会进行缓存 queryset = Entry.objects.all() print(queryset[5]) # Queries the database print(queryset[5]) # Queries the database again 实例2 # 已经对全部查询集求值过,则将检查缓存 queryset = Entry.objects.all() [entry for entry in queryset] # Queries the database print(queryset[5]) # Uses cache print(queryset[5]) # Uses cache 下面是一些其它的例子 , 它们会使得全部的查询集被求值并填充到缓存中 >>> [entry for entry in queryset] >>> bool(queryset) >>> entry in queryset >>> list(queryset) 注意 : 简单地打印查询集不会填充缓存 , 因为__repr__() 调用只会返回全部查询集的一个切片 更多 : OR lookups examples Manager更多详细资料 : https://docs.djangoproject.com/en/1.11/topics/db/managers/ 更多Making queries : https://docs.djangoproject.com/en/1.11/topics/db/queries/ Model API reference : https://docs.djangoproject.com/en/1.11/ref/models/ 下一章将会对本章的一些内容进行说明 , 及QuerySet API "},"05-Web框架/Django/11-Django - Forms.html":{"url":"05-Web框架/Django/11-Django - Forms.html","title":"Django - Forms","keywords":"","body":"Django - Forms 介绍 🍀 表单在网页中主要负责数据采集功能 , 比如我们可以利用表单来采集访问者的某些信息 , 例如 : 名字 , email地址 , 留言簿等等 Django提供了大量的工具和库来帮助我们构建表单来接收网站访问者的输入 , 然后处理以及响应输入 HTML表单 在HTML中 , 表单的作用是收集标签中的内容 , 即form标签中间可以由访问者添加类似于文本 , 选择 , 或者一些控制模块等等 , 然后这些内容将会被送到服务端 与 元素一样 , 一个表单必须指定两样东西 : where : 响应用户输入数据的URL how : 发送数据所使用的HTTP方式 例如 , Django Admin站点的登录表单包含如下几个元素 : type=\"text\" , 用户名 type=\"password\" , 密码 type=\"submit\" , 用于\"Log in\" 按钮 它还包含一些用户看不到的隐藏的文本字段 , Django使用他们来决定下一步的行为 它还告诉浏览器表单数据应该发往元素的action属性指定的URL , 如 : /admin/ 而且应该使用method属性指定的HTTP机制来发送 , 即是使用GET还是POST GET和POST 处理表单时只会用到POST和GET方法 Django的登录表单使用POST方法 , 在这个方法中浏览器组合表单数据 , 对它们进行编码以用于传输 , 将它们发送到服务器然后接收它的响应 mysite/myapp/views.py from django.shortcuts import render from django.views.decorators import csrf # 接收POST请求数据 def search_post(request): ctx ={} if request.POST: ctx['rlt'] = request.POST['q'] return render(request, \"post.html\", ctx) mysite/templates/post.html Lyon's Blog {% csrf_token %} {{ rlt }} 相反 , GET组合提交的数据为一个字符串 , 然后是用它来生成一个URL ; 这个URL将包含数据发送的地址以及数据的键和值 , 比如你在Django documentation中进行一次搜索 , 其将会生成一个URL https://docs.djangoproject.com/search/? mysite/myapp/views.py from django.http import HttpResponse from django.shortcuts import render_to_response # 表单 def search_form(request): return render_to_response('search_form.html') # 接收请求数据 def search(request): request.encoding='utf-8' if 'q' in request.GET: message = 'The content of your search is' + request.GET['q'] else: message = 'The form is empty' return HttpResponse(message) mysite/templates/get.html Lyon's Blog POST和GET用于实现不同的目的 如果需要改变系统状态的请求应该使用POST , 如果不影响系统状态的请求则应该使用GET GET还不适合密码表单 , 因为这意味着你的密码将出现在URL中, 以及浏览器的历史和服务器的日志中 , 而且都是以普通的文本格式 ; 它还不适合数据量大的表单和二进制数据 , 例如一张图片 ; 使用GET请求作为管理站点的表单具有安全隐患 : 攻击者很容易模拟表单请求来取得系统的敏感数据 不过GET方式适合网页搜索这样的表单 , 因为这种表示一个GET请求的URL可以很容易地作为书签 , 分享和重新提交 Forms In Django 🍀 Django的表单功能可以简化自动化大部分工作 , 而且还可以比大部分程序员自己所编写的代码更安全 Django会处理表单工作中的三个显著不同的部分 : 准备数据 , 重构数据 , 以便下一步提交 为数据创建HTML表单 接收并处理客户端提交的表单和数据 这些我们可以自己手工编写来实现 , 但是Django可以帮你完成这些所有的工作 在一个Web应用中 , 表单可能指HTML中的 , 或者生成它的Django的Form , 或者提交时发送的结构化数据、或者这些部分的总和 Django 的Form类 表单系统的核心部分是Django的Form类 , Django的模型描述一个对象的逻辑结构 , 行为以及展现给我们的方式 , 与此类似 , Form类描述一个表单并决定它如何工作和展现 就将Model中的ORM一样 , 表单类的字段会映射到HTML的 表单元素 (ModelForm通过一个Form映射模型类的字段到HTML表单的元素 ; Django的Admin站点就是基于这个的) 表单的字段本身就是一个个的类 ; 它们管理表单数据 , 并在提交表单时执行验证 表单字段在浏览器中呈现给用户的是一个HTML的\"小部件\" , 即用户界面的一个片段 每个字段类型都有一个合适的默认 Widget class , 在我们需要时可以将其覆盖 实例化、处理和渲染 🍀 在Django中渲染一个对象时 , 我们通常 : 在视图中获得它 (例如 , 通过视图函数从数据库中获取) 将它传递给模板上下文 使用模板变量将它扩展为HTML标记 在模板中渲染表单和渲染其他类型的对象几乎一样 , 除了有几个比较例外 在模型实例不包含数据的情况下 , 在模板中对它做处理很少有什么用处 ; 但是渲染一个未填充的表单却是非常有意义的 , 我们希望用户去填充它 ; 所以当我们的视图中处理模型实例时 , 我们一般从数据库中获取它 , 当我们处理表单时 , 我们一般在视图中实例化它 当我们实例化表单时 , 我们可以选择让它为空还是预先填充它 构建一个表单 🍀 HTML Form 如果我们想在自己的网站上创建一个简单的表单 , 以获取用户的名字 , 模板如下 : Your name: 这告诉浏览器以POST方式发送表单的数据到URL /your-name/ , 它将显示一个\"Your name\"文本字段 , 以及一个\"OK\"按钮 , 如果模板上下文包含一个your_name变量 , 它将用于预填充current_name字段 你将需要一个视图来渲染这个包含HTML表单的模板 , 并提供合适的current_name字段 当表单提交时 , 发往服务器的POST请求将包含表单数据 这是一个非常简单的表单 , 实际应用中 , 一个表单可能包含几十上百个字段 , 其中大部分需要预填充 , 而且我们预料到用户将来回编辑 , 提交几次才能完成操作 ; 即使在提交表单之前 , 我们也可能需要在浏览器中进行一些验证 , 我们可能想要使用更复杂的字段 , 这样可以让用户做一些事情 , 例如从日历中选择日期等等 , 那么这个时候 , 让Django来为我们完成大部分工作是很容易的 Django Form 🍀 上面我们已经构建好了一个HTML表单 , 那么现在我们就需要来构建一个Django表单了 from django import forms class NameForm(forms.Form): your_name = forms.CharField(label='Your name', max_length=100) 这个Form类仅仅定义了一个字段your_name , 字段允许的最大长度通过max_length 定义 , 它完成两件事情 ; 首先 , 它在HTML 上放置一个maxlength=100 , 这样浏览器将在第一时间阻止输入多于这个数目的字符 , 它还意味着当Django收到浏览器发送过来的表单时 , 它将验证数据的长度 Form的实例具有一个is_valid() 方法 , 它会为所有的字段执行验证程序 ; 如果所有的字段都包含有效的数据它将会返回True并且将表单的数据放到cleaned_data属性中 完整的表单 , 第一次渲染时 , 看上去将如下 : Your name: 注意 : 它不包含 标签 , 以及提交按钮 , 所以我们必须自己在模板中提供它们 视图 🍀 发送回Django网站的表单数据由视图处理 , 通常是发布表单的相同视图 , 这允许我们重用一些相同的逻辑 views.py from django.shortcuts import render from django.http import HttpResponseRedirect from .forms import NameForm def get_name(request): # if this is a POST request we need to process the form data if request.method == 'POST': # create a form instance and populate it with data from the request: form = NameForm(request.POST) # check whether it's valid: if form.is_valid(): # process the data in form.cleaned_data as required # ... # redirect to a new URL: return HttpResponseRedirect('/thanks/') # if a GET (or any other method) we'll create a blank form else: form = NameForm() return render(request, 'name.html', {'form': form}) 如上 , 如果访问视图的是一个GET请求 , 它将创建一个空的表单实例并将它放置到要渲染的模板的上下文中 , 这是我们在第一次访问该URL时发生的事情 如果使用POST请求提交表单 , 该视图将再次创建一个表单实例 , 并使用请求中的数据填充表单 , 即form = NameForm(request.POST) 这种方式称为绑定 , 即将数据绑定到表单 我们调用is_valid()方法 ; 如果不是True , 也就是说我们的所有数据中存在不合法的项 , 那么它就会返回到HTML Form , 也就是我们提交之前的位置 , 但是这个时候这个实例不是空的 (这一步是未绑定的) , HTML Form将使用前面提交合法的数据进行填充 , 而对于不合法的我们就可以对其进行编辑和修改 如果is_valid() 返回True , 我们就可以在cleaned_data属性中找到所有合法的表单数据 , 我们就可以使用这些数据去更新数据库或进行其他操作 , 然后将HTTP重定向发送给浏览器 , 告诉它下一步怎么走 模板 🍀 我们不需要在模板中做很多的工作 , 最简单的例子 : {% csrf_token %} {{ form }} 这样我们就可以通过模板语言中的form变量将所有的form字段和属性都会打包为HTML中的form 跨站请求伪造的防护 Django原生支持一个简单易用的 protection against Cross Site Request Forgeries , 当提交一个启用CSRF防护的POST表单时 , 你必须使用上面例子中的csrf_token 模板标签 HTML 5 输入类型和浏览器验证 如果你的表单包含URLField , EmailField 或其它整数字段类型 , Djanog将使用url , email 和 number这样的HTML 5 输入类型 ; 默认情况下 , 浏览器可能会对这些字段进行它们自身的验证 , 这些验证可能比Django的验证更严格 , 如果你想禁用这个行为 , 可以通过设置form标签的novalidate 属性 , 或者指定一个不同的字段 , 如TextInput More about Django Form classes 🍀 所有的表单类都被创建为django.forms.Form 的子类 , 包括Django Admin中的 ModelForm 实际上 , 如果你的表单打算直接用来添加和编辑Django的模型 , ModelForm 可以节省你的许多时间 , 精力和代码 , 因为它将根据Model类中构建一个表单以及相应的字段和属性 绑定和未绑定 🍀 绑定和未绑定的表单实例之间的区别如下 : 未绑定的表单没有关联的数据 , 当渲染给用户时 , 它将为空或包含默认的值 绑定的表单具有提交的数据 , 因此可以用来检验数据是否合法 ,如果渲染一个不合法的绑定的表单 , 它将包含内联的错误信息 , 告诉用户如何纠正数据 表单的is_bound 属性将告诉你一个表示是否具有绑定的数据 字段 🍀 前面的例子中 , 我们仅使用了一个字段 , 当然字段还有很多 , 我们可以在 Form fields 中找到完整的列表 窗口小部件 🍀 每个表单字段都有一个对应的 Widget class , 它对应一个HTML表单小部件 , 例如 : 在大部分情况下 , 字段都具有一个合理的默认Widget , 例如 , 默认情况下 , CharField具有一个TextInput Widget , 它在HTML中生成一个 >>> from django import forms >>> name = forms.TextInput(attrs={'size': 10, 'title': 'Your name',}) >>> name.render('name', 'A name') '' 字段数据 🍀 不管提交的是什么数据 , 一旦通过调用is_valid() 成功验证后 , 验证后的表单数据将位于form.cleaned_data 字典中 , 并且这些数据已经为你转换好Python类型 此时你依然可以从request.POST 中直接访问到未验证的数据 , 但是访问验证后的数据更好一些 from django.core.mail import send_mail if form.is_valid(): subject = form.cleaned_data['subject'] message = form.cleaned_data['message'] sender = form.cleaned_data['sender'] cc_myself = form.cleaned_data['cc_myself'] recipients = ['info@example.com'] if cc_myself: recipients.append(sender) send_mail(subject, message, sender, recipients) return HttpResponseRedirect('/thanks/') 有些字段类型需要一些额外的处理 , 例如 , 使用表单上传的文件需要不同地处理 (它们可以从request.POST获取 , 而不是request.FILES ) , 图和使用表单处理文件上传的更多细节 , 见Binding uploaded files to a form 关于Django中如何发送邮件的更多信息 , 见Sending email 使用表单模板 🍀 表单渲染选项 🍀 对于/ 来说 , 还有其他几个输出选项 : form.as_table , 以表格的形式将他们渲染在标签中 form.as_p , 将它们渲染在标签中 form.as_ul , 将它们渲染在标签中 注意 , 我们必须自己提供或 实例 # 实例输出{{ form.as_p }} Subject: Message: Sender: Cc myself: 手动渲染字段 🍀 我们不必让Django打开表单的字段 , 如果我们想要 , 我们也可以手动执行 (例如 , 允许我们重新排序字段) , 每个字段都是表单的一个属性 , 可以使用 {{ form.name_of_field }} 来访问 , 并将在Django模板中正确地渲染 , 如下 : {{ form.non_field_errors }} {{ form.subject.errors }} Email subject: {{ form.subject }} {{ form.message.errors }} Your message: {{ form.message }} {{ form.sender.errors }} Your email address: {{ form.sender }} {{ form.cc_myself.errors }} CC yourself? {{ form.cc_myself }} 完整的 元素还可以使用label_tag() 生成 {{ form.subject.errors }} {{ form.subject.label_tag }} {{ form.subject }} 渲染表单错误信息 🍀 对于错误信息 , Django已经帮我们处理好了 , 如下我们将自己处理每个字段的错误和表单整体的各种错误 Sender is required. 这个ul有一个errorlist CSS class , 你可以用它来定义外观 field属性 🍀 {{ field.label }} {{ field.label_tag }} tag. This includes the form’s label_suffix. For example, the default label_suffix is a colon: Email address: -> {{ field.id_for_label }} {{ field.value }} {{ field.html_name }} {{ field.help_text }} {{ field.errors }} containing any validation errors corresponding to this field. You can customize the presentation of the errors with a {% for error in field.errors %} loop. In this case, each object in the loop is a simple string containing the error message. -> {{ field.is_hidden }} {{ field.field }} 完整的属性和方法列表 , 见BoundField 循环隐藏和可见的字段 🍀 如果你在模板中手动布局一个表单 , 而不是依赖Django的默认表单布局 , 你可能会想要用不同于非隐藏的字段来处理不同的字段 ; 例如 , 因为隐藏的字段不显示任何内容 , 将错误信息放在 \"旁边\" 可能会引起用户的混淆 , 因此这些字段的错误应该以不同的方式处理 Django提供了两种方法 , 让你可以独立地遍历隐藏和可见字段 : visible_fields()和hidden_fields() , 如下 : {# Include the hidden fields #} {% for hidden in form.hidden_fields %} {{ hidden }} {% endfor %} {# Include the visible fields #} {% for field in form.visible_fields %} {{ field.errors }} {{ field.label_tag }} {{ field }} {% endfor %} 这个示例没有处理隐藏字段中的任何错误信息 , 通常 , 隐藏字段中的错误意味着表单被篡改 , 因为正常的表单填写不会改变他们 可重用表单模板 🍀 如果你的网站在多个地方对表单使用相同的渲染逻辑 , 你可以保存表单的循环到一个单独的模板来减少重复 , 然后在其他模板中使用include 标签来重用它 : # In your form template: {% include \"form_snippet.html\" %} # In form_snippet.html: {% for field in form %} {{ field.errors }} {{ field.label_tag }} {{ field }} {% endfor %} 如果传递到模板上写问中的表单对象具有一个不同的名称 , 你可以使用include标签的with参数来给它起个别名 : {% include \"form_snippet.html\" with form=comment_form %} 上面只是一些基础 , 表单还可以完成更多的工作 , 更多内容见 : The Forms Reference "},"05-Web框架/Django/12-Django - Template.html":{"url":"05-Web框架/Django/12-Django - Template.html","title":"Django - Template","keywords":"","body":"Django - Template 介绍 🍀 本篇相当于一个引子 , 了解即可 , 我们一般不这样去使用 上一篇中我们了解了视图 , 即处理请求返回响应 ; 通常我们都是返回一个字符串 , 一个以HTML规则编写的字符串 , 使其在浏览器上能够很好的显示 那么最初 , 我们都是直接返回一堆字符串 , 如下 : # 原始视图函数 from djang.shortcuts import HttpResponse def index(request): # 所有的视图函数都必须返回响应 return HttpResponse(\"\"\" Title %s \"\"\" % \"Hello World!\") Django为我们提供了另一种写法 : from django.template import Template,Context from django.shortcuts import HttpResponse,render def index(request): # 创建模板对象,其中{{ message }}如同%s一样占位 tem_obj = Template(\"\"\" Title {{ message }} \"\"\") # 创建上下文对象,用于渲染模板 con_obj = Context({'message':'Hello World'}) # 进行渲染 html = tem_obj.render(con_obj) # 将渲染完成的html返回给前端 return HttpResponse(html) 这种写法看起来并没有比原生视图函数有什么好 , 我们一般不这么写 , 而是使用如下写法 : from django.shortcuts import HttpResponse,render def index(request): message = \"Hello World!\" # render为我们进行了封装,我们只需直接传递模板文件名和上下文就可直接完成 return render(request,'index.html',{'message':message}) 我们知道 , 我们的页面 (也就是我们的模板) 经常有很多相同的代码 , 这是非常不好的 , 所以 , 这是Web框架需要解决的问题 所以作为一个Web框架 , Django需要一个方便的方式来动态生成HTML , 最常见的方法就是依赖于模板 Django项目可以配置一个或多个模板引擎 , Django为其自己的模板系统提供内置后端 , 也就是我们所说的Djanog模板语言 , 目前最流行的就是Jinja2 由于历史原因 , 对模板引擎的一般支持和Django模板语言的实现都存在于django.template 命名空间中 , 对于模板语言会放在下一篇中进行整理 Warning : 模板系统对于不受信任的模板作者是不安全的 , 如 : 一个站点不应允许其用户提供自己的模板 , 因为模板作者可以执行诸如XSS攻击和访问可能包含敏感信息的模板变量的属性 当我们使用Pycharm 创建一个项目时 , 会自动会我们创建一个templates 文件夹 , 就是用来存放我们的模板文件的 Python使用模板系统是一个三步过程 : 配置一个Engine 将模板代码编译成一个 Template对象 利用Context对象对模板进行渲染 注意 : 这一篇主要对于模板引擎的配置 , Template对象 , Context对象进行描述 ; 但是我们一般不会自己创建Template和Context对象 , 因为Django已经帮我们做了这些工作 , 所以我们主要还是直接使用render() Engine 🍀 模板引擎使用TEMPLATES 设置进行配置 , 位于settings.py 中 , 如下 : TEMPLATES = [ { # 实现Django模板后端API的模板引擎类的Python路径,内置后端是 # django.template.bakcends.django.DjangoTemplates # django.template.backends.jinja2.Jinja2 'BACKEND': 'django.template.backends.django.DjangoTemplates', # 根据搜索顺序定义引擎应该查找模板源文件的目录列表 'DIRS': [os.path.join(BASE_DIR, 'templates')] , # 告诉引擎是否应该在已安装的应用程序中查找模板,每个后端都为其模板应存储在其中的应用程序内的子目录定义一个常规名称 'APP_DIRS': True, # 包含后端特定的设置 'OPTIONS': { # 当模板被请求呈现时,可用于填充上下文的可调用Python路经列表 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, }, ] 用法 🍀 在django.template.loader 模块中定义了两个函数来加载模板 def get_template(template_name, using=None): \"\"\" Loads and returns a template for the given name. Raises TemplateDoesNotExist if no such template exists. \"\"\" # return:The exact type of the return value depends on the backend that loaded the template. Each backend has its own Template class. # How templates are searched and loaded depends on each engine’s backend and configuration. # using:engine's NAME,restrict search to a specific template engine def select_template(template_name_list, using=None): \"\"\" Loads and returns a template for one of the given names. Tries names in order and returns the first template found. Raises TemplateDoesNotExist if no such template exists. \"\"\" # select_template() is just like get_template(), except it takes a list of template names. It tries each name in order and returns the first template that exists. Template对象通过调用get_template() 和select_template() 生成 , 但是必须提供一个render() 方法 一个搜索算法🌰 TEMPLATES = [ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [ '/home/html/example.com', '/home/html/default', ], }, { 'BACKEND': 'django.template.backends.jinja2.Jinja2', 'DIRS': [ '/home/html/jinja2', ], }, ] 如果我们调用get_template('story_detail.html') , 那么Django将会寻找以下文件 : /home/html/example.com/story_detail.html ('django' engine) /home/html/default/story_detail.html ('django' engine) /home/html/jinja2/story_detail.html ('jinja2' engine) 如果调用select_template(['story_253_detail.html','story_detail.html']) , 则Django将会寻找如下文件 : /home/html/example.com/story_253_detail.html ('django' engine) /home/html/default/story_253_detail.html ('django' engine) /home/html/jinja2/story_253_detail.html ('jinja2' engine) /home/html/example.com/story_detail.html ('django' engine) /home/html/default/story_detail.html ('django' engine) /home/html/jinja2/story_detail.html ('jinja2' engine) 当Django找到一个存在的模板时 , 就会停止寻找 为了减少加载和渲染模板的重复性 , Django提供了一个快捷方式来自动化这个过程 , 即django.template.loader 中的render_to_string() , 具体如下 : def render_to_string(template_name, context=None, request=None, using=None): \"\"\" Loads a template and renders it with a context. Returns a string. template_name may be a string or a list of strings. template_name:要加载和渲染的模板名称,如果传入模板名称列表,则Django将会使用select_template() context:一个用于呈现模板上下文的dict request:一个可选的HttpRequest using:一个可选的模板引擎名称,搜索模板将被限制在该引擎 \"\"\" # render_to_string()相当于调用get_template()后并调用其render()方法 用法示例 : from django.template.loader import render_to_string rendered = render_to_string('my_template.html', {'foo': 'bar'}) engines 模板引擎可以使用django.template.engines : from django.template import engines # The lookup key — 'django' in this example — is the engine’s NAME. django_engine = engines['django'] template = django_engine.from_string(\"Hello {{ name }}!\") 内置后端 🍀 DjangoTemplates TEMPLATES = [ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [], # DjangoTemplate引擎会在已安装应用程序的模板子目录中寻找模板,这个通用名称是为了向后兼容而保留的 'APP_DIRS': True, # 可选配置 'OPTIONS': { # 控制是否启动HTML自动转义 'autoescape':True # 当模板被请求呈现时,用于填充上下文的可调用Python路径列表.这些可调用对象将请求对象作为参数,并返回一个合并到上下文的列表 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], # 打开模板调试模式,默认为DEBUG设置的值 'debug':True # 模板加载器的Python路径列表 'loaders':[ ( 'django.template.loaders.filesystem.Loader', [os.path.join(BASE_DIR, 'templates')], ), ], # 如果变量不存在,模板系统会默认插入引擎string_if_invalid的值 'string_if_invalid':'' # 用于读取磁盘上的模板文件的字符集,默认utf-8 'file_charset':'utf-8' # 一个标签和模板标签模块路径的字典,用于注册模板引擎 'libraries':{ 'myapp_tags':'path.to.myapp.tags', 'admin.urls':'django.contrib.admin.templatetags.admin_urls', }, # 一个要添加到内置插件的模板标签模块 'builtins': ['myapp.builtins'], }, }, ] Jinja2 安装 pip install Jinja2 将BACKEND 设置为django.template.backends.jinja2.Jinja2 最重要的OPTIONS条目是environment , 这是一个Python路径 , 可以返回一个Jinja2环境 , 默认为jinja2.Environment Django添加了几个与Jinja2不同的默认值 : 'autoescape' : True 'loader' : a loader configured for DIRS and APP_DIRS 'auto_reload' : settings.DEBUG 'undefined' : DebugUndefined if settings.DEBUG else Undefined Jinja2也接受如DjangoTemplate的OPTIONS : TEMPLATES = [ { 'BACKEND': 'django.template.backends.jinja2.Jinja2', 'DIRS': [] 'APP_DIRS': True, 'OPTIONS': { 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, }, ] Jinja2 : http://jinja.pocoo.org/docs/2.10/ 自定义后端 : https://docs.djangoproject.com/en/1.11/topics/templates/#custom-backends origin API : https://docs.djangoproject.com/en/1.11/topics/templates/#origin-api-and-3rd-party-integration Template 🍀 通过上文我们就可以配置好一个Engine了 , 那么接下来就是将模板代码编译成Template对象了 推荐创建Template对象的方法是调用Engine中的get_template() , select_template() 和工厂方法from_string() 同样django.template.backends.django.Template 也适用django.template.Template 通用的模板API , 也就是说无论DjangoTemplate 还是Jinja2 , 都可以通过django.template.Tempalte 来进行创建 class Template[source] 这个类存在于django.template.Template 中 , 构造函数如下 : def __init__(self, template_string, origin=None, name=None, engine=None): 实例 from django.template import Template template = Template(\"My name is {{ my_name }}.\") 注意 : 创建Template对象时 , 系统只解析一次原始模板代码 , 从那时起 , 它就被存储在内部 , 作为一个树形结构来提高性能 Context 🍀 一旦我们拥有了一个Template对象 , 我们就可以用它来渲染一个上下文 ; 并且可以重复使用相同的模板 , 使用不同的上下文多次渲染它 django.template.Context 除了上下文数据之外 , 还保存一些元数据 , 它被传递给Template.render() 来呈现模板 django.template.RequestContext 是Context存储当前HttpRequest并运行模板上下文处理器的子类 class Context(dict_ = None) [source] 构造函数如下 def __init__(self, dict_=None, autoescape=True, use_l10n=None, use_tz=None): 实例 >>> from django.template import Context, Template >>> template = Template(\"My name is {{ my_name }}.\") >>> context = Context({\"my_name\": \"Adrian\"}) >>> template.render(context) \"My name is Adrian.\" >>> context = Context({\"my_name\": \"Dolores\"}) >>> template.render(context) \"My name is Dolores.\" 大多数情况下 , 我们将Context通过传入完全填充的字典来实例化对象Context() , 但是Context , 使用标准字典语法 , 也可以在实例化对象后添加和删除项目 , 如下 : >>> from django.template import Context >>> c = Context({\"foo\": \"bar\"}) >>> c['foo'] 'bar' >>> del c['foo'] >>> c['foo'] Traceback (most recent call last): ... KeyError: 'foo' >>> c['newvariable'] = 'hello' >>> c['newvariable'] 'hello' 更多 : https://docs.djangoproject.com/en/1.11/ref/templates/api/ https://docs.djangoproject.com/en/1.11/topics/templates/ "},"05-Web框架/Django/13-Django - Template Language.html":{"url":"05-Web框架/Django/13-Django - Template Language.html","title":"Django - Template Language","keywords":"","body":"Django - Template Language 介绍 🍀 模板只是一个文本文件 , 它能够生成以下文本格式的文件 , 如 : HTML , XML , CSV , etv等 下面是一个简单的基本模板 , 每个元素将在本文后面解释 {% extends \"base_generic.html\" %} {% block title %}{{ section.title }}{% endblock %} {% block content %} {{ section.title }} {% for story in story_list %} {{ story.headline|upper }} {{ story.tease|truncatewords:\"100\" }} {% endfor %} {% endblock %} 模板包括在使用时会被替换掉的变量 , 以及控制模板逻辑的标签 变量 🍀 定义变量 变量名称由字母数字和下划线组成 , \".\"和\"_\" 也可以出现在变量部分 ; 变量名中不能有空格或标点符号 {{ variable }} 实例 My first name is {{ first_name }}. My last name is {{ last_name }}. 在上下文中 , {'first_name': 'John', 'last_name': 'Doe'} , 将呈现如下效果 : My first name is John. My last name is Doe. 字典查找 , 属性查找和列表索引查找用 \".\" 号实现 : {{ my_dict.key }} {{ my_object.attribute }} {{ my_list.0 }} 当模板系统遇到 \".\" 时 , 会按照以下顺序进行查找 : Dictionary lookup Attribute or method lookup Numeric index lookup 如果结果值是可调用的 , 它将不使用参数进行调用 , 而调用的结果则成为模板值 这个查找顺序可能会导致一些无法预料的行为 , 这些对象覆盖了字典查找 , 如下 : {% for k, v in defaultdict.iteritems %} Do something with k and v here... {% endfor %} # 由于字典查找首先发生,该行为将启动并提供一个默认值,而不是使用预期的iteritems()方法,在这种情况下,我们应该考虑先转换成字典 过滤器 🍀 可以通过过滤器来修改变量的显示 , 使用 \"|\" 来应用过滤器 单个过滤器 # 将文本转换为小写 {{ name|lower}} 链接过滤器 # 转义文本内容,将换行符转换为p标签 {{ text|escape|linebreaks}} 带参数过滤器 # 显示bio变量的前30个单词 {{ bio|truncatewords:30 }} # 过滤器参数中包含空格的必须被引用,用逗号和空格连接列表 {{ list|join:\", \"}} Django中提供了大约60个内置的模板过滤器 , 以下是一些常用的模板过滤器 : default : 如果一个变量是错误或者为空 , 则使用默认给定的 , 否则就使用变量的值 {{ value|default:\"nothing\"}} length : 返回值的长度 , 适用于字符串和列表 {{ value|length}} filesizeformat : 格式化值为一个人们可读的文件大小 , 如 : '13KB' , '4.1MB' , '102bytes'等 {{ value|filesizeformat}} # value = 123456789 # output : 117.7MB 更多内置过滤器 : built-in filter reference 标签 🍀 标签比变量更复杂 : 标签可以在输出中创建文本 ; 执行循环或逻辑控制 ; 将外部信息加载到模板中以供以后的变量使用 定义标签 {% tag %} Django附带大约二十个内置模板标签 , 以下是一些常用标签 : for : 遍历数组中的每个项目 # 展示运动员名单 {% for athlete in athlete_list %} {{ athlete.name }} {% endfor %} for ... empty : 当给出的组为空或者没有被找到时 , 所执行的操作 {% for person in person_list %} {{ person.name }} {% empty %} sorry,no person here {% endfor %} if , elif 和else : 流程控制 {% if athlete_list %} Number of athletes: {{ athlete_list|length }} {% elif athlete_in_locker_room_list %} Athletes should be out of the locker room soon! {% else %} No athletes. {% endif %} 使用过滤器和各种操作符 {% if athlete_list|length > 1 %} Team: {% for athlete in athlete_list %} ... {% endfor %} {% else %} Athlete: {{ athlete_list.0.name }} {% endif %} 注意 : 大多数模板的过滤器返回字符串 , 所以使用过滤器在数学上通常不会像所期望的那样工作 , length是一个列外 block和extends 这两个标签用户设置模板继承 , 这是一种在模板中减少 \"样板\" 的强大方法 , 见下文 内置标签参考 : built-in tag reference 自定义模板标签和过滤器 : Custom template tags and filters 注释 🍀 要在模板中注释行的一部分 , 可以使用注释语法 : # 单行注释 {# ... #} # 多行注释 {% comment %} ... {% endcomment %} 模板继承 🍀 Django模板引擎中最强大 , 也是最复杂的部分是模板继承 , 模板继承允许你创建一个基本 \"框架\" 模板 , 其中包含网站所有常用元素 , 并定义子模板可以覆盖的块 base.html {% block title %}My amazing site{% endblock %} {% block sidebar %} Home Blog {% endblock %} {% block content %}{% endblock %} 上面定义了一个简单的HTML框架文档 , 在这个例子中 , block标签定义了三个子模板可以填充的块 , 所有的block 标签都告诉模板引擎一个子模板可以覆盖模板的哪些部分 子模板可能如下所示 : {% extends \"base.html\" %} {% block title %}My amazing blog{% endblock %} {% block content %} {% for entry in blog_entries %} {{ entry.title }} {{ entry.body }} {% endfor %} {% endblock %} extends 标签用于告诉模板引擎 , 该模板扩展了另一个模板 , 当模板系统执行这个模板时 , 首先会找到父模板 , 也就是这里的base.html 于是 , 模板引擎就将block标签中的内容替换base.html 中block标签中的内容 , 根据blog_entries 的值 , 输出可能如下 : My amazing blog Home Blog Entry one This is my first entry. Entry two This is my second entry. 在子模板中为定义的块 , 会使用父模板中的块 , 也就是说 , 没有定义则以父模板作为备用 为了增加可读性 , 可以给标签进行命名 , 如下 : {% block content %} ... {% endblock content %} 自动HTML转义 🍀 为了避免变量值中带有的HTML字符被解析 , 我们有两种方式 : 将潜在有害的HTML字符转换为无害的字符 , 这种方式会把责任放在我们身上 , 需要我们自己来逃避数据 , 所以明显这不够安全 ; 这也是Django头几年的默认解决方案 利用Django的自动HTML转义 默认情况下 , 在Django中 , 每个模板都会自动转义每个变量标签的输出 , 具体来说 , 以下五个字符是会被转义的 : &lt; > 被转换成&gt; ' (单引号) 转换为&#39; \" (双引号) 转换为&quot; & 被转换为&amp; 注意 : 这种行为默认是开启的 关闭自动HTML转义 对于个人变量 使用safe过滤器 : # 会被转义 This will be escaped: {{ data }} # 不会被转义 This will not be escaped: {{ data|safe }} data中包含 , 结果如下 : This will be escaped: &lt;b&gt; This will not be escaped: 对于模板块 使用autoscape标签 : {% autoescape off %} Hello {{ name }} {% endautoescape %} autoscape标签接收两个参数 , on和off , 如下 : Auto-escaping is on by default. Hello {{ name }} {% autoescape off %} This will not be auto-escaped: {{ data }}. Nor this: {{ other_data }} {% autoescape on %} Auto-escaping applies again: {{ name }} {% endautoescape %} {% endautoescape %} 自动转义标记将其影响传递到扩展当前的模板和包含通过include标记的模板 , 如下 : base.html {% autoescape off %} {% block title %}{% endblock %} {% block content %} {% endblock %} {% endautoescape %} child.html {% extends \"base.html\" %} {% block title %}This &amp; that{% endblock %} {% block content %}{{ greeting }}{% endblock %} 呈现如下 : This &amp; that Hello! 自定义标签和过滤器 : https://docs.djangoproject.com/en/1.10/howto/custom-template-tags/ https://docs.djangoproject.com/en/1.10/ref/templates/language/#custom-tag-and-filter-libraries 更多Template Language相关 : https://docs.djangoproject.com/en/1.10/ref/templates/language/ "},"05-Web框架/Django/14-Django - Middleware.html":{"url":"05-Web框架/Django/14-Django - Middleware.html","title":"Django - Middleware","keywords":"","body":"Django - Middleware 介绍 🍀 在Django中 , 中间件本质上就是一个类 , 我们可以使用中间件来对请求和响应进行批量处理 , 中间件所在的层次介于WSGI协议与Django URL系统之间 , 它类似一个一个的盒子 , 所有的请求和响应到来时 , 都必须穿过一个一个的盒子 (中间件) , 如下 : 请求 → → 中间件1 → → 中间件2 → ... → 响应 ↓ ↓ 请求 ← ← 中间件1 ← ← 中间件2 ← ... ← 响应 它是一个轻量级 , 底层的 \"插件\" 系统 , 用于在全局修改Django的输入或输出 每个中间件负责完成某个特定的功能 , 如下为默认Django激活的中间件如下 : MIDDLEWARE = [ # 安全保护中间件 'django.middleware.security.SecurityMiddleware', # 会话中间件 'django.contrib.sessions.middleware.SessionMiddleware', # 通用中间件 'django.middleware.common.CommonMiddleware', # 跨站请求伪造保护中间件 'django.middleware.csrf.CsrfViewMiddleware', # 认证中间件 'django.contrib.auth.middleware.AuthenticationMiddleware', # 消息中间件 'django.contrib.messages.middleware.MessageMiddleware', # 防止点击劫持中间件 'django.middleware.clickjacking.XFrameOptionsMiddleware', ] 我们可以看到MIDDLEWARE是一个列表 , 也就是说中间件是有顺序的 , 我们在使用中间件时需要注意中间件的排序 , 因为有的中间件可能需要依赖某一中间件 , 所以其应该放在依赖的中间件之后 对于请求和响应的少量或部分处理 , 我们可以使用装饰器来实现 中间件排序 : Middleware ordering 内置中间件 : built-in middleware reference CSRF 🍀 CSRF 即Cross Site Request Forgery protection , 中文意思为跨站请求伪造 , 也被称为\"One Click Attack\"或者 Session Riding , 通常缩写为CSRF或XSRF , 是一种对网站的恶意利用 攻击通过在授权用户访问的页面中包含链接或者脚本的方式工作 , 例如 : 一个网站用户Bob可能正在浏览聊天论坛 , 而同时另一个用户Alice也在此论坛中 , 并且后者刚刚发布了一个具有Bob银行链接的图片消息 ; 设想一下 , Alice编写了一个在Bob的银行站点上进行取款的form提交的链接 , 并将此链接作为图片src ; 如果Bob的银行在cookie中保存他的授权信息 , 并且此cookie没有过期 , 那么当Bob的浏览器尝试装载图片时将提交这个取款form和他的cookie , 这样在没经Bob同意的情况下便授权了这次事务 所以为了防止CSRF的发生 , Django为我们提供了中间件django.middleware.csrf.CsrfViewMiddleware CSRF中间件使用 🍀 如果要在我们的视图中使用CSRF保护 , 我们需要进行如下操作 : CSRF中间件默认在MIDDLEWARE设置中被激活 , CSRF中间件应该在任何视图中间件之前 , 以确保CSRF攻击已被处理 在任何使用POST的表单模板中 , 如果表单用于内部URL , 则需要使用csrf_token标记form标签 , 如下 : {% csrf_token %} 在相应的视图函数中 , 确保使用RequestContext 来渲染响应 , 以便csrf_token能够正常使用 , render()函数 , 或者contrib应用以及通用视图都是用RequestContext 在Jinja2模板中用csrf_input代替了csrf_token 注意 : 如果传入的请求未能通过CsrfViewMiddleware执行的检查 , 则会向用户发送403 Forbidden 响应 ; 这也就是如果我们激活了CsrfViewMiddleware 中间件 , 而没添加csrf_token 时为什么会出现403 Forbidden错误 更多CSRF中间件使用参考 : Cross Site Request Forgery protection documentation 激活中间件 🍀 我们如果要使用中间件 , 就需要在Django配置中的MIDDLEWARE添加中间件组件 默认时 , Django已经为我们配置好了一些内置的中间件 , 如果我们想要使用自定义的中间件 , 那么我们就需要在该配置中进行添加了 , 如下 : MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', 'RbacMiddleware', # 激活Rbac中间件 ] 自定义中间件 🍀 有时候我们需要自定义中间件来达到我们的实际要求 , 其有两种方式 , 即通过类或者函数 通常我们使用类 , 如下 : class SimpleMiddleware(object): def __init__(self, get_response): self.get_response = get_response # One-time configuration and initialization. def __call__(self, request): # Code to be executed for each request before # the view (and later middleware) are called. response = self.get_response(request) # Code to be executed for each request/response after # the view is called. return response 在我们自定义中间件时需要注意如下 : __init__() 必须接受get_response参数 , 旧版中__init__()不接受任何参数 , 所以为了兼容性 , 我们应该这样写def __init__(self, get_response): 每个请求都会调用一次__call__()方法 当Web服务器启动时 , __init__()仅会被调用一次 MiddlewareMixin 🍀 上面的写法只适用于Django 1.9及之前的写法 , 在1.10的版本中 , Django为我们提供了django.utils.deprecation.MiddlewareMixin以简化MIDDLEWARE和旧的MIDDLEWARE_CLASSES兼容的中间件类 ; Django 1.10之后的版本使用MIDDLEWARE代替MIDDLEWARE_CLASSES , Django中包含的所有中间件类都兼容这两种设置 class MiddlewareMixin # 自定义中间件类需要继承该类 class MiddlewareMixin(object): def __init__(self, get_response=None): self.get_response = get_response super(MiddlewareMixin, self).__init__() def __call__(self, request): response = None if hasattr(self, 'process_request'): response = self.process_request(request) if not response: response = self.get_response(request) if hasattr(self, 'process_response'): response = self.process_response(request, response) return response ''' 注意: 为了解决版本的兼容问题, 我们不应该由django.utils.deprecation中来导入MiddlewareMixin, 因为在之后的版本MiddlewareMixin将会被剔除 ''' 如果与MIDDLEWARE_CLASSES一起使用 , 在不会使用__call__()方法 ; Django会直接调用process_request()和process_response() 在大多数情况下 , 继承这种混合将足以使旧式中间件与新系统兼容 , 具有足够的向后兼容性 钩子函数 🍀 在请求阶段中 , 调用视图之前 , Django会按照MIDDLEWARE中定义的顺序自顶向下应用中间件 , 我们需要用到以下两个钩子函数 : process_request() process_view() 在响应阶段中 , 调用视图之后 , 中间件会按照相反的顺序应用 , 自底向上 , 我们需要用到以下三个钩子函数 : process_exception() , 仅当视图抛出异常时使用 process_template_response() , 仅用于模板响应 process_response() 如下图 : 我们可以将这些中间件比作为一个洋葱 , 每个中间件类都是一个\"洋葱层\" 如果请求通过洋葱的所有层 , 一直到核心的视图 , 随后响应会按照相反的顺序原路返回 如果其中某一层短路并返回响应 , 那么将不能到达视图 , 而是直接在短路层就返回响应 process_request() 🍀 process_request(request): \"\"\" request:是一个HttpRequest对象 \"\"\" 在Django决定执行哪个视图之前 , 将会先调用process_request() process_request()应该返回一个None或者一个HttpResponse对象 , 返回说明如下 : 如果返回None , Django会继续处理这个请求 , 执行其它中间件的process_request() , 然后执行中间件的process_view() , 最后执行对应的视图 如果返回一个HttpResponse对象 , Django就不会去调用其他的中间件的request_view或request_exception或对应的视图 , 而是直接转变到响应阶段 , 按照原路返回 process_view() 🍀 process_view(request, view_func, view_args, view_kwargs): \"\"\" request:一个HttpRequest对象,与我们在前面视图函数中的request一样 view_func:是Django会调用的一个Python函数 view_args:一个会传递到视图的位置参数列表 view_kwargs:一个会传递到视图的关键字参数字典 view_args和view_kwargs都不包含第一个视图函数request \"\"\" process_view()会在Django调用视图之前被调用 , 它返回一个None或一个HttpResponse对象 , 返回说明如下 : 如果返回None , Django将会继续处理这个请求 , 执行其它的process_view()中间件然后调用对应的视图 如果返回一个HttpResponse对象 , Django就不会去调用其它中间件的process_view()或process_exception()或对应的视图 , 它将转变至响应阶段 , 并返回结果 Note Accessing request.POST inside middleware before the view runs or in process_view() will prevent any view running after the middleware from being able to modify the upload handlers for the request, and should normally be avoided. The CsrfViewMiddleware class can be considered an exception, as it provides the csrf_exempt() and csrf_protect() decorators which allow views to explicitly control at what point the CSRF validation should occur. process_exception() 🍀 process_exception(request, exception): \"\"\" request:一个HttpRequest对象 exception:是一个被视图中的方法抛出来的exception对象 \"\"\" 当一个视图抛出异常时 , Django会调用process_exception()来处理 ; process_exception()应该返回None或者HttpResponse对象 , 如果返回HttpResponse对象 , 则将应用模板响应和响应中间件 , 并将生成的响应返回给浏览器 , 否则Django会使用默认异常处理方式进行处理 注意 : 在处理响应期间 , 中间件的执行顺序是倒序执行的 , 所以如果异常中间件返回响应 , 那么下一层中间件的process_exception方法将不会调用 , 因为在上一层已经捕捉完成 process_template_response() 🍀 process_template_response(request, response): \"\"\" request:是一个HttpRequest对象 response:是一个TemplateResponse对象(或等价的对象), 由Django视图或者中间件返回 \"\"\" 这个方法必须返回一个实现了render方法的响应对象 , 它可以修改给定的response对象 , 通过修改response.tmplate_name和response.context_data或者它可以创建一个全新的TemplateResponse对象(或等价的对象) 并且一旦所有的模板响应中间件被调用 , 响应会自动被渲染 process_response() 🍀 process_response(request,response): \"\"\" request:一个HttpRequest对象 response:Django视图或者中间件返回的HttpResponse或者StreamingHttpResponse对象 \"\"\" process_response()在所有响应返回浏览器之前被调用 这个方法必须返回HttpResponse或者StreamingHttpResponse对象 , 它可以改变已有的response , 或者创建并返回新的HttpResponse或StreamingHttpResponse对象 process_response不像process_request和process_view那样会因为前一个中间件返回的HttpResponse而被跳过 , process_response方法总是会被调用 , 这意味着你的process_response方法不能依赖于process_request方法中的设置 处理流响应 🍀 不像HttpResponse , StreamingHttpResponse并没有content属性 , 所以 , 中间件再也不能假设所有响应都带有content属性 , 如果它们需要访问内容 , 他们必须测试是否为流式响应 , 并相应地调整自己的行为 , 如下 : if response.streaming: response.streaming_content = wrap_streaming_content(response.streaming_content) else: response.content = alter_content(response.content) 注意 : 我们需要假设streaming_content可能会大到在内存中无法容纳 , 响应中间件可能会把它封装在新的生成器中 , 但是一定不要销毁它 , 封装一般如下 : def wrap_streaming_content(content): for chunk in content: yield alter_content(chunk) RBAC案例 🍀 rbac即Role-Based Access Control , 基于角色的权限访问控制 , 这种控制极大地简化了权限的管理 , 下面为rbac中我们自定义使用的中间件案例 : import re from django.shortcuts import redirect,HttpResponse from django.conf import settings class MiddlewareMixin(object): def __init__(self, get_response=None): self.get_response = get_response super(MiddlewareMixin, self).__init__() def __call__(self, request): response = None if hasattr(self, 'process_request'): response = self.process_request(request) if not response: response = self.get_response(request) if hasattr(self, 'process_response'): response = self.process_response(request, response) return response # 继承MiddlewareMixin类 class RbacMiddleware(MiddlewareMixin): def process_request(self,request): # 获取当前请求的URL current_url = request.path_info # 当前请求不需要执行权限验证 for url in settings.VALID_URL: if re.match(url,current_url): return None # 获取Session中保存当前用户的权限 permission_list = request.session.get(\"permission_url_list\") if not permission_list: return redirect('/login/') # 判断是否具有权限并设置标志位 flag = False for db_url in permission_list: regax = \"^{0}$\".format(db_url) if re.match(regax, current_url): flag = True break # 最后如果具有权限那么继续走向下一个中间件或者视图 # 否则,返回响应 if not flag: return HttpResponse('无权访问') ''' 注意: 对于钩子函数是否定义在于我们自己,但是要注意中间件的工作原理, 比如在这里我们没有定义process_response方法, 但是在MiddlewareMixin类的__call__方法中, 使用了get_response方法 ''' 更多中间件相关 : middleware usage guide "},"05-Web框架/Django/15-Django - Sessions.html":{"url":"05-Web框架/Django/15-Django - Sessions.html","title":"Django - Sessions","keywords":"","body":"Django - Cookie与Sessions 介绍 🍀 基于 Internet的各种服务系统应运而生 , 建立商业站点或者功能比较完善的个人站点 , 常常需要记录访问者的一些信息 ; 论坛作为 Internet发展的产物之一 , 在 Internet 中发挥着越来越重要的作用 , 是用户获取、交流、传递信息的主要场所之一 , 论坛常常也需要记录访问者的一些基本信息 (如身份识别号码、密码、用户在 Web 站点购物的方式或用户访问该站点的次数) ; 目前公认的是 , 通过 Cookie 和 Session 技术来实现记录访问者的一些基本信息 Cookie Cookie 是在 HTTP 协议下 , 服务器或脚本可以维护客户工作站上信息的一种方式 Cookie 是由 Web 服务器保存在用户浏览器 (客户端) 上的小文本文件 , 它可以包含有关用户的信息 ; 无论何时用户链接到服务器 , Web 站点都可以访问 Cookie 信息 目前Cookie是临时的 , 有些则是持续的 , 临时的Cookie只在浏览器上保存一段规定的时间 , 一旦超过规定的时间 , 该Cookie就会被系统清除 持续的 Cookie 则保存在用户的 Cookie 文件中 , 下一次用户返回时 , 仍然可以对它进行调用 ; 在 Cookie 文件中保存 Cookie , 有些用户担心 Cookie 中的用户信息被一些别有用心的人窃取 , 而造成一定的损害 ; 其实 , 网站以外的用户无法跨过网站来获得 Cookie 信息 ; 如果因为这种担心而屏蔽 Cookie , 肯定会因此拒绝访问许多站点页面 , 因为 , 当今有许多 Web 站点开发人员使用 Cookie 技术 , 例如 Session 对象的使用就离不开 Cookie 的支持 Cookie可以弥补HTTP协议无状态的不足 , 在Session出现之前 , 基本上所有的网站都采用Cookie来跟踪会话 Django实现的Cookie 获取Cookie request.COOKIES['key'] requset.get_signed_cookie(self, key, default=RAISE_ERROR, salt='', max_age=None) \"\"\" get_signed_cookie() Attempts to return a signed cookie. If the signature fails or the cookie has expired, raises an exception... unless you provide the default argument in which case that value will be returned instead. \"\"\" 设置Cookie # 响应对象 rep = HttpResponse(...) rep ＝ render(request, ...) rep ＝ redirect() # 设置Cookie rep.set_cookie(self, key, value='', max_age=None, expires=None, path='/',domain=None, secure=False, httponly=False) \"\"\" set_cookie() Sets a cookie. ``expires`` can be: - a string in the correct format, - a naive ``datetime.datetime`` object in UTC, - an aware ``datetime.datetime`` object in any time zone. If it is a ``datetime.datetime`` object then ``max_age`` will be calculated. \"\"\" rep.set_signed_cookie(self, key, value, salt='', **kwargs) 由于cookie保存在客户端的电脑上 , 所以 , JavaScript和jquery也可以操作Cookie Session Cookie虽然一定程度上解决了\"保持状态\" 的需求 , 但是由于Cookie本身最大支持4096字节 , 以及Cookie本身保存在客户端 , 可能被拦截或窃取 , 因此就需要一种新的东西 . 它能支持更多的字节 , 并且他保存在服务器 , 有较高的安全性 在计算机中 , 尤其是在网络应用中 , 我们将Session称为“会话控制” Session 对象存储特定用户会话所需的属性及配置信息 , 这样 , 当用户在应用程序的 Web 页之间跳转时 , 存储在 Session 对象中的变量将不会丢失 , 而是在整个用户会话中一直存在下去 ; 当用户请求来自应用程序的 Web 页时 , 如果该用户还没有会话 , 则 Web 服务器将自动创建一个 Session 对象 , 当会话过期或被放弃后 , 服务器将终止该会话 Session 对象最常见的一个用法就是存储用户的首选项 , 例如 , 如果用户指明不喜欢查看图形 , 就可以将该信息存储在 Session 对象中 ; 注意会话状态仅在支持Cookie的浏览器中保留 Django支持所有的匿名会话 , 简单说就是使用跨网页之间可以进行通讯 , 比如显示用户名 , 用户是否已经发表评论 ; 这个Session框架让你存储和获取每个站点访客的任意数据 它将数据存储在服务端 , 并以Cookies的形式进行发送和接收数据 , Cookies包含一个Session ID , 而不是数据本身 (除非你使用的基于Cookie的后端) 启用Sessions 🍀 Django中的Sessions是通过中间件实现的 如果我们要启用Session功能 , 需要执行以下操作 : 编辑settings.py中的MIDDLEWARE , 确保其中包含django.contrib.sessions.middleware.SessionMiddleware ; 默认在我们使用django-admin startproject 命令时 , settings.py中已经启用该中间件 如果你不想使用Sessions , 你可以将MIDDLEWARE中的SessionMiddleware移除以及将INSTALLED_APPS中的django.contrib.sessions移除 , 它能够为你节省一点开销 配置Session引擎 🍀 默认情况下 , Django存储会话到你的数据库中 (使用django.contrib.sessions.models.Session) , 尽管这很方便 , 但是在某些情况下 , 在其他地方存储会话数据的速度更快 , 因此Django可以配置为在文件系统或缓存中存储会话数据 数据库 🍀 如果你想使用数据库支持的会话 , 你需要添加django.contrib.sessions 到你settings.py中的INSTALLED_APP设置中 , 默认就是使用的数据库 在配置完成之后 , 需要执行manage.py migrate 来安装村粗会话数据的一张数据库表 缓存 🍀 为了更好的性能 , 我们可以使用一个基于缓存的会话后端 使用Django的缓存系统存储会话数据之前 , 我们需要确保已经配置好了我们的缓存 , 关于缓存的配置见 : cache documentation 注意 : 如果你使用的是Memcached缓存后端 , 那么你应该只使用基于缓存的会话 ; 本地内存缓存后端不会保留足够长的数据 , 它会更快地使用文件或数据库会话 , 而不是通过文件或数据库缓存的后端发送所有数据 , 此外 , 本地内存缓存后端不是多进程安全的 , 因此对于生产环境来说可能不是一个好的选择 如果在 CACHES 中定义了多个缓存 , Django将使用默认的缓存 , 要使用另外的缓存 , 需要将SESSION_CACHE_ALIAS 设置为该缓存的名称 配置好缓存之后 , 对于如何在缓存中存储数据你有两个选择 : 对于简单的缓存会话存储 , 可以设置SESSION_ENGINE为django.contrib.sessions.backends.cache , 此时会话数据将直接存储在你的缓存中 , 然而缓存数据可能不会持久 : 如果缓存填满或者缓存服务器重启 , 缓存数据可能会被清理掉 若要持久的缓存数据 , 可以设置SESSION_ENGINE为django.contrib.sessions.backends.cached_db , 这使用直接写缓存 , 每次写入高速缓存也将写入数据库 , 会话读取仅在数据不在缓存中时才使用数据库 两种会话的存储都非常快 , 但是简单的缓存更快 , 因为它放弃了持久性 , 大部分情况下 , cached_db后端已经足够快 , 但是如果你需要榨干最后一点性能 , 并且接收会话数据丢失的风险 , 那么你可以使用cache 后端 注意使用cached_db会话后端 , 需要遵循 using database-backed sessions 文件 🍀 要使用基于文件的会话 , 将SESSION_ENGINE为django.contrib.sessions.backends.file 你可以设置SESSION_FILE_PATH来控制Djanog存储会话文件的地址 , 默认来自tempfile.gettempdir() ,大多数情况下为/tmp , 当然请确保你的Web服务器具有读取和写入这个位置的权限 Cookie 🍀 同样 , 使用基于Cookie的会话 , 设置SESSION_ENGINE为django.contrib.sessions.backends.signed_cookies , 此时 , 会话数据的存储将使用Django的工具进行cryptographic signing 和 SECRET_KEY 设置 建议保留SESSION_COOKIE_HTTPONLY设置为True , 以防止从JavaScript中访问存储的数据 注意 : 如果SECRET_KEY不保密 , 而你正在使用 PickleSerializer 这可能导致任意远程执行代码 拥有SECRET_KEY的攻击者不仅可以生成你的站点新人的伪造会话数据 , 而且还可以远程执行任意代码 , 因为数据是用pickle序列化的 如果你使用基于Cookie的会话 , 需要格外注意安全密钥对于任何可以远程访问的系统都是永远完全保密的 会话数据已签名但未加密 如果使用基于Cookie的会话 , 则会话数据可以被客户端读取 MAC(消息认证码)被用来保护数据不被客户端修改 , 这样会话数据在被篡改时就会失效 ; 如果保存Cookie的客户端 (例如你的浏览器) 不能保存所有的会话Cookie或丢失数据 , 会话同样会变得不合法 ; 尽管Django对数据进行压缩 , 仍然完全有可能超过每个Cookie常见的4096个字节的限制 没有实时保证 MAC可以保证数据的权威性 (由你的站点生成 , 而不是任何其他人) 和完整性 (包含全部的数据并且是正确的) , 但是它不能保证是最新的 ; 这意味着对于某些会话数据的使用 , 基于Cookie可能让你受到 replay attacks 其它方式的会话后端在服务器端保存每个会话并在用户注销时使它无效 , 而基于Cookie的会话不会在用户注销时失效 , 因此 , 如果攻击者窃取了用户的Cookie , 那么即使用户注销了 , 他们也可以使用该Cookie进行登录 ; Cookies只能被当做是\"过期的\" , 如果它们比你的SESSION_COOKIE_AGE 还要旧 性能 最后 , Cookie的大小对你网站的速度有影响 视图中使用Session 🍀 当SessionMiddleware激活时 , 每个HttpRequest对象 , 也就是传递给Django视图函数的第一个参数 , 将会具有一个session属性 , 它是一个类似字典对象 你可以在你的视图中任何地方读取并写入request.session , 并且可以多次编辑它 class backends.base.SessionBase \"\"\"这是所有会话对象的基类,它具有以下标准字典方法\"\"\" __getitem__(key) '''Example: fav_color = request.session['fav_color']''' __setitem__(key, value) '''Example: request.session['fav_color'] = 'blue'''' __delitem__(key) '''Example: del request.session['fav_color']. This raises KeyError if the given key isn’t already in the session.''' __contains__(key) '''Example: 'fav_color' in request.session''' get(key, default=None) '''Example: fav_color = request.session.get('fav_color', 'red')''' pop(key, default=__not_given) '''Example: fav_color = request.session.pop('fav_color', 'blue')''' keys() items() setdefault() clear() '''It also has these methods:''' flush() ''' Deletes the current session data from the session and deletes the session cookie. This is used if you want to ensure that the previous session data can’t be accessed again from the user’s browser (for example, the django.contrib.auth.logout() function calls it). ''' set_test_cookie() ''' Sets a test cookie to determine whether the user’s browser supports cookies. Due to the way cookies work, you won’t be able to test this until the user’s next page request. See Setting test cookies below for more information. ''' test_cookie_worked() ''' Returns either True or False, depending on whether the user’s browser accepted the test cookie. Due to the way cookies work, you’ll have to call set_test_cookie() on a previous, separate page request. See Setting test cookies below for more information. ''' delete_test_cookie() ''' Deletes the test cookie. Use this to clean up after yourself. ''' set_expiry(value) ''' Sets the expiration time for the session. You can pass a number of different values: If value is an integer, the session will expire after that many seconds of inactivity. For example, calling request.session.set_expiry(300) would make the session expire in 5 minutes. If value is a datetime or timedelta object, the session will expire at that specific date/time. Note that datetime and timedelta values are only serializable if you are using the PickleSerializer. If value is 0, the user’s session cookie will expire when the user’s Web browser is closed. If value is None, the session reverts to using the global session expiry policy. Reading a session is not considered activity for expiration purposes. Session expiration is computed from the last time the session was modified. ''' get_expiry_age() ''' Returns the number of seconds until this session expires. For sessions with no custom expiration (or those set to expire at browser close), this will equal SESSION_COOKIE_AGE. This function accepts two optional keyword arguments: modification: last modification of the session, as a datetime object. Defaults to the current time. expiry: expiry information for the session, as a datetime object, an int (in seconds), or None. Defaults to the value stored in the session by set_expiry(), if there is one, or None. ''' get_expiry_date() ''' Returns the date this session will expire. For sessions with no custom expiration (or those set to expire at browser close), this will equal the date SESSION_COOKIE_AGE seconds from now. This function accepts the same keyword arguments as get_expiry_age(). ''' get_expire_at_browser_close() ''' Returns either True or False, depending on whether the user’s session cookie will expire when the user’s Web browser is closed. ''' clear_expired() ''' Removes expired sessions from the session store. This class method is called by clearsessions. ''' cycle_key() ''' Creates a new session key while retaining the current session data. django.contrib.auth.login() calls this method to mitigate against session fixation. ''' 序列化 🍀 默认情况下 , Django使用JSON序列化会话数据 , 你额可以使用SESSION_SERIALIZER设置顶顶亿会话序列化格式 , 即使是使用我们写自己的序列化器 , 同样强烈建议使用JSON , 特别是在使用Cookie后端时 ; 自定义序列化器 : Write your own serializer 例如 , 如果使用pickle序列化会话数据 , 则会出现攻击情况 ; 如果你使用的是签署Cookie会话后端 , 并且SECRET_KEY被攻击者知道 (Django本身没有漏洞会导致它被泄漏) , 攻击者就可以在会话中插入一个字符串 , 在unpickle之后可以在服务器上执行任何代码 在因特网上这个攻击技术很简单并且很容易差到 , 尽管Cookie会话的存储对Cookie保存的数据进行了签名以防止篡改 , SECRET_KEY的泄漏会立即使得可以执行远程代码 捆绑序列化器 🍀 class serializers.JSONSerializer: \"\"\" 对django.core.signing中的JSON序列化方法的一个包装, 只能序列化基本数据类型 \"\"\" 另外 , 因为JSON只支持字符串作为键 , 注意使用非字符串作为request.session的键将不工作 >>> # initial assignment >>> request.session[0] = 'bar' >>> # subsequent requests following serialization & deserialization >>> # of session data >>> request.session[0] # KeyError >>> request.session['0'] 'bar' 类似地 , 无法在JSON中编码的数据 , 如非UTF-8字节 , 如\\xd9将不能被存储 class serializers.PickleSerializer: \"\"\"支持任意Python对象,但是可能导致远程执行代码的漏洞,如果攻击者知道了SECRET_KEY\"\"\" 自定义序列化器 🍀 对于PickleSerializer与JSONSerializer两者的差别 , 这是常见的情况 , 需要我们在便利性和安全性之间权衡 但是如果我们希望在JSON格式的会话中存储更高级的数据类型比如request.session和datatime , 我们需要自己编写一个序列化器 (或者在保存它们到Decimal中之前转换这些值使其成为一个可JSON序列化的对象) ; 虽然序列化这些值是相当简单的 (比如我们可以使用DjangoJSONEncoder) , 但是编写一个能够可靠地返回您所输入的相同内容的解码器是更加脆弱的 , 例如 , 返回一个datatime时 , 它可能实际上是与datatime格式碰巧相同的一个字符串 我们自定义序列化器时 , 必须实现两个方法 , dumps(self, obj)和loads(self,data) 来分别序列化和反序列化会话数据的字典 会话对象 🍀 在request.session上使用普通的Python字符串作为字典的键 , 这主要是为了方便而不是一条必须遵守的规则 以一个下划线开始的会话字典的键被Django保留作为内部使用 不要用新的对象覆盖request.session , 且不要访问或设置它的属性 , 要像Python中的字典一样使用它 设置Cookie测试 🍀 为了方便 , Django提供了一个简单的方法来测试用户的浏览器是否支持Cookie ; 只需要在一个视图中调用request.session中的set_cookie_worked() , 并在下一个视图中调用test_cookie_worked() , 注意不是在同一个视图中调用 由于Cookie的工作方式 , 在set_test_cookie()和test_cookie_worked()之间这种笨拙的分离是必要的 , 因为我们设置一个Cookie , 在浏览器的下一个请求之前 , 你不可能知道浏览器是否接受它 验证Cookie测试之后 , 我们可以使用delete_test_cookie()来进行清除操作 实例 from django.http import HttpResponse from django.shortcuts import render def login(request): if request.method == 'POST': if request.session.test_cookie_worked(): request.session.delete_test_cookie() return HttpResponse(\"You're logged in.\") else: return HttpResponse(\"Please enable cookies and try again.\") request.session.set_test_cookie() return render(request, 'foo/login_form.html') 视图外使用Sessions 🍀 这一节中的示例直接从django.contrib.session.backends.db导入SessionStore , 在我们的代码中应该从SESSION_ENGINE中导入SessionStore , 如下 : >>> from importlib import import_module >>> from django.conf import settings >>> SessionStore = import_module(settings.SESSION_ENGINE).SessionStore 可以使用一个API来操作视图之外的会话数据 : >>> from django.contrib.sessions.backends.db import SessionStore >>> s = SessionStore() >>> # stored as seconds since epoch since datetimes are not serializable in JSON. >>> s['last_login'] = 1376587691 >>> s.create() >>> s.session_key '2b1189a188b44ad18c35e113ac6ceead' >>> s = SessionStore(session_key='2b1189a188b44ad18c35e113ac6ceead') >>> s['last_login'] 1376587691 上述中SessionStore.create()旨在创建一个新的会话 (即一个没有从会话存储中加载 , 并且使用session_key=None) save()旨在保存现有会话 (即从存储中加载的会话) , 在新会话中调用save()也可以正常工作 , 但可能生成与现有的会话相冲突的session_key ; create()会调用save()和循环 , 知道生成一个未使用的session_key 如果你使用的是django.contrib.sessions.backends.db后端 , 每个会话都只是一个普通的Django模型 , Session模型定义在django/contrib/sessions/models.py中 ; 因为它是一个普通的模型 , 你可以使用普通的Django数据库API访问会话 : >>> from django.contrib.sessions.models import Session >>> s = Session.objects.get(pk='2b1189a188b44ad18c35e113ac6ceead') >>> s.expire_date datetime.datetime(2005, 8, 20, 13, 35, 12) 注意 , 我们需要调用get_decoded()以获得会话的字典 , 这是必须的 , 因为字典是以编码后的格式保存的 : >>> s.session_data 'KGRwMQpTJ19hdXRoX3VzZXJfaWQnCnAyCkkxCnMuMTExY2ZjODI2Yj...' >>> s.get_decoded() {'user_id': 42} 会话保存 🍀 默认情况下 , Django只有在会话被修改时才会保存会话到数据库中 , 即它的字典中的任何值被修改时 # Session is modified. request.session['foo'] = 'bar' # Session is modified. del request.session['foo'] # Session is modified. request.session['foo'] = {} # Gotcha: Session is NOT modified, because this alters # request.session['foo'] instead of request.session. request.session['foo']['bar'] = 'baz' 上面例子的最后一种情况 , 我们可以通过设置会话对象的modified属性显示地告诉会话对象已经被修改过 : request.session.modified = True 若修改这个默认的行为 , 可以设置SESSION_SAVE_EVERY_REQUEST为True , 当设置为True时 , Django将对每个请求都保存会话到数据库中 注意会话的Cookie只有在一个会话被创建或修改后才会发送 , 如果SESSION_SAVE_EVERY_REQUEST为True , 会话的Cookie将在每个请求中发送 类似地 , 每次会话Cookie发送时 , 会话Cookie的过期部分都会被更新 如果响应的状态是500 , 则会话不会保存 会话时长 🍀 你可以通过SESSION_EXPIRE_AT_BROWSER_CLOSE配置来控制会话框架使用浏览器时长的会话 , 还是持久的会话 默认情况下 , SESSION_EXPIRE_AT_BROWSER_CLOSE设置为False , 表示会话的Cookie保存在用户的浏览器中 , 时间为SESSION_COOKIE_AGE ; 如果我们不想让别人每次打开浏览器都需要登录时 , 可以这样做 如果SESSION_EXPIRE_AT_BROWSER_CLOSE设置为True , Django将使用浏览器时长的Cookie , 即如果用户关闭浏览器 , 那么Cookie就会立即过期 , 如果你想让别人每次打开浏览器时都要登录 , 那么就使用这个 这个设置时一个全局的默认值 , 我们可以通过调用request.session()的set_expiry()方法来进行覆盖 注意 : 某些浏览器 (如Chrome) 提供一种设置 , 允许用户在关闭并重新打开浏览器后继续使用会话 , 在某些情况下 , 这可能干扰SESSION_EXPIRE_AT_BROWSER_CLOSE设置并导致会话在浏览器关闭后不过期 , 在测试启用SESSION_EXPIRE_AT_BROWSER_CLOSE设置的Django应用时需要特别注意这一点 清除会话存储 🍀 随着用户在你的网站上创建新的会话 , 会话数据可能会在你的会话存储仓库中积累 , 如果你正在使用数据库作为后端 , django_session数据库表将持续增长 ; 如果你正在使用文件作为后端 , 你的临时目录包含的文件数量将持续增长 Django不提供自动清除过期会话的功能 , 因此 , 定期地清除会话时我们自己的任务 , Django提供一个清除用的管理命令来满足这个目的 : clearsessions , 建议定期调用这个命令 , 例如作为一个日常运行的cron任务 但是 , 以缓存为后端不存在这个问题 , 因为缓存会自动删除过期的数据 ; 以Cookie为后端也不存在这个问题 , 因为会话数据通过用户的浏览器保存 对于会话的行为有很多控制配置 , 详细见 : Django settings 更多Sessions相关 : How to use sessions "},"05-Web框架/Django/16-Django - Authentication System.html":{"url":"05-Web框架/Django/16-Django - Authentication System.html","title":"Django - Authentication System","keywords":"","body":"Django - Authentication System 介绍 🍀 Django为我们提供了一个认证系统 , 它提供了认证 (authentiaction) 和授权功能 (authorization) , 这两种功能在某些地方时耦合的 User对象 🍀 User对象是认证系统的核心 , 它们通常表示与你的站点进行交互的用户 , 并用于启用限制访问 , 注册用户信息和给创建者关联内容等 在Django的认证框架中只存在一种类型的用户 , 因此诸如superusers或管理员staff 用户只是具有特殊属性集的User对象 , 而不是不同类型的User对象 默认User的基本属性有 : uesrname password email first_name last_name 完整参考见 : full API documentation 创建 users 🍀 创建users最直接的方法时使用create_user()函数 , 如下 : >>> from django.contrib.auth.models import User >>> user = User.objects.create_user('john', 'lennon@thebeatles.com', 'johnpassword') # At this point, user is a User object that has already been saved # to the database. You can continue to change its attributes # if you want to change other fields. >>> user.last_name = 'Lennon' >>> user.save() 如果我们安装了admin , 我们可以交互式地创建users , 见 : create users interactively 创建 superusers 🍀 我们可以使用如下命令创建一个超级用户 : $ python manage.py createsuperuser --username=joe --email=joe@example.com 修改密码 🍀 Django不会在user模型上存储原始的 (明文) 密码 , 而只是一个哈希值 (完整见 : documentation of how passwords are managed ) , 因此 , 不要试图直接操作用户的密码属性 , 这就是为什么创建用户时使用帮助函数的原因 所以修改密码我们可以通过以下方式 : manage.py changepassword *username* 提供了一种从命令行更改用户密码的方法 , 它提示你修改一个给定的user密码 , 你必须输入两次 , 如果两次输入匹配 , 密码就会立即被修改 , 如果你没有提供user , 命令行将尝试修改与当前系统用户匹配的用户名的密码 通过set_password() >>> from django.contrib.auth.models import User >>> u = User.objects.get(username='john') >>> u.set_password('new password') >>> u.save() 如果你安装了Django admin , 可以在身份验证系统的管理页面上更改用户的密码 Django还提供视图和表单允许用户修改他们自己的密码 注意 : 更改用户密码将会注销所有会话 , 详见 : Session invalidation on password change 用户认证 🍀 使用authenticate()来验证一组凭证 , 它接收关键字参数credentials , 默认为username 和password authenticate(request=None, **credentials): \"\"\" request:HttpRequest对象 credentials:默认username和password \"\"\" 根据每个认证的后端进行验证 , 如果某个后端凭证通过则返回一个User对象 , 如果凭证对任何后端都无效 , 则主动触发PermissionDenied , 并返回None , 如下 : from django.contrib.auth import authenticate user = authenticate(username='john', password='secret') if user is not None: # A backend authenticated the credentials else: # No backend authenticated the credentials 权限和授权 🍀 Django本身提供了一个简单的权限系统 , 它提供了一种为特定用户和用户组分配权限的方法 Django中的admin站点也使用了该权限系统 , 使用的权限如下 : 查看\"add\"表单和添加对象仅限于具有\"add\"权限的用户类型对象 查看\"change\"表单和更改对象仅限于具有\"change\"权限的用户类型对象 删除一个对象仅限于具有“delete”权限的用户类型对象 权限不但可以根据每个对象的类型 , 而且可以根据特定的对象实例设置 , 通过ModelAdmin 提供的has_add_permission() , has_change_permission()和has_delete_permission()方法 , 可以针对相同类型的不同对象实例自定义权限 User对象具有两个多对多字段 : groups和user_permissions User对象可以使用和其他Django模型一样的方式访问他们相关联的对象 , 如下 : myuser.groups.set([group_list]) myuser.groups.add(group, group, ...) myuser.groups.remove(group, group, ...) myuser.groups.clear() myuser.user_permissions.set([permission_list]) myuser.user_permissions.add(permission, permission, ...) myuser.user_permissions.remove(permission, permission, ...) myuser.user_permissions.clear() 默认权限 🍀 当django.contrib.auth在你的INSTALLED_APPS配置中列出时 , 它将确保为你安装的应用中的每个Django模型创建3个默认的权限 , 即add , change和delete 当你运行manage.py migrate 时, 将创建这些权限 ; 在django.contrib.auth添加INSTALLED_APPS之后 , 首次运行migrate时 , 将为所有先前安装的模型创建默认权限 , 以及当时安装的任何新模型 ; 之后 , 每次运行manage.py migrate , 它将为新的模型创建默认权限(创建权限的函数与post_migrate信号连接) Groups 🍀 django.contrib.auth.models.Group模型是一种对用户进行分类的通用方式 , 通过这种方式你可以引用权限或其他标签都这些用户 ; 一个用户可以属于任意多个组 组中每个用户自动具有该组的权限 , 例如 , 如果 Site editors组具有can_edit_home_page权限 , 那么该组中的任何用户都具有该权限 除了权限之外 , 组还是给分类用户分配标签，添加功能的便捷方法 ; 例如 , 你可以创建一个组Special users , 只有在该组中的用户才能够访问会员的页面 编程方式创建权限 🍀 虽然我们可以在模型的Meta类中自定义权限 , 但是你也可以直接创建权限 , 例如 , 你可以在myapp中为BlogPost模型创建can_publish权限 : from myapp.models import BlogPost from django.contrib.auth.models import Permission from django.contrib.contenttypes.models import ContentType content_type = ContentType.objects.get_for_model(BlogPost) permission = Permission.objects.create( codename='can_publish', name='Can Publish Posts', content_type=content_type, ) 然后该权限可以通过user_permissions属性或者通过Group的permissions属性分配给用户 权限缓存 🍀 ModelBackend在第一次需要访问User对象的权限时会对权限进行缓存 , 由于对新添加的权限并不会立即检查 , 所以这种做法对request-response循环是非常有利的 (例如在admin中) , 如果你想要在添加新的权限后马上在测试或视图检查他们 , 最简单的解决办法是从数据库中重新获取User , 如下 : from django.contrib.auth.models import Permission, User from django.contrib.contenttypes.models import ContentType from django.shortcuts import get_object_or_404 from myapp.models import BlogPost def user_gains_perms(request, user_id): user = get_object_or_404(User, pk=user_id) # any permission check will cache the current set of permissions user.has_perm('myapp.change_blogpost') content_type = ContentType.objects.get_for_model(BlogPost) permission = Permission.objects.get( codename='change_blogpost', content_type=content_type, ) user.user_permissions.add(permission) # Checking the cached permission set user.has_perm('myapp.change_blogpost') # False # Request new instance of User # Be aware that user.refresh_from_db() won't clear the cache. user = get_object_or_404(User, pk=user_id) # Permission cache is repopulated from the database user.has_perm('myapp.change_blogpost') # True ... Web请求中的认证 🍀 Django使用Sessions和Middleware来拦截request objects到认证系统中 认证系统为每个请求提供一个request.user属性来代表当前的用户 , 如果当前的用户仍未登录 , 该属性将会被设置为一个AonnymousUser实例 , 否则该属性将会是一个User实例 我们可以使用is_authenticated属性来进行区分 : if request.user.is_authenticated: # Do something for authenticated users. ... else: # Do something for anonymous users. ... 登录用户 🍀 如果你有一个经过身份验证的用户 , 你想把它附带到当前的会话中 , 可以通过login()函数完成 login(request, user, backend=None): \"\"\" request:HttpRequest对象 user:User对象 backend:后端 \"\"\" login()使用Django的Session框架来将用户的ID保存在session中 注意 , 匿名会话期间的任何数据集在用户登录后都会保留在会话中 from django.contrib.auth import authenticate, login def my_view(request): username = request.POST['username'] password = request.POST['password'] user = authenticate(request, username=username, password=password) if user is not None: login(request, user) # Redirect to a success page. ... else: # Return an 'invalid login' error message. ... 选择验证后端 🍀 用户登录时 , 用户的ID和用于身份验证的后端保存在用户的会话中 , 这允许相同的身份验证后端在将来的请求中获取用户的详细信息 . 保存会话中的认证后端选择如下 : 使用可选的backend参数的值 (如果提供) 使用user.backend属性的值 (如果存在) 如果只有一个 , 则使用AUTHENTICATION_BACKENDS中的后端 否则 , 触发异常 登出用户 🍀 要登出一个已经通过django.contrib.auth.login()登入的用户 , 可以在视图中使用django.contrib.auth.logout() logout(request): \"\"\" request:HttpRequest对象 没有返回值 \"\"\" 实例 from django.contrib.auth import logout def logout_view(request): logout(request) # Redirect to a success page. 调用logou()时 , 当前请求的会话数据将被彻底清楚 , 这是为了防止另外一个人使用相同的Web浏览器登入并访问前一个用户的会话数据 , 如果你想在用户登出之后可以立即访问放入会话中的数据 , 则需要在调用django.conruib.auth.logout()之后放入 限制访问页面 🍀 原始方式 🍀 限制访问页面的简单原始方法时检查request.user.is_authenticated , 并重定向到登录页面 : from django.conf import settings from django.shortcuts import redirect def my_view(request): if not request.user.is_authenticated: return redirect('%s?next=%s' % (settings.LOGIN_URL, request.path)) # ... 或者显示错误信息 from django.shortcuts import render def my_view(request): if not request.user.is_authenticated: return render(request, 'myapp/login_error.html') # ... login_required 🍀 一个比较快捷的方式 , 可以使用login_required()装饰器 login_required(redirect_field_name='next', login_url=None): \"\"\" Decorator for views that checks that the user is logged in, redirecting to the log-in page if necessary. redirect_filed_name:重定向路径,设置为None可以从URL中移除 login_url:指定没有通过检查的用户的重定向向登录页面,默认为settings.LOGIN_URL \"\"\" 实例 from django.contrib.auth.decorators import login_required @login_required def my_view(request): ... login_required()完成下面的事情 : 如果用户没有登录 , 则重定向到settings.LOGIN_URL , 并且把当前请求的绝对路径作为查询参数传递到登陆页面 , 例如 : /accounts/login/?next=/polls/3/ 如果用户已经登入 , 则正常执行视图 , 视图的代码可以安全地假设用户已经登入 修改密码实例 @login_required def set_password(request): user = request.user state = None if request.method == 'POST': old_password = request.POST.get('old_password', '') new_password = request.POST.get('new_password', '') repeat_password = request.POST.get('repeat_password', '') if user.check_password(old_password): if not new_password: state = 'empty' elif new_password != repeat_password: state = 'repeat_error' else: user.set_password(new_password) user.save() return redirect(\"/log_in/\") else: state = 'password_error' content = { 'user': user, 'state': state, } return render(request, 'set_password.html', content) LoginRequiredMixin 🍀 当你使用基于类的视图时 , 可以使用LoginRequireMixin实现与login_required相同的行为 , 这个mixin应该位于继承列表中最左侧的位置 如果一个视图使用这个mixin，那么所有未经身份验证的用户的请求将被重定向到登录页面，或者显示HTTP 403 Forbidden错误，这取决于 raise_exception参数 您可以设置AccessMixin的任何参数来定制未授权用户的处理 : from django.contrib.auth.mixins import LoginRequiredMixin class MyView(LoginRequiredMixin, View): login_url = '/login/' redirect_field_name = 'redirect_to' user_passes_test 🍀 为了快捷 , 你可以使用user_passes_test装饰器 , 返回False时执行重定向 user_passes_test(test_func,login_url=None,redirect_field_name='next): \"\"\" Decorator for views that checks that the user passes the given test, redirecting to the log-in page if necessary. The test should be a callable that takes the user object and returns True if the user passes. test_func:一个以User对象为参数的回调函数 login_url:指定没有通过检查的用户的重定向向登录页面,默认为settings.LOGIN_URL redirect_field_name:重定向路径,设置为None可以从URL中移除 \"\"\" 实例 from django.contrib.auth.decorators import user_passes_test def email_check(user): return user.email.endswith('@example.com') @user_passes_test(email_check) def my_view(request): ... UserPassesTestMixin 🍀 当使用基于类的视图时 , 可以使用UserPassesTestMixin , 与user_passes_test类似 test_func() 你必须在你的类中覆盖test_func()方法来提供执行的测试 , 此外 , 你可以设置 AccessMixin 的任何参数来定制未授权用户的处理: from django.contrib.auth.mixins import UserPassesTestMixin class MyView(UserPassesTestMixin, View): def test_func(self): return self.request.user.email.endswith('@example.com') get_test_func() 你也可以覆盖get_test_func()方法以使mixin使用不同命名的函数来进行检查 (而不是test_func()) 由于UserPassesTestMixin的实现方式 , 你不能将它们放在继承列表中 , 以下内容不起作用 : class TestMixin1(UserPassesTestMixin): def test_func(self): return self.request.user.email.endswith('@example.com') class TestMixin2(UserPassesTestMixin): def test_func(self): return self.request.user.username.startswith('django') class MyView(TestMixin1, TestMixin2, View): ... permission_required 🍀 permission_required(perm, login_url=None, raise_exception=False): \"\"\" 检查一个用户是否有指定的权限 perm:权限名称,形式app.permission login_url:指定没有通过检查的用户的重定向登录页面,默认为settings.LOGIN_URL raise_exception:如果提供了该参数,装饰器会抛出PermissionDenied异常,从而导致403(HTTP Forbidden)视图替代重定向的登录页面 \"\"\" 实例 from django.contrib.auth.decorators import permission_required @permission_required('polls.can_vote') def my_view(request): ... 如class models.User中的has_perm()方法一样 , 权限名称采用\".\"的形式 , 例如 , polls.can_vote表示polls应用中一个模型的权限 装饰器也可以采取可迭代的权限 , 这种情况下 , 用户必须具有所有权限才能访问视图 PermissionRequiredMixin 🍀 对基于类的视图应用权限进行检查 , 可以使用PermissionRequiredMixin 这个mixin , 就相当于permission_required装饰器 , 如下 : from django.contrib.auth.mixins import PermissionRequiredMixin class MyView(PermissionRequiredMixin, View): permission_required = 'polls.can_vote' # Or multiple of permissions: permission_required = ('polls.can_open', 'polls.can_edit') 你可以设置 AccessMixin 的任何参数来定制未授权用户的处理 你还可以覆盖以下方法 : get_permission_required(): ''' 返回由mixin使用的许可名称的可迭代, 默认为permission_required属性,如有必要,转换为元组 ''' has_permission(): ''' 返回一个布尔值,表示当前用户是否具有执行装饰视图的权限 默认情况下,返回使用get_permission_required()返回的权限列表调用has_perms()的结果 ''' 在admin中管理用户 🍀 如果django.contrib.auth和django.contrib.admin这两个你都安装了 , 将可以通过admin方便地查看和管理用户 , 组和权限 ; 可以像其他任何Django模型一样创建和删除用户 , 可以创建组 , 并分配权限给用户和组 , admin中还会保存和显示对用户模型编辑的日志 admin更多相关见下一篇整理 认证视图 : Authentication Views 内置表单 : Built-in forms 更多相关内容 : https://docs.djangoproject.com/en/1.11/topics/auth/default/ 认证系统 : User authentication in Django "},"05-Web框架/Django/50-Django - 源码之startproject.html":{"url":"05-Web框架/Django/50-Django - 源码之startproject.html","title":"Django - 源码之startproject","keywords":"","body":"Django - 源码之startproject 介绍 🍀 django是Python中的一个Web框架 , 它的本质其实就是一个别人已经为我们写好了的 , Python第三方库 而我们使用它也是通过Python中的导入语句 , 将其导入后使用 我们看看django的文件系统 >>> import django >>> help(django) Help on package django: NAME django PACKAGE CONTENTS __main__ apps (package) conf (package) contrib (package) core (package) db (package) dispatch (package) forms (package) http (package) middleware (package) shortcuts template (package) templatetags (package) test (package) urls (package) utils (package) views (package) 文档树如下 django ├── apps ├── bin ├── conf ├── contrib ├── core ├── db ├── dispatch ├── forms ├── http ├── middleware ├── templatetages ├── test ├── urls ├── utils ├── views ├── __init__.py ├── __main__.py └── shortcuts.py 分析时 , 源码省略部分以pass带过 开始 🍀 在我们使用命令行安装django时 , 通常都会自动为我们添加一个环境变量 , 也就是django/bin/django-admin.py这个文件 , 我们可是在命令行输入django-admin命令来测试是否已经添加了环境变量 $ django-admin Type 'django-admin help ' for help on a specific subcommand. Available subcommands: [django] check compilemessages createcachetable dbshell diffsettings dumpdata flush inspectdb loaddata makemessages makemigrations migrate runserver sendtestemail shell showmigrations sqlflush sqlmigrate sqlsequencereset squashmigrations startapp startproject test testserver Note that only Django core commands are listed as settings are not properly configured (error: Requested setting INSTALLED_APPS, but settings are not configured. You must either define the environment variable DJANGO_SETTINGS_MODULE or call settings.configure() before accessing settings.). 如果命令行输出以上信息 , 那么就说明环境变量已经添加 , 如果没有 , 那么你就得自己添加了 , 如何添加环境变量可以访问如下链接操作 : www.baidu.com 现在我们已经知道了django的入口 , 就是django-admin.py , 根据命令行的提示我们就可以开始创建我们的Django项目了 # 用法如下 $ django-admin startproject [-h] [--version] [-v {0,1,2,3}] [--settings SETTINGS] [--pythonpath PYTHONPATH] [--traceback] [--no-color] [--template TEMPLATE] [--extension EXTENSIONS] [--name FILES] name [directory] 实际上我们使用PyCharm时 , 创建django项目 , 其内部也是帮我们调用了这条命令 , 接下来我们应该看看django-admin.py中包含了什么信息了 django/bin/django-admin.py #!/usr/bin/env python from django.core import management if __name__ == \"__main__\": management.execute_from_command_line() 在这个入口中 , 我们看到了django真正的入口 , 也就是在这个management里面 , 接下来我们看看我们在命令行输出的命令django是如何解析的 startproject 🍀 以django-admin startprojec为例 , 首先我们切换到要存放项目的目录 , 然后在命令行输入一下命令 $ django-admin startproject lyonyangproject 我们来看看这条命令到底是怎么执行的 毋庸置疑 , 创建我们的Django项目 , 将进行一些列复杂的加载工作 , 也就是整个项目所需要的配置等等的导入工作 , 我们将一层层的来观察这些动作 首先django-admin.py被执行 , 随后进入了django/core/management/__init__.py , 我们简单提取关键步骤 , 如下图 : 有了这个图 , 那么文字说明就好说了 , 在management.execute_from_command_line() 执行之前 , 我们看看django做了些什么 导入apps , 执行了其中的apps = Apps(installed_apps=None) , 这个apps实例暂时并没有真实的数据 , 它管理着一个存储安装应用的注册表 , 以及维护着一个与models的通道 导入settings , 执行settings = LazySettings() , 这一步至关重要 , 它所做的事情 , 都隐藏在其基类LazyObject中 , 因为LazySettings()是没有构造函数的 , 所以只能向它的父亲拿了 empty = object() class LazyObject(object): # 这个类的作用就是为了延迟实例化 # Avoid infinite recursion when tracing __init__ (#19456). _wrapped = None def __init__(self): # Note: if a subclass overrides __init__(), it will likely need to # override __copy__() and __deepcopy__() as well. # 这里并未进行真正意义上的初始化,因为empty是一个空对象 self._wrapped = empty ...... class LazySettings(LazyObject): def _setup(self, name=None): \"\"\" Load the settings module pointed to by the environment variable. This is used the first time we need any settings at all, if the user has not previously configured the settings manually. \"\"\" # ENVIRONMENT_VARIABLE = \"DJANGO_SETTINGS_MODULE\" # 这个环境变量会在execute函数执行时设置成\"[project].settings\" # 我们的项目就是lyonyangproject.settings settings_module = os.environ.get(ENVIRONMENT_VARIABLE) if not settings_module: desc = (\"setting %s\" % name) if name else \"settings\" raise ImproperlyConfigured( \"Requested %s, but settings are not configured. \" \"You must either define the environment variable %s \" \"or call settings.configure() before accessing settings.\" % (desc, ENVIRONMENT_VARIABLE)) # 此时一切就绪,完成真正的实例化 self._wrapped = Settings(settings_module) def __getattr__(self, name): # 这一步会在execute()中通过settings.INSTALLED_APPS激活 \"\"\" Return the value of a setting and cache it in self.__dict__. \"\"\" if self._wrapped is empty: self._setup(name) val = getattr(self._wrapped, name) self.__dict__[name] = val return val 导入工作差不多是完成了 , 但是此时这个settings却没有真正初始化 , 我们继续往下观察 导入工作完成后 , 那么就开始执行了 , 也就是调用execute_from_command_line()函数了 management/__init__.py def execute_from_command_line(argv=None): \"\"\" A simple method that runs a ManagementUtility. \"\"\" # 实例化ManagementUtility utility = ManagementUtility(argv) # 调用其execute方法 utility.execute() class ManagementUtility(object): \"\"\" Encapsulates the logic of the django-admin and manage.py utilities. \"\"\" def __init__(self, argv=None): # 获取命令行参数 self.argv = argv or sys.argv[:] # 执行命令的文件,django-admin.py self.prog_name = os.path.basename(self.argv[0]) self.settings_exception = None pass execute()方法源码如下 : def execute(self): \"\"\" Given the command-line arguments, this figures out which subcommand is being run, creates a parser appropriate to that command, and runs it. \"\"\" try: # 提取子命令名称,如:startproject subcommand = self.argv[1] except IndexError: subcommand = 'help' # Display help if no arguments were given. # Preprocess options to extract --settings and --pythonpath. # These options could affect the commands that are available, so they # must be processed early. # 实例化一个特定的参数解析器 parser = CommandParser(None, usage=\"%(prog)s subcommand [options] [args]\", add_help=False) # 预处理工作,添加参数 parser.add_argument('--settings') parser.add_argument('--pythonpath') parser.add_argument('args', nargs='*') # catch-all try: options, args = parser.parse_known_args(self.argv[2:]) # 设置settings和pythonpath参数 handle_default_options(options) except CommandError: pass # Ignore any option errors at this point. try: # 正常情况下,我们看到这样的语句差不多可以直接掠过了,因为似乎没有意义 # 但是settings却是一个特殊的情况,此时它并没有INSTALLED_APPS # 所以Python是找不到的,于是就会执行它的__getattr__方法来查找了 # 于是,在这里就完成了初始化工作 settings.INSTALLED_APPS except ImproperlyConfigured as exc: self.settings_exception = exc if settings.configured: # Start the auto-reloading dev server even if the code is broken. # The hardcoded condition is a code smell but we can't rely on a # flag on the command class because we haven't located it yet. # 下面跟Django的启动有关,暂且不说 if subcommand == 'runserver' and '--noreload' not in self.argv: try: autoreload.check_errors(django.setup)() except Exception: # The exception will be raised later in the child process # started by the autoreloader. Pretend it didn't happen by # loading an empty list of applications. apps.all_models = defaultdict(OrderedDict) apps.app_configs = OrderedDict() apps.apps_ready = apps.models_ready = apps.ready = True # Remove options not compatible with the built-in runserver # (e.g. options for the contrib.staticfiles' runserver). # Changes here require manually testing as described in # #27522. _parser = self.fetch_command('runserver').create_parser('django', 'runserver') _options, _args = _parser.parse_known_args(self.argv[2:]) for _arg in _args: self.argv.remove(_arg) # In all other cases, django.setup() is required to succeed. else: # 配置settings,logging,urlresolvers,以及注册应用 django.setup() self.autocomplete() if subcommand == 'help': if '--commands' in args: sys.stdout.write(self.main_help_text(commands_only=True) + '\\n') elif len(options.args) 接下来我们看看最后的这个fetch_command(subcommand) 和 run_from_argv(self.argv) fetch_command() 🍀 management/__init__.py def fetch_command(self, subcommand): \"\"\" Tries to fetch the given subcommand, printing a message with the appropriate command called from the command line (usually \"django-admin\" or \"manage.py\") if it can't be found. \"\"\" # Get commands outside of try block to prevent swallowing exceptions commands = get_commands() try: # 获取子命令模块对应的前缀,这里是django.core app_name = commands[subcommand] except KeyError: if os.environ.get('DJANGO_SETTINGS_MODULE'): # If `subcommand` is missing due to misconfigured settings, the # following line will retrigger an ImproperlyConfigured exception # (get_commands() swallows the original one) so the user is # informed about it. # 防止未初始化 settings.INSTALLED_APPS else: sys.stderr.write(\"No Django settings specified.\\n\") sys.stderr.write( \"Unknown command: %r\\nType '%s help' for usage.\\n\" % (subcommand, self.prog_name) ) sys.exit(1) if isinstance(app_name, BaseCommand): # If the command is already loaded, use it directly. klass = app_name else: # load_command_class会返回指定子命令相对应的Command类的实例 # load_command_class见下一小结 klass = load_command_class(app_name, subcommand) return klass 下面详细的解释一下load_command_class() load_command_class( ) 🍀 management/__init__.py def load_command_class(app_name, name): \"\"\" Given a command name and an application name, returns the Command class instance. All errors raised by the import process (ImportError, AttributeError) are allowed to propagate. \"\"\" # app_name:子模块对应的前缀名 # name:子命令 # 加载django.core.management.commands.startproject module = import_module('%s.management.commands.%s' % (app_name, name)) # 返回startproject中的Command类的实例 return module.Command() run_from_argv( ) 🍀 那么到这里 , 准备工作已经全部完成 , 现在就是真正的执行时刻了 , 在开始之前还有点事需要说明 , 这个方法存在的位置并不是子命令对应的Command中 , 而是在其最高基类BaseCommand中 , 所有的Command类都必须直接或者间接的继承BaseCommand类 对于run_from_argv源码就不贴了 , 因为实际上 , 它也不是正主 , run_from_argv主要就是设置环境 (比如Python路径和Django配置) , 随后它会调用BaseCommand类的execute()方法 , 但这不是绝对 , 因为有的派生类中重写了execute() : def execute(self, *args, **options): \"\"\" Try to execute this command, performing system checks if needed (as controlled by the ``requires_system_checks`` attribute, except if force-skipped). \"\"\" # 在需要是进行系统检查 ... # 最后会调用Command类中的handle output = self.handle(*args, **options) ... 上述中的handle()方法 , 必须在子类中实现 , 原因如下 : 在django/core/management/base.py , BaseCommand类中的handle() def handle(self, *args, **options): \"\"\" The actual logic of the command. Subclasses must implement this method. \"\"\" # 执行我?对不起我要给你抛个NotImplementedError raise NotImplementedError('subclasses of BaseCommand must provide a handle() method') 接下来 , 我们看看startproject.py中Command类的handle() def handle(self, **options): project_name, target = options.pop('name'), options.pop('directory') self.validate_name(project_name, \"project\") # Check that the project_name cannot be imported. try: import_module(project_name) except ImportError: pass else: raise CommandError( \"%r conflicts with the name of an existing Python module and \" \"cannot be used as a project name. Please try another name.\" % project_name ) # Create a random SECRET_KEY to put it in the main settings. options['secret_key'] = get_random_secret_key() # 加载其基类TemplateCommand中的handle方法 # PS:TempalteCommand的基类为BaseCommand super(Command, self).handle('project', project_name, target, **options) 最后TemplateCommand类中的handle()会为我们进行Django项目的布局到指定目录 , 至此 , 命令执行完毕 , 我们所看到的所有默认目录也已经创建完毕 小结 🍀 到这里对于django项目的开始已经有了基本的了解了 : 在命令行执行django-admin.py相关命令 执行management中的execute_from_command_line()函数 实例化ManagementUtility类并调用execute()方法 随后就是获取命令行输入的参数实例化相应的Command类 调用类中的handle()方法 注意 : django-admin命令并不仅仅根据django/core/management/commands来加载 , 而是会将所有的Application下的management/commands 都加载进入commands字典中 该commands字典是通过 , management/__init__.py 中的get_commands()函数生成的 @lru_cache.lru_cache(maxsize=None) def get_commands(): \"\"\" Returns a dictionary mapping command names to their callback applications. ... \"\"\" pass 到这里 , 我们可以想 , 既然django会到各个应用中去寻找management/commands目录 , 再寻找subcommand , 那么如果在自己的应用下创建一个mycommand , 然后定义一个Command类 , 重写handle()方法 , 是不是就自定制django-admin命令了 没错 , 这一点在django的官方文档中已经提供相关教程了 , 想要自定制命令就点击下面的教程链接吧 : Writing custom django-admin commands "},"05-Web框架/Django/51-Django - 源码之runserver.html":{"url":"05-Web框架/Django/51-Django - 源码之runserver.html","title":"Django - 源码之runserver","keywords":"","body":"Django - 源码之runserver 介绍 🍀 上一篇中 , 我们分析了Django项目从无到有的过程 , 也就是django-admin startproject命令 , 随后我们要做的就是启动这个项目 , 也就是执行django-admin runserver命令 实际上 , 我们在创建项目时 , 就已经见过这个命令字眼了 , 截取部分代码如下 : management/__init__ def execute(self): \"\"\" Given the command-line arguments, this figures out which subcommand is being run, creates a parser appropriate to that command, and runs it. \"\"\" ...... # 截取部分片段,为了便于查找,删去部分注释 if settings.configured: if subcommand == 'runserver' and '--noreload' not in self.argv: try: autoreload.check_errors(django.setup)() except Exception: apps.all_models = defaultdict(OrderedDict) apps.app_configs = OrderedDict() apps.apps_ready = apps.models_ready = apps.ready = True _parser = self.fetch_command('runserver').create_parser('django', 'runserver') _options, _args = _parser.parse_known_args(self.argv[2:]) for _arg in _args: self.argv.remove(_arg) # In all other cases, django.setup() is required to succeed. else: django.setup() ...... 在我们第一次创建Django项目时 , 会直接执行django.setup() , 在上一篇中 , 关于导入工作中忽略了一条语句 : from django.utils import autoreload, lru_cache, six , 这其中的autoreload是一个自动加载的触发器 , 它会加载一个配置RUN_RELOADER = True , 这也是我们自动重启服务端的一个开关 , 默认它是开着的 实际上执行runserver与startproject是一样的 , 只不过在配置时 , runserver会进行一些错误检查 , 主要是为了检查其兼容性 , 随后像其他命令一样 , 实例化各自模块中的Command类 , 随后调用execute() → handle() , 我们直接从handle()开始 handle 🍀 django/core/management/commands/runserver.py def handle(self, *args, **options): # 导入Django配置文件 from django.conf import settings if not settings.DEBUG and not settings.ALLOWED_HOSTS: raise CommandError('You must set settings.ALLOWED_HOSTS if DEBUG is False.') # 判断ipv6是否可用,该方式需要通过add_arguments来添加 self.use_ipv6 = options['use_ipv6'] if self.use_ipv6 and not socket.has_ipv6: raise CommandError('Your Python does not support IPv6.') self._raw_ipv6 = False if not options['addrport']: # 默认使用本地ip地址,端口为8000 self.addr = '' self.port = self.default_port else: # 获取addrport中的相关参数 m = re.match(naiveip_re, options['addrport']) if m is None: raise CommandError('\"%s\" is not a valid port number ' 'or address:port pair.' % options['addrport']) self.addr, _ipv4, _ipv6, _fqdn, self.port = m.groups() if not self.port.isdigit(): raise CommandError(\"%r is not a valid port number.\" % self.port) if self.addr: if _ipv6: self.addr = self.addr[1:-1] self.use_ipv6 = True self._raw_ipv6 = True elif self.use_ipv6 and not _fqdn: raise CommandError('\"%s\" is not a valid IPv6 address.' % self.addr) if not self.addr: self.addr = '::1' if self.use_ipv6 else '127.0.0.1' self._raw_ipv6 = self.use_ipv6 # 启动服务器 self.run(**options) 再随后 , 在run中会调用inner_run , 具体源码如下 : def inner_run(self, *args, **options): # If an exception was silenced in ManagementUtility.execute in order # to be raised in the child process, raise it now. autoreload.raise_last_exception() threading = options['use_threading'] # 'shutdown_message' is a stealth option. shutdown_message = options.get('shutdown_message', '') quit_command = 'CTRL-BREAK' if sys.platform == 'win32' else 'CONTROL-C' self.stdout.write(\"Performing system checks...\\n\\n\") self.check(display_num_errors=True) # Need to check migrations here, so can't use the # requires_migrations_check attribute. self.check_migrations() now = datetime.now().strftime('%B %d, %Y - %X') if six.PY2: now = now.decode(get_system_encoding()) self.stdout.write(now) self.stdout.write(( \"Django version %(version)s, using settings %(settings)r\\n\" \"Starting development server at %(protocol)s://%(addr)s:%(port)s/\\n\" \"Quit the server with %(quit_command)s.\\n\" ) % { \"version\": self.get_version(), \"settings\": settings.SETTINGS_MODULE, \"protocol\": self.protocol, \"addr\": '[%s]' % self.addr if self._raw_ipv6 else self.addr, \"port\": self.port, \"quit_command\": quit_command, }) try: # 这里最终获取的是WSGIHandler的实例,并且中间件的加载也是在这一步中完成的 handler = self.get_handler(*args, **options) # 我们把实参补全来观察 # run('127.0.0.1', 8000, WSGIHandler(), False, threading, WSGIServer) run(self.addr, int(self.port), handler, ipv6=self.use_ipv6, threading=threading, server_cls=self.server_cls) except socket.error as e:: pass # 省略我们直接看看真正的run吧 def run(addr, port, wsgi_handler, ipv6=False, threading=False, server_cls=WSGIServer): server_address = (addr, port) if threading: # 重新构造WSGIServer,并继承了socketserver.ThreadingMixIn和原WSGIServer httpd_cls = type(str('WSGIServer'), (socketserver.ThreadingMixIn, server_cls), {}) else: httpd_cls = server_cls # 实例化新的WSGIServer httpd = httpd_cls(server_address, WSGIRequestHandler, ipv6=ipv6) if threading: # 加快自动重启以及防止线程不正常终止 httpd.daemon_threads = True # wsgi_handler=WSGIHandler(),set_app结果:self.application = WSGIHandler() httpd.set_app(wsgi_handler) # socketserver.serve_forever,至此Web服务器启动 httpd.serve_forever() 处理请求 🍀 调用serve_forver()之后 , 我们的服务端就已经做好随时 \"接客\" (HTTP请求) 的准备了 def serve_forever(self, poll_interval=0.5): \"\"\"Handle one request at a time until shutdown. Polls for shutdown every poll_interval seconds. Ignores self.timeout. If you need to do periodic tasks, do them in another thread. \"\"\" self.__is_shut_down.clear() try: # XXX: Consider using another file descriptor or connecting to the # socket to wake this up instead of polling. Polling reduces our # responsiveness to a shutdown request and wastes cpu at all other # times. with _ServerSelector() as selector: selector.register(self, selectors.EVENT_READ) while not self.__shutdown_request: ready = selector.select(poll_interval) if ready: # 处理请求 self._handle_request_noblock() self.service_actions() finally: self.__shutdown_request = False self.__is_shut_down.set() 在分析如何处理请求之前 , 我们需要理清由type构造的这个新的WSGIServer 到底继承了基类的哪些东西 , 因为这关系到在请求处理过程 , 到底会执行该实例的哪一个方法 由于这个构造出来的新类其继承体系有点庞大 , 所以这里将直接观察其真正的执行方法 self._handle_reqeust_noblock() 具体内容如下 : def _handle_request_noblock(self): \"\"\"Handle one request, without blocking. I assume that selector.select() has returned that the socket is readable before this function was called, so there should be no risk of blocking in get_request(). \"\"\" try: # 获取请求和客户端地址 request, client_address = self.get_request() except OSError: return if self.verify_request(request, client_address): try: # 调用finish_request self.process_request(request, client_address) except: self.handle_error(request, client_address) self.shutdown_request(request) else: self.shutdown_request(request) self.process_request(request, client_address) 具体内容如下 : def process_request(self, request, client_address): self.finish_request(request, client_address) self.shutdown_request(request) self.finish_request(request, client_address) 具体内容如下 : def finish_request(self, request, client_address): \"\"\"Finish one request by instantiating RequestHandlerClass.\"\"\" # self.RequestHandlerClass = WSGIRequestHandler self.RequestHandlerClass(request, client_address, self) 就像源码注释中所说 , 它将通过实例化一个RequestHandleClass类 , 来处理一个请求 , 这个类就是WSGIRequestHandler , 这个类的构造函数在其最高基类BaseRequestHandler 中 , 如下 : def __init__(self, request, client_address, server): self.request = request self.client_address = client_address self.server = server self.setup() try: self.handle() finally: self.finish() 也就是说 , 在实例化时会调用类中的handler方法 , 这个方法在WSGIRequestHandler中被重写了 , 如下 : def handle(self): \"\"\"Copy of WSGIRequestHandler, but with different ServerHandler\"\"\" self.raw_requestline = self.rfile.readline(65537) if len(self.raw_requestline) > 65536: self.requestline = '' self.request_version = '' self.command = '' self.send_error(414) return if not self.parse_request(): # An error code has been sent, just exit return # 实例化并设置HTTP环境变量 handler = ServerHandler( self.rfile, self.wfile, self.get_stderr(), self.get_environ() ) handler.request_handler = self # backpointer for logging # self.server = httpd = httpd_cls(server_address, WSGIRequestHandler, ipv6=ipv6) # self.server.get_app() = WSGIHandler() handler.run(self.server.get_app()) 最后执行run , 该方法来自于ServerHandler的最高基类BaseHandler , 源码如下 : def run(self, application): \"\"\"Invoke the application\"\"\" # Note to self: don't move the close()! Asynchronous servers shouldn't # call close() from finish_response(), so if you close() anywhere but # the double-error branch here, you'll break asynchronous servers by # prematurely closing. Async servers must return from 'run()' without # closing if there might still be output to iterate over. try: # 设置WSGi环境变量 self.setup_environ() # self.result = WSGIHandler()(self.environ, self.start_response) # 调用__call__方法,返回结果 self.result = application(self.environ, self.start_response) self.finish_response() except: try: self.handle_error() except: # If we get an error handling an error, just give up already! self.close() raise # ...and let the actual server figure it out. WSGIHandler().__call__(self.environ, self.start_response) 如下 : def __call__(self, environ, start_response): set_script_prefix(get_script_name(environ)) signals.request_started.send(sender=self.__class__, environ=environ) # 生成请求对象 request = self.request_class(environ) # 根据请求获取响应对象 response = self.get_response(request) response._handler_class = self.__class__ # 状态码 status = '%d %s' % (response.status_code, response.reason_phrase) # 响应头 response_headers = [(str(k), str(v)) for k, v in response.items()] for c in response.cookies.values(): response_headers.append((str('Set-Cookie'), str(c.output(header='')))) start_response(force_str(status), response_headers) if getattr(response, 'file_to_stream', None) is not None and environ.get('wsgi.file_wrapper'): response = environ['wsgi.file_wrapper'](response.file_to_stream) return response 最后finish_response() , 返回响应 , 关闭套接字 ; 当然 , 服务器还是继续等待 \"客人\" 来光临 ! def finish_response(self): \"\"\"Send any iterable data, then close self and the iterable Subclasses intended for use in asynchronous servers will want to redefine this method, such that it sets up callbacks in the event loop to iterate over the data, and to call 'self.close()' once the response is finished. \"\"\" try: if not self.result_is_file() or not self.sendfile(): for data in self.result: self.write(data) self.finish_content() finally: self.close() 小结 🍀 分析过程中 , 为了避免派生类重写了基类中的方法而导致分析出错 , 不妨将所有方法整合到一个类中 , 虽然这个工作也不好做 , 但是却是不会出错 我们通过一条 \"执行线\" 来完成本次小结 : django-admin runserver → Command() → handle() → run() → → inner_run() → self.get_handler(*args, **options) → → basehttp.run() → httpd → httpd.serve_forever() → → self.RequestHandlerClass(request, client_address, self) → self.handle() → → ServerHandler(self.rfile, self.wfile, self.get_stderr(), self.get_environ()) → → handler.run(self.server.get_app()) → → WSGIHandler()(self.environ, self.start_response) → __call__ → self.finish_response() 处理请求过程 : 当一个HTTP请求到达服务器 , WSGIServer类会通过调用WSGIRequestHandler类的handle()方法来处理HTTP请求 , 在处理请求时 , 会先创建一个WSGI应用程序(WSGIHandler)接口的实例 , 随后作为参数传给ServerHandler类 , 最后对其进行处理 "},"05-Web框架/Django/52-Django - 源码之middleware.html":{"url":"05-Web框架/Django/52-Django - 源码之middleware.html","title":"Django - 源码之middleware","keywords":"","body":"Django - 源码之middleware 介绍 🍀 在关于上一篇runserver命令的分析中 , 实际上我们跳过了一步 , 那就是关于中间件加载的 当执行django-admin runsercer命令时 , 我们知道会执行runserver.Command类的handle()方法 , 那么加载中间件的这一步在哪里呢 它就藏在WSGIHandler中 , 并且在实例化时就会执行 , 而我们获取这个实例是通过调用runserver.Command类的get_handler()方法获取的 , 它在inner_run中被调用 , 如下 : runserver.Command.inner_run() def inner_run(self, *args, **options): pass # 截取如下内容 try: # 调用get_handler(),返回一个WSGIHandler实例 # 注意该实例实现了__call__方法... handler = self.get_handler(*args, **options) run(self.addr, int(self.port), handler, ipv6=self.use_ipv6, threading=threading, server_cls=self.server_cls) except socket.error as e: pass get_handler() def get_handler(self, *args, **options): \"\"\" Returns the default WSGI handler for the runner. \"\"\" return get_internal_wsgi_application() 随后调用get_internal_wsgi_application() → get_wsgi_application() → WSGIHandler() 其构造函数如下 : def __init__(self, *args, **kwargs): super(WSGIHandler, self).__init__(*args, **kwargs) self.load_middleware() load_middleware 🍀 def load_middleware(self): \"\"\" Populate middleware lists from settings.MIDDLEWARE (or the deprecated MIDDLEWARE_CLASSES). Must be called after the environment is fixed (see __call__ in subclasses). \"\"\" # 请求中间件 self._request_middleware = [] # 视图中间件 self._view_middleware = [] # 模板中间件 self._template_response_middleware = [] # 响应中间件 self._response_middleware = [] # 异常中间件 self._exception_middleware = [] if settings.MIDDLEWARE is None: # 在django比较老的版本(1.10之前)中使用的是settings.MIDDLEWARE_CLASS # 这一部分主要是为了解决兼容性问题 warnings.warn( \"Old-style middleware using settings.MIDDLEWARE_CLASSES is \" \"deprecated. Update your middleware and use settings.MIDDLEWARE \" \"instead.\", RemovedInDjango20Warning ) # convert_exception_to_response会将返回的异常转换成响应,它是一个装饰器 # self._legacy_get_response函数作用为应用请求中间件 handler = convert_exception_to_response(self._legacy_get_response) # 从settings中加载中间件 for middleware_path in settings.MIDDLEWARE_CLASSES: # 导入中间件所在模块 mw_class = import_string(middleware_path) try: # 实例化中间件 mw_instance = mw_class() except MiddlewareNotUsed as exc: if settings.DEBUG: if six.text_type(exc): logger.debug('MiddlewareNotUsed(%r): %s', middleware_path, exc) else: logger.debug('MiddlewareNotUsed: %r', middleware_path) continue # 根据中间件类型,将其process_xxxx方法添加如中间件列表 if hasattr(mw_instance, 'process_request'): self._request_middleware.append(mw_instance.process_request) if hasattr(mw_instance, 'process_view'): self._view_middleware.append(mw_instance.process_view) # 后三种加载顺序为后来者居上 if hasattr(mw_instance, 'process_template_response'): self._template_response_middleware.insert(0, mw_instance.process_template_response) if hasattr(mw_instance, 'process_response'): self._response_middleware.insert(0, mw_instance.process_response) if hasattr(mw_instance, 'process_exception'): self._exception_middleware.insert(0, mw_instance.process_exception) else: # 默认我们创建Django项目时,settings.MIDDLEWARE不为None # self._get_response()解析请求并调用响应的视图,最后返回响应 handler = convert_exception_to_response(self._get_response) for middleware_path in reversed(settings.MIDDLEWARE): # 导入中间件所在模块 middleware = import_string(middleware_path) try: # 实例化中间件 # 中间件接收一个get_handler参数,这里为self._get_response mw_instance = middleware(handler) except MiddlewareNotUsed as exc: if settings.DEBUG: if six.text_type(exc): logger.debug('MiddlewareNotUsed(%r): %s', middleware_path, exc) else: logger.debug('MiddlewareNotUsed: %r', middleware_path) continue if mw_instance is None: raise ImproperlyConfigured( 'Middleware factory %s returned None.' % middleware_path ) if hasattr(mw_instance, 'process_view'): self._view_middleware.insert(0, mw_instance.process_view) if hasattr(mw_instance, 'process_template_response'): self._template_response_middleware.append(mw_instance.process_template_response) if hasattr(mw_instance, 'process_exception'): self._exception_middleware.append(mw_instance.process_exception) # 执行中间件实例中的__call__方法,process_request()与process_response()正藏在这里 # 该__call__方法是现在MiddlewareMixin中 \"\"\" def __call__(self, request): response = None if hasattr(self, 'process_request'): response = self.process_request(request) if not response: # response = self._get_request(request) response = self.get_response(request) if hasattr(self, 'process_response'): response = self.process_response(request, response) return response \"\"\" handler = convert_exception_to_response(mw_instance) # We only assign to this when initialization is complete as it is used # as a flag for initialization being complete. # 最后完成中间件链的加载 self._middleware_chain = handler 在上面的代码清单中 , 我们分成两部分来说 , 因为对于中间件的加载 , 在django1.11之前的版本 , 肯定是不会有这么长的 , 原因在于 , 在django1.11中 , 为了解决与老版本之间的兼容性问题 , 作出了一些调整 在老版本中 , Django会直接应用请求中间件和响应中间件 , 也就是process_request , process_response , 在早起中间件中 , process_response总是会被调用 , 即使在这之前process_request 已经发生短路并返回了一个响应 而在新版本中 , 请求经过的中间件和响应经过的中间件层数是一样的 , 也就是说 , 一旦发生短路 , 响应就会按照相反的顺序返回 , 根本不会到达后面的中间件 , 所以这也是为什么在下部分代码中 , 只有视图中间件 , 模板中间件和异常中间件相关的内容了 self._get_response 🍀 那么接下来我们就需要看看关于这后部分三个中间件的细节内容了 , 它们在self._get_response()中 , 该方法在初始化时就已经被传入各个中间件中 : def _get_response(self, request): \"\"\" Resolve and call the view, then apply view, exception, and template_response middleware. This method is everything that happens inside the request/response middleware. \"\"\" response = None if hasattr(request, 'urlconf'): urlconf = request.urlconf set_urlconf(urlconf) resolver = get_resolver(urlconf) else: resolver = get_resolver() # 进行url匹配,查找相关视图 resolver_match = resolver.resolve(request.path_info) callback, callback_args, callback_kwargs = resolver_match request.resolver_match = resolver_match # Apply view middleware for middleware_method in self._view_middleware: # self._view_middleware中为process_view # 即各个视图中间件中的process_view方法 response = middleware_method(request, callback, callback_args, callback_kwargs) if response: # 如果响应不为空,终止处理 break if response is None: # 返回视图函数 wrapped_callback = self.make_view_atomic(callback) try: # 调用视图函数 response = wrapped_callback(request, *callback_args, **callback_kwargs) except Exception as e: # 应用异常中间件 response = self.process_exception_by_middleware(e, request) # Complain if the view returned None (a common error). if response is None: if isinstance(callback, types.FunctionType): # FBV view_name = callback.__name__ else: # CBV view_name = callback.__class__.__name__ + '.__call__' raise ValueError( \"The view %s.%s didn't return an HttpResponse object. It \" \"returned None instead.\" % (callback.__module__, view_name) ) # If the response supports deferred rendering, apply template # response middleware and then render the response elif hasattr(response, 'render') and callable(response.render): # 如果响应支持延迟渲染,就应用模板中间件 for middleware_method in self._template_response_middleware: response = middleware_method(request, response) # Complain if the template response middleware returned None (a common error). if response is None: raise ValueError( \"%s.process_template_response didn't return an \" \"HttpResponse object. It returned None instead.\" % (middleware_method.__self__.__class__.__name__) ) try: response = response.render() except Exception as e: response = self.process_exception_by_middleware(e, request) return response 到这里 , 加载工作就差不多了 , 而在上一篇关于runserver的分析中 , 我们也已经知道 , 当请求来到时 , 会调用ServerHandler的最高基类BaseHandler中的run()方法 , 并且已经将WSGIHandler()设置为了application , 如下 , 我们再次将run()源码贴出来 : def run(self, application): \"\"\"Invoke the application\"\"\" # Note to self: don't move the close()! Asynchronous servers shouldn't # call close() from finish_response(), so if you close() anywhere but # the double-error branch here, you'll break asynchronous servers by # prematurely closing. Async servers must return from 'run()' without # closing if there might still be output to iterate over. try: self.setup_environ() # self.result = WSGIHandler()(self.environ, self.start_response) # 即调用WSGIHandler类的__call__方法 self.result = application(self.environ, self.start_response) self.finish_response() except: try: self.handle_error() except: # If we get an error handling an error, just give up already! self.close() raise # ...and let the actual server figure it out. 现在 , 该亮出这个__call__了 : def __call__(self, environ, start_response): set_script_prefix(get_script_name(environ)) signals.request_started.send(sender=self.__class__, environ=environ) # 实例化请求 request = self.request_class(environ) # 处理请求,返回响应对象 response = self.get_response(request) response._handler_class = self.__class__ status = '%d %s' % (response.status_code, response.reason_phrase) response_headers = [(str(k), str(v)) for k, v in response.items()] for c in response.cookies.values(): response_headers.append((str('Set-Cookie'), str(c.output(header='')))) start_response(force_str(status), response_headers) if getattr(response, 'file_to_stream', None) is not None and environ.get('wsgi.file_wrapper'): response = environ['wsgi.file_wrapper'](response.file_to_stream) return response 最后 , 我们来看看这个处理请求的函数get_response() : def get_response(self, request): \"\"\"Return an HttpResponse object for the given HttpRequest.\"\"\" # Setup default url resolver for this thread set_urlconf(settings.ROOT_URLCONF) # self._middleware_chain在加载时已经完成 # 被装饰后的self._get_response response = self._middleware_chain(request) # This block is only needed for legacy MIDDLEWARE_CLASSES; if # MIDDLEWARE is used, self._response_middleware will be empty. try: # Apply response middleware, regardless of the response for middleware_method in self._response_middleware: # 调用中间件 response = middleware_method(request, response) # Complain if the response middleware returned None (a common error). if response is None: raise ValueError( \"%s.process_response didn't return an \" \"HttpResponse object. It returned None instead.\" % (middleware_method.__self__.__class__.__name__)) except Exception: # Any exception should be gathered and handled signals.got_request_exception.send(sender=self.__class__, request=request) response = self.handle_uncaught_exception(request, get_resolver(get_urlconf()), sys.exc_info()) response._closable_objects.append(request) # If the exception handler returns a TemplateResponse that has not # been rendered, force it to be rendered. if not getattr(response, 'is_rendered', True) and callable(getattr(response, 'render', None)): # 渲染模板响应 response = response.render() if response.status_code == 404: logger.warning( 'Not Found: %s', request.path, extra={'status_code': 404, 'request': request}, ) return response 到这里 , 对于中间件的分析就差不多了 , 是时候理一理了 小结 🍀 首先 , 中间件的加载是在启动时就已经加载完成 , 也就是还没有执行httpd.serve_forever()之前就已经完成 每一个中间件都是一个类 , 在 Django1.10 以后 通过继承 MiddlewareMixin 来保证Django版本之间的兼容 , 这是一个过渡 ; 在每一个中间件中会实现 process_reqeust() , process_view() , process_template_response() , process_response() , process_exception() 中间件处理步骤 : 请求通过请求中间件 , 如果process_request返回的response为空 , 则继续下一步 , 否则应用响应中间件处理传入请求与中间件返回的response 应用视图中间件 (应用之前会进行url匹配查找视图函数) , 如果process_view返回的response为空 , 则继续下一步 , 否则应用响应中间件处理传入请求与中间件返回的response 调用视图函数进行处理 如果视图抛出异常 , 应用异常中间件 , 应用响应中间件处理传入请求与中间件返回的response 如果返回的response支持延迟渲染 , 应用模板中间件 应用响应中间件 , 处理传入请求与中间件返回 "},"05-Web框架/Django/53-Django - 源码之url.html":{"url":"05-Web框架/Django/53-Django - 源码之url.html","title":"Django - 源码之url","keywords":"","body":"Django - 源码之url 介绍 🍀 上一篇对中间件的源码进行了阅读 , 我们知道了 , 当请求到来时 , 首先会应用请求中间件 , 随后就是进行URL匹配 , 去寻找对应的视图了 在上一篇的代码中 , 实际上我们已经见过了 , 那么这一篇就要对其进行详细的分析了 说先引出其入口 def _get_response(self, request): \"\"\" Resolve and call the view, then apply view, exception, and template_response middleware. This method is everything that happens inside the request/response middleware. \"\"\" response = None # 加载settings.ROOT_URLCONF,即根目录中的urls.py # 并返回一个 **RegexURLResolver** 对象 if hasattr(request, 'urlconf'): # 一般情况下,在默认request中没有urlconf属性 urlconf = request.urlconf set_urlconf(urlconf) resolver = get_resolver(urlconf) else: resolver = get_resolver() # **进行url匹配,查找相关视图** resolver_match = resolver.resolve(request.path_info) # 分解视图函数以及参数 callback, callback_args, callback_kwargs = resolver_match request.resolver_match = resolver_match # Apply view middleware for middleware_method in self._view_middleware: # self._view_middleware中为process_view # 即各个视图中间件中的process_view方法 response = middleware_method(request, callback, callback_args, callback_kwargs) if response: # 如果响应不为空,终止处理 break 由上可知 , 在_get_response() 中构造了RegexURLResolver对象 , 随后调用该对象的 resolve() 方法 , 最后从返回值中获取视图函数与参数 resolve 🍀 def resolve(self, path): path = force_text(path) # path may be a reverse_lazy object tried = [] # regex是一个类变量 # regex = LocaleRegexDescriptor() # LocaleRegexDescriptor是一个描述器类,当执行self.regex时会执行__get__方法 # self.regex返回一个经过编译的正则表达式 match = self.regex.search(path) if match: # 去除前缀mysite.url new_path = path[match.end():] # 遍历urlpatterns for pattern in self.url_patterns: try: # pattern为url()返回的RegexURLResolver(For include)或RegexURLPattern sub_match = pattern.resolve(new_path) except Resolver404 as e: sub_tried = e.args[0].get('tried') if sub_tried is not None: tried.extend([pattern] + t for t in sub_tried) else: tried.append([pattern]) else: # 未出现异常执行 if sub_match: # Merge captured arguments in match with submatch # 获取对应参数 sub_match_dict = dict(match.groupdict(), **self.default_kwargs) sub_match_dict.update(sub_match.kwargs) # If there are *any* named groups, ignore all non-named groups. # Otherwise, pass all non-named arguments as positional arguments. sub_match_args = sub_match.args if not sub_match_dict: sub_match_args = match.groups() + sub_match.args return ResolverMatch( sub_match.func, sub_match_args, sub_match_dict, sub_match.url_name, [self.app_name] + sub_match.app_names, [self.namespace] + sub_match.namespaces, ) tried.append([pattern]) raise Resolver404({'tried': tried, 'path': new_path}) raise Resolver404({'path': path}) 获取的 urlpatterns 中 , url() 函数会返回两种对象 , 源码可见 : def url(regex, view, kwargs=None, name=None): if isinstance(view, (list, tuple)): # 第一种,view为一个元组,元组中包含一个列表和元组 # 这是在进行路由分发时发生的,也就是使用include # For include(...) processing. urlconf_module, app_name, namespace = view return RegexURLResolver(regex, urlconf_module, kwargs, app_name=app_name, namespace=namespace) elif callable(view): # 第二种,view为一个函数 return RegexURLPattern(regex, view, kwargs, name) else: raise TypeError('view must be a callable or a list/tuple in the case of include().') 首先我们来看看第二种 , 也就是view为函数的情况 , 其返回一个RegexURLPattern对象 RegexURLPattern 🍀 class RegexURLPattern(LocaleRegexProvider): def __init__(self, regex, callback, default_args=None, name=None): LocaleRegexProvider.__init__(self, regex) self.callback = callback # the view self.default_args = default_args or {} self.name = name # 摘取如下部分 def resolve(self, path): # 完成url解析 match = self.regex.search(path) if match: # If there are any named groups, use those as kwargs, ignoring # non-named groups. Otherwise, pass all non-named arguments as # positional arguments. kwargs = match.groupdict() args = () if kwargs else match.groups() # In both cases, pass any extra_kwargs as **kwargs. kwargs.update(self.default_args) # ResolverMatch类中定义了__gititem__方法 return ResolverMatch(self.callback, args, kwargs, self.name) 看看这个返回的ResolverMatch , 源码如下 : class ResolverMatch(object): def __init__(self, func, args, kwargs, url_name=None, app_names=None, namespaces=None): # 分解出的视图函数 self.func = func # 视图函数参数 self.args = args self.kwargs = kwargs self.url_name = url_name # If a URLRegexResolver doesn't have a namespace or app_name, it passes # in an empty value. self.app_names = [x for x in app_names if x] if app_names else [] self.app_name = ':'.join(self.app_names) self.namespaces = [x for x in namespaces if x] if namespaces else [] self.namespace = ':'.join(self.namespaces) if not hasattr(func, '__name__'): # CBV # A class-based view self._func_path = '.'.join([func.__class__.__module__, func.__class__.__name__]) else: # FBV # A function-based view self._func_path = '.'.join([func.__module__, func.__name__]) view_path = url_name or self._func_path self.view_name = ':'.join(self.namespaces + [view_path]) def __getitem__(self, index): # 通过解包即可依次获得视图函数与各参数 return (self.func, self.args, self.kwargs)[index] 这就是最后在_get_response()中获取的结果了 , 对ResolverMatch 进行解包 接下来就是第二种情况了 , 也就是view为include() 返回的结果 , 它是一个元组 , 形式 : (list,tuple) include 🍀 首先我们需要弄清楚 , include返回的元组中到底有什么内容 , 其源码如下 : def include(arg, namespace=None, app_name=None): # arg: # - six.string_types (PY3 : str) # - tuple # - list if app_name and not namespace: raise ValueError('Must specify a namespace if specifying app_name.') if app_name: warnings.warn( 'The app_name argument to django.conf.urls.include() is deprecated. ' 'Set the app_name in the included URLconf instead.', RemovedInDjango20Warning, stacklevel=2 ) if isinstance(arg, tuple): # callable returning a namespace hint try: urlconf_module, app_name = arg except ValueError: if namespace: raise ImproperlyConfigured( 'Cannot override the namespace for a dynamic module that provides a namespace' ) warnings.warn( 'Passing a 3-tuple to django.conf.urls.include() is deprecated. ' 'Pass a 2-tuple containing the list of patterns and app_name, ' 'and provide the namespace argument to include() instead.', RemovedInDjango20Warning, stacklevel=2 ) # 获取urlconf模块,应用名,命名空间 urlconf_module, app_name, namespace = arg else: # No namespace hint - use manually provided namespace urlconf_module = arg if isinstance(urlconf_module, six.string_types): # urlconf_module为字符串,导入该url模块 urlconf_module = import_module(urlconf_module) # 获取内部的urlpatterns patterns = getattr(urlconf_module, 'urlpatterns', urlconf_module) # 获取app_name app_name = getattr(urlconf_module, 'app_name', app_name) if namespace and not app_name: warnings.warn( 'Specifying a namespace in django.conf.urls.include() without ' 'providing an app_name is deprecated. Set the app_name attribute ' 'in the included module, or pass a 2-tuple containing the list of ' 'patterns and app_name instead.', RemovedInDjango20Warning, stacklevel=2 ) namespace = namespace or app_name # Make sure we can iterate through the patterns (without this, some # testcases will break). if isinstance(patterns, (list, tuple)): # list为分发的url for url_pattern in patterns: # Test if the LocaleRegexURLResolver is used within the include; # this should throw an error since this is not allowed! if isinstance(url_pattern, LocaleRegexURLResolver): raise ImproperlyConfigured( 'Using i18n_patterns in an included URLconf is not allowed.') # 返回一个元组 return (urlconf_module, app_name, namespace) include实现了路由分发 , 但是实际上 , 它就是在 url() 中又套了一层 url() , 在每一个urls中都必须有一个urlpatterns , 通过一层一层的urlpatterns , 就可以实现路由分发了 最后 , 如果我们不使用include() , 实际上也是可以实现路由分发的 : # 版本一 urlpatterns = [ url(r'^home/', ( # 该列表即urlpatterns,可用函数替换掉 [ url(r'^index/', views.index), url(r'^login/', views.login), url(r'^register/', views.register), ], None, # app_name None # namespace )), ] # 版本二 def get_urlpatterns(): urlpatterns = [ url(r'^index/', views.index), url(r'^login/', views.login), url(r'^register/', views.register), ] return urlpatterns urlpatterns = [ url(r'^home/', ( get_urlpatterns, None, # app_name None # namespace )), ] 小结 🍀 在这一章关于URL的源码中 , 印象最深刻的还属 __get__ 的使用 , 构造描述器类 ( LocaleRegexDescriptor )来完成需求 , 以及以解包的方式获取 __gitItem__ 中的相关值 __get__ 示例 class Descriptor: def __get__(self): print(\"Visit me and execute me.\") class Onwer: desc = Descriptor() o = Onwer() o.d \"\"\" 执行结果: Visit me and execute me. \"\"\" __getitem__ 示例 class Foo: def __getitem__(self, item): return ('lyon', 'kenneth', 'even')[item] f = Foo() lyon, kenneth, even = f \"\"\" 执行结果: lyon kenneth even \"\"\" "},"05-Web框架/Django/54-Django - 源码之admin.html":{"url":"05-Web框架/Django/54-Django - 源码之admin.html","title":"Django - 源码之admin","keywords":"","body":"Django - 源码之Admin 介绍 🍀 Django为我们提供了一个强大的后台管理页面 , 也就是admin 在我们创建应用时 , 默认的 urls.py 中第一条就进行了admin分发 , 如下 : url(r'^admin/', admin.site.urls) 其应用增删改查路由规则如下 : 这些url都是admin为我们自动生成的 , 这也是我们需要了解的重点 # application:应用名 # table:表名 - /admin/application/table/ # 查询数据 - /admin/application/table/add/ # 添加数据 - /admin/application/table/1/change/ # 修改数据 - /admin/application/table/1/delete/ # 删除数据 admin.site.urls 🍀 在源码目录中 , admin 下的 sites.py 中使用了一个全局对象 # This global object represents the default admin site, for the common case. # You can instantiate AdminSite in your own code to create a custom admin site. site = AdminSite() 随后访问该实例的urls属性 , 如下 : @property def urls(self): return self.get_urls(), 'admin', self.name 该属性返回了一个元组 , 并且形式如 : (list,tuple) , 在上一篇URL的分析中我们已经知道 , 这正是进行路由分发 , 元组中的第一个元素为分发的子路由 self.get_urls()源码如下 : def get_urls(self): from django.conf.urls import url, include # Since this module gets imported in the application's root package, # it cannot import models from other applications at the module level, # and django.contrib.contenttypes.views imports ContentType. from django.contrib.contenttypes import views as contenttype_views def wrap(view, cacheable=False): def wrapper(*args, **kwargs): return self.admin_view(view, cacheable)(*args, **kwargs) wrapper.admin_site = self return update_wrapper(wrapper, view) # Admin-site-wide views. # admin本身视图 urlpatterns = [ url(r'^$', wrap(self.index), name='index'), url(r'^login/$', self.login, name='login'), url(r'^logout/$', wrap(self.logout), name='logout'), url(r'^password_change/$', wrap(self.password_change, cacheable=True), name='password_change'), url(r'^password_change/done/$', wrap(self.password_change_done, cacheable=True), name='password_change_done'), url(r'^jsi18n/$', wrap(self.i18n_javascript, cacheable=True), name='jsi18n'), url(r'^r/(?P\\d+)/(?P.+)/$', wrap(contenttype_views.shortcut), name='view_on_site'), ] # Add in each model's views, and create a list of valid URLS for the # app_index valid_app_labels = [] for model, model_admin in self._registry.items(): # model:models.UserInfo # model_admin:ModelAdmin(models.UserInfo, admin.site) # 为self._registry中的model生成增删改查url # self._registry默认为空,当我们在应用的admin.py中注册时会进行添加 # model_admin为ModelAdmin实例 urlpatterns += [ url(r'^%s/%s/' % (model._meta.app_label, model._meta.model_name), include(model_admin.urls)), ] if model._meta.app_label not in valid_app_labels: valid_app_labels.append(model._meta.app_label) # If there were ModelAdmins registered, we should have a list of app # labels for which we need to allow access to the app_index view, if valid_app_labels: regex = r'^(?P' + '|'.join(valid_app_labels) + ')/$' urlpatterns += [ url(regex, wrap(self.app_index), name='app_list'), ] return urlpatterns register 🍀 注册model到self._registry , 是通过register()实现的 , 如 : admin.site.register(models.UserInfo) def register(self, model_or_iterable, admin_class=None, **options): \"\"\" Registers the given model(s) with the given admin class. The model(s) should be Model classes, not instances. If an admin class isn't given, it will use ModelAdmin (the default admin options). If keyword arguments are given -- e.g., list_display -- they'll be applied as options to the admin class. If a model is already registered, this will raise AlreadyRegistered. If a model is abstract, this will raise ImproperlyConfigured. \"\"\" if not admin_class: # 默认使用ModelAdmin admin_class = ModelAdmin if isinstance(model_or_iterable, ModelBase): # 将model class放入列表中 model_or_iterable = [model_or_iterable] for model in model_or_iterable: if model._meta.abstract: raise ImproperlyConfigured( 'The model %s is abstract, so it cannot be registered with admin.' % model.__name__ ) if model in self._registry: raise AlreadyRegistered('The model %s is already registered' % model.__name__) # Ignore the registration if the model has been # swapped out. if not model._meta.swapped: # If we got **options then dynamically construct a subclass of # admin_class with those **options. if options: # For reasons I don't quite understand, without a __module__ # the created class appears to \"live\" in the wrong place, # which causes issues later on. options['__module__'] = __name__ admin_class = type(\"%sAdmin\" % model.__name__, (admin_class,), options) # Instantiate the admin class to save in the registry # 注册后示例:models.UserInfo : ModelAdmin(models.UserInfo, admin.site) self._registry[model] = admin_class(model, self) self._registry 是一个字典 , 最后注册完成后 , 字典的元素的key 为 modes.UserInfo , 而value则是一个ModelAdmin对象 , 对于model的url生成 , 就藏在ModelAdmin中 ModelAdmin 🍀 提取ModelAdmin中的部分内容 因为在分发的过程中 , 执行了include(model_admin.urls) @property def urls(self): return self.get_urls() self.get_urls() def get_urls(self): from django.conf.urls import url def wrap(view): def wrapper(*args, **kwargs): return self.admin_site.admin_view(view)(*args, **kwargs) wrapper.model_admin = self return update_wrapper(wrapper, view) info = self.model._meta.app_label, self.model._meta.model_name # 自动生成url列表 urlpatterns = [ url(r'^$', wrap(self.changelist_view), name='%s_%s_changelist' % info), url(r'^add/$', wrap(self.add_view), name='%s_%s_add' % info), url(r'^(.+)/history/$', wrap(self.history_view), name='%s_%s_history' % info), url(r'^(.+)/delete/$', wrap(self.delete_view), name='%s_%s_delete' % info), url(r'^(.+)/change/$', wrap(self.change_view), name='%s_%s_change' % info), # For backwards compatibility (was the change url before 1.9) url(r'^(.+)/$', wrap(RedirectView.as_view( pattern_name='%s:%s_%s_change' % ((self.admin_site.name,) + info) ))), ] return urlpatterns 上面自动生成的url对应视图如下 : class ModelAdmin(BaseModelAdmin): def __init__(self, model, admin_site): self.model = model self.opts = model._meta self.admin_site = admin_site super(ModelAdmin, self).__init__() @csrf_protect_m def changelist_view(self, request, extra_context=None): \"\"\" 查看model列表 \"\"\" pass def add_view(self, request, form_url='', extra_context=None): \"\"\" 添加数据 \"\"\" return self.changeform_view(request, None, form_url, extra_context) def change_view(self, request, object_id, form_url='', extra_context=None): \"\"\" 编辑数据 \"\"\" return self.changeform_view(request, object_id, form_url, extra_context) @csrf_protect_m def delete_view(self, request, object_id, extra_context=None): \"\"\" 删除数据 \"\"\" with transaction.atomic(using=router.db_for_write(self.model)): return self._delete_view(request, object_id, extra_context) def history_view(self, request, object_id, extra_context=None): \"\"\" 查看历史记录 \"\"\" pass 自定制Admin 🍀 当我们在admin.py 中间注册我们的model时 , 一般我们只需要传入一个参数 , 就是我们的model , 因为django为我们默认是用了ModelAdmin , 也就是admin_class参数 , 当然我们可以自己传入这个admin_class , 这样我们就可以完全定制属于我们自己admin了 定制之前 , 我们需要知道在ModelAdmin中的定制配置 @python_2_unicode_compatible class ModelAdmin(BaseModelAdmin): \"Encapsulates all admin options and functionality for a given model.\" # 定制显示的列 list_display = ('__str__',) # 定制可跳转的列 list_display_links = () # 定制右侧快速筛选 list_filter = () # 定制连表查询自动select_related list_select_related = False # 定制页面显示条数 list_per_page = 100 # 定制显示全部条数大小,只有当真实数据小于该值才应用 list_max_show_all = 200 # 定制可编辑的列 list_editable = () # 定制模糊搜索功能 search_fields = () # 对Date和DateTime类型进行搜索 date_hierarchy = None # 详细页面,按钮为\"Sava as new\"或\"Sava and add another\" save_as = False # 点击保存并继续编辑 save_as_continue = True # 详细页面,在页面上方是否也显示保存删除等按钮 save_on_top = False # 分页插件 paginator = Paginator # preserve_filters = True # 详细页面,如果有其他表和当前表做外键关联,那么详细页面可以进行动态增加和删除 inlines = [] # Custom templates (designed to be over-ridden in subclasses) add_form_template = None change_form_template = None change_list_template = None delete_confirmation_template = None delete_selected_confirmation_template = None object_history_template = None popup_response_template = None # Actions # 定制action中的操作 actions = [] action_form = helpers.ActionForm # Action选项在页面上方显示 actions_on_top = True # Action选项在页面下方显示 actions_on_bottom = False # 显示选择个数 actions_selection_counter = True checks_class = ModelAdminChecks 后期补充 ... "},"05-Web框架/Django/Django - Django命令整理.html":{"url":"05-Web框架/Django/Django - Django命令整理.html","title":"Django - Django命令整理","keywords":"","body":"Django - Django命令整理 介绍 🍀 django-admin是用于管理Django的命令行工具集 , 此外在每个Django项目中会自动为我们生成一个manage.py , 它与django-admin相同 , 但是会帮我们处理以下几件事情 : 它将为你的项目包添加环境变量 它用于设置DJANGO_SETTINGS_MODULE环境变量 , 因此它指向项目的settings.py文件 在我们编写项目时 , 通常使用manage.py会比django-admin方便些 , 但是如果我们需要在多个Django项目的settings文件中切换 , 可以使用django-admin加上DJANGO_SETTINGS_MODULE或者--settings参数 用法 $ django-admin [options] $ manage.py [options] $ python -m django [options] 对于以上三种方式的命令格式 , 其command与options都是一致的 , 哪一种格式都能达到我们的要求 , 通常我们使用manage.py格式是最多的 , 所以下面就以manage.py为示例了 $ python manage.py [options] 后续省略开头的python进行示例 基础命令 🍀 # 显示使用信息和每个应用的命令列表 $ manage.py help # 显示包含所有可用命令的列表 $ manage.py help --comands # 显示某一个命令的描述及可用的命令列表 $ manage.py help # 获取django版本 $ manage.py version # 创建Django项目 $ django-admin startproject name [directory] # 运行所有已安装的测试程序 $ manage.py test # 启动本地Web服务器 $ manage.py runserver [addrport] # 将迁移添加到migrations目录 $ manage.py makemigrations # 迁移数据库 $ manage.py migrate # 进行数据迁移并返回所执行的SQL语句 $ manage.py sqlmigrate # 刷新数据库 $ manage.py flush # 检查项目中的任何问题,而不进行迁移和访问数据库 $ manage.py check [app_label [app_label ...]] # 创建缓存表 $ manage.py createcachetable # 运行ENGINE设置中指定的数据库引擎命令行客户端 $ manage.py dbshell # 显示当前setting文件与Django默认settings文件之间的差异 $ manage.py diffsettings # 显示结果中\"###\"表示默认设置中没有定义的设置 # 发送测试电子邮件 $ manage.py sendtestemial [email] [email ...]] # 启动Python交互式解释器 $ manage.py shell -i {ipython,bpython,python} # 创建应用 $ manage.py startapp name [directory] # 创建超级用户 $ manage.py createsuperuser # 指定控制台打印的通知和调试信息量,以migrate为例 $ manage.py migrate --verbosity 2 # --verbosity {0,1,2,3}, -v {0,1,2,3} ''' 0,无输出 1,正常输出(默认) 2,详细输出 3,非常详细输出 ''' 代码执行命令 🍀 # 不带参数 from django.core import management from django.core.management.commands import loaddata management.call_command('flush', verbosity=0, interactive=False) management.call_command('loaddata', 'test_data', verbosity=0) management.call_command(loaddata.Command(), 'test_data', verbosity=0) # 带参数 # Similar to the command line management.call_command('dumpdata', '--natural-foreign') # Named argument similar to the command line minus the initial dashes and # with internal dashes replaced by underscores management.call_command('dumpdata', natural_foreign=True) # `use_natural_foreign_keys` is the option destination variable management.call_command('dumpdata', use_natural_foreign_keys=True) 更多详细内容 : django-admin and manage.py "},"05-Web框架/Django-Rest-Framework/":{"url":"05-Web框架/Django-Rest-Framework/","title":"Django-Rest-Framework","keywords":"","body":"Django Rest Framework 教程 本教程是一个以官方文档为模板的中文教程 , 但在内容上会增加一些注释已经说明 , 帮助您简单的完成 django-rest-framework 的学习 官网 : http://www.django-rest-framework.org/ "},"05-Web框架/Django-Rest-Framework/Quickstart.html":{"url":"05-Web框架/Django-Rest-Framework/Quickstart.html","title":"Quickstart","keywords":"","body":"快速开始 我们将创建一个简单的API , 允许管理员用户查看和编辑系统中的用户和组 创建项目 🍀 # 创建项目目录 mkdir tutorial cd tutorial # 创建虚拟环境 virtualenv env source env/bin/activate # Windows上使用`env\\Scripts\\activate` # 安装Django和Django REST framework into the virtualenv pip install django pip install djangorestframework # 创建Django项目和应用 django-admin.py startproject tutorial . # Note the trailing '.' character cd tutorial django-admin.py startapp quickstart cd .. 该项目目录如下 : $ pwd /tutorial $ find . . ./manage.py ./tutorial ./tutorial/__init__.py ./tutorial/quickstart ./tutorial/quickstart/__init__.py ./tutorial/quickstart/admin.py ./tutorial/quickstart/apps.py ./tutorial/quickstart/migrations ./tutorial/quickstart/migrations/__init__.py ./tutorial/quickstart/models.py ./tutorial/quickstart/tests.py ./tutorial/quickstart/views.py ./tutorial/settings.py ./tutorial/urls.py ./tutorial/wsgi.py 同步数据库 python manage.py migrate 模型 🍀 我们使用Django默认的两个模型 , 用户(User)和组 (Group) , 你可以使用 Admin 来进行管理 创建两个超级用户 python manage.py createsuperuser --emaill Lyon@example.com --username Lyon python manage.py createsuperuser --emaill Kenneth@example.com --username Kenneth 序列化器 🍀 我们需要定制一些序列化器来决定我们数据的表现形式 在 quickstart 应用下新建 serializers.py : from django.contrib.auth.models import User, Group from rest_framework import serializers class UserSerializer(serializers.HyperlinkedModelSerializer): \"\"\" 用户序列化器 \"\"\" class Meta: model = User fields = ('url', 'username', 'email', 'groups') class GroupSerializer(serializers.HyperlinkedModelSerializer): \"\"\" 组序列化器 \"\"\" class Meta: model = Group fields = ('url', 'name') 这里使用超链接模型序列化器 , 因为超链接是非常好的RESTful设计 , 当然你也可以使用其他的序列化器 视图 🍀 tutorial/quickstart/views.py from django.contrib.auth.models import User, Group from rest_framework import viewsets from quickstart.serializers import UserSerializer, GroupSerializer class UserViewSet(viewsets.ModelViewSet): \"\"\" 允许查看或编辑用户的API \"\"\" queryset = User.objects.all().order_by('-date_joined') serializer_class = UserSerializer class GroupViewSet(viewsets.ModelViewSet): \"\"\" 允许查看或编辑组的API \"\"\" queryset = Group.objects.all() serializer_class = GroupSerializer 路由 🍀 tutorial/urls.py from django.conf.urls import url, include from rest_framework import routers from quickstart import views # 因为使用的是viewsets,所以使用路由器进行注册 router = routers.DefaultRouter() router.register(r'users', views.UserViewSet) router.register(r'groups', views.GroupViewSet) urlpatterns = [ url(r'^', include(router.urls)), # rest_framework自带的url,login与logout: # - url(r'^login/$', login, login_kwargs, name='login'), # - url(r'^logout/$', logout, name='logout'), url(r'^api-auth/', include('rest_framework.urls', namespace='rest_framework')) ] 配置 🍀 在 tutorial/settings.py 的 INSTALLED_APPS 中 , 添加 rest_framework INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'quickstart', 'rest_framework', # 此处为添加项 ] 测试API 🍀 首先我们运行我们的项目程序 , 随后使用浏览器访问项目服务器地址 , 或者使用命令行工具 , 如 : httpie 等 查看我们的API , http://127.0.0.1:8000/ , 结果如下 : 随后我们可以通过API来获取用户数据 , 访问 http://127.0.0.1:8000/users/ , 结果如下 : 到这里 , django-rest-framework的简单使用就结束了 , 后续内容请看下一篇 "},"05-Web框架/Django-Rest-Framework/Tutorial 1 Serialization.html":{"url":"05-Web框架/Django-Rest-Framework/Tutorial 1 Serialization.html","title":"Tutorial 1 Serialization","keywords":"","body":"Tutorial 1: Serialization 介绍 🍀 本教程将会通过一些简单的代码来实现 Web API. 这个过程将会介绍 REST framework 的各个组件, 带你深入理解各个组件是如何一起工作 创建一个新的环境 🍀 为了确保我们的包配置与我们正在进行的其他项目保持良好的隔离 , 我们将使用 virtualenv 来创建一个新的虚拟环境 virtualenv env source env/bin/activate 在新的虚拟环境中安装 django 与 django rest framework pip install django pip install djangorestframework pip install pygments # 我们将使用这个模块来提高代码高亮 友情链接 : virtualenv , pygments 开始 🍀 首先我们创建一个新的项目 cd ~ django-admin.py startproject tutorial cd tutorial 创建应用 snippets python manage.py startapp snippets 配置应用 INSTALLED_APPS = [ ... 'rest_framework', 'snippets.apps.SnippetsConfig', ] 创建一个Model 🍀 我们首先创建一个简单的模型 from django.db import models from pygments.lexers import get_all_lexers from pygments.styles import get_all_styles # get_all_lexers() 返回所有的词法分析器 LEXERS = [item for item in get_all_lexers() if item[1]] # 语言类别 LANGUAGE_CHOICES = sorted([(item[1][0], item[0]) for item in LEXERS]) # get_all_styles() 返回所有样式的名称 STYLE_CHOICES = sorted((item, item) for item in get_all_styles()) class Snippet(models.Model): created = models.DateTimeField(auto_now_add=True) title = models.CharField(max_length=100, blank=True, default='') code = models.TextField() linenos = models.BooleanField(default=False) language = models.CharField(choices=LANGUAGE_CHOICES, default='python', max_length=100) style = models.CharField(choices=STYLE_CHOICES, default='friendly', max_length=100) class Meta: ordering = ('created',) 我们还需要为我们的代码片段模型创建一个初始迁移 , 并第一次同步数据库 python manage.py makemigrations snippets python manage.py migrate 创建一个序列化类 🍀 我们在Web API上首先需要做的一件事是提供一种将 Snippet 实例序列化和反序列化的方法 , 使之成为诸如json之类的表示形式的方式 我们可以通过声明与Django的表单非常相似的序列化器 (serializer) 来做到这一点 在 snippets 目录中创建 serializers.py , 内容如下 : from rest_framework import serializers from snippets.models import Snippet, LANGUAGE_CHOICES, STYLE_CHOICES class SnippetSerializer(serializers.Serializer): id = serializers.IntegerField(read_only=True) title = serializers.CharField(required=False, allow_blank=True, max_length=100) code = serializers.CharField(style={'base_template': 'textarea.html'}) linenos = serializers.BooleanField(required=False) language = serializers.ChoiceField(choices=LANGUAGE_CHOICES, default='python') style = serializers.ChoiceField(choices=STYLE_CHOICES, default='friendly') def create(self, validated_data): \"\"\" 根据已验证的数据,创建并返回一个新的 Snippet 实例 \"\"\" return Snippet.objects.create(**validated_data) def update(self, instance, validated_data): \"\"\" 根据已验证的数据,更新并返回一个新 Snippet 实例 \"\"\" instance.title = validated_data.get('title', instance.title) instance.code = validated_data.get('code', instance.code) instance.linenos = validated_data.get('linenos', instance.linenos) instance.language = validated_data.get('language', instance.language) instance.style = validated_data.get('style', instance.style) instance.save() return instance 序列化器类分为两个部分 : 第一部分定义了序列化/反序列化的字段 第二部分 create() 和 update() 方法定义了当调用 serializer.save() 时如何创建或修改实例 序列化器类与Django Form类非常相似 , 并且在各个字段中包含相似的验证标志 , 例如 required , max_length , default 等 另外 , 在某些情况下字段标志还可以控制序列化器如何显示 , 比如渲染到HTML时 , {'base_template': 'textarea.html'} 等同于Django Form 类中的 widget=widgets.Textarea , 这对于控制如何显示可浏览的API特别有用 , 我们将在后面的教程中看到 我们还可以通过使用 ModelSerializer (相当于ModelForm) 类来节省一些时间 , 稍后我们将会看到 , 但是现在我们将显式的定义序列化器 使用序列化器 🍀 在我们进一步讨论之前 , 我们将熟悉使用新的序列化器类 , 让我们先进入 Django shell python manage.py shell 那么接下来我们将在 shell 中创建几个 Snippet 实例一起工作 # 导入相关依赖 from snippets.models import Snippet from snippets.serializers import SnippetSerializer from rest_framework.renderers import JSONRenderer from rest_framework.parsers import JSONParser snippet = Snippet(code='foo = \"bar\"\\n') snippet.save() snippet = Snippet(code='print \"hello, world\"\\n') snippet.save() 现在我们已经有一些实例了 , 让我们看一看如何将实例序列化 注 : Model → Serialiezer serializer = SnippetSerializer(snippet) serializer.data # {'id': 2, 'title': '', 'code': 'print \"hello, world\"\\n', 'linenos': False, 'language': 'python', 'style': 'friendly'} 现在我们将模型实例 (model instance) 转化成Python原生数据类型 , 为了完成实例化过程 , 我们将数据渲染成 json 注 : Serialiezer → JSON content = JSONRenderer().render(serializer.data) content # '{\"id\":2,\"title\":\"\",\"code\":\"print \\\\\"hello, world\\\\\"\\\\n\",\"linenos\":false,\"language\":\"python\",\"style\":\"friendly\"}' 反序列化是相似的 , 首先我们将流 (stream) 解析成Python原生数据类型… from django.utils.six import BytesIO stream = BytesIO(content) data = JSONParser().parse(stream) 然后, 我们将Python原生数据恢复成正常的对象实例 注 : JSON → Serialiezer serializer = SnippetSerializer(data=data) serializer.is_valid() # True serializer.validated_data # OrderedDict([('title', ''), ('code', 'print \"hello, world\"\\n'), ('linenos', False), ('language', 'python'), ('style', 'friendly')]) serializer.save() # 请注意 , API和表单很相似 . 当我们用我们的序列器 (serializer) 写视图的时候 , 相似性会更明显. 除了将模型模型实例 (model instance) 序列化外 , 我们也能序列化查询集 (querysets) , 只需要添加一个序列化参数 many=True serializer = SnippetSerializer(Snippet.objects.all(), many=True) serializer.data # [OrderedDict([('id', 1), ('title', u''), ('code', u'foo = \"bar\"\\n'), ('linenos', False), ('language', 'python'), ('style', 'friendly')]), OrderedDict([('id', 2), ('title', u''), ('code', u'print \"hello, world\"\\n'), ('linenos', False), ('language', 'python'), ('style', 'friendly')]), OrderedDict([('id', 3), ('title', u''), ('code', u'print \"hello, world\"'), ('linenos', False), ('language', 'python'), ('style', 'friendly')])] 使用ModelSerializers 🍀 我们的 SnippetSerializer 类复制了 Snippet 模型中的许多信息 , 如果我们能让代码更简洁一些 , 那就太好了 就像Django提供了 Form 类和 ModelForm 类一样 , REST 框架也有 Serializer 类和 ModelSerializer 类 让我们使用 ModelSerializer 类重构我们的序列化器 class SnippetSerializer(serializers.ModelSerializer): class Meta: model = Snippet fields = ('id', 'title', 'code', 'linenos', 'language', 'style') 序列化器有一个很好的特性 , 就是你可以通过打印序列实例的结构 (representation) 查看它的所有字段 . 输入 python manage.py shell 打开Django shell , 尝试如下代码 : from snippets.serializers import SnippetSerializer serializer = SnippetSerializer() print(repr(serializer)) # SnippetSerializer(): # id = IntegerField(label='ID', read_only=True) # title = CharField(allow_blank=True, max_length=100, required=False) # code = CharField(style={'base_template': 'textarea.html'}) # linenos = BooleanField(required=False) # language = ChoiceField(choices=[('Clipper', 'FoxPro'), ('Cucumber', 'Gherkin'), ('RobotFramework', 'RobotFramework'), ('abap', 'ABAP'), ('ada', 'Ada')... # style = ChoiceField(choices=[('autumn', 'autumn'), ('borland', 'borland'), ('bw', 'bw'), ('colorful', 'colorful')... 要记住 , ModelSerializer 类没有做任何神奇的事情 , 它们只是创建序列化器类的快捷方式 : 一组自动确定的字段 简单默认实现的 create() 和 update() 方法 用序列化器写常规的Django视图 🍀 让我们看看如何使用我们的序列化器类来编写一些API视图 , 目前 , 我们不会使用REST框架的其他特性 , 只是写一些常规的Django视图 编辑 snippets/views.py : from django.http import HttpResponse, JsonResponse from django.views.decorators.csrf import csrf_exempt from rest_framework.renderers import JSONRenderer from rest_framework.parsers import JSONParser from snippets.models import Snippet from snippets.serializers import SnippetSerializer 我们的根API将会是一个视图 , 它支持列出所有现有的 snippets , 或者创建一个新的 snippets @csrf_exempt def snippet_list(request): \"\"\" 列出所有的 snippets,或者创建一个新的 snippet. \"\"\" if request.method == 'GET': snippets = Snippet.objects.all() serializer = SnippetSerializer(snippets, many=True) return JsonResponse(serializer.data, safe=False) elif request.method == 'POST': data = JSONParser().parse(request) serializer = SnippetSerializer(data=data) if serializer.is_valid(): serializer.save() return JsonResponse(serializer.data, status=201) return JsonResponse(serializer.errors, status=400) 注意 , 因为我们希望能够从没有CSRF令牌的客户端 POST 数据到这个视图 , 所以我们需要将视图标记为 csrf_exempt , 通常我们是不会这样做 , REST 框架视图使用了比这更合理的方式 , 不过那不是我们现在的目的 我们还需要一个视图对应单个 snippet , 并且我们可以使用这个视图进行检索 , 更新或删除 snippet @csrf_exempt def snippet_detail(request, pk): \"\"\" 检索、更新或删除 snippet. \"\"\" try: snippet = Snippet.objects.get(pk=pk) except Snippet.DoesNotExist: return HttpResponse(status=404) if request.method == 'GET': serializer = SnippetSerializer(snippet) return JsonResponse(serializer.data) elif request.method == 'PUT': data = JSONParser().parse(request) serializer = SnippetSerializer(snippet, data=data) if serializer.is_valid(): serializer.save() return JsonResponse(serializer.data) return JsonResponse(serializer.errors, status=400) elif request.method == 'DELETE': snippet.delete() return HttpResponse(status=204) 最后 , 我们需要使用路由将这些视图对应起来 , 创建 snippets/urls.py 文件 from django.conf.urls import url from snippets import views urlpatterns = [ url(r'^snippets/$', views.snippet_list), url(r'^snippets/(?P[0-9]+)/$', views.snippet_detail), ] 同时需要配置 tutorial/urls.py , 添加我们的 snippet 应用的 URLs from django.conf.urls import url, include urlpatterns = [ url(r'^', include('snippets.urls')), ] 值得注意的是 , 我们目前还有一些边界情况没有进行处理 , 如果我们发送错误的 json 数据 , 或者一个请求是用一个视图无法处理的方法进行的 , 那么我们将得到一个500的错误 , “Server Error” 测试我们的API 🍀 首先退出 shell quit() 随后启动Django开发服务器 python manage.py runserver Validating models... 0 errors found Django version 1.11, using settings 'tutorial.settings' Development server is running at http://127.0.0.1:8000/ Quit the server with CONTROL-C. 在另一个终端窗口中 , 我们可以来测试这个服务器 我们可以使用 curl , 或者 httpie , Httpie 是一个使用Python编写的对用户友好的http客户端 , 让我们安装它 (虽然上一章节中已经说明过) pip install httpie 我们可以获取 snippets 列表 http http://127.0.0.1:8000/snippets/ HTTP/1.0 200 OK ... [ { \"code\": \"foo = \\\"bar\\\"\\n\", \"id\": 1, \"language\": \"python\", \"linenos\": false, \"style\": \"friendly\", \"title\": \"\" }, { \"code\": \"print \\\"hello, world\\\"\\n\", \"id\": 2, \"language\": \"python\", \"linenos\": false, \"style\": \"friendly\", \"title\": \"\" }, ] 我们也可以指定 id 获取响应 snippet http http://127.0.0.1:8000/snippets/2/ HTTP/1.0 200 OK ... { \"code\": \"print \\\"hello, world\\\"\\n\", \"id\": 2, \"language\": \"python\", \"linenos\": false, \"style\": \"friendly\", \"title\": \"\" } 类似地 , 我们也可以使用浏览器访问获得相同的 json 数据 到目前为止 , 我们做得很好 , 我们编写的序列化 API 和 Django's Forms API 比较相似 , 同时编写了一些常规的Django视图. 我们的 API 没有做什么特殊的事情 , 除了作出json响应外 , 还有一些边缘事件没有处理 , 但至少是一个还有点功能的 Web API. 在教程的第2部分 , 我们将介绍如何对我们的 API 进行改进. "},"05-Web框架/Django-Rest-Framework/Tutorial 2 Requests and Responses.html":{"url":"05-Web框架/Django-Rest-Framework/Tutorial 2 Requests and Responses.html","title":"Tutorial 2 Requests and Responses","keywords":"","body":"Tutorial 2: Requests and Responses 从这节开始, 我们会接触到 REST 框架的核心. 让我们介绍一些基本构建组件 Request对象 🍀 REST framework 引入了一个 Request 对象 , 它扩展了常规的 HttpRequest , 并提供了灵活的请求解析 . Request 对象的核心功能是 request.data 属性 , 它和 request.POST 属性很相似 , 但是它对 Web APIs 更加有用 request.POST # 只处理表单数据,仅用于 'POST' 方法. request.data # 处理任意数据,可以用于 'POST', 'PUT' 和 'PATCH' 方法. Response对象 🍀 REST framework 也引入了 Response 对象 , 它是一类用为渲染和使用内容协商来决定返回给客户端的正确内容类型的 TemplateResponse return Response(data) # 按照客户的需求类型来渲染内容 状态码 🍀 在视图中使用HTTP状态码并不总是易读的 , 错误代码很容易被忽略 . REST framework 为每一个状态码提供了更明确的标识符，例如状态模块中的 HTTP_400_BAD_REQUEST , 使用这些标识符代替纯数字标识符是一个不错的注意 装饰API视图 🍀 REST framework 提供了两个装饰器来编写API视图 @api_view , 用于 FBV (function based view) APIView , 用于 CBV (class-based view) 这些装饰器提供了一些功能 , 例如确保从你的视图中获取 Request 对象 , 以及在 Response 对象中添加上下文 同时还提供一些行为 , 例如在合适的时候返回 405 Method Not Allowed 响应 , 例如处理在访问错误输入的 request.data 时出现的 ParseError 异常 协同工作 🍀 好了 , 让我们开始使用这些新组件来写一些视图吧 在 views.py 中我们不再需要 JSONResponse 类 , 现在删除它们 , 我们可以轻微地重构我们的视图 from rest_framework import status from rest_framework.decorators import api_view from rest_framework.response import Response from snippets.models import Snippet from snippets.serializers import SnippetSerializer @api_view(['GET', 'POST']) def snippet_list(request): \"\"\" 列出所有的 snippets,或者创建一个新的 snippet. \"\"\" if request.method == 'GET': snippets = Snippet.objects.all() serializer = SnippetSerializer(snippets, many=True) return Response(serializer.data) elif request.method == 'POST': serializer = SnippetSerializer(data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data, status=status.HTTP_201_CREATED) return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) 我们的实例视图是前面的修改版 , 更简洁 , 和我们使用的 Form API 很相似 , 同时使用了命名状态码 , 让响应代码意义更明显 下面是 views.py 中单个 snippet 的视图 @api_view(['GET', 'PUT', 'DELETE']) def snippet_detail(request, pk): \"\"\" 检索、更新或删除 snippet. \"\"\" try: snippet = Snippet.objects.get(pk=pk) except Snippet.DoesNotExist: return Response(status=status.HTTP_404_NOT_FOUND) if request.method == 'GET': serializer = SnippetSerializer(snippet) return Response(serializer.data) elif request.method == 'PUT': serializer = SnippetSerializer(snippet, data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data) return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) elif request.method == 'DELETE': snippet.delete() return Response(status=status.HTTP_204_NO_CONTENT) 这应该是非常熟悉的 , 与常规的Django视图并没有太多的不同 请注意 , 我们不再明确指定请求或响应的上下文类型 , request.data 可以处理的 json 格式的请求 , 同样也可以处理其他格式 . 同样的 , 我们允许 REST framework 将响应对象的数据渲染成正确的内容类型返回给客户端 在URLs中添加可选格式后缀 🍀 为了充分利用我们的响应不再是单一内容类型的事实 , 我们可以在API尾部添加格式后缀 , 格式后缀为我们提供了一个参考的格式 , 这意味着我们的API将能够处理诸如 http://example.com/api/items/4.json 之类的url 在视图中添加一个 format 关键字参数 , 像这样 def snippet_list(request, format=None): 和 def snippet_detail(request, pk, format=None): 现在更新 snippets/urls.py , 在已经存在的URL中添加一个 format_suffix_patterns 集合 from django.conf.urls import url from rest_framework.urlpatterns import format_suffix_patterns from snippets import views urlpatterns = [ url(r'^snippets/$', views.snippet_list), url(r'^snippets/(?P[0-9]+)$', views.snippet_detail), ] urlpatterns = format_suffix_patterns(urlpatterns) 我们并不需要添加这些额外的url , 但是它为我们提供了一种简单明了的方式来指定特定的格式 进行测试 🍀 继续像我们在教程第1部分中所做的那样 , 通过命令行测试API , 所有的工作都是类似的 , 同时我们可以很好地处无效请求产生的错误 我们可以像之前一样 , 获得 snippets 列表 http http://127.0.0.1:8000/snippets/ HTTP/1.1 200 OK ... [ { \"id\": 1, \"title\": \"\", \"code\": \"foo = \\\"bar\\\"\\n\", \"linenos\": false, \"language\": \"python\", \"style\": \"friendly\" }, { \"id\": 2, \"title\": \"\", \"code\": \"print \\\"hello, world\\\"\\n\", \"linenos\": false, \"language\": \"python\", \"style\": \"friendly\" } ] 我们可以通过使用 Accept 响应头控制返回响应的格式 : http http://127.0.0.1:8000/snippets/ Accept:application/json # Request JSON http http://127.0.0.1:8000/snippets/ Accept:text/html # Request HTML 或者在URL后添加格式后缀 : http http://127.0.0.1:8000/snippets.json # JSON 后缀 http http://127.0.0.1:8000/snippets.api # 可浏览的 API 后缀 同样的 , 我们可以使用 Content-Type 头控制我们请求的格式 # POST using form data http --form POST http://127.0.0.1:8000/snippets/ code=\"print 123\" { \"id\": 3, \"title\": \"\", \"code\": \"print 123\", \"linenos\": false, \"language\": \"python\", \"style\": \"friendly\" } # POST using JSON http --json POST http://127.0.0.1:8000/snippets/ code=\"print 456\" { \"id\": 4, \"title\": \"\", \"code\": \"print 456\", \"linenos\": false, \"language\": \"python\", \"style\": \"friendly\" } 如果你使用 --debug 参数 , 那么你可以看到请求头中的请求类型 使用浏览器打开 http://127.0.0.1:8000/snippets/ 浏览可视化 🍀 由于 API 响应类型是根据客户端的请求进行选择的 , 因此 , 当使用 web 浏览器请求的时候 , 默认会使用 HTML 格式来表示资源 , 这允许 API 返回一个完整的浏览器可视的 HTML 表示 拥有一个浏览器可视化的 API 是非常有用的 , 这会使得开发和使用 API 变的极为简单 , 这也让其他开发者更容易查看和使用你的 API 查看 browsable api 主题获取更更多关于 browsable API 的信息 , 比如 特性 , 定制 下一步 🍀 在教程的第3部分, 我们将开始使用基于类的视图(CBV) , 并介绍如何使用通用的视图来减少代码量 "},"05-Web框架/Django-Rest-Framework/Tutorial 3 Class-based Views.html":{"url":"05-Web框架/Django-Rest-Framework/Tutorial 3 Class-based Views.html","title":"Tutorial 3 Class-based Views","keywords":"","body":"Tutorial 3: Class-based Views 我们也可以使用基于类的视图编写我们的 API , 如我们所见 , 这是一个有利的模式 , 允许我们重用共同的功能 , 使3我们的代码不重复 用基于类的视图重构我们的API 🍀 重构 views.py from snippets.models import Snippet from snippets.serializers import SnippetSerializer from django.http import Http404 from rest_framework.views import APIView from rest_framework.response import Response from rest_framework import status class SnippetList(APIView): \"\"\" 列出所有的 snippets,或者创建一个新的 snippet. \"\"\" def get(self, request, format=None): snippets = Snippet.objects.all() serializer = SnippetSerializer(snippets, many=True) return Response(serializer.data) def post(self, request, format=None): serializer = SnippetSerializer(data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data, status=status.HTTP_201_CREATED) return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) 到目前为止 , 一起都很好 , 它和之前的情况非常类似 , 但我们可以更好的区分不同的 HTTP 方法 , 我们需要继续更新 views.py 中的实例视图 class SnippetDetail(APIView): \"\"\" 检索、更新或删除 snippet. \"\"\" def get_object(self, pk): try: return Snippet.objects.get(pk=pk) except Snippet.DoesNotExist: raise Http404 def get(self, request, pk, format=None): snippet = self.get_object(pk) serializer = SnippetSerializer(snippet) return Response(serializer.data) def put(self, request, pk, format=None): snippet = self.get_object(pk) serializer = SnippetSerializer(snippet, data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data) return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) def delete(self, request, pk, format=None): snippet = self.get_object(pk) snippet.delete() return Response(status=status.HTTP_204_NO_CONTENT) 接下来 , 我们还需要用基于类的视图的方式 , 重构 snippets/urls.py from django.conf.urls import url from rest_framework.urlpatterns import format_suffix_patterns from snippets import views urlpatterns = [ url(r'^snippets/$', views.SnippetList.as_view()), url(r'^snippets/(?P[0-9]+)/$', views.SnippetDetail.as_view()), ] urlpatterns = format_suffix_patterns(urlpatterns) 至此 , 如果你运行你的开发服务器 , 那么一切还是和之前的一样 使用mixins 🍀 使用基于类的视图的一大优势是 , 它允许我们轻松地创建可重用的行为 到目前为止 , 我们所使用的 create/retriev/update/delete 操作和我们所创建的任何模型API视图都是非常相似 , 这些常见的行为是在 REST 框架的 mixin 类中实现的 让我们看看如何使用 mixin 类来编写 views.py 模块 from snippets.models import Snippet from snippets.serializers import SnippetSerializer from rest_framework import mixins from rest_framework import generics class SnippetList(mixins.ListModelMixin, mixins.CreateModelMixin, generics.GenericAPIView): queryset = Snippet.objects.all() serializer_class = SnippetSerializer def get(self, request, *args, **kwargs): return self.list(request, *args, **kwargs) def post(self, request, *args, **kwargs): return self.create(request, *args, **kwargs) 我们将花一点时间来看看这里到底发生了什么 , 我们使用 GenericAPIView 来构建我们的视图 , 并添加 ListModelMixin 和 CreateModelMixin 基类提供了核心功能 , mixin 类提供了.list() 和 .create() , 然后我们绑定 get 和 post 方法到合适的动作, 到目前为止 , 已经变得足够简单 class SnippetDetail(mixins.RetrieveModelMixin, mixins.UpdateModelMixin, mixins.DestroyModelMixin, generics.GenericAPIView): queryset = Snippet.objects.all() serializer_class = SnippetSerializer def get(self, request, *args, **kwargs): return self.retrieve(request, *args, **kwargs) def put(self, request, *args, **kwargs): return self.update(request, *args, **kwargs) def delete(self, request, *args, **kwargs): return self.destroy(request, *args, **kwargs) 类似地 , 我们使用 GenericAPIView 类提供核心功能 , 添加 mixins 提供 .retrieve() , .update() and .destroy() 动作 使用基于generic类的视图 🍀 我们使用 mixin 类使用比之前较少的代码编写视图 , 但我们可以更进一步 , REST framework 提供了一组已经混合的 generics 视图 , 我们可以使用它来进一步缩减 views.py 模块 from snippets.models import Snippet from snippets.serializers import SnippetSerializer from rest_framework import generics class SnippetList(generics.ListCreateAPIView): queryset = Snippet.objects.all() serializer_class = SnippetSerializer class SnippetDetail(generics.RetrieveUpdateDestroyAPIView): queryset = Snippet.objects.all() serializer_class = SnippetSerializer 现在我们的代码已经越来越像Django的使用了 接下来 , 我们将介绍本教程的第4部分 , 我们将了解如何处理 API 的认证和权限 "},"05-Web框架/Django-Rest-Framework/Tutorial 4 Authentication & Permissions.html":{"url":"05-Web框架/Django-Rest-Framework/Tutorial 4 Authentication & Permissions.html","title":"Tutorial 4 Authentication & Permissions","keywords":"","body":"Tutorial 4: Authentication & Permissions 当前 , 我们的 API 没有限制, 谁都可以编辑或删除 snippets , 我们需要一些更高级的行为来确保 : 代码片段总是与创建者联系在一起 只有授权用户才能创建 snippets 只有 snippet 创建者可以更新或者删除它 未授权的请求只有只读权限 添加信息到模型中 🍀 我们需要对我们的 Snippet 模型类做一些修改 , 首先 , 添加两个字段 , 一个用来代表代码片段的创建者 , 另一个用来存储高亮显示的HTML代码 修改 models.py 添加字段到 Snippet 模型中 owner = models.ForeignKey('auth.User', related_name='snippets', on_delete=models.CASCADE) highlighted = models.TextField() 同时 , 我们需要确保 , 模型在保存的时候 , 使用 pyments 代码高亮库填充 highlighted 字段 我们需要额外导入 : from pygments.lexers import get_lexer_by_name from pygments.formatters.html import HtmlFormatter from pygments import highlight 现在我们可以模型类中添加 .save() 方法 : def save(self, *args, **kwargs): \"\"\" 使用 `pygments` 库来创建代码高亮的HTML代替 snippet \"\"\" lexer = get_lexer_by_name(self.language) linenos = 'table' if self.linenos else False options = {'title': self.title} if self.title else {} formatter = HtmlFormatter(style=self.style, linenos=linenos, full=True, **options) self.highlighted = highlight(self.code, lexer, formatter) super(Snippet, self).save(*args, **kwargs) 完成这些工作后 , 我们需要更新数据库表 , 通常我们会创建一个数据库迁移来完成这个任务 , 但是为了本教程的目的 , 我们只需要删除原来的数据库 , 然后重新创建 rm -f db.sqlite3 rm -r snippets/migrations python manage.py makemigrations snippets python manage.py migrate 你需要创建一些不同的用户 , 用来测试 API , 最快的方式是使用 createsuperuser 命令 python manage.py createsuperuser 为我们的模型添加端口 🍀 现在我们已经创建了一些用户 , 我们最好将用户添加到我们的 API , 我们很容易创建一个新的序列 , 在serializers.py 文件中添加 : from django.contrib.auth.models import User class UserSerializer(serializers.ModelSerializer): snippets = serializers.PrimaryKeyRelatedField(many=True, queryset=Snippet.objects.all()) class Meta: model = User fields = ('id', 'username', 'snippets') 因为 snippets 与 User 模型是反向关系 , 使用 ModelSerializer 类 , 默认不会包含它 , 所以我们需要手动为用户序列添加这个字段 我们还需要添加两个视图到 views.py 中 , 我们为用户添加只读视图, 因此我们使用基于视图的一般类 ListAPIView 和 RetrieveAPIView from django.contrib.auth.models import User class UserList(generics.ListAPIView): queryset = User.objects.all() serializer_class = UserSerializer class UserDetail(generics.RetrieveAPIView): queryset = User.objects.all() serializer_class = UserSerializer 确保导入了 UserSerializer 类 from snippets.serializers import UserSerializer 最后我们需要修改 URL 配置 , 添加这些视图到 API 中 , 添加以下内容到 urls.py 中 url(r'^users/$', views.UserList.as_view()), url(r'^users/(?P[0-9]+)/$', views.UserDetail.as_view()), 将Snippets与Users关联 🍀 现在 , 如果我们创建一个 snippet , 我们没法将用户和创建的 snippet 实例联系起来 , 虽然用户不是序列表示的部分 , 但是它代表传入请求的一个属性 我们通过重写 snippet 视图的 .perform_create() 方法来处理这个问题 , 它允许我们修改如何保存实例 , 并且处理传入请求或请求的URL中隐含的任何信息 在 SnippetList 类中 , 添加以下方法 : def perform_create(self, serializer): serializer.save(owner=self.request.user) 现在 , 我们序列的 create() 方法将会传入一个有效请求数据的 owner 字段 更新我们的serializer 🍀 现在 , snippets 和创建他们的用户已经建立了联系 , 更新我们的 SnippetSerializer 来表示用户 , 在 serializers.py 中添加字段 owner = serializers.ReadOnlyField(source='owner.username') PS : 确保你在 Meta 的字段列表中也添加了 owner 这个字段会做一些有趣的事情 , source 参数控制哪个属性被作用于一个字段 , 并且可以指向 serialized 实例上的任何属性 , 它也能像上面一样使用点标记 (.) , 在这种情况下 , 它将遍历给定的属性 , 就像Django的模板语言一样 我们添加的字段是无类型的 ReadOnlyField 类 , 与其他类型字段 , 如 CharField , BooleanField 等相比 , 无类型的 ReadOnlyfField 总是只读的 , 它用于序列化表示 , 但是不能用于数据反序列化时更新模型实例 , 在这里我们也可以使用 CharField(read_only=True) 为视图添加权限 🍀 现在 , snippets 与 users 已经相关联 , 我们希望确保只有经过身份验证的用户才能创建 , 更新和删除 snippets REST framework 中包含了许多权限类 , 我们可以使用这些类来限制谁可以访问给定的视图 , 在这种情况下 , 我们需要 使用IsAuthenticatedOrReadOnly , 它将确保经过身份验证的请求获得读写访问 , 而未经身份验证的请求则只有只读权限 首先 , 在 views.py 中导入如下代码 : from rest_framework import permissions 然后在 SnippetList 和 SnippetDetail 视图类中添加如下属性 permission_classes = (permissions.IsAuthenticatedOrReadOnly,) 在可浏览API中添加登录 🍀 如果你打开浏览器并操控可浏览的API , 你将发现你不再有创建新的 snippets 的权限 , 为了做到这一点 , 我们需要以用户的身份登录 我们可以在我们的项目级别的 URLconf : urls.py 文件中添加一个登录视图 添加入到语句 from django.conf.urls import include 并添加一个包含登录和注销视图的 url urlpatterns += [ url(r'^api-auth/', include('rest_framework.urls')), ] r'^api-auth/' 可以使用你想要的URL 现在 , 如果再次打开浏览器 , 刷新页面 , 你将可以看到一个 Login 链接在页面的右上角 , 现在可以使用已经创建的用户登录 , 创建 snippets 一旦你创建了一些 snippets , 访问 '/user/' 端 , 你会注意到在每个用户的 snippets 字段 , 会显示跟用户有关的 snippets id 对象级别权限 🍀 虽然我们希望所有 snippets 都能被任何人看到 , 但是也要确保只有创建该 snippets 的用户才能更新或删除它 要做到这一点 , 我们需要创建一个用户权限 在 snippets 应用下 , 创建一个新文件 , permissions.py from rest_framework import permissions class IsOwnerOrReadOnly(permissions.BasePermission): \"\"\" 自定义仅允许对象的owners可修改的权限 \"\"\" def has_object_permission(self, request, view, obj): # 读权限允许任何请求, # 因此我们总是允许GET,HEAD或者OPTIONS请求 if request.method in permissions.SAFE_METHODS: return True # 写权限仅允许该snippet对戏那个的所有者,owner return obj.owner == request.user 现在 , 通过编辑 SnipetDetail 视图类中的 permission_classes 属性 ,我们可以添加自定义权限到我们的 snippet 实例端 permission_classes = (permissions.IsAuthenticatedOrReadOnly, IsOwnerOrReadOnly,) 确保导入 IsOwnerOrReadOnly 类 from snippets.permissions import IsOwnerOrReadOnly 现在 , 如果你再使用浏览器 , 你会发现只有你登录与创建 snippets 一致的用户 , 你才有权限使用 DELETE 和 PUT 动作 验证API 🍀 由于现在 API 有权限集合 , 在我们需要编辑任何 snippets 的时候 , 需要认证我们的请求 , 我们没有设置他任何认证类 ( authentication classes ) , 默认情况下只有 SessionAuthentication 和 BasicAuthentication 当我们通过浏览器进行交互时 , 我们可以登录 , 浏览器会话 (session) 将为请求提供认证 如果我们以编程的方式使用API , 我们需要为每个请求提供明确的 认证凭证 如果我们尝试在没有认证的情况下创建 snippet , 我们会获得一个 error http POST http://127.0.0.1:8000/snippets/ code=\"print 123\" { \"detail\": \"Authentication credentials were not provided.\" } 我们可以通过提供之前创建的用户的用户名和密码 , 来创建 snippet http -a admin:password123 POST http://127.0.0.1:8000/snippets/ code=\"print 789\" { \"id\": 1, \"owner\": \"admin\", \"title\": \"foo\", \"code\": \"print 789\", \"linenos\": false, \"language\": \"python\", \"style\": \"friendly\" } 概要 🍀 我们的 API 已经具有一个相当精细的权限集合 , 同时为系统用户和他们创建的 snippets 提供了端点 在教程的第5部分 , 我们将介绍如何为高亮的 snippets 创建一个HTML端点 , 将所有内容联系起来 , 同时为系统中的关系使用超链接提高我们 API 的凝聚力 "},"05-Web框架/Django-Rest-Framework/Tutorial 5 Relationships & Hyperlinked APIs.html":{"url":"05-Web框架/Django-Rest-Framework/Tutorial 5 Relationships & Hyperlinked APIs.html","title":"Tutorial 5 Relationships & Hyperlinked APIs","keywords":"","body":"Tutorial 5: Relationships & Hyperlinked APIs 目前 , 我们的API中的关系是通过使用主键来表示的 . 在本教程的这一部分中 , 我们将改进我们的API的内聚性和可见性 , 通过使用超链接来实现关系 为我们的根API创建一个端点 🍀 现在我们有了 'snippets' 和 'users' 的端点 , 但是没有为我们的API设置单独的入口 . 为了创建一个单独的入口 , 我们将使用一个常规的基于函数的视图以及 @api_view 装饰器创建一个入口端点 . 在文件 snippets/views.py 中添加 : from rest_framework.decorators import api_view from rest_framework.response import Response from rest_framework.reverse import reverse @api_view(['GET']) def api_root(request, format=None): return Response({ 'users': reverse('user-list', request=request, format=format), 'snippets': reverse('snippet-list', request=request, format=format) }) 在这里我们需要注意两点 , 首先我们使用 REST framework 的 reverse 方法限定返回的 URLs , 其次 , URL 格式使用方便的名字作为标识符 , 稍后会在 snippets/urls.py 中声明 创建一个高亮的snippets断点 🍀 还有一个明显的事情就是我们的 pastebin API 缺乏代码高亮的端点 与我们其他的API端点不同 , 我们不想使用 JSON , 而只使用 HTML 显示 . REST framework 提供了两种渲染方式 , 一种是用模板渲染 , 另一种是用预渲染 HTML , 在这个端点 , 我们使用第二种渲染方式 另一个需要我们思考的是 , 在创建高亮代码视图的时候 , 高亮视图在通用视图中是不存在的 , 我们不会返回一个对象实例 , 而是返回对象的一个属性 我们不使用 generic 视图 , 而是通过基础类 , 在 snippets/views.py 中创建我们自己的 .get() 方法 from rest_framework import renderers from rest_framework.response import Response class SnippetHighlight(generics.GenericAPIView): queryset = Snippet.objects.all() renderer_classes = (renderers.StaticHTMLRenderer,) def get(self, request, *args, **kwargs): snippet = self.get_object() return Response(snippet.highlighted) 像往常一样 , 我们需要添加新的视图到 URL 配置中 , 文件snippets/urls.py url(r'^$', views.api_root), 然后为高亮 snippet 添加一个url样式 url(r'^snippets/(?P[0-9]+)/highlight/$', views.SnippetHighlight.as_view()), 为我们的API添加超链接 🍀 在Web API设计中 , 处理实体之间的关系是一项非常有挑战的事情 , 代表一种关系可以有很多种方式 使用主键 在实体间使用超链接 在相关的实体上使用唯一的 slug 字段 使用相关实体的默认字符串 在父表示中使用嵌套的实体 其他自定义的表示 REST framework 支持以上所有的方式 , 正向或反向关系均可以使用 , 或者像使用一般外键一样使用自定义的管理方式 在这种情况下 , 我们在实体间使用超链接方法 , 为了达到目的 , 我们将修改我们的序列 ( serializers ) , 扩展 HyperlinkedModelSerializer 代替 ModelSerializer HyperlinkedModelSerializer 和 ModelSerializer 有以下几点不同 : 默认不包含 id 字段 它包含一个 url 字段 , 使用 HyperlinkedIdentityField 关系使用 HyperlinkedRelatedField 代替 PrimaryKeyRelatedField 我们可以快速的将存在的序列重写成超链接的方式 , 文件 snippets/serializers.py class SnippetSerializer(serializers.HyperlinkedModelSerializer): owner = serializers.ReadOnlyField(source='owner.username') highlight = serializers.HyperlinkedIdentityField(view_name='snippet-highlight', format='html') class Meta: model = Snippet fields = ('url', 'id', 'highlight', 'owner', 'title', 'code', 'linenos', 'language', 'style') class UserSerializer(serializers.HyperlinkedModelSerializer): snippets = serializers.HyperlinkedRelatedField(many=True, view_name='snippet-detail', read_only=True) class Meta: model = User fields = ('url', 'id', 'username', 'snippets') 注意 , 我们还新添加了一个 'highlighted' 字段 , 这个字段的类型和 url 字段类型一致 , 只是它指向 'snippet-highlight' 端点 , 而不是 'snippet-detail' 因为我们已经配置了 URLs 后缀 , 比如 '.json' , 同时我们需要在 highlight 字段中指明后缀 , .html 确保我们的URL模式均已命名 🍀 如果我们要使用超链接 API , 我们必须确保对 URL 模型进行命名 , 让我们看看哪些链接需要命名 : 根API指向 user-list 和 snippet-list snippet 序列包含一个指向 snippet-highlight 字段 user 序列包含一个指向 snippet-detail 字段 我们的 snippet 和 user 序列包含 'url' 字段默认指向 '{model_name}-detail' , 当前情况指向 'snippet-detail' 和 'user-detail' 命名加入 URL 配置之后 , snippets/urls.py 应该是下面这样子 : from django.conf.urls import url, include from rest_framework.urlpatterns import format_suffix_patterns from snippets import views # API endpoints urlpatterns = format_suffix_patterns([ url(r'^$', views.api_root), url(r'^snippets/$', views.SnippetList.as_view(), name='snippet-list'), url(r'^snippets/(?P[0-9]+)/$', views.SnippetDetail.as_view(), name='snippet-detail'), url(r'^snippets/(?P[0-9]+)/highlight/$', views.SnippetHighlight.as_view(), name='snippet-highlight'), url(r'^users/$', views.UserList.as_view(), name='user-list'), url(r'^users/(?P[0-9]+)/$', views.UserDetail.as_view(), name='user-detail') ]) 添加分页 🍀 users 和 snippets 的列表视图可能会返回大量的实例 , 所以我们要对返回的结果进行分页 , 并允许客户端访问每个页面 我们可以改变默认的列表样式来使用分页 , 在 tutorial/settings.py 文件 , 添加如下配置 REST_FRAMEWORK = { 'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination', 'PAGE_SIZE': 10 } REST framework 的所有设置都是在 settings 中 REST_FRAMEWORK 字典中的 , 它可以帮我们区分项目中的其他配置 同时 , 我们也可以自定义分页的样式 , 在这里 , 我们使用默认方式 浏览API 🍀 如果我们打开浏览器 , 并访问可浏览的 API , 你会发现你可以使用下面的链接使用 API 你也可以看到 snippet 实例的 'highlight' 链接 , 这些链接会返回高亮的 HTML 代码 在教程的第6部分 , 我们会介绍怎么使用 ViewSets 和 Routers 通过更少的代码 , 实现我们的 API "},"05-Web框架/Django-Rest-Framework/Tutorial 6 ViewSets & Routers.html":{"url":"05-Web框架/Django-Rest-Framework/Tutorial 6 ViewSets & Routers.html","title":"Tutorial 6 ViewSets & Routers","keywords":"","body":"Tutorial 6: ViewSets & Routers REST framework 中有一个 ViewSets 的抽象 , 它可以让开发者将精力集中在API的状态和交互上 , 同时帮助开发者 , 基于共同约定 , 自动处理 URL 构建 ViewSet 类几乎和 View 类一样 , 除了它提供的 read 或者 update 操作 , 而不是像 get 或 put 一样的方法 一个 ViewSet 类在它被实例化成一个视图集合的最后时刻 , 通过一个处理复杂 URL 配置的 Router 类绑定 , 且只绑定一个方法集合 使用ViewSets重构 🍀 首先使用单个 UserViewSet 视图重构 UserList 和 UserDetail 视图 文件 snippets/views.py from rest_framework import viewsets class UserViewSet(viewsets.ReadOnlyModelViewSet): \"\"\" 该viewset自动提供 list 和 detail 功能 \"\"\" queryset = User.objects.all() serializer_class = UserSerializer 这里我们使用 ReadOnlyModelViewSet 类自动提供默认的 'read-only' 操作 . 我们需要像使用常规视图一样 , 设置 queryset 和 serializer_class 属性 , 但是我们不再需要为两个分开的类提供相同的信息 接下来替换 SnippetList , SnippetDetail 和 SnippetHighlight 视图类 from rest_framework.decorators import detail_route from rest_framework.response import Response class SnippetViewSet(viewsets.ModelViewSet): \"\"\" 这个viewset自动提供 list,create,retrieve,update,destroy功能 此外,我们还提供了一个额外的\"高亮显示\"功能 \"\"\" queryset = Snippet.objects.all() serializer_class = SnippetSerializer permission_classes = (permissions.IsAuthenticatedOrReadOnly, IsOwnerOrReadOnly,) @detail_route(renderer_classes=[renderers.StaticHTMLRenderer]) def highlight(self, request, *args, **kwargs): snippet = self.get_object() return Response(snippet.highlighted) def perform_create(self, serializer): serializer.save(owner=self.request.user) 这一次我们使用了 ModelViewSet 类获得默认的完整的读写操作 注意 , 我们同时使用了 @detail_route 装饰器 , 用于创建一个自定义动作 , 即 highlight , 这个装饰器可以用于添加任何不适合 create/update/delete 方式的自定义端点 使用@detail_route 装饰器自定义的动作默认会响应 GET 请求 , 如果我们需要响应 POST 请求 , 我们可以使用 methods 参数 自定义动作的默认 URLs 取决于它们的名字 , 如果你想改变 url 构建方法 , 你可以在使用装饰器的时候传入 url_path 关键字参数 将ViewSets绑定到URLs 🍀 视图的处理方法仅会按照我们的 URL conf 对相应方法进行绑定 , 现在我们为我们为您的 ViewSets 显示地创建一个视图集合 , 来看看发生了什么 snippets/urls.py 文件 , 我们绑定我们的 ViewSet 类到一组具体的视图 from snippets.views import SnippetViewSet, UserViewSet, api_root from rest_framework import renderers snippet_list = SnippetViewSet.as_view({ 'get': 'list', 'post': 'create' }) snippet_detail = SnippetViewSet.as_view({ 'get': 'retrieve', 'put': 'update', 'patch': 'partial_update', 'delete': 'destroy' }) snippet_highlight = SnippetViewSet.as_view({ 'get': 'highlight' }, renderer_classes=[renderers.StaticHTMLRenderer]) user_list = UserViewSet.as_view({ 'get': 'list' }) user_detail = UserViewSet.as_view({ 'get': 'retrieve' }) 注意我们如何从每个 ViewSet 类 , 通过绑定 http 方法到响应的动作来创建多个视图 现在 , 我们将我们的资源绑定到了具体的视图 , 我们可以像往常一样将我们的视图注册到 url 配置中 urlpatterns = format_suffix_patterns([ url(r'^$', api_root), url(r'^snippets/$', snippet_list, name='snippet-list'), url(r'^snippets/(?P[0-9]+)/$', snippet_detail, name='snippet-detail'), url(r'^snippets/(?P[0-9]+)/highlight/$', snippet_highlight, name='snippet-highlight'), url(r'^users/$', user_list, name='user-list'), url(r'^users/(?P[0-9]+)/$', user_detail, name='user-detail') ]) 使用Routers 🍀 因为我们使用 ViewSet 代替 View , 实际上我们不需要自己设计 URL 配置 , 我们可以通过 Router 类 , 将资源 (resources) , 视图 (views) , urls自动联系起来 , 我们只需要使用 Router 类注册合适的视图集合 重写 snippets/urls.py from django.conf.urls import url, include from rest_framework.routers import DefaultRouter from snippets import views # 创建路由器并注册视图 router = DefaultRouter() router.register(r'snippets', views.SnippetViewSet) router.register(r'users', views.UserViewSet) # API URLs 由路由器自动确定 urlpatterns = [ url(r'^', include(router.urls)) ] 使用 router 注册的视图集合提供一个 urlpattern , 包括两个参数 - 视图的 URL 前缀和视图集合本身 我们使用默认 DefaultRouter 类也会自动为我们创建API根视图 , 现在我们可以从 views 模块中删除 api_root 方法 权衡使用views和viewsets 🍀 viewsets 是一个非常有用的抽象 , 它可以确保 URL 原型和你的 API 保持一致 , 最大限度的减少代码量 , 允许你将精力放在 API 的交互和表示上 , 而不是放在编写 URL conf 上 这并不意味在所有地方都要使用 viewsets , 在使用基于类的视图和基于函数的视图时 , 需要进行权衡 , 使用 viewsets 没有单独构建 views 明确 在教程第7部分, 我们将介绍 , 如何添加一个 APP schema , 并使用客户端库或命令行工具与我们的 API进行交互 "},"05-Web框架/Django-Rest-Framework/Tutorial 7 Schemas & client libraries.html":{"url":"05-Web框架/Django-Rest-Framework/Tutorial 7 Schemas & client libraries.html","title":"Tutorial 7 Schemas & client libraries","keywords":"","body":"Tutorial 7: Schemas & client libraries schema 是一种机器可读的文档 , 用于描述可用的API端点 , URLS , 以及他们支持的操作 schema 可以用于自动生成文档 , 也可以用于驱动可以与API交互的动态客户端库 Core API 🍀 为了提供 schema 支持, REST 框架使用 Core API Core API 是用于描述 APIs 的文档规范 . 它可以用来提供内部可用端点内部表示格式和API暴露的可能的交互 . 它可以用于服务端或客户端 当用于服务端时 , Core API 允许API支持呈现 schema 或渲染超媒体格式 当用于客户端 , Core API 允许动态驱动的客户端库与任何支持 schema 或超媒体格式的 API 交互 添加一个schema 🍀 REST framework 支持明确定义的 schema 视图 , 或自动生成的 schemas. 由于我们使用 ViewSets 和Routers , 我们可以很简单的自动生成 schema 你需要安装 coreapi pip install coreapi 在 URL 配置中包含一个自动生成的 schema 视图 from rest_framework.schemas import get_schema_view schema_view = get_schema_view(title='Pastebin API') urlpatterns = [ url(r'^schema/$', schema_view), ... ] 如果你使用浏览器访问 API 根节点 , 在选项中 , 你可以看到 corejson 选项变成可用的状态 我们也可以使用命令行 , 通过在 Accept 请求头中指定期望的内容类型 , 请求 schema $ http http://127.0.0.1:8000/schema/ Accept:application/coreapi+json HTTP/1.0 200 OK Allow: GET, HEAD, OPTIONS Content-Type: application/coreapi+json { \"_meta\": { \"title\": \"Pastebin API\" }, \"_type\": \"document\", ... 默认的输出风格使用的是Core JSON编码 其他的 schema 格式 , 比如 Open API (以前称作Swagger) , 同样支持 使用命令行客户端 🍀 现在 , 我们的 API 暴露了一个 schema 端点 , 我们可以使用动态客户端库与 API 交互 , 为了证明这点 , 我们是用 Core API 命令行客户端 命令行客户端需要使用 coreapi-cli 包 pip install coreapi-cli 通过命令行检查 , coreapi-cli 是否可用 $ coreapi Usage: coreapi [OPTIONS] COMMAND [ARGS]... Command line client for interacting with CoreAPI services. Visit http://www.coreapi.org for more information. Options: --version Display the package version number. --help Show this message and exit. Commands: ... 首先我们使用命令行客户端加载 API schema $ coreapi get http://127.0.0.1:8000/schema/ snippets: { highlight(id) list() read(id) } users: { list() read(id) } 我们还没有认证 , 所以我们只能看到只读端点 , 符合我们设计的 API 权限 让我们尝试使用命令行客户端 , 列出已经存在的 snippets $ coreapi action snippets list [ { \"url\": \"http://127.0.0.1:8000/snippets/1/\", \"id\": 1, \"highlight\": \"http://127.0.0.1:8000/snippets/1/highlight/\", \"owner\": \"lucy\", \"title\": \"Example\", \"code\": \"print('hello, world!')\", \"linenos\": true, \"language\": \"python\", \"style\": \"friendly\" }, ... 有些 API 端点依赖命名参数 , 比如 , 我们要获取指定 snippet 的高亮 HTML , 需要提供一个 id $ coreapi action snippets highlight --param id=1 Example ... 认证我们的客户端 🍀 如果我们想要创建 , 编辑 , 删除 snippets , 我们需要认证一个有效的用户 , 这种情况下 , 我们只使用基本身份验证 将 和 替换成真实的用户名和密码 $ coreapi credentials add 127.0.0.1 : --auth basic Added credentials 127.0.0.1 \"Basic \" 现在 , 如果我们重新获取 schema , 我们可以看到所有的可用交互的集合 $ coreapi reload Pastebin API \"http://127.0.0.1:8000/schema/\"> snippets: { create(code, [title], [linenos], [language], [style]) delete(id) highlight(id) list() partial_update(id, [title], [code], [linenos], [language], [style]) read(id) update(id, code, [title], [linenos], [language], [style]) } users: { list() read(id) } 现在我们可以 和这些端点交互 , 比如 , 创建一个新的 snippet $ coreapi action snippets create --param title=\"Example\" --param code=\"print('hello, world')\" { \"url\": \"http://127.0.0.1:8000/snippets/7/\", \"id\": 7, \"highlight\": \"http://127.0.0.1:8000/snippets/7/highlight/\", \"owner\": \"lucy\", \"title\": \"Example\", \"code\": \"print('hello, world')\", \"linenos\": false, \"language\": \"python\", \"style\": \"friendly\" } 删除 snippet coreapi action snippets delete --param id=7 除了使用命令行客户端 , 开发者也可以使用客户端库与你的 API 进行交互 , Python客户端第一个可用的库 Javascript , 将在不久之后发布 有关定义 schema 生成和使用 Core API 客户端库 , 你可以参考完整的文档 回到我们的工作 🍀 我们使用很少的代码 , 拥有了一个完整的可浏览的 pastebin Web API , 它包含一个 schema-driven 客户端库 , 完整的身份认证 , 对象级权限和多格式渲染器 我们走过了设计过程的每一步, 看到了如何使用常规的Django视图进行定制. 你可以在GitHub上查阅最终的代码 tutorial code , 或者在 the sandbox 中进行尝试 到这里 , 我们已经完成了教程 , 如果你想跟多的参与到 REST framework 项目 , 你可以使用以下几种方式 : 在 GitHub 上进行审查 , 提交问题 , 发出 pull requests 加入 REST framework discussion group , 帮助构建社区 在Twitter上关注 作者 , 并发送 hi "},"05-Web框架/Flask/":{"url":"05-Web框架/Flask/","title":"Flask","keywords":"","body":"Flask初识 介绍 🍀 Flask是一个微型框架 , 它基于Python , 并且依赖着两个外部库 : Jinja2模板引擎和Werkzeug WSGI工具集 Flask的 \"微\" (Micro) 并不是意味着把整个Web应用放入到一个Python文件 , 尽管确实可以这么做 , 其主要时候指 , Flask旨在保持代码简介且易于扩展 , 所以Flaks不会为你做太多的选择 , 比如选择什么样的数据库 , 选择什么样的模板引擎 , 这些都取决你 默认情况下 , Flask并不包含数据库抽象层 , 表单验证或者任何其他现有库 (Django) 能处理的 , 相反 , Flask支持扩展 , 这些扩展能够添加功能到你的应用 , 就像是Flask本身实现的一样 . 众多的扩展提供了数据库集成 , 表单验证 , 上传处理 , 多种开放的认证技术等功能 Flask可能是 \"微\" 型的 , 但是它已经能够在各种各样的需求中生产使用 配置和约定 🍀 Flask有许多带有合理默认值的配置项 , 也遵循一些惯例 , 比如 : 按惯例 , 模板和静态文件存储在应用Python源代码树下的子目录中 , 模板文件夹名称与Django一样 \"templates\" , 静态文件夹名称 \"static\" 等等 总之 , Flask由于它的 \"微\" , 当然也可以说 \"轻\" , 使它得到的广泛的应用 , 便于扩展 , 而不像Django那样 , 强大却有时会显得笨重 "},"05-Web框架/Flask/01-Flask - 源码简要说明.html":{"url":"05-Web框架/Flask/01-Flask - 源码简要说明.html","title":"Flask - 源码简要说明","keywords":"","body":"Flask - 源码简要说明 介绍 🍀 内容概况 flask ├── json │ ├── __init__.py │ └── tag.py ├── __init__.py ├── __main__.py ├── _compat.py # 实现关于Python版本兼容性的配置 ├── app.py # 实现WSGI应用程序对象,即Flask ├── blueprints.py # 蓝图 ├── cli.py # 实现简单的命令行应用程序 ├── config.py # 实现与配置相关的对象 ├── ctx.py # 实现上下文相关的对象 ├── debughelpers.py # debug模式相关 ├── globals.py # 定义了所有的全局对象 ├── helpers.py ├── logging.py ├── sessions.py ├── signals.py # 基于blinker的信号 ├── templating.py ├── testing.py ├── views.py # 提供了类似于Djando的CBV └── wrappers.py # 实现了WSGI包装器,即request和response 阅读指引 🍀 本目录下为 Flask 源码阅读相关 , 读者应该对 WSGI 和 socketserver 有一定的了解 , 因为在某些部分这可能成为阻碍 , 相对而言 , Flask 的源码比 Django 要简单得多 , 因为 Django 过于庞大 , 并且耦合度高 如果您有一定的 Web 框架基础 , 对于 Flask 框架的学习可能会变得简单 , 您可以通过阅读源码来获得更多的灵感 , 该目录文章为本人学习交流所撰 , 欢迎交流 如果您没有 Web 框架基础 , 那么您不妨通过 Flask 官方的文档来进行学习 , 链接在此 : Flask官方文档 ; 中文文档 , 该文档翻译不一定准确 , 但是可以借鉴 更多 Flask 相关中文翻译 : http://www.pythondoc.com/ "},"05-Web框架/Flask/02-Flask - 源码之开始.html":{"url":"05-Web框架/Flask/02-Flask - 源码之开始.html","title":"Flask - 源码之开始","keywords":"","body":"Flask - 源码之开始 介绍 🍀 Flask 中文文档比较齐全 , 阅读源码最好的方式应该是从最简单的应用开始 直接使用官方快速入门中的最小的应用开始 from flask import Flask # 实例化Flask对象 # __name__ 为模块名,当前为 __main__ app = Flask(__name__) # 绑定路由 @app.route('/') def hello_world(): return 'Hello World!' if __name__ == '__main__': app.run() 绑定路由 🍀 我们首先实例化了 Flask 对象 , 我们传入了一个参数 import_name , 该参数的概念是给 Flask 一个属于你的应用程序的概念 , 它用于查找文件系统上的资源 , 可以由扩展名用于改进调试信息等 随后写了一个视图函数 hello_world 以及给这个视图函数添加了一个装饰器 ; 当然 , 我们已经知道这个装饰器的作用是添加路由规则 , 我们看看它具体是怎么做的 flask.app.Flask.route() : def route(self, rule, **options): \"\"\" rule:URL规则的字符串 **options:该参数将在实例化Rule对象时作为参数传入 - options参数: - defaults=None,默认值,当URL中无参数,函数需要参数时,使用defaults={'page': 1} - subdomain=None,子域名访问,默认由Map对象提供,即为 '' - methods=None,允许的请求方式 - build_only=False,如果为True,则URL无法匹配但是仍然会构建 - endpoint=None,端点,用于反向生成URL,即:url_for() - strict_slashes=None,对URL最后的 / 符号是否严格要求,默认由Map对象提供,即为True - redirect_to=None,重定向到指定地址 - alias=False,如果为True,则作为另一条端点和参数相同的规则的别名 - host=None,为整个主机提供匹配规则 \"\"\" def decorator(f): # 获取endpoint参数,默认是为None的 # endpoint参数用于反向生成url时使用 endpoint = options.pop('endpoint', None) self.add_url_rule(rule, endpoint, f, **options) return f return decorator app.route('/') == decorator →→ @app.route('/') == @decorator , 于是在此装饰器执行时 , 将执行 self.add_url_rule() , 源码如下 : flask.app.Flask.add_url_rule() : @setupmethod # 该装饰器与调试模式有关,我们可以跳过它 def add_url_rule(self, rule, endpoint=None, view_func=None, provide_automatic_options=None, **options): if endpoint is None: # 返回视图函数的函数名 endpoint = _endpoint_from_view_func(view_func) options['endpoint'] = endpoint # 获取options中的methods参数,它是一个列表 methods = options.pop('methods', None) if methods is None: # 如果view_func为CBV方式,并且有methods参数,否则使用('GET) methods = getattr(view_func, 'methods', None) or ('GET',) if isinstance(methods, string_types): raise TypeError('Allowed methods have to be iterables of strings, ' 'for example: @app.route(..., methods=[\"POST\"])') # 转换成大写 methods = set(item.upper() for item in methods) # 必要属性 required_methods = set(getattr(view_func, 'required_methods', ())) # 强制启用自动选项处理 if provide_automatic_options is None: provide_automatic_options = getattr(view_func, 'provide_automatic_options', None) if provide_automatic_options is None: if 'OPTIONS' not in methods: provide_automatic_options = True required_methods.add('OPTIONS') else: provide_automatic_options = False # 添加必要属性到methods methods |= required_methods # 实例化Rule对象 rule = self.url_rule_class(rule, methods=methods, **options) rule.provide_automatic_options = provide_automatic_options # 生成url并完成绑定 self.url_map.add(rule) if view_func is not None: # view_func为视图函数 old_func = self.view_functions.get(endpoint) if old_func is not None and old_func != view_func: raise AssertionError('View function mapping is overwriting an ' 'existing endpoint function: %s' % endpoint) # 将视图函数加入Flask对象的view_functions属性中,以端点为key # self.view_functions = {} self.view_functions[endpoint] = view_func 启动WSGI服务器 🍀 到这里 , 好像路由与视图函数都准备好了 , 那么接下来就是启动该应用了 , app.run() def run(self, host=None, port=None, debug=None, load_dotenv=True, **options): ...... from werkzeug.serving import run_simple try: # 启动WSGI应用 run_simple(host, port, self, **options) finally: self._got_first_request = False 接下来将会执行 werkzeug.serving.run_simple 中的 inner def inner(): try: fd = int(os.environ['WERKZEUG_SERVER_FD']) except (LookupError, ValueError): fd = None # 创建一个服务器实例 # BaseWSGIServer srv = make_server(hostname, port, application, threaded, processes, request_handler, passthrough_errors, ssl_context, fd=fd) if fd is None: log_startup(srv.socket) # 启动服务器 # BaseWSGIServer.serve_forever() srv.serve_forever() BaseWSGIServer 继承了http.server.HTTPServer , BaseWSGIServer.serve_forever() 如下 : def serve_forever(self): self.shutdown_signal = False try: # 一次处理一个请求直到服务器关闭 # 将BaseWSGIServer对象作为参数传入 HTTPServer.serve_forever(self) except KeyboardInterrupt: pass finally: self.server_close() 由于 HTTPServer 继承自 socketserver.TCPServer , 并且它并没有重写 serve_forever , 所以 , 源代码如下 : def serve_forever(self, poll_interval=0.5): \"\"\"Handle one request at a time until shutdown. Polls for shutdown every poll_interval seconds. Ignores self.timeout. If you need to do periodic tasks, do them in another thread. \"\"\" self.__is_shut_down.clear() try: # XXX: Consider using another file descriptor or connecting to the # socket to wake this up instead of polling. Polling reduces our # responsiveness to a shutdown request and wastes cpu at all other # times. with _ServerSelector() as selector: selector.register(self, selectors.EVENT_READ) while not self.__shutdown_request: ready = selector.select(poll_interval) if ready: self._handle_request_noblock() self.service_actions() finally: self.__shutdown_request = False self.__is_shut_down.set() 到这里 , 我们不妨来对比一下 , 在 Django 中 , 创建服务器实例是由 wsgiref.simple_server.WSGIServer 衍生而来 , 而 WSGIServer 继承了http.server.HTTPServer 而在 Flask 中 , 如上 , 也继承了 http.server.HTTPServer 创建服务器实例 🍀 在 BaseWSGIServer 进行实例化时 , 与 Django 一样 , 都传入了一个 RequestHandlerClass 参数 , 这个参数听名字就知道 , 它是处理请求的核心 , 源码如下 : class BaseWSGIServer(HTTPServer, object): \"\"\"Simple single-threaded, single-process WSGI server.\"\"\" # 省略部分代码 def __init__(self, host, port, app, handler=None, passthrough_errors=False, ssl_context=None, fd=None): if handler is None: # werkzeug.serving.WSGIRequestHandler # Django:django.core.servers.basehttp.WSGIRequestHandler handler = WSGIRequestHandler # RequestHandlerClass为出去self后第二个参数,handler HTTPServer.__init__(self, get_sockaddr(host, int(port), self.address_family), handler) 回到 serve_forever 中 , 调用 self._handle_request_noblock() , 随后再调用 self.process_request(request, client_address) def process_request(self, request, client_address): \"\"\"Call finish_request. Overridden by ForkingMixIn and ThreadingMixIn. \"\"\" self.finish_request(request, client_address) self.shutdown_request(request) 最后调用了 self.finish_request(request, client_address) def finish_request(self, request, client_address): \"\"\"Finish one request by instantiating RequestHandlerClass.\"\"\" self.RequestHandlerClass(request, client_address, self) 实例化WSGI请求处理类 🍀 至此 , 在创建服务器实例 , 也就是 BaseWSGIServer 时 , 已经将该类传入 , 即 WSGIRequestHandler ; 重点来了 , WSGIRequestHandler 自身根本没有构造函数 , 它的基类 socketserver.TCPServer 还是没有 , 继续往上发现 , 关于 RequestHandlerClass 初始化的函数在继承链的顶部 socketserver.BaseServer 中 , 其构造函数如下 : def __init__(self, request, client_address, server): self.request = request self.client_address = client_address self.server = server self.setup() try: # 该函数在WSGIRequestHandler中进行了重构 self.handle() finally: self.finish() WSGIRequestHandler.handler() 如下 : def handle(self): \"\"\"Handles a request ignoring dropped connections.\"\"\" rv = None try: # 其基类的handler rv = BaseHTTPRequestHandler.handle(self) except (socket.error, socket.timeout) as e: self.connection_dropped(e) except Exception: if self.server.ssl_context is None or not is_ssl_error(): raise if self.server.shutdown_signal: self.initiate_shutdown() return rv def handle(self): \"\"\"Handle multiple requests if necessary.\"\"\" self.close_connection = True # 该方法在WSGIRequestHandler被重写 self.handle_one_request() while not self.close_connection: self.handle_one_request() 重写源码如下 : def handle_one_request(self): \"\"\"Handle a single HTTP request.\"\"\" self.raw_requestline = self.rfile.readline() if not self.raw_requestline: self.close_connection = 1 elif self.parse_request(): # 运行WSGI应用服务器 return self.run_wsgi() 视图调度 🍀 摘取 run_wsgi() 部分代码如下 : def run_wsgi(self): if self.headers.get('Expect', '').lower().strip() == '100-continue': self.wfile.write(b'HTTP/1.1 100 Continue\\r\\n\\r\\n') # 环境处理 self.environ = environ = self.make_environ() headers_set = [] headers_sent = [] def write(data): pass def start_response(status, response_headers, exc_info=None): pass def execute(app): # 调用Flask应用实例的__call__方法 # Flask(__name__)(environ, start_response) application_iter = app(environ, start_response) try: for data in application_iter: write(data) if not headers_sent: write(b'') finally: if hasattr(application_iter, 'close'): application_iter.close() application_iter = None try: # self.server = BaseWSGIServer # BaseWSGIServer.app即Flask应用实例 execute(self.server.app) pass Flask.__call__ 源码如下 : def __call__(self, environ, start_response): \"\"\"The WSGI server calls the Flask application object as the WSGI application. This calls :meth:`wsgi_app` which can be wrapped to applying middleware.\"\"\" # WSGI服务器调用Flask应用对象作为WSGI应用 return self.wsgi_app(environ, start_response) def wsgi_app(self, environ, start_response): # 请求上下文对象 ctx = self.request_context(environ) error = None try: try: # 将请求上下文对象推入栈中 # _request_ctx_stack.push(self) # self = RequestContext(environ) ctx.push() # 分派请求 response = self.full_dispatch_request() except Exception as e: error = e response = self.handle_exception(e) except: error = sys.exc_info()[1] raise # 执行Response对象的__call__方法 # 这里将由werkzeug来进行处理 # werkzeug.wrappers.BaseResponse.__call__ # start_response在run_wsgi函数中 # def __call__(self, environ, start_response): \"\"\"Process this response as WSGI application. :param environ: the WSGI environment. :param start_response: the response callable provided by the WSGI server. :return: an application iterator \"\"\" # app_iter, status, headers = self.get_wsgi_response(environ) # start_response(status, headers) # return app_iter return response(environ, start_response) finally: if self.should_ignore_error(error): error = None ctx.auto_pop(error) self.full_dispatch_request() def full_dispatch_request(self): \"\"\"Dispatches the request and on top of that performs request pre and postprocessing as well as HTTP exception catching and error handling. .. versionadded:: 0.7 \"\"\" self.try_trigger_before_first_request_functions() try: request_started.send(self) # 请求预处理 rv = self.preprocess_request() if rv is None: # 进行视图调度 rv = self.dispatch_request() except Exception as e: rv = self.handle_user_exception(e) # 完成请求 return self.finalize_request(rv) 预处理过程如下 : def preprocess_request(self): \"\"\"Called before the request is dispatched. Calls :attr:`url_value_preprocessors` registered with the app and the current blueprint (if any). Then calls :attr:`before_request_funcs` registered with the app and the blueprint. If any :meth:`before_request` handler returns a non-None value, the value is handled as if it was the return value from the view, and further request handling is stopped. \"\"\" # 从请求上下文栈中获取蓝图 bp = _request_ctx_stack.top.request.blueprint # 预处理函数 # self.url_value_preprocessors = {} funcs = self.url_value_preprocessors.get(None, ()) if bp is not None and bp in self.url_value_preprocessors: funcs = chain(funcs, self.url_value_preprocessors[bp]) for func in funcs: # 执行预处理 func(request.endpoint, request.view_args) # 在处理请求之前调用的函数 # self.before_request_funcs = {} funcs = self.before_request_funcs.get(None, ()) if bp is not None and bp in self.before_request_funcs: funcs = chain(funcs, self.before_request_funcs[bp]) for func in funcs: rv = func() if rv is not None: # 有返回值请求处理结束 return rv 视图调度 , self.dispatch_request() def dispatch_request(self): \"\"\"Does the request dispatching. Matches the URL and returns the return value of the view or error handler. This does not have to be a response object. In order to convert the return value to a proper response object, call :func:`make_response`. .. versionchanged:: 0.7 This no longer does the exception handling, this code was moved to the new :meth:`full_dispatch_request`. \"\"\" # 从栈中获取请求上下文对象 req = _request_ctx_stack.top.request if req.routing_exception is not None: self.raise_routing_exception(req) rule = req.url_rule # if we provide automatic options for this URL and the # request came with the OPTIONS method, reply automatically if getattr(rule, 'provide_automatic_options', False) \\ and req.method == 'OPTIONS': return self.make_default_options_response() # otherwise dispatch to the handler for that endpoint # 通过endpoint参数获取视图函数并调用,视图函数参数从获取的请求上下文对象中获取 return self.view_functions[rule.endpoint](**req.view_args) 视图调度完成后 , 接下来就是完成请求了 , 从 dispatch_request 或者 preprocess_request 中已经获取了需要的 rv , 最后就是执行 full_dispatch_request() 中的最后一行 return self.finalize_request(rv) finalize_request() 源码如下 : def finalize_request(self, rv, from_error_handler=False): \"\"\"Given the return value from a view function this finalizes the request by converting it into a response and invoking the postprocessing functions. This is invoked for both normal request dispatching as well as error handlers. Because this means that it might be called as a result of a failure a special safe mode is available which can be enabled with the `from_error_handler` flag. If enabled, failures in response processing will be logged and otherwise ignored. :internal: \"\"\" # 将视图返回值转换成response对象 response = self.make_response(rv) try: # 请求结束后处理 response = self.process_response(response) request_finished.send(self, response=response) except Exception: if not from_error_handler: raise self.logger.exception('Request finalizing failed with an ' 'error while handling an error') # 返回响应 return response 到这里其实我们已经分析的差不多了 , 当 response 对象获取之后 , 一步步往外返回 , 将会返回到 werkzeug 层次 , 当然 werkzeug 也是使用 socketserver 的一部分功能来完成这些操作 , 这一部分就不再分析了 小结 🍀 首先 , 从整体来讲 , 我们可以通过与 Django 进行对比 : Django , 使用 wsgiref + socketserver + http Flask , 使用 werkzeug + socketserver + http 在传输层 , 两者都是使用的 socketserver , 当然它们在 socketserver 的基础上做了一些不同的改变 那么对于 Flask 运行到处理请求流程如下 : 创建 Flask 应用对象 添加路由映射 启动服务器 请求来临 , 创建请求上下文对象 , 并压入请求上下文栈 处理请求 , 从栈中获取对象 , 调用视图 (dispatch_request) 将视图返回值打包成响应对象 完成响应 "},"05-Web框架/Flask/03-Flask - 源码之配置.html":{"url":"05-Web框架/Flask/03-Flask - 源码之配置.html","title":"Flask - 源码之配置","keywords":"","body":"Flask - 源码之配置 介绍 🍀 Flask 中的配置主要使用 flask/config.py 中的两个对象 : Config , ConfigAttribute Config 🍀 Config 是 dict 的子类 , 所以它的一些行为跟 dict 一样 # 为了方便阅读,删除部分代码 # 删除部分以 ... 代表 class Config(dict): def __init__(self, root_path, defaults=None): dict.__init__(self, defaults or {}) self.root_path = root_path def from_envvar(self, variable_name, silent=False): \"\"\" 更新配置,从环境变量中获取,等价于如下: app.config.from_pyfile(os.environ['YOURAPPLICATION_SETTINGS']) \"\"\" rv = os.environ.get(variable_name) ... return self.from_pyfile(rv, silent=silent) def from_pyfile(self, filename, silent=False): \"\"\" 更新配置,从文件中获取配置 \"\"\" filename = os.path.join(self.root_path, filename) # 获取一个module对象 d = types.ModuleType('config') d.__file__ = filename try: with open(filename, mode='rb') as config_file: # 加载配置到,module对象的命名空间中 exec(compile(config_file.read(), filename, 'exec'), d.__dict__) ... self.from_object(d) return True def from_object(self, obj): \"\"\" 更新配置,从对象中获取配置,官方实例: app.config.from_object('yourapplication.default_config') from yourapplication import default_config app.config.from_object(default_config) \"\"\" if isinstance(obj, string_types): obj = import_string(obj) for key in dir(obj): # 获取配置模块的属性列表 if key.isupper(): self[key] = getattr(obj, key) def from_json(self, filename, silent=False): \"\"\" 更新配置,从json文件中获取配置 类似于from_pyfile,但是返回方式不同 \"\"\" filename = os.path.join(self.root_path, filename) try: with open(filename) as json_file: obj = json.loads(json_file.read()) ... return self.from_mapping(obj) def from_mapping(self, *mapping, **kwargs): \"\"\" 更新配置, \"\"\" mappings = [] if len(mapping) == 1: if hasattr(mapping[0], 'items'): mappings.append(mapping[0].items()) else: mappings.append(mapping[0]) ... mappings.append(kwargs.items()) for mapping in mappings: for (key, value) in mapping: if key.isupper(): self[key] = value return True def get_namespace(self, namespace, lowercase=True, trim_namespace=True): \"\"\" 返回包含自己配置选项的字典 namespace:配置的命名空间 \"\"\" def __repr__(self): return '' % (self.__class__.__name__, dict.__repr__(self)) 因为它是字典的子类 , 所以你可以使用 update() 一次性更新多个配置 app.config.update( DEBUG=True, SECRET_KEY='...' ) 关于通过 from_object() 方法来配置 , 你可以利用继承实现如下 : # configmodule.py class Config(object): DEBUG = False TESTING = False DATABASE_URI = 'sqlite://:memory:' class ProductionConfig(Config): DATABASE_URI = 'mysql://user@localhost/foo' class DevelopmentConfig(Config): DEBUG = True class TestingConfig(Config): TESTING = True # demo.py app.config.from_object('configmodule.ProductionConfig') ConfigAttribute 🍀 该类的作用就是为config设置一些属性 class ConfigAttribute(object): \"\"\" 将一个属性转接到Config, 该类是一个描述器类,即实现了__get__方法的类, __get__的作用是,当通过另一个类的实例来访问该对象时, 将会执行__get__方法,在Flask中如下: class Flask(_PackageBoundObject): testing = ConfigAttribute('TESTING') self.config = self.make_config(instance_relative_config) application = Flask(__name__) # 执行ConfigAttribute中的__get__方法 # 该配置在self.config中已被设置 application.testing \"\"\" def __init__(self, name, get_converter=None): self.__name__ = name self.get_converter = get_converter def __get__(self, obj, type=None): \"\"\" obj:即Flask对象 \"\"\" if obj is None: return self rv = obj.config[self.__name__] if self.get_converter is not None: rv = self.get_converter(rv) return rv def __set__(self, obj, value): obj.config[self.__name__] = value defaults_config 🍀 接下来我们看看关于 Flask 的一些默认的设置 , 首先是 Flask 对象中的 defaults_config , 它是一个 ImmutableDict 对象 ImmutableDict 是 werkzeug 中特意构造的一个数据类型 , 不可变字典 default_config = ImmutableDict({ 'ENV': None, # 由helpers.get_env()获取,默认为production # 是否启用调试模式 'DEBUG': None, # 由helpers.get_debug_flag()获取,默认为True # 是否启用测试模式 'TESTING': False, # 是否显示启用异常传播 'PROPAGATE_EXCEPTIONS': None, # 当 TESTING 或 DEBUG 为真时,总是开启的 'PRESERVE_CONTEXT_ON_EXCEPTION': None, # 缺省情况下,如果应用在调试模式下运行, # 那么请求环境在发生异常时不会被弹出, # 以方便调试器内省数据, # 可以通过这个配置来禁止这样做, # 还可以使用这个配置强制不执行调试, # 这样可能有助于调试生产应用(风险大) # 密钥 'SECRET_KEY': None, # 持久化会话的存活时间 'PERMANENT_SESSION_LIFETIME': timedelta(days=31), # 开关x-sendfile 'USE_X_SENDFILE': False, # 服务器的名称和端口,用于支持子域 'SERVER_NAME': None, # 应用的路径 'APPLICATION_ROOT': '/', # 会话cookie的名称 'SESSION_COOKIE_NAME': 'session', # 会话cookie的域 'SESSION_COOKIE_DOMAIN': None, # 会话cookie的路径 'SESSION_COOKIE_PATH': None, # cookie的httponly标志 'SESSION_COOKIE_HTTPONLY': True, # 设置cookie的安全标志 'SESSION_COOKIE_SECURE': False, # cookie是否使用SameSite属性 'SESSION_COOKIE_SAMESITE': None, # 是否刷新请求 'SESSION_REFRESH_EACH_REQUEST': True, # 拒绝内容长度超过该值的请求,单位为字节 'MAX_CONTENT_LENGTH': None, # 默认缓存控制的最大期限 'SEND_FILE_MAX_AGE_DEFAULT': timedelta(hours=12), # 反馈坏请求异常 'TRAP_BAD_REQUEST_ERRORS': None, # 是否执行HTTP异常处理 'TRAP_HTTP_EXCEPTIONS': False, 'EXPLAIN_TEMPLATE_LOADING': False, # url模式方案 'PREFERRED_URL_SCHEME': 'http', # 是否把对象编码为ASCII 'JSON_AS_ASCII': True, # 是否按键值排序JSON对象 'JSON_SORT_KEYS': True, # jsonify响应是否完美打印 'JSONIFY_PRETTYPRINT_REGULAR': False, # json类型 'JSONIFY_MIMETYPE': 'application/json', # 自动重载模板 'TEMPLATES_AUTO_RELOAD': None, # 最大cookie尺寸 'MAX_COOKIE_SIZE': 4093, }) Flask 对象默认配置 : # 静态文静路径 static_url_path=None, # 静态文件夹 static_folder='static', static_host=None, host_matching=False, subdomain_matching=False, template_folder='templates', instance_path=None, instance_relative_config=False, root_path=None 配置加载 🍀 那么了解了 config.py 中的内容后 , 我们应该想的是 , Flask 到底是如何去加载的 首先在我们实例化 Flask 对象 , 有这么一个操作 : # instance_relative_config默认为False self.config = self.make_config(instance_relative_config) 这个 make_config 就是加载配置了 def make_config(self, instance_relative=False): # root_path在Flask的基类中已经被设置,就是当前的根目录 # root_path = get_root_path(self.import_name) root_path = self.root_path if instance_relative: root_path = self.instance_path # 这里self.defaults_config在上一小节已经详细说明了 defaults = dict(self.default_config) defaults['ENV'] = get_env() defaults['DEBUG'] = get_debug_flag() # 返回一个Config对象,即Config(root_path, defaults) return self.config_class(root_path, defaults) 更多的配置需要在相关应用上介绍 "},"05-Web框架/Flask/04-Flask - 源码之路由.html":{"url":"05-Web框架/Flask/04-Flask - 源码之路由.html","title":"Flask - 源码之路由","keywords":"","body":"Flask - 源码之路由 介绍 🍀 在分析 Flask 的请求处理流程中 , 已经碰到了一些路由相关的代码了 , 但是并未深入 , 现在就来看看吧 添加路由 🍀 通常我们使用 Flask 中的装饰器 route 来完成路由注册 , 实际上 , 它也仅仅是一个中介 , 方便我们使用 ; 本质上它只是帮我们调用了 Flask 对象中的 add_url_rule 方法 , 如下 : def route(self, rule, **options): def decorator(f): endpoint = options.pop('endpoint', None) self.add_url_rule(rule, endpoint, f, **options) return f return decorator 也就是说我们可以这样来注册路由 : app = Flask(__name__) def index(): pass app.add_url_rule('/', 'index', index) 而 add_url_rule 中 , 我们截取重要部分来分析 : def add_url_rule(self, rule, endpoint=None, view_func=None, provide_automatic_options=None, **options): if endpoint is None: endpoint = _endpoint_from_view_func(view_func) options['endpoint'] = endpoint methods = options.pop('methods', None) # if the methods are not given and the view_func object knows its # methods we can use that instead. If neither exists, we go with # a tuple of only ``GET`` as default. if methods is None: # 此处添加GET,在后续会加入OPTIONS和HEAD methods = getattr(view_func, 'methods', None) or ('GET',) if isinstance(methods, string_types): raise TypeError('Allowed methods have to be iterables of strings, ' 'for example: @app.route(..., methods=[\"POST\"])') methods = set(item.upper() for item in methods) # Methods that should always be added required_methods = set(getattr(view_func, 'required_methods', ())) # starting with Flask 0.8 the view_func object can disable and # force-enable the automatic options handling. if provide_automatic_options is None: provide_automatic_options = getattr(view_func, 'provide_automatic_options', None) if provide_automatic_options is None: if 'OPTIONS' not in methods: provide_automatic_options = True required_methods.add('OPTIONS') else: provide_automatic_options = False # Add the required methods now. # 此处会将required_methods中的OPTIONS加入methods中 methods |= required_methods # 实例化Rule对象,并不会对rule做出改变 # 实例化过程中会将 HEAD 加入到methods中 rule = self.url_rule_class(rule, methods=methods, **options) rule.provide_automatic_options = provide_automatic_options # self.url_map = Map() # 所有的路由将全部存储在Map对象中,并且路由的转换工作也将在该对象中完成 self.url_map.add(rule) if view_func is not None: old_func = self.view_functions.get(endpoint) if old_func is not None and old_func != view_func: raise AssertionError('View function mapping is overwriting an ' 'existing endpoint function: %s' % endpoint) # 将视图函数加入view_functions中,默认为{} self.view_functions[endpoint] = view_func 绑定路由 🍀 我们已经知道 , 路由的转换是利用Map 对象来实现的 , self.url_map.add(rule) 源码如下 : def add(self, rulefactory): # Rule.get_rules()是一个生成器,返回Rule实例 for rule in rulefactory.get_rules(self): # Rule.bind()会将url绑定到Map对象,也就是这里self # 并且会创建一个正则表达式,其规则将会从Map对象中获取 rule.bind(self) # 将Rule对象加入_rules列表中 self._rules.append(rule) # 加入_rules_by_endpoint中 self._rules_by_endpoint.setdefault(rule.endpoint, []).append(rule) self._remap = True 在上面的 add 方法中 , 最重要的就是 rule.bind(self) , 我们看看细节部分 : def bind(self, map, rebind=False): if self.map is not None and not rebind: raise RuntimeError('url rule %r already bound to map %r' % (self, self.map)) # 为Rule对象添加map属性 self.map = map if self.strict_slashes is None: # map.strict_slashes = True self.strict_slashes = map.strict_slashes if self.subdomain is None: # map.default_subdomain = '' self.subdomain = map.default_subdomain # 完成正则表达式并存储它 self.compile() self.compile() 如下 : def compile(self): \"\"\"Compiles the regular expression and stores it.\"\"\" assert self.map is not None, 'rule not bound' if self.map.host_matching: domain_rule = self.host or '' else: domain_rule = self.subdomain or '' self._trace = [] self._converters = {} self._static_weights = [] self._argument_weights = [] regex_parts = [] def _build_regex(rule): \"\"\" 构建正则表达式,并放入regex_parts中 \"\"\" index = 0 # parse_rule(rule)会返回一个生成器,迭代时返回(converter, arguments, variable) for converter, arguments, variable in parse_rule(rule): # 只有使用静态规则时,converter才为None if converter is None: regex_parts.append(re.escape(variable)) self._trace.append((False, variable)) for part in variable.split('/'): if part: self._static_weights.append((index, -len(part))) else: if arguments: c_args, c_kwargs = parse_converter_args(arguments) else: c_args = () c_kwargs = {} # 获取转换器 convobj = self.get_converter( variable, converter, c_args, c_kwargs) regex_parts.append('(?P%s)' % (variable, convobj.regex)) self._converters[variable] = convobj self._trace.append((True, variable)) self._argument_weights.append(convobj.weight) self.arguments.add(str(variable)) index = index + 1 _build_regex(domain_rule) regex_parts.append('\\\\|') self._trace.append((False, '|')) _build_regex(self.is_leaf and self.rule or self.rule.rstrip('/')) if not self.is_leaf: self._trace.append((False, '/')) if self.build_only: return regex = r'^%s%s$' % ( u''.join(regex_parts), (not self.is_leaf or not self.strict_slashes) and '(?/?)' or '' ) self._regex = re.compile(regex, re.UNICODE) 转换器 🍀 在上面这段代码中 , 主要流程为 : 根据 url 中的信息 , 解析使用什么转换器 , 以及含有的变量等 , 再利用转换器的规则 , 生成路由放入 regex_parts 中 ; Map 对象中提供了一些默认的转换器 : # Map对象构造函数上方 default_converters = ImmutableDict(DEFAULT_CONVERTERS) DEFAULT_CONVERTERS = { 'default': UnicodeConverter, 'string': UnicodeConverter, 'any': AnyConverter, 'path': PathConverter, 'int': IntegerConverter, 'float': FloatConverter, 'uuid': UUIDConverter, } 这些转换器都是通过继承 BaseConverter 类实现的 class BaseConverter(object): \"\"\"Base class for all converters.\"\"\" regex = '[^/]+' weight = 100 def __init__(self, map): self.map = map def to_python(self, value): \"\"\" 路由匹配时,匹配成功后传递给视图函数中参数的值 \"\"\" return value def to_url(self, value): \"\"\" 使用url_for反向生成URL时,传递的参数经过该方法处理,返回值用于生成URL的参数 \"\"\" # 用指定的编码对value进行编码 return url_quote(value, charset=self.map.charset) 以 UnicodeConverter 为例 : class UnicodeConverter(BaseConverter): def __init__(self, map, minlength=1, maxlength=None, length=None): BaseConverter.__init__(self, map) if length is not None: length = '{%d}' % int(length) else: if maxlength is None: maxlength = '' else: maxlength = int(maxlength) length = '{%s,%s}' % ( int(minlength), maxlength ) self.regex = '[^/]' + length # Rule('/pages/'), # Rule('/') @app.route('/') def string_view(lang_code): return lang_code 自定义转换器 🍀 在 Flask 默认的转换器中 , 并没有支持正则的 , 如果我们需要像 Django 一样 , 支持正则 , 那就需要我们自己来增加这个规则了 , 也就是自定义一个转换器 from flask import Flask,url_for from werkzeug.routing import BaseConverter app = Flask(__name__) class RegexConverter(BaseConverter): \"\"\" 正则转换器 \"\"\" def __init__(self, map, regex): super(RegexConverter, self).__init__(map) self.regex = regex def to_python(self, value): return int(value) def to_url(self, value): return super(RegexConverter, self).to_url(value) # 添加到Map对象的converters中 app.url_map.converters['regex'] = RegexConverter @app.route('/index/') def index(nid): return \"Index\" 反向生成URL 🍀 在 Django 中 , 利用 reverse() 来反向生成 URL , 而在 Flask 中 , 也提供了一个函数可以反向生成 URL : url_for() def url_for(endpoint, **values): # 获取应用上下文 appctx = _app_ctx_stack.top # 获取请求上下文 reqctx = _request_ctx_stack.top if appctx is None: raise RuntimeError( 'Attempted to generate a URL without the application context being' ' pushed. This has to be executed when application context is' ' available.' ) # If request specific information is available we have some extra # features that support \"relative\" URLs. if reqctx is not None: # 请求上下文对象的url适配器 url_adapter = reqctx.url_adapter blueprint_name = request.blueprint if endpoint[:1] == '.': if blueprint_name is not None: endpoint = blueprint_name + endpoint else: endpoint = endpoint[1:] external = values.pop('_external', False) # Otherwise go with the url adapter from the appctx and make # the URLs external by default. else: # 应用上下文适配器 url_adapter = appctx.url_adapter if url_adapter is None: raise RuntimeError( 'Application was not able to create a URL adapter for request' ' independent URL generation. You might be able to fix this by' ' setting the SERVER_NAME config variable.' ) external = values.pop('_external', True) anchor = values.pop('_anchor', None) method = values.pop('_method', None) scheme = values.pop('_scheme', None) appctx.app.inject_url_defaults(endpoint, values) # This is not the best way to deal with this but currently the # underlying Werkzeug router does not support overriding the scheme on # a per build call basis. old_scheme = None if scheme is not None: if not external: raise ValueError('When specifying _scheme, _external must be True') old_scheme = url_adapter.url_scheme url_adapter.url_scheme = scheme try: try: # 通过适配器构建url rv = url_adapter.build(endpoint, values, method=method, force_external=external) finally: if old_scheme is not None: url_adapter.url_scheme = old_scheme except BuildError as error: # We need to inject the values again so that the app callback can # deal with that sort of stuff. values['_external'] = external values['_anchor'] = anchor values['_method'] = method values['_scheme'] = scheme return appctx.app.handle_url_build_error(error, endpoint, values) if anchor is not None: rv += '#' + url_quote(anchor) return rv 补充 🍀 关于路由默认的 methods 属性 , Rule 对象实例化时 , 会完成3次添加 : 执行 add_url_rule , 添加 GET 属性 通过 required_methods 与 methods 并集的结果 , 添加 OPTIONS 实例化 Rule 对象时 , 添加 HEAD 属性 在 Flask 对象进行实例化时 , 会首先将静态文件路由进行添加 if self.has_static_folder: assert bool(static_host) == host_matching, 'Invalid static_host/host_matching combination' self.add_url_rule( self.static_url_path + '/', endpoint='static', host=static_host, view_func=self.send_static_file ) 自动添加的静态文件规则如下 : ' (HEAD, OPTIONS, GET) -> static>, "},"05-Web框架/Flask/05-Flask - 源码之视图.html":{"url":"05-Web框架/Flask/05-Flask - 源码之视图.html","title":"Flask - 源码之视图","keywords":"","body":"Flask - 源码之视图 介绍 🍀 在 Flask 请求处理流程中 , 视图的调用是由 dispatch_request() 方法来控制的 如果我们使用 FBV 的方式 , 由于请求方法是由我们定义条件语句控制的 , 所以 dispatch_request() 可以直接使用 , 但是如果我们像 Django 那样来使用 , 那么我们就需要重写 dispatch_request() 了 , 不过在 Flask 中 , 已经有相关的类帮我们实现了 在 flask.views.py 中已经帮我们实现了 CBV , 我们可以继承他们来使用 class View(object): \"\"\" 使用该类必须重写dispatch_reqeust方法, 该类中有一个decorators属性,可以放入一些装饰器, 装饰器将会自动装饰在视图上 \"\"\" pass class MethodViewType(type): \"\"\" 该类为MethodView类的元类,它决定了视图的methods属性 \"\"\" pass class MethodView(with_metaclass(MethodViewType, View)): \"\"\" 为我们已经实现了dispatch_request方法,我们可以直接使用 \"\"\" pass View 🍀 class View(object): methods = None provide_automatic_options = None # 视图装饰器有关 decorators = () def dispatch_request(self): \"\"\" 子类必须继承 \"\"\" raise NotImplementedError() @classmethod def as_view(cls, name, *class_args, **class_kwargs): \"\"\" 将类转换成视图 \"\"\" def view(*args, **kwargs): # 实例化视图类 self = view.view_class(*class_args, **class_kwargs) # 通过dispatch_request方法来控制类中方法的调用 return self.dispatch_request(*args, **kwargs) if cls.decorators: view.__name__ = name view.__module__ = cls.__module__ for decorator in cls.decorators: view = decorator(view) view.view_class = cls view.__name__ = name view.__doc__ = cls.__doc__ view.__module__ = cls.__module__ view.methods = cls.methods view.provide_automatic_options = cls.provide_automatic_options return view 实例 from flask import Flask, request, render_template from flask.views import View app = Flask(__name__) class BaseView(View): def get_template_name(self): raise NotImplementedError def render_template(self, context): return render_template(self.get_template_name(), **context) def dispatch_request(self): if request.method != \"GET\": return \"UNSUPPORTED!\" context = {'users': self.get_users()} return self.render_template(context) class UserView(BaseView): def get_template_name(self): return 'user.html' def get_users(self): return [{ 'username': 'Lyon', 'avatar': 'https://github.com/lyonyang/blogs/blob/master/assets/avatar/one.jpg' }] app.add_url_rule('/users', view_func=UserView.as_view('userview')) if __name__ == '__main__': app.run() MethodViewType 🍀 class MethodViewType(type): \"\"\"Metaclass for :class:`MethodView` that determines what methods the view defines. \"\"\" def __init__(cls, name, bases, d): super(MethodViewType, cls).__init__(name, bases, d) # d为视图参数的字典 # MethodView使用该元类时,会将空字典传入d if 'methods' not in d: methods = set() # http_method_funcs = frozenset(['get', 'post', 'head', # 'options','delete', 'put', 'trace', 'patch']) for key in http_method_funcs: # 如果视图中定义了属性方法,那么就在methods中添加对应属性 if hasattr(cls, key): methods.add(key.upper()) if methods: cls.methods = methods MethodView 🍀 class MethodView(with_metaclass(MethodViewType, View)): def dispatch_request(self, *args, **kwargs): meth = getattr(self, request.method.lower(), None) if meth is None and request.method == 'HEAD': meth = getattr(self, 'get', None) assert meth is not None, 'Unimplemented method %r' % request.method return meth(*args, **kwargs) 实例 from flask import Flask, jsonify, abort, g from flask.views import MethodView app = Flask(__name__) def user_required(f): def decorator(*args, **kwargs): if not g.user: abort(401) return f(*args, **kwargs) return decorator class UserAPI(MethodView): decorators = [user_required,] def get(self): return jsonify({ 'username': 'Lyon', 'avatar': 'https://github.com/lyonyang/blogs/blob/master/assets/avatar/one.jpg' }) def post(self): return \"UNSUPPORTED!\" app.add_url_rule('/user', view_func=UserAPI.as_view('userview')) if __name__ == '__main__': app.run() "},"05-Web框架/Flask/06-Flask - 源码之蓝图.html":{"url":"05-Web框架/Flask/06-Flask - 源码之蓝图.html","title":"Flask - 源码之蓝图","keywords":"","body":"Flask - 源码之蓝图 介绍 🍀 首先 , 我们得说说蓝图的作用 蓝图 (Blueprint) 实现了应用的模块化 , 使用蓝图让应用层次清晰 , 开发者可以更容易的开发和维护项目 , 蓝图通常作用于相同的 URL 前缀 , 比如/user/:id , /user/profile 这样的地址都以 /user 开头 , 那么他们就可以放在一个模块中 构建蓝图 🍀 我们从示例开始 : myapplication/simple_page.py from flask import Blueprint, render_template, abort from jinja2 import TemplateNotFound # Blueprint类与Flask类一样,都继承了_PackageBoundObject # Blueprint相当于Flask的子应用 simple_page = Blueprint('simple_page', __name__, template_folder='templates') @simple_page.route('/', defaults={'page': 'index'}) @simple_page.route('/') def show(page): try: return render_template('pages/%s.html' % page) except TemplateNotFound: abort(404) Blueprint 类与 Flask 类非常相似 , 它就像是一个应用 , 上面代码中 , 首先实例化一个应用对象 , 虽然绑定路由与视图函数 , 然而它与 Flask 的不同之处就在于 , route 完成的操作并没有真的完成路由的添加 , 而是完成了一个函数的添加 , 我们看看源码 : def route(self, rule, **options): def decorator(f): # 与Flask类中的route方法不同的是,蓝图中将视图函数的函数名作为endpoint endpoint = options.pop(\"endpoint\", f.__name__) self.add_url_rule(rule, endpoint, f, **options) return f return decorator Blueprint.add_url_rule() 如下 : def add_url_rule(self, rule, endpoint=None, view_func=None, **options): if endpoint: assert '.' not in endpoint, \"Blueprint endpoints should not contain dots\" if view_func and hasattr(view_func, '__name__'): assert '.' not in view_func.__name__, \"Blueprint view function name should not contain dots\" # 传入一个匿名函数,该函数将在蓝图注册时被调用 self.record(lambda s: s.add_url_rule(rule, endpoint, view_func, **options)) Blueprint.record() 如下 : def record(self, func): if self._got_registered_once and self.warn_on_modifications: from warnings import warn warn(Warning('The blueprint was already registered once ' 'but is getting modified now. These changes ' 'will not show up.')) # 将函数追加到deferred_functions中 self.deferred_functions.append(func) 至此 , 我们已经完成了一个蓝图的构建 , 但是此时路由并没有注册 , 它仅仅将注册路由的函数放入 deferred_functions 中 , 等待蓝图注册时被调用 注册蓝图 🍀 现在我们需要把构建好的蓝图注册到我们的应用中 , 如下 : from flask import Flask from myapplication.simple_page import simple_page app = Flask(__name__) app.register_blueprint(simple_page) Flask.register_blueprint() 如下 : def register_blueprint(self, blueprint, **options): first_registration = False if blueprint.name in self.blueprints: assert self.blueprints[blueprint.name] is blueprint, ( 'A name collision occurred between blueprints %r and %r. Both' ' share the same name \"%s\". Blueprints that are created on the' ' fly need unique names.' % ( blueprint, self.blueprints[blueprint.name], blueprint.name ) ) else: # 注册蓝图到Flask应用对象 self.blueprints[blueprint.name] = blueprint self._blueprint_order.append(blueprint) first_registration = True # 将回调在构建蓝图实例时的延迟函数,即deferred_functions中的函数 # 函数为:lambda s: s.add_url_rule(rule, endpoint, view_func, **options) # s为flask.blueprints.BlueprintSetupState实例 blueprint.register(self, options, first_registration) Blueprint.register() 具体如下 : def register(self, app, options, first_registration=False): self._got_registered_once = True # 创建一个flask.blueprints.BlueprintSetupState实例 state = self.make_setup_state(app, options, first_registration) if self.has_static_folder: state.add_url_rule( self.static_url_path + '/', view_func=self.send_static_file, endpoint='static' ) for deferred in self.deferred_functions: # 调用flask.blueprints.BlueprintSetupState实例的add_url_rule方法 deferred(state) flask.blueprints.BlueprintSetupState.add_url_rule() 如下 : def add_url_rule(self, rule, endpoint=None, view_func=None, **options): if self.url_prefix is not None: if rule: rule = '/'.join(( self.url_prefix.rstrip('/'), rule.lstrip('/'))) else: rule = self.url_prefix options.setdefault('subdomain', self.subdomain) if endpoint is None: endpoint = _endpoint_from_view_func(view_func) defaults = self.url_defaults if 'defaults' in options: defaults = dict(defaults, **options.pop('defaults')) # 使用flask.Flask.add_url_rule方法 # 第二个参数为endpoint参数,为蓝图名称.视图名称,simple_page.show self.app.add_url_rule(rule, '%s.%s' % (self.blueprint.name, endpoint), view_func, defaults=defaults, **options) 如果是使用蓝图注册路由 , 那么第一个路由同样是设置静态文件路由 , 在 flask.blueprints.Blueprint.register() 中可见如下内容 : if self.has_static_folder: state.add_url_rule( self.static_url_path + '/', view_func=self.send_static_file, endpoint='static' ) 该蓝图注册到应用时 , 路由注册规则如下 : # 可以在flask.Flask.add_url_rule中 # line 1215:self.url_map.add(rule)下添加一行输出代码: # print(rule.__repr()) # 随后启动应用,就能得到如下信息 # 我们也可以输出flas.Flask.view_functions属性查看绑定的视图函数,这里就不说明了 ' (HEAD, OPTIONS, GET) -> static>, ' (HEAD, OPTIONS, GET) -> simple_page.show>, simple_page.show> 蓝图还可以在不同的位置挂载 : app.register_blueprint(simple_page, url_prefix='/pages') 生成规则如下 : ' (HEAD, OPTIONS, GET) -> static>, ' (HEAD, OPTIONS, GET) -> simple_page.show>, simple_page.show> 蓝图资源 🍀 蓝图也可以提供资源 , 有时候你会只为他提供的资源而引入一个蓝图 蓝图资源文件夹 🍀 我们可以通过访问 Blueprint 对象的 root_path 属性来访问蓝图资源文件夹 : >>> simple_page.root_path '/Users/username/TestProject/myapplication' 并且你可以使用 open_response() 函数快速获取文件资源 : with simple_page.open_resource('static/style.css') as f: code = f.read() 静态文件 🍀 与 Flask 一样 , Blueprint 可以通过 static_folder 关键字参数提供一个指向文件系统上文件夹的路径 , 这可以是一个绝对路径 , 也可以是相对于蓝图文件夹的相对路径 : admin = Blueprint('admin', __name__, static_folder='static') 模板 🍀 同样的 , 蓝图也提供模板 : admin = Blueprint('admin', __name__, template_folder='templates') 总而言之 , 蓝图相当于 Flask 应用实例下的 \"Flask\" 应用实例 (\"子应用\") , 它能将你的项目理想化 对于 Blueprint 对象中的方法 , 你不妨看看 , 也许有你想要的功能 "},"05-Web框架/Flask/07-Flask - 源码之本地线程.html":{"url":"05-Web框架/Flask/07-Flask - 源码之本地线程.html","title":"Flask - 源码之本地线程","keywords":"","body":"Flask - 源码之本地线程 介绍 🍀 Flask 中的一条设计原则是保持任务的简单 , 任务的实现不需要花费太多的代码 , 也不会限制到你 ; 例如 , 为了保持线程安全 , Flask 使用了本地线程 (thread-local) , 所以在一个请求中你不需要在函数之间传递对象 本地线程 (thread-local) : 希望不同的线程对于内容的修改只在线程内发挥作用 , 线程之间互不影响 Threading的Local 🍀 我们可以通过一个例子来看看 , 本地线程是如何实现的 , 示例如下 : import threading data = threading.local() data.number = 1 print(data.number) log = [] def func(): data.number = 2 log.append(data.number) thread = threading.Thread(target=func) thread.start() thread.join() print(log) print(data.number) \"\"\" 执行结果: 1 [2] # 在线程内data.number变成了其他的值 1 # 但是没有影响到开始设置的值 \"\"\" 之所以会有这样的结果 , 都是因为 threading.local() 在作祟 , 以上面的代码为例 , 我们来分析一下这个 local , 其源码如下 : class local: # 仅允许_local__iml和__dict__进行绑定 # 其他属性绑定将会触发AttributeError __slots__ = '_local__impl', '__dict__' def __new__(cls, *args, **kw): if (args or kw) and (cls.__init__ is object.__init__): raise TypeError(\"Initialization arguments are not supported\") self = object.__new__(cls) # _localimpl为管理本地线程dicts属性的类 impl = _localimpl() impl.localargs = (args, kw) impl.locallock = RLock() object.__setattr__(self, '_local__impl', impl) # 初始化_localimpl对象的dicts属性 impl.create_dict() return self def __getattribute__(self, name): \"\"\" 此处内容省略 \"\"\" def __setattr__(self, name, value): \"\"\" 此处内容省略 \"\"\" def __delattr__(self, name): \"\"\" 此处内容省略 \"\"\" 我们需要先弄明白 impl.create_dict() 做了什么操作 , 因为这里是本地线程的一个关键点 , 还有一个关键点就是 __setattr__ 方法 , 先看看 impl.create_dict() : def create_dict(self): \"\"\" 为当前线程创建一个新字典,并返回它 \"\"\" localdict = {} # self.key:{ id(Thread) -> (ref(Thread), thread-local dict) } key = self.key # 获取当前线程对象 thread = current_thread() # 获取当前线程对象id idt = id(thread) def local_deleted(_, key=key): thread = wrthread() if thread is not None: del thread.__dict__[key] def thread_deleted(_, idt=idt): local = wrlocal() if local is not None: dct = local.dicts.pop(idt) # 封装成ReferenceType对象 wrlocal = ref(self, local_deleted) wrthread = ref(thread, thread_deleted) # 在当前线程对象的__dict__属性中,以线程id为key,wrlocal为value设置值 # 以保存不同线程的状态 thread.__dict__[key] = wrlocal # 以线程对象id为key,(ReferenceType,ReferenceType)对象为value # self为_localimpl对象 # self.dicts数据形式如下: # {2552096368904: (, {'number': 1})} self.dicts[idt] = wrthread, localdict # 未设置值前localdict为空 return localdict 此时 impl.dicts 属性已经有了 , 接下来回到我们的示例代码 , 当本地线程对象实例化完成之后 , 下一步就是设置属性 data.number = 1 , 也就是会执行 local 对象的 __setattr__ 方法 , 在上面我们把它给省略了 , 现在列出来 : def __setattr__(self, name, value): if name == '__dict__': raise AttributeError( \"%r object attribute '__dict__' is read-only\" % self.__class__.__name__) with _patch(self): return object.__setattr__(self, name, value) 可以看到 , 它走了一个 _patch 方法 , 继续看看 _patch 的详细内容 : # 该装饰器用于将_patch转换为上下文对象 @contextmanager def _patch(self): impl = object.__getattribute__(self, '_local__impl') try: # 返回当前进程对象中的字典 # 如:{'number': 1} dct = impl.get_dict() except KeyError: dct = impl.create_dict() args, kw = impl.localargs self.__init__(*args, **kw) # impl.locallock = RLock() # RLock是一个上下文对象 with impl.locallock: # 设置属性到local对象 object.__setattr__(self, '__dict__', dct) yield 到这里我们可以看出 , 如果在 _localimpl 对象的 dicts 中不存在以线程 id 为 key 的键值对 , 那么必定会调用 create_dict() 来为其创建一个 , 创建形式如下 : # key为当前线程对象id,wrlocal为ReferenceType对象 threading.current_thread().__dict__[key] = wrlocal # 随后以当前线程对象id为key,wrthread,localdict为value存入_localimpl.dicts中 # whthread中存入了当前线程对象,localdict为设置属性字典 # self.dicts[idt] = wrthread, localdict # 当然local对象的__dict__中也存在属性,因为最后调用了object的setattr方法 object.__setattr__(self, name, value) 本地线程的实现原理就是 , 数据的改变是在线程内部进行的 , 在每一个线程内部都有一个独立的字典 , 存放着那些数据 , 并且通过线程 id 和 dicts 属性 , 保存了不同线程的状态 Werkzeug的Local 🍀 总而言之 , 本地线程的实现 , 相当于在线程内部建立了一个数据副本 , 只不过我们需要一些手段来保存好这些线程的状态 上面分析的是 threading 中的本地线程 , 而 Flask 基于的 Werkzeug , 它自己实现了本地线程 , 也就是 werkzeug.local.Local 对象 : class Local(object): __slots__ = ('__storage__', '__ident_func__') def __init__(self): # 此处不能使用self.__storage__ = {}来初始化,原因: # 1. 首先会调用self.__setattr__ # 2. 随后执行self.__ident_func__(),于是会调用self.__getattr__ # 3. self.__storage__[self.__ident_func__()][name]会再次调用__getattr__ # 4. 于是,这里将永远递归下去 object.__setattr__(self, '__storage__', {}) object.__setattr__(self, '__ident_func__', get_ident) def __iter__(self): return iter(self.__storage__.items()) def __call__(self, proxy): \"\"\"Create a proxy for a name.\"\"\" return LocalProxy(self, proxy) def __release_local__(self): self.__storage__.pop(self.__ident_func__(), None) def __getattr__(self, name): try: return self.__storage__[self.__ident_func__()][name] except KeyError: raise AttributeError(name) def __setattr__(self, name, value): # 获取线程/协程标识符 ident = self.__ident_func__() storage = self.__storage__ try: storage[ident][name] = value except KeyError: # 以线程/协程标识符为key,属性键值对为value storage[ident] = {name: value} def __delattr__(self, name): try: del self.__storage__[self.__ident_func__()][name] except KeyError: raise AttributeError(name) 相对来讲 , Werkzeug 自己实现的本地线程 , 可能比 threading 提供的本地线程更加简单明了 , 两者区别如下 : Werkzeug 使用了自定义的 __storage__ 保存不同线程下的状态 Werkzeug 提供了释放本地线程的 release_local 方法 Werkzeug 使用 get_ident 函数来获取线程/协程标识符 在 werkzeug.local 中 , gent_ident 的导入如下 : try: from greenlet import getcurrent as get_ident except ImportError: try: from thread import get_ident except ImportError: from _thread import get_ident 如果已经安装了 Greenlet , 会优先使用 Greenlet , 否则将使用系统线程 ; Greenlet 是以 C 扩展模块形式接入 Python 的轻量级协程 , 它运行在操作系统进程的内部 , 但是会被协作式地调度 小结 🍀 Werkzeug 基于自己实现的 Local 还实现了两种数据结果 : LocalStack : 基于 werkzeug.local.Local 实现的栈结果 , 可以将对象推入 , 弹出 , 也可以快速拿到栈顶对象 LocalProxy : 作用和名字一样 , 最标准的代理模式 , 构造此结构时接收一个可以调用的参数 (一般为函数) , 这个函数执行后就是通过 LocalStack 实例化的栈的栈顶对象 ; 对于 LocalProxy 对象的操作实际上都会转发到这个栈顶对象 (也就是一个 thread-local 对象) 上面 本地线程是 Flask 中非常重要的一部分 , 因为在请求处理时 , 为了解决请求对象在每一个视图函数传递 (意味着每个视图函数需要像 Django 那样添加一个 request 参数) 的问题 , Flask 巧妙地使用上下文把某些对象变为全局可访问 (实际上是特定环境的局部对象的代理) , 再配合本地线程 , 这样每个线程看到的上下文对象都是不同的 本地线程 与 上下文 的结合 , 解决了 Flask 请求的问题 "},"05-Web框架/Flask/08-Flask - 源码之上下文.html":{"url":"05-Web框架/Flask/08-Flask - 源码之上下文.html","title":"Flask - 源码之上下文","keywords":"","body":"Flask - 源码之上下文 介绍 🍀 阅读本文时 , 请先了解 Flask 本地线程 相关内容 在 Flask 中实现了两种上下文对象 : 应用上下文与请求上下文 , 它们两者都是本地线程的 应用上下文 应用上下文存在的主要原因是 , 在过去 , 没有更好的方式来在请求上下文中附加一堆函数 , 因为 Flask 设计的支柱之一是你可以在一个 Python 进程中拥有多个应用 那么代码如何找到 \"正确的\" 应用呢 ? 解决这个问题常用的方法是使用 current_app 代理 (基于 werkzeug.local.Local 实现的 LocalProxy 对象) , 它被限制在当前请求的应用引用 应用上下文的典型应用场景是缓存一些在发生请求之前要使用到的资源 , 比如生成数据库连接和缓存一些对象 请求上下文 本地线程解决了请求对象在函数之间传递的问题 , 但是为了依赖注入或者尝试重用与请求相关的值的代码 , 我们需要一个有效的请求上下文 请求上下文发生在 HTTP 请求开始 , WSGIServer 调用 Flask.__call__() 之后 开始示例 🍀 先看一个简单的例子 from flask import Flask, request app = Flask(__name__) @app.route('/people/') def people(): name = request.args.get('name') return \"People Page!\" if __name__ == '__main__': app.run() 我们先细想一下 , 这里先引用了 flask.request , 但是直到用户访问 /people/ 时才通过 request.args.get('name') 获得请求的 name 字段 , 而在引用时这个请求还没有发生 , 那么请求上下文是怎么获得的呢 ? 其流程是这样的 : 用户访问产生请求 在发生请求的过程中向 _request_ctx_stack 推入这个请求上下文对象 , 它会变成栈顶 , request 就会成为这个请求上下文 , 也就包含了本次请求相关的信息和数据 在视图函数中使用 request 就可以使用 request.args.get('name') 了 flask.request 就是获取一个名为 _request_ctx_stack 的栈顶对象的 LocalProxy 实例 : # partial函数的作用是返回一个给定参数的函数 from functools import partial from werkzeug.local import LocalStack, LocalProxy # _lookup_req_object的name参数将固定为'request' request = LocalProxy(partial(_lookup_req_object, 'request')) def _lookup_req_object(name): # 获取_request_ctx_stack栈顶对象,也就是RequestContext对象 top = _request_ctx_stack.top if top is None: raise RuntimeError(_request_ctx_err_msg) # 获取RequestContext.request属性值 return getattr(top, name) 上面已经说过 , 请求上下文发生在 HTTP 请求开始 , 而请求的开始则是 Flask.__call__() 开始 , WSGIServer 将会调用 Flask 应用对象作为 WSGI 应用 , 也就是会调用 Flask.wsgi_app() : def wsgi_app(self, environ, start_response): # 实例化请求上下文对象 ctx = self.request_context(environ) error = None try: try: # 将请求上下文对象压入栈中,在这之前会先将应用上下文压入栈中 ctx.push() # 返回response对象 response = self.full_dispatch_request() except Exception as e: error = e response = self.handle_exception(e) except: error = sys.exc_info()[1] raise # 调用BaseResponse的__call__方法 # 交给WSGI服务器处理 return response(environ, start_response) finally: if self.should_ignore_error(error): error = None ctx.auto_pop(error) RequestContext.push() 如下 : def push(self): \"\"\"Binds the request context to the current context.\"\"\" # 获取栈顶 top = _request_ctx_stack.top if top is not None and top.preserved: top.pop(top._preserved_exc) # Before we push the request context we have to ensure that there # is an application context. app_ctx = _app_ctx_stack.top if app_ctx is None or app_ctx.app != self.app: # 生成应用上下文AppContext app_ctx = self.app.app_context() # 将应用上下文推入栈中 app_ctx.push() self._implicit_app_ctx_stack.append(app_ctx) else: self._implicit_app_ctx_stack.append(None) if hasattr(sys, 'exc_clear'): sys.exc_clear() # 将请求上下文推入栈中 _request_ctx_stack.push(self) if self.session is None: session_interface = self.app.session_interface self.session = session_interface.open_session( self.app, self.request ) if self.session is None: self.session = session_interface.make_null_session(self.app) 可以看到在 RequestContext.push() 中 , 并不是仅仅将请求上下文压入了栈中 , 同时它还生成了应用上下文并压入了栈中 也就是说 , 事实上在 Web 应用环境中 , 请求上下文和应用上下文是一一对应的 , 请求上下文和应用上下文都是本地线程的 全局变量 🍀 Flask 中有 6 个全局变量 : 2 个本地线程变量和 4 个上下文变量 它们都储存在 flask.globals.py : # context locals # 请求上下文栈,存储请求上下文,基于werkzeug的本地线程实现的栈结构 _request_ctx_stack = LocalStack() # 应用上下文栈,存储应用上下文,基于werkzeug的本地线程实现的栈结构 _app_ctx_stack = LocalStack() # 应用上下文,它是当前app的实例对象 current_app = LocalProxy(_find_app) # 请求上下文,它封装了客户端发出的HTTP请求中的内容 request = LocalProxy(partial(_lookup_req_object, 'request')) # 请求上下文,它存储了用户会话 session = LocalProxy(partial(_lookup_req_object, 'session')) # 应用上下文,它是处理请求时用作临时存储的对象 g = LocalProxy(partial(_lookup_app_object, 'g')) LocalStack() 的内是在 werkzeug.local.Local() 的基础上实现栈的一个结果 , 而 werkzeug.local.Local() 在上一篇中已经分析过了 LocalProxy() 是一个代理对象 , 如通过它来获取请求上下文对象中的 request 属性 关于 LocalProxy 的一些说明 : LocalProxy 传入一个函数为参数 , 其构造函数如下 def __init__(self, local, name=None): # _类名__属性名为私有属性的另一表现形式,此处等价于如下: # self.__local = local object.__setattr__(self, '_LocalProxy__local', local) object.__setattr__(self, '__name__', name) if callable(local) and not hasattr(local, '__release_local__'): # \"local\" is a callable that is not an instance of Local or # LocalManager: mark it as a wrapped function. object.__setattr__(self, '__wrapped__', local) LocalProxy 不会进行额外的操作 , 它会将对其本身的操作转接到上下文对象 我们也可以利用 LocalStack 与 LocalProxy 自己来实现一个全局可访问的 current_user : from werkzeug.local import LocalStack, LocalProxy from flask import Flask import random app = Flask(__name__) _user_err_msg = '''\\ Working outside of login user.\\ ''' _user_stack = LocalStack() def get_current_user(): top = _user_stack.top if top is None: raise RuntimeError(_user_err_msg) return top current_user = LocalProxy(get_current_user) @app.before_request def before_request(): users = ['Lyon', 'Kenneth'] user = random.choice(users) _user_stack.push(user) @app.teardown_appcontext def teardown(exc=None): _user_stack.pop() @app.route('/user') def user_view(): return current_user.__str__() if __name__ == '__main__': app.run() 服务启动后 , 我们多次访问 http://127.0.0.1:5000/user 可观察响应 请求上下文 🍀 在我们使用 flask.request 之前 , 我们必须保证在 _request_ctx_stack 中有 RequestContext 对象 , 因为在 Flask 中 , 请求的处理是从创建 RequestContext 对象 , 并将该对象压入 _request_ctx_stack 栈开始的 # ctx = self.request_context(environ) # environ是由WSGIRequestHandler.make_enviro()制造而来 class RequestContext(object): \"\"\" 请求上下文中包含了请求相关的所有信息 \"\"\" def __init__(self, app, environ, request=None): # Flask应用实例 self.app = app if request is None: # 实例化Request对象 request = app.request_class(environ) self.request = request # 为请求创建一个URL适配器 self.url_adapter = app.create_url_adapter(self.request) self.flashes = None self.session = None # 一个隐式的应用上下文栈 self._implicit_app_ctx_stack = [] # 显示上下文是否被保留 self.preserved = False # remembers the exception for pop if there is one in case the context # preservation kicks in. self._preserved_exc = None # 请求后执行函数 self._after_request_functions = [] # 将Request对象与URL连接 self.match_request() 既然是上下文对象 , 也就以为着在 RequestContext 中必然定义了 __enter__ 与 __exit__ : def __enter__(self): # 将RequestContext对象压入栈中并返回 self.push() return self def __exit__(self, exc_type, exc_value, tb): # 关闭上下文环境时从栈中弹出 self.auto_pop(exc_value) if BROKEN_PYPY_CTXMGR_EXIT and exc_type is not None: reraise(exc_type, exc_value, tb) 所以我们可以使用 with 来开启上下文环境 from flask import Flask from flask.globals import _request_ctx_stack app = Flask(__name__) # 如果你在请求开始前或者请求结束后查看请求上下文栈中的stack # 很不幸,请求开始前还没有这一属性 # 请求结束后,这一属性也被销毁,因为请求上下文对象销毁了 with app.test_request_context('/?next=http://example.com/') as rqc: print(rqc.request) print(_request_ctx_stack._local.stack) \"\"\" 执行结果: [] \"\"\" 回调与错误 🍀 在 Flask 中 , 请求处理时如果发生了一个错误将会发生什么事 ? 这个特殊的行为如下: 在每个请求之前 , 执行 before_request() 上绑定的函数 , 如果这些函数中的某个返回了一个响应 , 其它的函数将不再被调用 , 任何情况下 , 这个返回值都将替换视图函数的返回值 (这一步就像 Django 中的中间件一样) 如果 before_request() 上绑定的函数没有返回一个响应 , 常规的请求处理将会生效 , 匹配的视图函数有机会返回一个响应 视图的返回值之后会被转换成一个实际的响应对象 , 并交给 after_request() 上绑定的函数适当地替换或修改它 在请求的最后 , 会执行 teardown_request() 上绑定的函数 , 这总会发生 , 即使在一个未处理的异常抛出后或是没有请求前处理器执行过 (例如在测试环境中你有时会想不执行请求前回调) 在生产模式中 , 如果一个异常没有被捕获 , 将调用 500 internal server 的处理 , 在生产模式中 , 即便异常没有被处理过 , 也会冒泡给 WSGI 服务器 , 如此 , 像交互式调试器这样的东西可以提供丰富的调试信息 应用上下文 🍀 应用上下文会按需自动创建和销毁 , 如在将请求上下文对象压入栈中时 , 如果应用上下文栈中没有 , 则会先创建应用上下文 , 它不会在线程间移动 , 并且也不会在请求间共享 应用上下文通常是用来缓存那些用于请求之前创建或者请求使用情况下的资源 , 例如数据库连接是注定要使用应用上下文 . 存储的东西时应该为应用程序上下文选择唯一的名称 , 因为这是一个 Flask 应用和扩展之间共享的地方 class AppContext(object): \"\"\"The application context binds an application object implicitly to the current thread or greenlet, similar to how the :class:`RequestContext` binds request information. The application context is also implicitly created if a request context is created but the application is not on top of the individual application context. \"\"\" def __init__(self, app): self.app = app self.url_adapter = app.create_url_adapter(None) #: The class that is used for the :data:`~flask.g` instance. #: #: Example use cases for a custom class: #: #: 1. Store arbitrary attributes on flask.g. #: 2. Add a property for lazy per-request database connectors. #: 3. Return None instead of AttributeError on unexpected attributes. #: 4. Raise exception if an unexpected attr is set, a \"controlled\" flask.g. #: #: In Flask 0.9 this property was called `request_globals_class` but it #: was changed in 0.10 to :attr:`app_ctx_globals_class` because the #: flask.g object is now application context scoped. # app_ctx_globals_class = _AppCtxGlobals self.g = app.app_ctx_globals_class() # 引用计数,以追踪被压入栈的次数 self._refcnt = 0 "},"05-Web框架/Flask/09-Flask - 源码之信号.html":{"url":"05-Web框架/Flask/09-Flask - 源码之信号.html","title":"Flask - 源码之信号","keywords":"","body":"Flask - 源码之信号 介绍 🍀 项目功能越复杂 , 代码量越大 , 就越需要在其之上做开发和维护是很痛苦的 , 尤其是对于团队的新人 ; 而信号就是在框架核心功能或者一些 Flask 扩展发生动作时发送的通知 , 利用信号可以实现一部分的业务解藕 在 Flask 中 , 信号功能由 Blinker 库提供 , 如果没有安装该库就无法使用信号功能 , 但是不会影响其他功能 , 因为如果没有该库 , Flask 将提供一个假的信号 , flask.signals.py 中 : signals_available = False try: from blinker import Namespace signals_available = True except ImportError: class Namespace(object): def signal(self, name, doc=None): return _FakeSignal(name, doc) class _FakeSignal(object): \"\"\"If blinker is unavailable, create a fake class with the same interface that allows sending of signals but will fail with an error on anything else. Instead of doing anything on send, it will just ignore the arguments and do nothing instead. \"\"\" def __init__(self, name, doc=None): self.name = name self.__doc__ = doc def _fail(self, *args, **kwargs): raise RuntimeError('signalling support is unavailable ' 'because the blinker library is ' 'not installed.') send = lambda *a, **kw: None connect = disconnect = has_receivers_for = receivers_for = \\ temporarily_connected_to = connected_to = _fail del _fail # The namespace for code signals. If you are not Flask code, do # not put signals in here. Create your own namespace instead. _signals = Namespace() 所以我们应该先安装 Blinker : $ pip install blinker 下面是一个 Blinker 的示例 : from blinker import signal # 创建信号 started = signal('test-started') def each(round): print(\"Round {}!\".format(round)) def round_two(round): print(\"Only {}\".format(round)) # 订阅信号,each为接收者 started.connect(each) # round_two为接收者,sender为发送者 # 表示只有发送者为2时才接收 started.connect(round_two, sender=2) for round in range(1,4): # 发送信号 started.send(round) Flask 中有一些钩子 , 如 before_request 和 after_request , 这些钩子不需要 Blinker 库并且允许你改变请求对象 (request) 或者响应对象 (response) , 而信号和钩子做的事情很像 , 只不过信号并不对请求对象和响应对象做改变 , 仅承担记录和通知的工作 内置信号 🍀 在 flask.signals.py 中我们可以看到 , Flask 内置了 10 个信号 : # 模板渲染成功时发送 template_rendered = _signals.signal('template-rendered') # 模板渲染前发送 before_render_template = _signals.signal('before-render-template') # 建立请求上下文后,在请求处理开始前发送 request_started = _signals.signal('request-started') # 在响应发送给客户端之前发送 request_finished = _signals.signal('request-finished') # 请求销毁时发送,无论请求成败都会发送 request_tearing_down = _signals.signal('request-tearing-down') # 请求处理抛出异常时发送 got_request_exception = _signals.signal('got-request-exception') # 应用上下文销毁时发送 appcontext_tearing_down = _signals.signal('appcontext-tearing-down') # 应用上下文进栈中时发送 appcontext_pushed = _signals.signal('appcontext-pushed') # 应用上下文出栈时发送 appcontext_popped = _signals.signal('appcontext-popped') # 调用flask在其中添加数据时发送 message_flashed = _signals.signal('message-flashed') 创建信号 🍀 我们以 request_started 为例来看看其内部实现 : from blinker import Namespace _signals = Namespace() # 调用Namespace对象的signal方法 # 完成信号对象的创建,并使其成为全局引用 request_started = _signals.signal('request-started') Namespace.signal() 如下 : class Namespace(dict): \"\"\"A mapping of signal names to signals.\"\"\" def signal(self, name, doc=None): \"\"\" 返回NamedSignal对象 \"\"\" try: return self[name] except KeyError: # Namespace为内置对象dict的派生类, # 设置并返回值, # self.request-started = NameSignal('request-started') return self.setdefault(name, NamedSignal(name, doc)) 订阅信号 🍀 如果我们要使用内置信号 , 那么首先我们需要订阅信号 , 也就是使用 Signal.connect() 方法 from flask import Flask, request_started app = Flask(__name__) # log_reqeust函数为接收方,app为发送方 # 对于接收函数的参数,第一个位置不可缺省, # 因为在send调用该函数时,内部传入了一个sender实参 def log_request(sender, **extra): print('Before the request comes ...') # 订阅信号 request_started.connect(log_request, app) @app.route('/index') def index(): return 'index page' if __name__ == '__main__': app.run() connect() 源码如下 : def connect(self, receiver, sender=ANY, weak=True): \"\"\" Connect *receiver* to signal events sent by *sender*. receiver:为一个可调用对象 \"\"\" receiver_id = hashable_identity(receiver) if weak: # # receiver将在send时被调用,self._cleanup_receiver receiver_ref = reference(receiver, self._cleanup_receiver) receiver_ref.receiver_id = receiver_id else: receiver_ref = receiver if sender is ANY: sender_id = ANY_ID else: sender_id = hashable_identity(sender) self.receivers.setdefault(receiver_id, receiver_ref) # self._by_sender与self._by_receiver为两个默认字典,其value默认为set # {sender_id:{receiver_id,}} self._by_sender[sender_id].add(receiver_id) # {receiver_id:{sender_id,}} self._by_receiver[receiver_id].add(sender_id) del receiver_ref # 此时self._weak_senders为空,所以以下不会执行 if sender is not ANY and sender_id not in self._weak_senders: # wire together a cleanup for weakref-able senders try: sender_ref = reference(sender, self._cleanup_sender) sender_ref.sender_id = sender_id except TypeError: pass else: self._weak_senders.setdefault(sender_id, sender_ref) del sender_ref # 此处条件不成立,也不会执行 if ('receiver_connected' in self.__dict__ and self.receiver_connected.receivers): try: self.receiver_connected.send(self, receiver=receiver, sender=sender, weak=weak) except: self.disconnect(receiver, sender) raise # receiver_connected为空 if receiver_connected.receivers and self is not receiver_connected: try: receiver_connected.send(self, receiver_arg=receiver, sender_arg=sender, weak_arg=weak) except: self.disconnect(receiver, sender) raise return receiver 发送信号 🍀 信号的发送是通过 Signal.send() 来完成的 , 而这一步早已经被定义在 Flask 对象中了 , 如下 : def full_dispatch_request(self): self.try_trigger_before_first_request_functions() try: # 请求处理前发送信号 request_started.send(self) rv = self.preprocess_request() if rv is None: # 分派请求 rv = self.dispatch_request() except Exception as e: rv = self.handle_user_exception(e) return self.finalize_request(rv) Signal.send() 如下 : def send(self, *sender, **kwargs): \"\"\"Emit this signal on behalf of *sender*, passing on \\*\\*kwargs. Returns a list of 2-tuples, pairing receivers with their return value. The ordering of receiver notification is undefined. :param \\*sender: Any object or ``None``. If omitted, synonymous with ``None``. Only accepts one positional argument. :param \\*\\*kwargs: Data to be sent to receivers. \"\"\" # Using '*sender' rather than 'sender=None' allows 'sender' to be # used as a keyword argument- i.e. it's an invisible name in the # function signature. if len(sender) == 0: sender = None elif len(sender) > 1: raise TypeError('send() accepts only one positional argument, ' '%s given' % len(sender)) else: # 取*sender元组中的第一个元素,即self (app) sender = sender[0] if not self.receivers: return [] else: # 返回并完成调用 return [(receiver, receiver(sender, **kwargs)) for receiver in self.receivers_for(sender)] Signal.receivers_for() 如下 : def receivers_for(self, sender): \"\"\"Iterate all live receivers listening for *sender*.\"\"\" # TODO: test receivers_for(ANY) # self.receivers在信号订阅时被设置 if self.receivers: sender_id = hashable_identity(sender) if sender_id in self._by_sender: # 按照上面的例子我们使用的sender不是ANY, # 所以self._by_sender[ANY_ID]为一个空集合, # {sender_id:{receiver_id,}} # self._by_sender[sender_id]为本例ids ids = (self._by_sender[ANY_ID] | self._by_sender[sender_id]) else: ids = self._by_sender[ANY_ID].copy() for receiver_id in ids: # 根据receiver_id获取weakref对象 receiver = self.receivers.get(receiver_id) if receiver is None: continue if isinstance(receiver, WeakTypes): # strong为订阅函数,即本例的log_reqeust # 这里你可能会疑惑,见下 strong = receiver() if strong is None: # 释放信号 self._disconnect(receiver_id, ANY_ID) continue receiver = strong # 返回函数对象 yield receiver 在上面这段代码中 , 对于 strong = receiver() 我们知道 , WeakTypes = (ref, BoundMethodWeakref) , 而在这两个类型中 , ref 才是正主 ; 不用想我们也知道 , ref 也就是 ReferenceType 中必然有 __call__ 方法 , 但是该方法仅仅一个 pass 摆在那里 , 而调用的返回值却返回了我们的订阅函数 , 这不正常 于是 , 在 ReferenceType 的上方我找到了说明 , Weak-reference support module 这个类型是一个弱引用类型 , 它是一个特殊的存在 , 当你对弱引用对象进行引用时 , 并不能保持该类对象的活动 , 只有通过调用引用判断 ; 如果该引用还存活着 , 那么将返回其引用对象 , 否则将会进行回调 大致过程如下 : # 依次调用代码 receiver_ref = reference(receiver, self._cleanup_receiver) weak = callable_reference(object, callback) return annotatable_weakref(object, callback) class annotatable_weakref(ref): 弱引用对象没有属性或方法 , 如下有一个示例 : import weakref class Foo: pass # 实例化Foo o = Foo() # 包装成弱引用对象 r = weakref.ref(o) # 调用弱引用对象 r_result = r() print(o is r_result) \"\"\" 执行结果: True \"\"\" 弱引用详见 : weakref 最后 , 对于其它信号的发送相关代码位置 , 我们可以通过导入信息来查看 , 导入信息如下 : # app.py (5个) from .signals import appcontext_tearing_down, got_request_exception, \\ request_finished, request_started, request_tearing_down # ctx.py (2个) from .signals import appcontext_pushed, appcontext_popped # templating.py (2个) from .signals import template_rendered, before_render_template # helpers.py (1个) from .signals import message_flashed 这里就不再分析其它信号了 自定义信号 🍀 在我们的应用中 , 我们可以直接使用 Blinker 创建信号 , 如下 , 定义一中对于上传大文件的信号 : from blinker import Namespace web_signals = Namespace() large_file_saved = web_signals.signal('large-file-saved') 简直不要太简单 装饰器方式 🍀 在 Signal 对象中还有一个 connect_via() 装饰器订阅信号 , 如下 : def connect_via(self, sender, weak=False): def decorator(fn): self.connect(fn, sender, weak) return fn return decorator 这个就没必要分析了 , 看看用法吧 , 以 flask.appcontext_tearing_down 为例 : from flask import Flask, appcontext_tearing_down, session app = Flask(__name__) @appcontext_tearing_down.connect_via(app) def close_db_connection(sender, **extra): print('Database connection closed ...') @app.route('/index') def index(): return 'index page' if __name__ == '__main__': app.run() 另外在 Flask-Login 插件中还带了 6 种信号 , 可以基于其中的信号做一些额外工作 , 待后续添加 "},"05-Web框架/Flask/10-Flask - 扩展.html":{"url":"05-Web框架/Flask/10-Flask - 扩展.html","title":"Flask - 扩展","keywords":"","body":"Flask - 扩展 介绍 🍀 Flask 扩展多方面地扩充了 Flask 功能 , 例如它们添加了数据库支持以及其他常见任务 Flask 扩展的生态非常繁荣 , Flask 扩展被列出在 Flask Extension Registry 上并且我们可以直接用 easy_install 或者 pip 进行下载安装 下面介绍一些常用的扩展以及它们的使用方式 Flask-Script 🍀 Django 提供了如下管理命令 : $ python manage.py startapp $ python manage.py runserver Flask 也可以通过 Flask-Script 添加运行服务器 , 设置数据库 , 定制 shell 等功能的命令 安装 $ pip install flask-script 创建 py 文件 manage.py , 内容如下 : from flask_script import Manager app = Flask(__name__) # configure your app # Manager将跟踪从命令行调用的所有命令和句柄 manager = Manager(app) if __name__ == \"__main__\": manager.run() 随后我们在当前目录下 : >python manage.py --help # 看来默认有shell和runserver usage: manage.py [-?] {shell,runserver} ... positional arguments: {shell,runserver} shell Runs a Python shell inside Flask application context. runserver Runs the Flask development server i.e. app.run() optional arguments: -?, --help show this help message and exit 创建命令 🍀 接下来我们需要创建我们自己的命令 , 创建命令有三种方式 : 通过实现 Command 类 使用 @command 装饰器 使用 @option 装饰器 通过 Command 类 : from flask_script import Command class Hello(Command): \"prints hello world\" def run(self): print(\"hello world\") # 将创建的命令添加到Manager实例 manager.add_command('hello', Hello()) 通过 @command 装饰器 : @manager.command def lyon(): \"Just say lyon\" print(\"lyon\") 通过 @option 装饰器 : # @option用于读复杂命令进行控制 @manager.option('-n', '--name', help='Your name') def send(name): \"send name of you\" print(\"hello\", name) 我们再次执行 python manage.py --help >python manage.py --help usage: manage.py [-?] {hello,lyon,send,shell,runserver} ... positional arguments: {hello,lyon,send,shell,runserver} hello prints hello world lyon Just say lyon send send name of you shell Runs a Python shell inside Flask application context. runserver Runs the Flask development server i.e. app.run() optional arguments: -?, --help show this help message and exit 添加参数 🍀 大多数命令都采用了在命令行中传递许多命名参数或者位置参数 , 为了方便这一点 , 我们可以使用 Command 类中的 option_list 属性 : from flask_script import Command, Manager, Option class Hello(Command): option_list = ( Option('--name', '-n', dest='name'), ) def run(self, name): print \"hello %s\" % name 或者定义 get_options 方法 : class Hello(Command): def __init__(self, default_name='Joe'): self.default_name=default_name def get_options(self): return [ Option('-n', '--name', dest='name', default=self.default_name), ] def run(self, name): print \"hello\", name 如果使用的是 @command 装饰器 , 那么我们直接加在被装饰函数中就可以了 @manager.command def verify(verified=False): \"\"\" Checks if verified \"\"\" print \"VERIFIED?\", \"YES\" if verified else \"NO\" 结果如下 : > python manage.py verify VERIFIED? NO > python manage.py verify -v VERIFIED? YES > python manage.py verify --verified VERIFIED? YES 其次就是创建命令时使用的 @option 了 , 也可添加任意多个选项 : @manager.option('-n', '--name', dest='name', default='joe') @manager.option('-u', '--url', dest='url', default=None) def hello(name, url): if url is None: print \"hello\", name else: print \"hello\", name, \"from\", url Documentation : Read docs @ pythonhosted.org Flask-DebugToolbar 🍀 Django 有非常知名的 Django-DebugToolbar , 而 Flask 也有对应的替代工具 Flask-DebugToolbar 它会在浏览器上添加右边栏 , 可以快速查看环境变量 , 上下文内容 , 方便调试 安装 $ pip install flask-debugtoolbar 使用前提 : debug 必须药设置为 True 示例 from flask import Flask from flask_debugtoolbar import DebugToolbarExtension app = Flask(__name__) app.debug = True app.config['SECRET_KEY'] = 'a secret key' toolbar = DebugToolbarExtension(app) @app.route('/') def hello(): return '' if __name__ == '__main__': app.run(host='127.0.0.1', port=9000, debug=app.debug) 接下来使用浏览器访问 http://127.0.0.1:9000/ 就可以看到有右边栏了 Flask-DebugToolbar 内置了很多面板 , 如下 : 面板 功能 Versions 列出安装的包的版本 Time 显示处理当前请求花费的时间的信息 HTTP Headers 显示当前请求的 HTTP 头信息 Request Vars 显示当前请求带的变量 , 包含请求参数 , cookie 信息等 Config 显示 app.config 的变量值 Templates 显示模板请求参数信息 SQLAlchemy 显示当前请求下的 SQL , 需要设置 SQLALCHEMY_RECORD_QUERIES 为 True Logging 显示请求过程中的日志信息 Route List 列出 Flask 的路由规则 Profiler 对当前请求添加性能分析 , 默认是关闭的 , 需要点击红色的钩 , 让它变成绿色 Documentation : Read docs @ github.com Flask-Migrate 🍀 使用关系型数据库时 , 修改数据库模型和更新数据库这样的工作时有发生 , 而且很重要 SQLAlchemy 作者为此开发了迁移框架 Alembic , Flask-Migrate 就是基于 Alembic 做了轻量级封装 , 并集成到 Flask-Script 中 , 所有操作都通过 Flask-Script 命令完成 , 它能跟踪数据库结构的变化 , 把变化的部分应用到数据库中 安装 $ pip install Flask-Migrate 示例 manage.py from flask import Flask from flask-script import Manager from flask_sqlalchemy import SQLAlchemy from flask_migrate import Migrate, MigrateCommand app = Flask(__name__) app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///app.db' db = SQLAlchemy(app) migrate = Migrate(app, db) class User(db.Model): id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(128)) manager = Manager(app) manager.add_command(\"db\",MigrateCommand) if __name__ == '__main__': manager.run() 执行命令 # 初始化 >python manage.py db init Python35\\site-packages\\flask_sqlalchemy\\__init__.py:794: FSADeprecationWarning: SQLALCHEMY_TRACK_MODIFICATIONS adds significant overhead and will be disabled by default in the future. Set it to True or False to suppress this warning. 'SQLALCHEMY_TRACK_MODIFICATIONS adds significant overhead and ' Creating directory demo\\migrations ... done Creating directory demo\\migrations\\versions ... done Generating demo\\migrations\\alembic.ini ... done Generating demo\\migrations\\env.py ... done Generating demo\\migrations\\README ... done Generating demo\\migrations\\script.py.mako ... done Please edit configuration/connection/logging settings in 'demo\\\\migrations\\\\alembic.ini' before proceeding. # 创建迁移脚本 >python manage.py db migrate Python35\\site-packages\\flask_sqlalchemy\\__init__.py:794: FSADeprecationWarning: SQLALCHEMY_TRACK_MODIFICATIONS adds significant overhead and will be disabled by default in the future. Set it to True or False to suppress this warning. 'SQLALCHEMY_TRACK_MODIFICATIONS adds significant overhead and ' INFO [alembic.runtime.migration] Context impl SQLiteImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. INFO [alembic.autogenerate.compare] Detected added table 'user' Generating demo\\migrations\\versions\\d121144e719e_.py ... done 更新数据库 >python manage.py db upgrade Python35\\site-packages\\flask_sqlalchemy\\__init__.py:794: FSADeprecationWarning: SQLALCHEMY_TRACK_MODIFICATIONS adds significant overhead and will be disabled by default in the future. Set it to True or False to suppress this warning. 'SQLALCHEMY_TRACK_MODIFICATIONS adds significant overhead and ' INFO [alembic.runtime.migration] Context impl SQLiteImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. INFO [alembic.runtime.migration] Running upgrade -> d121144e719e, empty message Documentation : Read docs @ pythonhosted.org Flask-RESTful 🍀 Flask-RESTful 帮助你快速创建 REST API 服务 安装 $ pip install flask-restful 示例 config.py DEBUG = True SQLALCHEMY_DATABASE_URI = 'sqlite:///app.db' UPLOAD_FOLDER = '/tmp/permdir' SQLALCHEMY_TRACK_MODIFICATIONS = False SECRET_KEY = 'a secret key' manage.py from flask import Flask, request from flask_restful import Resource, Api, reqparse, fields, marshal_with from flask_sqlalchemy import SQLAlchemy app = Flask(__name__) app.config.from_object('config') api = Api(app) db = SQLAlchemy(app) parser = reqparse.RequestParser() parser.add_argument('admin', type=bool, help='Use super manager mode', default=False) resource_fields = { 'id': fields.Integer, 'name': fields.String, 'address': fields.String } class User(db.Model): __tablename__ = 'restful_user' id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(128), nullable=False) address = db.Column(db.String(128), nullable=True) db.create_all() class UserResource(Resource): @marshal_with(resource_fields) def get(self, name): user = User.query.filter_by(name=name).first() return user def put(self, name): address = request.form.get('address', '') user = User(name=name, address=address) db.session.add(user) db.session.commit() return {'ok': 0}, 201 def delete(self, name): args = parser.parse_args() is_admin = args['admin'] if not is_admin: return {'error': 'You do not have permissions'} user = User.query.filter_by(name=name).first() db.session.delete(user) db.session.commit() return {'ok': 0} api.add_resource(UserResource, '/users/') if __name__ == '__main__': app.run(host='127.0.0.1', port=9000, debug=True) 利用 http 工具在命令行访问 : # 添加数据 >http -f put http://localhost:9000/users/Lyon address='Beijing' HTTP/1.0 201 CREATED Content-Length: 16 Content-Type: application/json Date: Thu, 28 Jun 2018 12:00:18 GMT Server: Werkzeug/0.12.2 Python/3.5.2 { \"ok\": 0 } # 删除数据 >http -f delete http://localhost:9000/users/Lyon --print b { \"error\": \"You do not have permissions\" } # 以管理员身份删除数据 >http -f delete http://localhost:9000/users/Lyon admin=1 --print b { \"ok\": 0 } # 查询数据 >http -f get http://localhost:9000/users/Lyon --print b { \"address\": null, \"id\": 0, \"name\": null } Documentation : Read docs @ flask-restful.readthedocs.org Flask-Admin 🍀 有了 Flask-Admin 的帮助 , 我们用很少的代码就能像 Django 那样实现一个管理后台 , 它支持 Pymongo , Peewee , Mongoengine , SQLAlchemy 等数据库使用方法 , 自带了基于模型的数据管理 , 文件管理 , Redis 的页面命令行等类型后台 , 尤其是模型的管理后台 , 甚至可以细粒度定制字段级别的权限 安装 $ pip install Flask-Admin 示例 Flask 示例 Documentation : Read docs @ flask-admin.readthedocs.org "},"05-Web框架/Flask/DBUtils.html":{"url":"05-Web框架/Flask/DBUtils.html","title":"DBUtils","keywords":"","body":"DBUtils 介绍 🍀 DBUtils 是 Python 的一个用于实现数据库连接池的模块 , 此连接池有两种连接模式 模式一 🍀 为每个线程创建一个连接 , 线程即使调用了 close 方法 , 也不会关闭 , 只是把连接重新放到连接池 , 供自己线程再次使用 , 当线程终止时 , 连接自动关闭 import time import pymysql import threading from DBUtils.PooledDB import PooledDB, SharedDBConnection POOL = PersistentDB( # 使用链接数据库的模块 creator=pymysql, # 一个链接最多被重复使用的次数,None表示无限制 maxusage=None, # 开始会话前执行的命令列表,如:[\"set datestyle to ...\", \"set time zone ...\"] setsession=[], # ping MySQL服务端,检查是否服务可用 # 0 = None = never, # 1 = default = whenever it is requested, # 2 = when a cursor is created, # 4 = when a query is executed, # 7 = always ping=0, # 如果为False,conn.close()实际上被忽略,供下次使用,再线程关闭时,才会自动关闭链接 # 如果为True,conn.close()则关闭链接,那么再次调用pool.connection时就会报错,因为已经真的关闭了连接(pool.steady_connection()可以获取一个新的链接) closeable=False, # 本线程独享值得对象,用于保存链接对象,如果链接对象被重置 threadlocal=None, host='127.0.0.1', port=3306, user='root', password='123', database='pooldb', charset='utf8' ) def func(): conn = POOL.connection(shareable=False) cursor = conn.cursor() cursor.execute('select * from tb1') result = cursor.fetchall() cursor.close() conn.close() func() 模式二 🍀 创建一批连接到连接池 , 供所有线程共享使用 (由于 pymysql , MySQLdb 等 threadsafety 值为 1 , 所以该模式连接池中的线程会被所有线程共享) import time import pymysql import threading from DBUtils.PooledDB import PooledDB, SharedDBConnection POOL = PooledDB( # 使用链接数据库的模块 creator=pymysql, # 连接池允许的最大连接数,0和None表示不限制连接数 maxconnections=6, # 初始化时,链接池中至少创建的空闲的链接,0表示不创建 mincached=2, # 链接池中最多闲置的链接,0和None不限制 maxcached=5, # 链接池中最多共享的链接数量,0和None表示全部共享 # PS: 无用,因为pymysql和MySQLdb等模块的 threadsafety都为1,所有值无论设置为多少,_maxcached永远为0,所以永远是所有链接都共享 maxshared=3, # 连接池中如果没有可用连接后,是否阻塞等待;True,等待;False,不等待然后报错 blocking=True, # 一个链接最多被重复使用的次数,None表示无限制 maxusage=None, # 开始会话前执行的命令列表,如:[\"set datestyle to ...\", \"set time zone ...\"] setsession=[], # ping MySQL服务端,检查是否服务可用 # 0 = None = never, # 1 = default = whenever it is requested, # 2 = when a cursor is created, # 4 = when a query is executed, # 7 = always ping=0, host='127.0.0.1', port=3306, user='root', password='123', database='pooldb', charset='utf8' ) def func(): # 检测当前正在运行连接数的是否小于最大链接数,如果不小于则等待或报raise TooManyConnections异常 # 否则则优先去初始化时创建的链接中获取链接 SteadyDBConnection, # 然后将SteadyDBConnection对象封装到PooledDedicatedDBConnection中并返回, # 如果最开始创建的链接没有链接,则去创建一个SteadyDBConnection对象,再封装到PooledDedicatedDBConnection中并返回, # 一旦关闭链接后,连接就返回到连接池让后续线程继续使用 conn = POOL.connection() # print(th, '链接被拿走了', conn1._con) # print(th, '池子里目前有', pool._idle_cache, '\\r\\n') cursor = conn.cursor() cursor.execute('select * from tb1') result = cursor.fetchall() conn.close() func() "},"05-Web框架/Flask/virtualenv基本使用.html":{"url":"05-Web框架/Flask/virtualenv基本使用.html","title":"virtualenv基本使用","keywords":"","body":"virtualenv基本使用 介绍 🍀 随着我们所开发或者管理的项目越来越多 , 这就导致了有可能存在不同版本的Python , 又或者是不同版本的Python库 , 于是问题就出现了 , 库的版本问题颇快了向后兼容性的情况相当常见 , 而且零依赖的正式应用也不大可能存在 , 所以项目中的两个或者更多出现依赖性冲突就会频繁出现 所以 , 为了解决这些冲突 , virtualenv出现了 , virtualenv能够允许多个不同版本的Python安装 , 每一个服务与各自的项目 , 但是它并不是分别独立安装一个Python的副本 , 而是提供了一种方式使得环境保持独立 安装virtualenv 🍀 实际上 , virtualenv就是一个Python库 , 所以我们可以使用pip等命令进行安装 Mac OS X 或者 Linux 下 $ sudo pip install virtualenv 如果使用Ubuntu , 请尝试 $ sudo apt-get install python-virtualenv 在 Windows 下 $ pip install virtualenv 创建虚拟环境 🍀 通常我们会先创建一个项目文件夹 , 在其下创建venv虚拟环境 : $ mkdir myproject $ cd myproject $ virtualenv venv New python executable in venv/bin/python Installing distribute............done. 指定Python解释器 $ virtualenv -p /usr/bin/python2.7 venv 激活虚拟环境 🍀 在OS X 和Linux 下 $ . venv/bin/activate 在 Windows 下 $ venv\\scripts\\activate 在 Mac 下 $ source venv/bin/activate 退出虚拟环境 🍀 在OS X 和Linux 下 $ . venv/bin/deactivate 在 Windows 下 $ venv\\scripts\\deactivate.bat 在 Mac 下 $ deactivate "},"05-Web框架/Tornado/":{"url":"05-Web框架/Tornado/","title":"Tornado","keywords":"","body":"Tornado初识 "},"06-Redis/":{"url":"06-Redis/","title":"Redis","keywords":"","body":"Redis REmote DIctionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统 Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API 它通常被称为数据结构服务器 , 因为值(value)可以是 字符串(String), 哈希(Map) , 列表(list) , 集合(sets) 和有序集合(sorted sets)等类型 "},"06-Redis/01-Redis - 简介.html":{"url":"06-Redis/01-Redis - 简介.html","title":"Redis - 简介","keywords":"","body":"Redis - 简介 介绍 🍀 REmote DIctionary Server(Redis) 是一个由 Salvatore Sanfilippo 写的 key-value 存储系统 Redis是一个开源的使用 ANSI C 语言编写 , 遵守BSD协议 , 支持网络 , 可基于内存亦可持久化的日志型 , Key-Value 数据库 , 并提供多种语言的API 特点 Redis 与其他 key - value 缓存产品有以下三个特点 : Redis支持数据的持久化 , 可以将内存中的数据保持在磁盘中 , 重启的时候可以再次加载进行使用 Redis不仅仅支持简单的 key-value 类型的数据 , 同时还提供 list , set , zset , hash等数据结构的存储 Redis支持数据的备份 , 即 master-slave 模式的数据备份 优势 性能极高 – Redis能读的速度是 110000次/s , 写的速度是 81000次/s 丰富的数据类型 – Redis支持二进制案例的 Strings , Lists , Hashes , Sets 及 Ordered Sets 数据类型操作 原子 – Redis的所有操作都是原子性的 , 同时Redis还支持对几个操作全并后的原子性执行 丰富的特性 – Redis还支持 publish/subscribe , 通知 key 过期等等特性 安装 🍀 方式一 $ yum isntall redis 运行 $ redis-server /etc/redis.conf 方式二 : $ wget http://download.redis.io/releases/redis-4.0.10.tar.gz $ tar xzf redis-4.0.10.tar.gz $ cd redis-4.0.10 $ make 运行 $ src/redis-server 与内置客户端进行交互 : $ src/redis-cli redis> set foo bar OK redis> get foo \"bar\" 配置 🍀 Redis 的配置文件位于 Redis 安装目录下 , 文件名为 redis.conf 我们可以通过 CONFIG 命令查看或者设置配置项 查看配置 🍀 语法 redis 127.0.0.1:6379> CONFIG GET CONFIG_SETTING_NAME 实例 redis 127.0.0.1:6379> CONFIG GET loglevel 1) \"loglevel\" 2) \"notice\" 使用 * 号获取所有配置项 : redis 127.0.0.1:6379> CONFIG GET * 修改配置 🍀 你可以通过修改 redis.conf 文件或使用 CONFIG SET 命令来修改配置 语法 redis 127.0.0.1:6379> CONFIG SET CONFIG_SETTING_NAME NEW_CONFIG_VALUE 实例 redis 127.0.0.1:6379> CONFIG SET loglevel \"notice\" OK redis 127.0.0.1:6379> CONFIG GET loglevel 1) \"loglevel\" 2) \"notice\" 数据类型 🍀 Redis支持五种数据类型 : string (字符串) , hash (哈希) , list (列表) , set (集合) 及 zset(sorted set : 有序集合) String 🍀 string 是 Redis 最基本的类型 , 你可以理解成与 Memcached 一模一样的类型 , 一个 key 对应一个 value string 类型是二进制安全的 , 意思是 Redis 的 string 可以包含任何数据 , 比如 jpg 图片或者序列化的对象 string 类型是 Redis 最基本的数据类型 , 一个键最大能存储 512 MB 实例 redis 127.0.0.1:6379> SET name \"redis.net.cn\" OK redis 127.0.0.1:6379> GET name \"redis.net.cn\" 在以上实例中我们使用了 Redis 的 SET 和 GET 命令 , 键为 name , 对应的值为redis.net.cn 注意 : 一个键最大能存储 512 MB Hash 🍀 Redis hash 是一个键值对集合 Redis hash 是一个 string 类型的 field 和 value 的映射表 , hash 特别适合用于存储对象 实例 redis 127.0.0.1:6379> HMSET user:1 username redis.net.cn password redis.net.cn points 200 OK redis 127.0.0.1:6379> HGETALL user:1 1) \"username\" 2) \"redis.net.cn\" 3) \"password\" 4) \"redis.net.cn\" 5) \"points\" 6) \"200\" redis 127.0.0.1:6379> 以上实例中 hash 数据类型存储了包含用户脚本信息的用户对象 , 实例中我们使用了 Redis HMSET , HEGTALL 命令 , user:1 为键值 每个 hash 可以存储 2^(32-1) 键值对 , 相当于 40 多亿 List 🍀 Redis 列表是简单的字符串列表 , 按照插入顺序排序 , 你可以添加一个元素导列表的头部 (左边) 或者尾部 (右边) 实例 redis 127.0.0.1:6379> lpush redis.net.cn redis (integer) 1 redis 127.0.0.1:6379> lpush redis.net.cn mongodb (integer) 2 redis 127.0.0.1:6379> lpush redis.net.cn rabitmq (integer) 3 redis 127.0.0.1:6379> lrange redis.net.cn 0 10 1) \"rabitmq\" 2) \"mongodb\" 3) \"redis\" redis 127.0.0.1:6379> 列表最多可存储 2^(32-1) 元素 (4294967295 , 每个列表可存储40多亿) Set 🍀 Redis 的 Set 是 string 类型的无序集合 集合是通过哈希表实现的 , 所以添加 , 删除 , 查找的复杂度都是 O(1) sadd 命令 添加一个 string 元素到 , key 对应的 set 集合中 , 成功返回 1 ,如果元素以及在集合中返回 0 , key 对应的 set 不存在返回错误 sadd key member 实例 redis 127.0.0.1:6379> sadd redis.net.cn redis (integer) 1 redis 127.0.0.1:6379> sadd redis.net.cn mongodb (integer) 1 redis 127.0.0.1:6379> sadd redis.net.cn rabitmq (integer) 1 redis 127.0.0.1:6379> sadd redis.net.cn rabitmq (integer) 0 redis 127.0.0.1:6379> smembers redis.net.cn 1) \"rabitmq\" 2) \"mongodb\" 3) \"redis\" 注意 : 以上实例中 rabitmq 添加了两次 , 但根据集合内元素的唯一性 , 第二次插入的元素将被忽略 集合中最大的成员数为 2^(32-1) (4294967295, 每个集合可存储40多亿个成员) zset 🍀 Redis zset 和 Set 一样也是string类型元素的集合 , 且不允许重复的成员 不同的是每个元素都会关联一个 double 类型的分数 , redis 正是通过分数来为集合中的成员进行从小到大的排序。 zset 的成员是唯一的 , 但分数 (score) 却可以重复 zadd 命令 添加元素到集合 , 元素在集合中存在则更新对应 score zadd key score member 实例 redis 127.0.0.1:6379> zadd redis.net.cn 0 redis (integer) 1 redis 127.0.0.1:6379> zadd redis.net.cn 0 mongodb (integer) 1 redis 127.0.0.1:6379> zadd redis.net.cn 0 rabitmq (integer) 1 redis 127.0.0.1:6379> zadd redis.net.cn 0 rabitmq (integer) 0 redis 127.0.0.1:6379> ZRANGEBYSCORE redis.net.cn 0 1000 1) \"redis\" 2) \"mongodb\" 3) \"rabitmq\" "},"06-Redis/02-Redis - 配置参数说明.html":{"url":"06-Redis/02-Redis - 配置参数说明.html","title":"Redis - 配置参数说明","keywords":"","body":"Redis - 配置参数说明 参数说明 🍀 redis.conf 配置项说明如下 : Redis 默认不是以守护进程的方式运行 , 可以通过该配置项修改 , 使用yes启用守护进程 daemonize no 当 Redis 以守护进程方式运行时 , Redis 默认会把 pid 写入 /var/run/redis.pid 文件 , 可以通过 pidfile 指定 pidfile /var/run/redis.pid 指定 Redis 监听端口 , 默认端口为 6379 , 作者在自己的一篇博文中解释了为什么选用 6379 作为默认端口 , 因为 6379 在手机按键上 MERZ 对应的号码 , 而 MERZ 取自意大利歌女 Alessia Merz 的名字 port 6379 绑定的主机地址 bind 127.0.0.1 当客户端闲置多长时间后关闭连接 , 如果指定为0 , 表示关闭该功能 timeout 300 指定日志记录级别 , Redis总共支持四个级别 : debug , verbose , notice , warning , 默认为 verbose loglevel verbose 日志记录方式 , 默认为标准输出 , 如果配置 Redis 为守护进程方式运行 , 而这里又配置为日志记录方式为标准输出 , 则日志将会发送给 /dev/null logfile stdout 设置数据库的数量 , 默认数据库为0 , 可以使用SELECT 命令在连接上指定数据库id databases 16 指定在多长时间内 , 有多少次更新操作 , 就将数据同步到数据文件 , 可以多个条件配合 save Redis 默认配置文件中提供了三个条件 : save 900 1 save 300 10 save 60 10000 分别表示900秒 ( 15分钟 ) 内有1个更改 , 300秒 ( 5分钟)内有10个更改以及60秒内有10000个更改 指定存储至本地数据库时是否压缩数据 , 默认为yes , Redis 采用 LZF 压缩 , 如果为了节省 CPU 时间 , 可以关闭该选项 , 但会导致数据库文件变的巨大 rdbcompression yes 指定本地数据库文件名 , 默认值为 dump.rdb dbfilename dump.rdb 指定本地数据库存放目录 dir ./ 设置当本机为 slav 服务时 , 设置 master 服务的IP地址及端口 , 在 Redis 启动时 , 它会自动从 master 进行数据同步 slaveof 当 master 服务设置了密码保护时 , slav 服务连接 master 的密码 masterauth 设置 Redis 连接密码 , 如果配置了连接密码 , 客户端在连接Redis时需要通过 AUTH 命令提供密码 , 默认关闭 requirepass foobared 设置同一时间最大客户端连接数 , 默认无限制 , Redis 可以同时打开的客户端连接数为 Redis 进程可以打开的最大文件描述符数 , 如果设置 maxclients 0 , 表示不作限制 , 当客户端连接数到达限制时 , Redis 会关闭新的连接并向客户端返回 max number of clients reached 错误信息 maxclients 128 指定 Redis 最大内存限制 , Redis 在启动时会把数据加载到内存中 , 达到最大内存后 , Redis 会先尝试清除已到期或即将到期的 Key , 当此方法处理 后 , 仍然到达最大内存设置 , 将无法再进行写入操作 , 但仍然可以进行读取操作 , Redis 新的 vm 机制 , 会把 Key 存放内存 , Value 会存放在 swap 区 maxmemory 指定是否在每次更新操作后进行日志记录 , Redis 在默认情况下是异步的把数据写入磁盘 , 如果不开启 , 可能会在断电时导致一段时间内的数据丢失 , 因为 redis本身同步数据文件是按上面 save 条件来同步的 , 所以有的数据会在一段时间内只存在于内存中 , 默认为no appendonly no 指定更新日志文件名 , 默认为 appendonly.aof appendfilename appendonly.aof 指定更新日志条件 , 共有3个可选值 : no : 表示等操作系统进行数据缓存同步到磁盘 ( 快 ) always : 表示每次更新操作后手动调用 fsync() 将数据写到磁盘 ( 慢 , 安全 ) everysec : 表示每秒同步一次 ( 折衷 , 默认值 ) appendfsync everysec 指定是否启用虚拟内存机制 , 默认值为no , 简单的介绍一下 , VM 机制将数据分页存放 , 由 Redis 将访问量较少的页即冷数据 swap 到磁盘上 , 访问多的页面由磁盘自动换出到内存中 ( 在后面的文章我会仔细分析Redis的VM机制 ) vm-enabled no 虚拟内存文件路径 , 默认值为 /tmp/redis.swap , 不可多个Redis实例共享 vm-swap-file /tmp/redis.swap 将所有大于 vm-max-memory 的数据存入虚拟内存,无论 vm-max-memory 设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys) , 也就是说,当 vm-max-memory 设置为 0 的时候,其实是所有value 都存在于磁盘 , 默认值为 0 vm-max-memory 0 Redis swap文件分成了很多的 page , 一个对象可以保存在多个 page 上面 , 但一个 page 上不能被多个对象共享 , vm-page-size 是要根据存储的 数据大小来设定的 , 作者建议如果存储很多小对象 , page 大小最好设置为 32 或者 `4bytes ; 如果存储很大大对象 , 则可以使用更大的 page , 如果不 确定 , 就使用默认值 vm-page-size 32 设置 swap 文件中的 page 数量 , 由于页表 ( 一种表示页面空闲或使用的bitmap ) 是在放在内存中的 , 在磁盘上每 8 个 pages 将消耗 1byte 的内存 , vm-pages 134217728 设置访问 swap 文件的线程数,最好不要超过机器的核数,如果设置为 0 , 那么所有对 swap 文件的操作都是串行的 , 可能会造成比较长时间的延迟 , 默认值为 4 vm-max-threads 4 设置在向客户端应答时 , 是否把较小的包合并为一个包发送 , 默认为开启 glueoutputbuf yes 指定在超过一定的数量或者最大的元素超过某一临界值时 , 采用一种特殊的哈希算法 hash-max-zipmap-entries 64 hash-max-zipmap-value 512 指定是否激活重置哈希 , 默认为开启 ( 后面在介绍Redis的哈希算法时具体介绍 ) activerehashing yes 指定包含其它的配置文件 , 可以在同一主机上多个 Redis 实例之间使用同一份配置文件 , 而同时各个实例又拥有自己的特定配置文件 include /path/to/local.conf "},"06-Redis/03-Redis - 基础命令.html":{"url":"06-Redis/03-Redis - 基础命令.html","title":"Redis - 基础命令","keywords":"","body":"Redis - 基础命令 介绍 🍀 Redis 命令用于在 Redis 服务上执行操作 要在 Redis 服务上执行命令需要一个 Redis 客户端 , Redis 客户端在我们之前下载的 Redis 的安装包中 我们只需在 Redis 服务启动后 , 执行如下命令连接 Redis 服务 : $ redis-cli 启动 Redis 客户端后 , 我们可以使用 PING 命令检测 Redis 服务是否启动 : $ redis-cli 127.0.0.1:6379> 127.0.0.1:6379> PING PONG 127.0.0.1:6379> 如果需要在远程 Redis 服务上执行命令 , 我们只需添加一些参数 : $ redis-cli -h host -p port -a password 实例 $ redis-cli -h 127.0.0.1 -p 3769 键命令 🍀 Redis 键命令用于管理 Redis 的键 语法 : redis 127.0.0.1:6379> COMMAND KEY_NAME 实例 redis 127.0.0.1:6379> SET w3ckey redis OK # 删除键w3ckey,成功删除返回(integer) 1 redis 127.0.0.1:6379> DEL w3ckey (integer) 1 Redis 键相关基本命令 : 序号 命令及描述 1 DEL key , 该命令用于在 key 存在是删除 key 2 DUMP key , 序列化给定 key , 并返回被序列化的值 3 EXISTS key , 检查给定 key 是否存在 4 EXPIRE key , seconds 为给定 key 设置过期时间 5 EXPIREAT key timestamp , EXPIREAT 的作用和 EXPIRE 类似 , 都用于为 key 设置过期时间 , 不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳(unix timestamp) 6 PEXPIRE key milliseconds , 设置 key 的过期时间亿以毫秒计 7 PEXPIREAT key milliseconds-timestamp 设置 key 过期时间的时间戳 (unix timestamp) 以毫秒计 8 KEYS pattern , 查找所有符合给定模式( pattern)的 key 9 MOVE key db , 将当前数据库的 key 移动到给定的数据库 db 当中 10 PERSIST key , 移除 key 的过期时间 , key 将持久保持 11 PTTL key , 以毫秒为单位返回 key 的剩余的过期时间 12 TTL key , 以秒为单位 , 返回给定 key 的剩余生存时间(TTL, time to live) 13 RANDOMKEY , 从当前数据库中随机返回一个 key 14 RENAME key newkey , 修改 key 的名称 15 RENAMENX key newkey , 仅当 newkey 不存在时 , 将 key 改名为 newkey 16 TYPE key , 返回 key 所储存的值的类型 字符串命令 🍀 Redis 字符串数据类型的相关命令用于管理 Redis 字符串值 语法 redis 127.0.0.1:6379> COMMAND KEY_NAME 实例 redis 127.0.0.1:6379> SET w3ckey redis OK redis 127.0.0.1:6379> GET w3ckey \"redis\" 常用 Redis 字符串命令如下 : 序号 命令及描述 1 SET key value , 设置指定 key 的值 2 GET key , 获取指定 key 的值 3 GETRANGE key start end , 返回 key 中字符串值的子字符 4 GETSET key value , 将给定 key 的值设为 value , 并返回 key 的旧值(old value) 5 GETBIT key offset , 对 key 所储存的字符串值 , 获取指定偏移量上的位(bit) 6 MGET key[key2..] , 获取所有(一个或多个)给定 key 的值 7 SETBIT key offset value , 对 key 所储存的字符串值 , 设置或清除指定偏移量上的位(bit) 8 SETEX key seconds value , 将值 value 关联到 key , 并将 key 的过期时间设为 seconds (以秒为单位) 9 SETNX key value , 只有在 key 不存在时设置 key 的值 10 SETRANGE key offset value , 用 value 参数覆写给定 key 所储存的字符串值 , 从偏移量 offset 开始 11 STRLEN key , 返回 key 所储存的字符串值的长度 12 MSET key value [key value ...] , 同时设置一个或多个 key-value 对 13 MSETNX key value [key value ...] , 同时设置一个或多个 key-value 对 , 当且仅当所有给定 key 都不存在 14 PSETEX key milliseconds value , 这个命令和 SETEX 命令相似 , 但它以毫秒为单位设置 key 的生存时间 , 而不是像 SETEX 命令那样 , 以秒为单位 15 INCR key , 将 key 中储存的数字值增一 16 INCRBY key increment , 将 key 所储存的值加上给定的增量值（increment） 17 INCRBYFLOAT key increment , 将 key 所储存的值加上给定的浮点增量值（increment） 18 DECR key , 将 key 中储存的数字值减一 19 DECRBY key decrement , key 所储存的值减去给定的减量值(decrement) 20 APPEND key value , 如果 key 已经存在并且是一个字符串 , APPEND 命令将 value 追加到 key 原来的值的末尾 哈希命令 🍀 语法 redis 127.0.0.1:6379> COMMAND KEY_NAME 实例 redis 127.0.0.1:6379> HMSET w3ckey name \"redis tutorial\" description \"redis basic commands for caching\" likes 20 visitors 23000 OK redis 127.0.0.1:6379> HGETALL w3ckey 1) \"name\" 2) \"redis tutorial\" 3) \"description\" 4) \"redis basic commands for caching\" 5) \"likes\" 6) \"20\" 7) \"visitors\" 8) \"23000\" Redis Hash 相关基本命令 : 序号 命令及描述 1 HDEL key field2 [field2] , 删除一个或多个哈希表字段 2 HEXISTS key field , 查看哈希表 key 中 , 指定的字段是否存在 3 HGET key field , 获取存储在哈希表中指定字段的值 4 HGETALL key , 获取在哈希表中指定 key 的所有字段和值 5 HINCRBY key field increment , 为哈希表 key 中的指定字段的整数值加上增量 increment 6 HINCRBYFLOAT key field increment , 为哈希表 key 中的指定字段的浮点数值加上增量 increment 7 HKEYS key , 获取所有哈希表中的字段 8 HLEN key , 获取哈希表中字段的数量 9 HMGET key field1 [field2] , 获取所有给定字段的值 10 HMSET key field1 value1 [field2 value2 ] , 同时将多个 field-value (域-值)对设置到哈希表 key 中 11 HSET key field value , 将哈希表 key 中的字段 field 的值设为 value 12 HSETNX key field value , 只有在字段 field 不存在时 , 设置哈希表字段的值 13 HVALS key , 获取哈希表中所有值 14 HSCAN key cursor [MATCH pattern] [COUNT count] 迭代哈希表中的键值对 列表命令 🍀 语法 redis 127.0.0.1:6379> COMMAND KEY_NAME 实例 redis 127.0.0.1:6379> LPUSH w3ckey redis (integer) 1 redis 127.0.0.1:6379> LPUSH w3ckey mongodb (integer) 2 redis 127.0.0.1:6379> LPUSH w3ckey mysql (integer) 3 redis 127.0.0.1:6379> LRANGE w3ckey 0 10 1) \"mysql\" 2) \"mongodb\" 3) \"redis\" Redis List 相关基本命令如下 : 序号 命令及描述 1 BLPOP key1 [key2 ] timeout , 移出并获取列表的第一个元素 , 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 2 BRPOP key1 [key2 ] timeout 移出并获取列表的最后一个元素 , 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 3 BRPOPLPUSH source destination timeout , 从列表中弹出一个值 , 将弹出的元素插入到另外一个列表中并返回它 ; 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 4 LINDEX key index , 通过索引获取列表中的元素 5 `LINSERT key BEFORE AFTER pivot value` , 在列表的元素前或者后插入元素 6 LLEN key , 获取列表长度 7 LPOP key , 移出并获取列表的第一个元素 8 LPUSH key value1 [value2] , 将一个或多个值插入到列表头部 9 LPUSHX key value , 将一个或多个值插入到已存在的列表头部 10 LRANGE key start stop , 获取列表指定范围内的元素 11 LREM key count value , 移除列表元素 12 LSET key index value , 通过索引设置列表元素的值 13 LTRIM key start stop , 对一个列表进行修剪(trim) , 就是说 , 让列表只保留指定区间内的元素 , 不在指定区间之内的元素都将被删除 14 RPOP key , 移除并获取列表最后一个元素 15 RPOPLPUSH source destination , 移除列表的最后一个元素 , 并将该元素添加到另一个列表并返回 16 RPUSH key value1 [value2] , 在列表中添加一个或多个值 17 RPUSHX key value , 为已存在的列表添加值 集合命令 🍀 Redis 中 集合是通过哈希表实现的 , 所以添加 , 删除 , 查找的复杂度都是 O(1) 语法 redis 127.0.0.1:6379> COMMAND KEY_NAME 实例 redis 127.0.0.1:6379> SADD w3ckey redis (integer) 1 redis 127.0.0.1:6379> SADD w3ckey mongodb (integer) 1 redis 127.0.0.1:6379> SADD w3ckey mysql (integer) 1 redis 127.0.0.1:6379> SADD w3ckey mysql (integer) 0 redis 127.0.0.1:6379> SMEMBERS w3ckey 1) \"mysql\" 2) \"mongodb\" 3) \"redis\" Redis Set 相关基本命令如下 : 序号 命令及描述 1 SADD key member1 [member2] , 向集合添加一个或多个成员 2 SCARD key , 获取集合的成员数 3 SDIFF key1 [key2] , 返回给定所有集合的差集 4 SDIFFSTORE destination key1 [key2] , 返回给定所有集合的差集并存储在 destination 中 5 SINTER key1 [key2] , 返回给定所有集合的交集 6 SINTERSTORE destination key1 [key2] , 返回给定所有集合的交集并存储在 destination 中 7 SISMEMBER key member , 判断 member 元素是否是集合 key 的成员 8 SMEMBERS key , 返回集合中的所有成员 9 SMOVE source destination member , 将 member 元素从 source 集合移动到 destination 集合 10 SPOP key , 移除并返回集合中的一个随机元素 11 SRANDMEMBER key [count] , 返回集合中一个或多个随机数 12 SREM key member1 [member2] , 移除集合中一个或多个成员 13 SUNION key1 [key2] , 返回所有给定集合的并集 14 SUNIONSTORE destination key1 [key2] , 所有给定集合的并集存储在 destination 集合中 15 SSCAN key cursor [MATCH pattern] [COUNT count] ,迭代集合中的元素 有序集合命令 🍀 有序集合的成员是唯一的,但分数(score)却可以重复 语法 redis 127.0.0.1:6379> COMMAND KEY_NAME 实例 redis 127.0.0.1:6379> ZADD w3ckey 1 redis (integer) 1 redis 127.0.0.1:6379> ZADD w3ckey 2 mongodb (integer) 1 redis 127.0.0.1:6379> ZADD w3ckey 3 mysql (integer) 1 redis 127.0.0.1:6379> ZADD w3ckey 3 mysql (integer) 0 redis 127.0.0.1:6379> ZADD w3ckey 4 mysql (integer) 0 redis 127.0.0.1:6379> ZRANGE w3ckey 0 10 WITHSCORES 1) \"redis\" 2) \"1\" 3) \"mongodb\" 4) \"2\" 5) \"mysql\" 6) \"4\" Redis Sorted Set 相关基本命令如下 : 序号 命令及描述 1 ZADD key score1 member1 [score2 member2] , 向有序集合添加一个或多个成员 , 或者更新已存在成员的分数 2 ZCARD key , 获取有序集合的成员数 3 ZCOUNT key min max , 计算在有序集合中指定区间分数的成员数 4 ZINCRBY key increment member , 有序集合中对指定成员的分数加上增量 increment 5 ZINTERSTORE destination numkeys key [key ...] , 计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中 6 ZLEXCOUNT key min max , 在有序集合中计算指定字典区间内成员数量 7 ZRANGE key start stop [WITHSCORES] , 通过索引区间返回有序集合成指定区间内的成员 8 ZRANGEBYLEX key min max [LIMIT offset count] , 通过字典区间返回有序集合的成员 9 ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT] , 通过分数返回有序集合指定区间内的成员 10 ZRANK key member , 返回有序集合中指定成员的索引 11 ZREM key member [member ...] , 移除有序集合中的一个或多个成员 12 ZREMRANGEBYLEX key min max , 移除有序集合中给定的字典区间的所有成员 13 ZREMRANGEBYRANK key start stop , 移除有序集合中给定的排名区间的所有成员 14 ZREMRANGEBYSCORE key min max , 移除有序集合中给定的分数区间的所有成员 15 ZREVRANGE key start stop [WITHSCORES] , 返回有序集中指定区间内的成员 , 通过索引 , 分数从高到底 16 ZREVRANGEBYSCORE key max min [WITHSCORES] , 返回有序集中指定分数区间内的成员 , 分数从高到低排序 17 ZREVRANK key member , 返回有序集合中指定成员的排名 , 有序集成员按分数值递减(从大到小)排序 18 ZSCORE key member , 返回有序集中 , 成员的分数值 19 ZUNIONSTORE destination numkeys key [key ...] , 计算给定的一个或多个有序集的并集 , 并存储在新的 key 中 20 ZSCAN key cursor [MATCH pattern] [COUNT count] , 迭代有序集合中的元素（包括元素成员和元素分值） HyperLogLog命令 🍀 Redis HyperLogLog 是用来做基数统计的算法 , HyperLogLog 的优点是 , 在输入元素的数量或者体积非常非常大时 , 计算基数所需的空间总是固定的 , 并且是很小的 在 Redis 里面 , 每个 HyperLogLog 键只需要花费 12 KB 内存 , 就可以计算接近 2^64 个不同元素的基 数 这和计算基数时 , 元素越多耗费内存就越多的集合形成鲜明对比 但是 , 因为 HyperLogLog 只会根据输入元素来计算基数 , 而不会储存输入元素本身 , 所以 HyperLogLog 不能像集合那样 , 返回输入的各个元素 下表列出了 redis HyperLogLog 的基本命令 : 序号 命令及描述 1 PFADD key element [element ...] , 添加指定元素到 HyperLogLog 中 2 PFCOUNT key [key ...] , 返回给定 HyperLogLog 的基数估算值 3 PFMERGE destkey sourcekey [sourcekey ...] , 将多个 HyperLogLog 合并为一个 HyperLogLog "},"06-Redis/04-Redis - 数据库.html":{"url":"06-Redis/04-Redis - 数据库.html","title":"Redis - 数据库","keywords":"","body":"Redis - 数据库 介绍 🍀 Redis 服务器默认会创建 16 个数据库 , 该值由服务器配置的 databases 选项决定 , 默认为16 , 查看方式如下 : 127.0.0.1:6379> config get databases 1) \"databases\" 2) \"16\" 切换数据库 127.0.0.1:6379> SELECT 1 OK 127.0.0.1:6379[1]> SELECT 0 OK 127.0.0.1:6379> 生存时间 🍀 通过 EXPIRE 命令或者 PEXPIRE 命令 , 客户端可以以秒或者毫秒精度为数据库中的某个键设置生存时间 (Time To Live , TTL) , 在经过指定的秒数或者毫秒数之后 , 服务器就会自动删除生存时间为 0 的键 实例 127.0.0.1:6379> SET key value OK 127.0.0.1:6379> EXPIRE key 5 (integer) 1 127.0.0.1:6379> GET key # 5秒之内 \"value\" 127.0.0.1:6379> GET key # 5秒之后 (nil) 过期时间 🍀 与 EXPIRE 命令和 REXPIRE 命令类似 , 客户端可以通过 EXPIREAT 命令或 PEXPIREAT 命令 , 以秒或者毫秒精度给数据库中的某个键设置过期时间 (Expire Time) 过期时间是 UNIX 时间戳 , 当键的过期时间来临时 , 服务器就会自动从数据库中删除这个键 实例 127.0.0.1:6379> SET key value OK 127.0.0.1:6379> EXPIREAT key 1377257300 (integer) 1 127.0.0.1:6379> Time 1) \"1377257296\" 2) \"296543\" 127.0.0.1:6379> GET key # 1377257300之前 \"value\" 127.0.0.1:6379> Time 1) \"1529772303\" 2) \"230656\" 127.0.0.1:6379> GET key # 1377257300之后 (nil) TTL 命令和 PTTL 命令接受一个带有生存时间或者过期时间的键 , 返回这个键的剩余生存时间 , 也就是 , 返回距离这个键被服务器自动删除还有多长时间 实例 127.0.0.1:6379> SET key value OK 127.0.0.1:6379> EXPIRE key 1000 (integer) 1 127.0.0.1:6379> TTL key (integer) 997 127.0.0.1:6379> PTTL key (integer) 93633 我们可以发现 Redis 有四个不同的命令可以用于设置键的生存时间或过期时间 : EXPIRE # 命令用于将键key的生存时间设置为ttl秒 PEXPIRE # 命令用于将键key的生存时间设置为ttl毫秒 EXPIREAT # 命令用于将键key的生存时间设置为timestamp毫秒 PEXPIREAT # 命令用于将键key的过期时间设置为timestamp毫秒 虽然有多种不同单位和不同形式的设置命令 , 但是实际上 EXPIRE , PEXPIRE , EXPIREAT 三个命令都是使用 PEXPIREAT 命令来实现的 : 无论客户端执行的是以上四个命令中的哪一个 , 经过转换之后 , 最终执行的效果都和执行 PEXPIREAT 命令一样 保存过期时间 当客户端执行 PEXPIREAT 命令 (或者其他三个命令) 为一个数据库键设置过期时间时 , 服务器会在数据库的过期字典中关联给定的数据库键和过期时间 移除过期时间 PERSIST 命令是 PEXPIREAT 命令的反操作 : PERSIST 命令在过期字典中查找给定的键 , 并解除和值 (过期时间) 在过期字典中的关联 Redis 过期键删除策略 : 通过配合使用惰性删除和定期删除两种策略 , 服务器可以很好地在合理使用 CPU 时间和避免浪费内存空间之间取得平衡 持久化 🍀 Redis 是一个键值对数据库服务器 , 服务器中通常包含着任意个非空数据库 , 而每个非空数据库中又可以包含任意个键值对 , 为了方便起见 , 我们将服务器中的非空数据库以及他们的键值对统称为数据库状态 因为 Redis 是内存数据库 , 它将自己的数据库状态储存在内存里面 , 所以如果不想办法将储存在内存中的数据库状态保存到磁盘里面 , 那么一旦服务器进程退出 , 服务器中的数据库状态也会消失不见 , 因此为了解决这个问题 , Redis 提供了持久化功能 RDB持久化 🍀 RDB 持久化功能可以将 Redis 在内存中的数据库状态保存到磁盘里面 , 避免数据意外丢失 RDB 持久化既可以手动执行 , 也可以根据服务器配置选项定期执行 , 该功能可以将某个时间点上的数据库状态保存到一个 RDB 文件中 RDB 持久化功能所生成的 RDB 文件是一个经过压缩的二进制文件 , 通过该文件可以还原生成 RDB 文件时的数据库状态 RDB 文件的创建和载入 有两个命令可以用于生成 RDB 文件 : SAVE , 会阻塞 Redis 服务器进程 , 知道 RDB 文件创建完毕为止 , 在服务器进程阻塞期间 , 服务器不能处理任何请求 redis> SAVE OK BGSAVE , 会派生出一个子进程 , 然后由子进程负责创建 RDB 文件 , 服务器进程 (父进程) 继续处理命令请求 redis> BGSAVE Background saving started 和使用 SAVE 命令或者 BGSAVE 命令创建 RDB 文件不同 , RDB 文件的载入工作是在服务器启动时自动执行的 , 所以 Redis 并没有专门用于载入 RDB 文件的命令 , 只要 Redis 服务器在启动时检测到 RDB 文件存在 , 就会自动载入 RDB 文件 并且服务器在载入 RDB 文件期间 , 会一直处于阻塞状态 , 直到载入工作完成为止 注意 : 在载入或生成 RDB 文件时 , 只会载入未过期的键 , 而过期的键会被直接忽略 AOF持久化 🍀 除了 RDB 持久化功能之外 , Redis 还提供了 AOF (Append Only File) 持久化功能 , 与 RDB 持久化通过保存数据库中的键值对来记录数据库状态不同 , AOF 持久化是通过保存 Redis 服务器所执行的写命令来记录数据库状态的 AOF 持久化功能的实现可以分为命令追加 (Append) , 文件写入 , 文件同步 (Sync) 三个步骤 AOF 文件载入与数据还原 因为 AOF 文件里面包含了重建数据库状态所需的所有写命令 , 所以服务器只要读入并重新执行一遍 AOF 文件里面保存的写命令 , 就可以还原服务器关闭之前的数据库状态 Redis 读取 AOF 文件并还原数据库状态的详细步骤如下 : 创建一个不带网络连接的伪客户端 (fake client) : 因为 Redis 的命令只能在客户端上下文中执行 , 而载入 AOF 文件时所使用的命令直接来源于 AOF 文件而不是网络连接 , 所以服务器使用了一个没有网络连接的伪客户端来执行 AOF 文件保存的写命令 , 伪客户端执行命令的效果和带网络连接的客户端执行命令的效果完全一样 从 AOF 文件中分析并读取出一条写命令 使用伪客户端执行被读出的命令 一直执行步骤 2 和步骤 3 , 知道 AOF 文件中的所有写命令都被处理完毕为止 AOF 重写 由于随着服务器运行时间的流逝 , AOF 文件中的内容会越来越多 , 文件的体积也会越来越大 , 为了解决这 AOF 文件体积膨胀的问题 , Redis 提供了 AOF 文件重写 (rewrite) 功能 , 通过该功能 , Redis 服务器可以创建一个新的 AOF 文件来替代现有的 AOF 文件 和生成 RDB 文件时类似 , 在执行 AOF 重写的过程中 , 程序会对数据库中的键进行检查 , 已过期的键不会被保存到重写后的 AOF 文件中 由于 Redis 是单线程的 , 那么在重写 AOF 文件期间 , 服务器将无法处理客户端发来的命令请求 , 所以 Redis 决定将 AOF 重写程序放到子进程里执行 , 以达到如下目的 : 子进程进行 AOF 重写期间 , 服务器进程 (父进程) 可以继续处理命令请求 子进程带有服务器进程的数据副本 , 使用子进程而不是线程 , 可以在避免使用锁的情况下 , 保证数据的安全性 但是由于子进程进行 AOF 重写期间 , 服务器进程还需要继续处理命令请求 , 而新的命令可能会对现有的数据库状态进程修改 , 从而使得服务器当前的数据库状态和重写后的 AOF 文件所保存的数据库状态不一致 ; 为此 , Redis 服务器设置了一个 AOF 重写缓冲区 , 这个缓冲区在服务器创建子进程之后开始使用 , 当 Redis 服务器执行完一个写命令之后 , 它会同时将这个写命令发送给 AOF 缓冲区和 AOF 重写缓冲区 也就是说 AOF 重写期间 , 服务器进程需要执行以下三个工作 : 执行客户端发来的命令 将执行后的写命令追加到 AOF 缓冲区 将执行后的写命令追加到 AOF 重写缓冲区 当子进程完成 AOF 重写工作后 , 它会向父进程发送一个信号 , 会调用一个信号处理函数 , 并执行以下工作 : 将 AOF 重写缓冲区中的所有内容写入到新的 AOF 文件中 , 这时新 AOF 文件所保存的数据库状态将和服务器当前的数据库状态一致 对新的 AOF 文件进行改名 , 原子地覆盖现有的 AOF 文件 , 完成新旧两个 AOF 文件的替换 注意 : 默认如果 AOF 持久化功能开启 , 那么将优先使用 AOF 发布订阅 🍀 Redis 发布订阅(pub/sub)是一种消息通信模式 : 发送者(pub)发送消息 , 订阅者(sub)接收消息 Redis 客户端可以订阅任意数量的频道 下图展示了频道 channel1 , 以及订阅这个频道的三个客户端 : client2 , client5 和 client1 之间的关系 : 当有新消息通过 PUBLISH 命令发送给频道 channel1 时 , 这个消息就会被发送给订阅它的三个客户端 : 实例 以下实例演示了发布订阅是如何工作的 , 在我们实例中我们创建了订阅频道名为 redisChat : redis 127.0.0.1:6379> SUBSCRIBE redisChat Reading messages... (press Ctrl-C to quit) 1) \"subscribe\" 2) \"redisChat\" 3) (integer) 1 现在 , 我们先重新开启个 redis 客户端 , 然后在同一个频道 redisChat 发布两次消息 , 订阅者就能接收到消息 redis 127.0.0.1:6379> PUBLISH redisChat \"Redis is a great caching technique\" (integer) 1 redis 127.0.0.1:6379> PUBLISH redisChat \"Learn redis by w3cschool.cc\" (integer) 1 # 订阅者的客户端会显示如下消息 1) \"message\" 2) \"redisChat\" 3) \"Redis is a great caching technique\" 1) \"message\" 2) \"redisChat\" 3) \"Learn redis by w3cschool.cc\" Redis 发布订阅常用命令 : 序号 命令及描述 1 PSUBSCRIBE pattern [pattern ...] , 订阅一个或多个符合给定模式的频道 2 PUBSUB subcommand [argument [argument ...]] , 查看订阅与发布系统状态 3 PUBLISH channel message , 将信息发送到指定的频道 4 PUNSUBSCRIBE [pattern [pattern ...]] , 退订所有给定模式的频道 5 SUBSCRIBE channel [channel ...] , 订阅给定的一个或多个频道的信息 6 UNSUBSCRIBE [channel [channel ...]] , 指退订给定的频道 "},"06-Redis/05-Redis - 事务.html":{"url":"06-Redis/05-Redis - 事务.html","title":"Redis - 事务","keywords":"","body":"Redis - 事务 介绍 🍀 Redis 事务可以一次执行多个命令 , 并且带有以下两个重要的保证 : 事务是一个单独的隔离操作 : 事务中的所有命令都会序列化 , 按顺序地执行 , 事务在执行的过程中 , 不会被其他客户端发送来的命令请求所打断 事务是一个原子操作 : 事务中的命令要么全部被执行 , 要么全部都不执行 一个事务从开始到执行会经历以下三个阶段 : 开始事务 命令入队 执行事务 实例 🍀 以下是一个事务的例子 , 它先以 MULTI 开始一个事务 , 然后将多个命令入队到事务中 , 最后由 EXEC 命令触发事务 , 一并执行事务中的所有命令 : redis 127.0.0.1:6379> MULTI OK redis 127.0.0.1:6379> SET book-name \"Mastering C++ in 21 days\" QUEUED redis 127.0.0.1:6379> GET book-name QUEUED redis 127.0.0.1:6379> SADD tag \"C++\" \"Programming\" \"Mastering Series\" QUEUED redis 127.0.0.1:6379> SMEMBERS tag QUEUED redis 127.0.0.1:6379> EXEC 1) OK 2) \"Mastering C++ in 21 days\" 3) (integer) 3 4) 1) \"Mastering Series\" 2) \"C++\" 3) \"Programming\" 单个 Redis 命令的执行是原子性的 , 但 Redis 没有在事务上增加任何维持原子性的机制 , 所以 Redis 事务的执行并不是原子性的 事务可以理解为一个打包的批量执行脚本 , 但批量指令并非原子化的操作 , 中间某条指令的失败不会导致前面已做指令的回滚 , 也不会造成后续的指令不做 比如 : redis 127.0.0.1:7000> multi OK redis 127.0.0.1:7000> set a aaa QUEUED redis 127.0.0.1:7000> set b bbb QUEUED redis 127.0.0.1:7000> set c ccc QUEUED redis 127.0.0.1:7000> exec 1) OK 2) OK 3) OK 如果在 set b bbb 处失败 , set a 已成功不会回滚 , set c 还会继续执行 Redis 事务命令 🍀 下表列出了 redis 事务的相关命令 : 序号 命令及描述 1 DISCARD , 取消事务 , 放弃执行事务块内的所有命令 2 EXEC , 执行所有事务块内的命令 3 MULTI , 标记一个事务块的开始 4 UNWATCH , 取消 WATCH 命令对所有 key 的监视 5 WATCH key [key ...] , 监视一个(或多个) key , 如果在事务执行之前这个(或这些) key 被其他命令所改动 , 那么事务将被打断 "},"06-Redis/06-Redis - 主从复制.html":{"url":"06-Redis/06-Redis - 主从复制.html","title":"Redis - 主从复制","keywords":"","body":"Redis - 主从复制 介绍 🍀 在 Redis 中 , 用户可以通过执行 SLAVEOF 命令或者设置 slaveof 选项 , 让一个服务器去复制 (replicate) 另一个服务器 , 我们称呼被复制的服务器为主服务器 (master) , 而对主服务器进行复制的服务器则被称为从服务器 (slave) 假设现在有两个 Redis 服务器 , 地址分别为 127.0.0.1:6379 和 127.0.0.1:12345 , 如果服务器 127.0.0.1:12345 发送以下命令 : 127.0.0.1:12345> SLAVEOF 127.0.0.1 6379 那么服务器 127.0.0.1:12345 将成为 127.0.0.1:6379 的从服务器 , 而服务器 127.0.0.1:6379 则会成为 127.0.0.1:12345 的主服务器 Redis 的复制功能分为同步 (sync) 和命令传播 (command propagate) 同步 🍀 当客户端向从服务器发送 SLAVEOF 命令 , 要求从服务器复制主服务器时 , 从服务器首先需要执行同步操作 , 也就是 , 将从服务器的数据库状态更新至主服务器当前所处的数据库状态 从服务器对主服务器的同步操作需要通过向主服务器发送 SYNC 命令来完成 , 其执行步骤如下 : 从服务器向主服务器发送 SYNC 命令 收到 SYNC 命令的主服务器执行 BGSAVE 命令 , 在后台生成一个 RDB 文件 , 并使用一个缓冲区记录从现在开始执行的所有写命令 当主服务器的 BGSAVE 命令执行完毕时 , 主服务器会将 BGSAVE 命令生成的 RDB 文件发送给从服务器 , 从服务器接收并载入这个 RDB 文件 , 将自己的数据库状态更新至主服务器执行 BGSAVE 命令时的数据库状态 主服务器将记录在缓冲区里面的所有写命令发送给从服务器 , 从服务器执行这些写命令 , 将自己的数据库状态更新至主服务器数据库当前所处的状态 命令传播 🍀 在同步操作完毕之后 , 主从服务器两者的数据库将达到一致状态 , 但这种一致并不是一成不变的 , 每当主服务器执行客户端发送的写命令时 , 主服务器的数据库就有可能会被修改 , 并导致主从服务器状态不一致 为了让主从服务器再次回到一致状态 , 主服务器需要对从服务器执行命令传播操作 : 主服务器会将自己执行的写命令 , 也即造成主服务器不一致的那条写命令 , 发送给从服务器执行 , 当从服务器执行了相同的写命令之后 , 主从服务器将再次回到一致状态 PSYNC 🍀 由于 SYNC 命令在处理断线重复制情况下时效率低下 , Redis 从 2.8 版本开始 , 使用 PSYNC 命令代替 SYNC 命令来执行复制时的同步操作 PSYNC 命令具有完整重同步 (full resynchronization) 和部分重同步 (partial resynchronization) 两种模式 : 完整重同步用于处理初次复制情况 : 完整重同步的执行步骤与 SYNC 命令的执行步骤一样 , 它们都是通过让主服务器创建并发送 RDB 文件 , 以及向从服务器发送保存在缓冲区里面的写命令来进行同步 而部分重同步则用于处理断线后重复制情况 : 当从服务器在断线后重新连接主服务器时 , 如果条件允许 , 主服务器可以将主从服务器连接断开期间执行的写命令发送给从服务器 , 从服务器只要接收并执行这些写命令 , 就可以将数据库更新至主服务器当前所处的状态 "},"06-Redis/07-Redis - 集群.html":{"url":"06-Redis/07-Redis - 集群.html","title":"Redis - 集群","keywords":"","body":"Redis - 集群 介绍 🍀 Redis 集群是 Redis 提供的分布式数据库方案 , 集群通过分片 (sharding) 来进行数据共享 , 并提供复制和故障转移功能 节点 🍀 一个 Redis 集群通常由多个节点 (node) 组成 , 在刚开始的时候 , 每个节点都是相互独立的 , 它们都处于一个只包含自己的集群当中 , 要组建一个真正可工作的集群 , 我们必须将各个独立的节点连接起来 , 构成一个包含多个节点的集群 连接各个节点可以使用 CLUSTER MEET 命令来完成 , 命令格式如下 : CLUSTER MEET 查看集群节点 CLUSTER NODES 一个节点就是一个运行在集群模式下的 Redis 服务器 , Redis 服务器在启动时会根据 cluster-enabled 配置选项是否为 yes 来决定是否开启服务器的集群模式 槽指派 🍀 Redis 集群通过分片的方式来保存数据库中的键值对 : 集群的整个数据被分为 16384 个槽 (slot) , 数据库中的每个键都属于这 16384 个槽的其中一个 , 集群中的每个节点可以处理 0 个或最多 16384 个槽 当数据库中的 16384 个槽都有节点在处理时 , 集群处于上线状态 , 相反的 , 如果数据库中公有任何一个槽没有得到处理 , 那么集群处于下线状态 通过向节点发送 CLUSTER ADDSLOTS 命令 , 我们可以将一个或多个槽指派给节点负责 CLUSTER ADDSLOTS [slot ...] 当客户端向节点发送与数据库键有关的命令时 , 接收命令的节点会计算出命令要处理的数据库键属于哪个槽 , 并检查这个槽是否指派给了自己 : 如果键所在的槽正好就指派给了当前节点 , 那么节点直接执行这个命令 如果键所在的槽并没有指派给当前节点 , 那么节点会向客户端返回一个 MOVED 错误 , 指引客户端转向至正确的节点 , 并再次发送之前想要执行的命令 如果需要将已经指派给某个节点的槽改为指派给另一个节点 , 可以执行重新分片操作 复制与故障转移 🍀 Redis 集群中的节点分为主节点 (master) 和从节点 (slave) , 其中主节点用于处理槽 , 而从节点则用于复制某个节点 , 并在被复制的主节点下线时 , 代替下线主节点继续处理命令请求 设置从节点 # 可以让接收命令的节点成为node_id所指定节点的从节点,并开始节点主从复制 CLUSTER REPLICATE 故障检测 集群中的每个节点都会定期地向集群中的其他节点发送 PING 消息 , 以此来检测对方是否在线 , 如果接收 PING 消息的节点没有在规定的时间内 , 向发送 PING 消息的节点返回 PONG 消息 , 那么发送 PING 消息的节点就会将接收 PING 消息的节点标记为疑似下线 (probable fail , PFAIL) 集群中的各个节点会通过互相发消息的方式来交换集群中各个节点的状态信息 , 例如某个节点是处于在线状态 , 疑似下线状态 , 还是已下线状态 如果在一个集群里面 , 半数以上负责处理槽的主节点将某个主节点 x 报告为疑似下线 , 那么这个主节点 x 将被标记为已下线 , 将主节点 x 标记为下线的节点会向集群广播一条关于主节点 x 的 FALL 消息 , 所有收到这条 FALL 消息的节点都会立即将主节点 x 标记为已下线 故障转移 当一个从节点发现自己正在复制的主节点进入了已下线状态时 , 从节点将会开始对下线主节点进行故障转移 , 以下是故障转移的执行步骤 : 复制下线主节点的所有从节点里面 , 会有一个从节点被选中 被选中的从节点会执行 SLAVEOF no one 命令 , 成为新的主节点 新的主节点会撤销所有对已下线主节点的槽指派 , 并将这些槽全部指派给自己 新的主节点向集群广播一条 PONG 消息 , 这条 PONG 消息可以让集群中的其他节点立即知道这个节点已经由从节点变成了主节点 , 并且这个主节点已经接管了原本由已下线节点负责处理的槽 新的主节点开始接收和自己负责处理的槽有关的命令请求 , 故障转移完成 新的主节点是通过选举产生的 消息 🍀 集群中的各个节点通过发送和接收消息来进行通信 , 我们称发送消息的节点为发送者 , 接收消息的节点为接收者 节点发送的消息主要有以下五种 : MEET 消息 : 当发送者接到客户端发送的 CLUSTER MEET 命令时 , 发送会向接收者发送 MEET 消息 , 请求接收者加入到发送者当前所处的集群里面 PING 消息 : 集群里的每个节点默认每隔一秒钟就会从已知节点列表中随机选出五个节点 , 然后对五个节点中最长时间没有发送过 PING 消息的节点发送 PING 消息 , 以此来检测被选中的节点是否在线 ; 除此之外 , 如果节点 A 最后一次收到节点 B 发送的 PONG 消息的时间 , 距离当前时间已经超过了节点 A 的 cluster-node-timeout 选项设置时长的一半 , 那么节点 A 也会向节点 B 发送 PING 消息 , 这可以防止节点 A 因为长时间没有随机选中节点 B 作为 PING 消息的发送对象而导致节点 B 的信息更新滞后 PONG 消息 : 当接收者收到发送者发来的 MEET 消息时 , 为了向发送者确认这条 MEET 消息或者 PING 消息已达到 , 接收者会向发送者返回一条 PONG 消息 , 另外 , 一个节点也可以通过向集群广播自己的 PONG 消息来让集群中的其他节点立即刷新关于这个节点的认识 , 例如当一次故障转移操作成功执行之后 , 新的主节点会向集群广播一条 PONG 消息 , 以此来让集群中的其他节点立即知道这个节点已经变成了主节点 , 并且接管了已经下线节点负责的槽 FAIL 消息 : 当一个主节点 A 判断另一个主节点 B 已经进入 FAIL 状态时 , 节点 A 会向集群广播一条关于节点 B 的 FAIL 消息 , 所有收到这条消息的节点都会立即将节点 B 标记为已下线 PUBLISH 消息 : 当节点接收到一个 PUBLISH 命令时 , 节点会执行这个命令 , 并向集群广播一条 PUBLIST 消息 , 所有接收到这条 PUBLISH 消息的节点都会执行相同的 PUBLISH 命令 "},"06-Redis/08-Redis - Sentinel.html":{"url":"06-Redis/08-Redis - Sentinel.html","title":"Redis - Sentinel","keywords":"","body":"Redis - Sentinel 介绍 🍀 Sentinel (哨岗 , 哨兵) 是 Redis 的高可用性 (high availability) 解决方案 : 由一个或多个 Sentinel 实例组成的 Sentinel 系统可以监视任意多个主服务器 , 并在被监视的主服务器进入下线状态时 , 自动将下线主服务器属下的某个从服务器升级为新的主服务器 , 然后由新的主服务器代替已下线的主服务器继续处理命令请求 启动并初始化Sentinel 🍀 启动一个 Sentinel 可以使用命令 : $ redis-sentinel /path/to/your/sentinel.conf 或者命令 : $ redis-sentinel /path/to/your/sentinel.conf --sentinel 当一个 Sentinel 启动时 , 它需要执行以下步骤 : 初始化服务器 将普通 Redis 服务器使用的代码替换成 Sentinel 专用代码 初始化 Sentinel 状态 根据给定的配置文件 , 初始化 Sentinel 的监视主服务器列表 创建连向主服务器的网络连接 初始化服务器 🍀 因为 Sentinel 本质上只是一个运行在特殊模式下的 Redis 服务器 , 所以启动 Sentinel 的第一步 , 就是初始化一个普通的 Redis 服务器 ; 不过 , 因为 Sentinel 执行的工作和普通 Redis 服务器执行的工作不同 , 所以 Sentinel 的初始化过程和普通 Redis 服务器的初始化过程并不完全相同 例如 , 普通服务器在初始化时会通过载入 RDB 文件或者 AOF 文件来还原数据库状态 , 但是因为 Sentinel 并不适用数据库 , 所以初始化 Sentinel 时就不会载入 RDB 文件或者 AOF 文件 Sentinel 模式下 Redis 服务器主要功能的使用情况如下 : 功能 使用情况 数据库和键值对方面的命令 , 不如 SET , DEL , FLUSHDB 不使用 事务命令 , 比如 MULTI 和 WATCH 不使用 脚本命令 , 比如 EVAL 不使用 RDB 持久化命令 , 比如 SAVE 和BGSAVE 不使用 AOF 持久化命令 , 比如 BGREWRITEAOF 不使用 复制命令 , 比如 SLAVEOF Sentinel 内部可以使用 , 但客户端不可以使用 发布与订阅命令 , 比如 PUBLISH 和 SUBSCRIBE SUBSCRIBE , PSUBSCRIBE , UNSUBSCRIBE , PUNSUBSCRIBE 四个命令在 Sentinel 内部和客户端都可以使用 , 但 PUBLISH 命令只能在 Sentinel内部使用 文件事件处理器 (负责发送命令请求 , 处理命令回复) Sentinel 内部使用 , 但关联的文件事件处理器和普通 Redis 服务器不同 时间事件处理器 (负责执行 serverCron函数) Sentinel 内部使用 , 时间事件的处理器仍然是 serverCron 函数 , serverCron 函数会调用 sentinel.c/sentinelTimer 函数 , 后者包含了 Sentinel 要执行的所有操作 初始化 Sentinel 的最后一步是创建连向被监视主服务器的网络连接 , Sentinel 将成为主服务器的客户端 , 它可以向主服务器发送命令 , 并从命令回复中获取相关的信息 对于每个被 Sentinel 监视的主服务器来说 , Sentinel 会创建两个连向主服务器的异步网络连接 : 一个是命令连接 , 这个连接专门用于主服务器发送命令 , 并接收命令回复 另一个是订阅连接 , 这个连接专门用于订阅主服务器的 __sentinel__:hello 频道 Sentinel 默认会以每十秒一次的频率 , 通过命令连接向被监视的主服务器发送 INFO 命令 , 并通过分析 INFO 命令的回复来获取主服务器的当前信息 通过分析主服务器返回的 INFO 命令回复 , Sentinel 可以获取以下两方面的信息 : 一方面是关于主服务器本身的信息 , 包括 run_id 域记录的服务器运行 ID , 以及 role 域记录的服务器角色 另一方面是关于主服务器属下所有从服务器的信息 , 每个从服务器都由一个 \"slave\" 字符串开头的行记录 , 每行的 ip= 域记录了从服务器的 IP 地址 , 而 port= 域则记录了从服务器的端口号 , 根据这些 IP 地址和端口号 , Sentinel 无须用户提供从服务器的地址信息 , 就可以自动发现从服务器 检测主观下线状态 🍀 在默认情况下 , Sentinel 会以每秒一次的频率向所有与它创建了命令连接的实例 (包括主服务器 , 从服务器 , 其他 Sentinel 在内) 发送 PING 命令 , 并通过实例返回的 PING 命令回复来判断实例是否在线 Sentinel 配置文件中的 down-after-milliseconds 毫秒内 , 连续向 Sentinel 返回无效回复 , 那么 Sentinel 会修改这个实例所对应的实例结构 , 在结构的 flags 属性中打开 SRI_S_DOWN 标识 , 以此来标识这个实例已经进入主观下线状态 用户设置的 down-after-milliseconds 选项的值 , 不仅会被 Senitinel 用来判断主服务器的主观下线状态 , 还会被用于判断主服务器属下的所有从服务器 , 以及所有同样监视这个主 服务器的其他 Sentinel 的主观下线状态 检测客观下线状态 🍀 当 Sentinel 将一个主服务器判断为主观下线之后 , 为了确认这个主服务器是否真的下线了 , 它会向同样监视这一主服务器的其他 Sentinel 进行询问 , 看它们是否也认为主服务器已经进入了下线状态 (可以是主观下线或者客观下线) , 当 Sentinel 从其他 Sentinel 那里接收到足够数量的已下线判断之后 , Sentinel 就会将从服务器判定为客观下线 , 并对主服务器执行故障转移操作 选举领头 Sentinel 🍀 当一个主服务器被判断为客观下线时 , 监视这个下线主服务器的各个 Sentinel 会进行协商 , 选举出一个领头 Sentinel , 并由领头 Sentinel 对下线主服务器执行故障转移操作 故障转移操作包括以下三个步骤 : 在已下线主服务器属下的所有从服务器里面 , 挑选一个从服务器 , 并将其转换为主服务器 让已下载主服务器属下的所有从服务器改为复制新的主服务器 将已下线主服务器设置为新的主服务器的从服务器 , 当这个旧的主服务器重新上线时 , 它就会成为新的主服务器的从服务器 "},"06-Redis/Python操作MongoDB.html":{"url":"06-Redis/Python操作MongoDB.html","title":"Python操作MongoDB","keywords":"","body":"Python操作MongoDB 介绍 🍀 MongoDB 是一个基于分布式文件存储的数据库 , 由 C++ 编写 MongoDB 是一个介于关系型数据库和非关系型数据库 (NoSQL) 之间的产品 , 是非关系数据库当中功能最丰富 , 最像关系数据库的 它有如下优点 : 文档型存储 使用高效的二进制 BSON 作为数据存储 , BSON 是一个类似 JSON 的格式 , 选择 BSON 可以提供更快的遍历速度 , 提供比 JSON 更多的内置数据类型 自带高可用及分区的解决方案 , 分别为副本集 (Replica Set) 和分片(sharding) 基于文档的富查询语言 , MongoDB 支持动态查询 , 支持非常多的查询方式 , 并且可以对文档中的属性建立索引 内置聚合工具 , 可以通过 MapReduce 等方式进行复杂的统计核并行计算 MongoDB 在 3.0 之后增加了高性能 , 可伸缩 , 支持压缩和文档级锁的数据存储引擎 WiredTiger MongoDB概念 🍀 SQL术语/概念 MongoDB术语/概念 解释/说明 database database 数据库 table collection 数据库表/集合 row document 数据记录行/文档 column field 数据字段/域 index index 索引 table joins 表连接 , MongoDB 不支持 primary key primary key 主键 , MongoDB 自动将_id字段设置为主键 数据库 🍀 在 MongoDB 中 , 多个文档组成集合 , 多个集合可以组成数据库 数据库也通过名字来标识 , 数据库名可以是满足以下条件的任意UTF-8字符串 : 不能是空字符串 (\"\") 不得含有' ' (空格) , . , $ , / , \\ 和 \\0 (空字符) 应全部小写 最多64字节 有一些数据库名是保留的 , 可以直接访问这些有特殊作用的数据库 admin : 从身份认证的角度讲 , 这是 “root” 数据库 , 如果将一个用户添加到admin数据库 , 这个用户将自动获得所有数据库的权限 , 再者 , 一些特定的服务器端命令也只能从admin数据库运行 , 如列出所有数据库或关闭服务器 local: 这个数据库永远都不可以复制 , 且一台服务器上的所有本地集合都可以存储在这个数据库中 config: MongoDB用于分片设置时 , 分片信息会存储在config数据库中 集合 🍀 集合就是一组文档 , 如果将MongoDB中的一个文档比喻为关系型数据的一行 , 那么一个集合就是相当于一张表 集合存在于数据库中 , 通常情况下为了方便管理 , 不同格式和类型的数据应该插入到不同的集合 , 但其实集合没有固定的结构 , 这意味着我们完全可以把不同格式和类型的数据统统插入一个集合中 组织子集合的方式就是使用 “.” , 分隔不同命名空间的子集合 比如一个具有博客功能的应用可能包含两个集合 , 分别是 blog.posts 和 blog.authors , 这是为了使组织结构更清晰 , 这里的 blog 集合 (这个集合甚至不需要存在）跟它的两个子集合没有任何关系 在MongoDB中 , 使用子集合来组织数据非常高效 , 值得推荐 当第一个文档插入时 , 集合就会被创建 , 合法的集合名 : 集合名不能是空字符串\"\" ; 集合名不能含有 \\0 字符 (空字符) , 这个字符表示集合名的结尾 ; 集合名不能以 \"system.\" 开头 , 这是为系统集合保留的前缀 ; 用户创建的集合名字不能含有保留字符 , 有些驱动程序的确支持在集合名里面包含 , 这是因为某些系统生成的集合中包含该字符 ; 除非你要访问这种系统创建的集合 , 否则千万不要在名字里出现$ ; 文档 🍀 文档是MongoDB的核心概念 , 文档就是键值对的一个有序集 {'msg':'hello','foo':3} , 类似于python中的有序字典 需要注意的是 : 文档中的键/值对是有序的 ; 文档中的值不仅可以是在双引号里面的字符串 , 还可以是其他几种数据类型 (甚至可以是整个嵌入的文档) ; MongoDB区分类型和大小写 ; MongoDB的文档不能有重复的键 ; 文档中的值可以是多种不同的数据类型 , 也可以是一个完整的内嵌文档。文档的键是字符串。除了少数例外情况 , 键可以使用任意UTF-8字符 ; 文档键命名规范 : 键不能含有 \\0 (空字符) , 这个字符用来表示键的结尾 ; . 和 $ 有特别的意义 , 只有在特定环境下才能使用 ; 以下划线 \"_\" 开头的键是保留的(不是严格要求的) ; PS : 把数据库名添加到集合名前 , 得到集合的完全限定名 , 即命名空间 , 如 : 如果要使用 test 数据库中的 coll.posts 集合 , 这个集合的命名空间就是 test.coll.ports , 命名空间的长度不得超过121个字节 , 且在实际使用中应该小于100个字节 连接MongoDB 🍀 >>> from pymongo import MongoClient # 默认主机与端口 >>> client = MongoClient() # 指定主机与端口 >>> client = MongoClient('localhost', 27017) # MongoDBURI格式 >>> client = MongoClient('mongodb://localhost:27017/') 获取数据库 🍀 >>> db = client.test_database # 如果你的数据库是这样的test-database,可以使用字典点方式 >>> db = client['test-database'] 获取集合 🍀 >>> collection = db.test_collection >>> collection = db['test-collection'] 关于 MongoDB 中的集合和数据库一个重要注意事项是 , 它们是延迟创建的 , 上面的命令实际上都没有在MongoDB 服务器上执行任何操作 , 而是当第一个文档插入到集合和数据库中时 , 才创建集合和数据库 文档 🍀 MongoDB中的数据使用JSON样式的文档表示(并存储)。在Pymono中 , 我们使用字典来表示文档 , 如下 : >>> import datetime >>> post = {\"author\": \"Mike\", ... \"text\": \"My first blog post!\", ... \"tags\": [\"mongodb\", \"python\", \"pymongo\"], ... \"date\": datetime.datetime.utcnow()} 插入文档 🍀 单条插入 >>> posts = db.posts >>> post_id = posts.insert_one(post).inserted_id >>> post_id ObjectId('...') 批量插入 >>> new_posts = [{\"author\": \"Mike\", ... \"text\": \"Another post!\", ... \"tags\": [\"bulk\", \"insert\"], ... \"date\": datetime.datetime(2009, 11, 12, 11, 14)}, ... {\"author\": \"Eliot\", ... \"title\": \"MongoDB is fun\", ... \"text\": \"and pretty easy too!\", ... \"date\": datetime.datetime(2009, 11, 10, 10, 45)}] >>> result = posts.insert_many(new_posts) >>> result.inserted_ids [ObjectId('...'), ObjectId('...')] 查询文档 🍀 查看数据库中所有集合 >>> db.collection_names(include_system_collections=False) [u'posts'] 单条查询 # pprint用于数据格式化 >>> import pprint >>> pprint.pprint(posts.find_one()) {u'_id': ObjectId('...'), u'author': u'Mike', u'date': datetime.datetime(...), u'tags': [u'mongodb', u'python', u'pymongo'], u'text': u'My first blog post!'} 指定条件查询 >>> pprint.pprint(posts.find_one({\"author\": \"Mike\"})) {u'_id': ObjectId('...'), u'author': u'Mike', u'date': datetime.datetime(...), u'tags': [u'mongodb', u'python', u'pymongo'], u'text': u'My first blog post!'} 按对象查询 >>> post_id ObjectId(...) >>> pprint.pprint(posts.find_one({\"_id\": post_id})) {u'_id': ObjectId('...'), u'author': u'Mike', u'date': datetime.datetime(...), u'tags': [u'mongodb', u'python', u'pymongo'], u'text': u'My first blog post!'} 由字符串转换成对象 from bson.objectid import ObjectId # The web framework gets post_id from the URL and passes it as a string def get(post_id): # Convert from string to ObjectId: document = client.db.collection.find_one({'_id': ObjectId(post_id)}) 多条查询 >>> for post in posts.find(): ... pprint.pprint(post) ... {u'_id': ObjectId('...'), u'author': u'Mike', u'date': datetime.datetime(...), u'tags': [u'mongodb', u'python', u'pymongo'], u'text': u'My first blog post!'} {u'_id': ObjectId('...'), u'author': u'Mike', u'date': datetime.datetime(...), u'tags': [u'bulk', u'insert'], u'text': u'Another post!'} {u'_id': ObjectId('...'), u'author': u'Eliot', u'date': datetime.datetime(...), u'text': u'and pretty easy too!', u'title': u'MongoDB is fun'} 指定条件查询 >>> for post in posts.find({\"author\": \"Mike\"}): ... pprint.pprint(post) ... {u'_id': ObjectId('...'), u'author': u'Mike', u'date': datetime.datetime(...), u'tags': [u'mongodb', u'python', u'pymongo'], u'text': u'My first blog post!'} {u'_id': ObjectId('...'), u'author': u'Mike', u'date': datetime.datetime(...), u'tags': [u'bulk', u'insert'], u'text': u'Another post!'} 计数查询 🍀 获取查询结果总条数 >>> posts.count() 3 >>> posts.find({\"author\": \"Mike\"}).count() 2 范围查询 🍀 >>> d = datetime.datetime(2009, 11, 12, 12) >>> for post in posts.find({\"date\": {\"$lt\": d}}).sort(\"author\"): ... pprint.pprint(post) ... {u'_id': ObjectId('...'), u'author': u'Eliot', u'date': datetime.datetime(...), u'text': u'and pretty easy too!', u'title': u'MongoDB is fun'} {u'_id': ObjectId('...'), u'author': u'Mike', u'date': datetime.datetime(...), u'tags': [u'bulk', u'insert'], u'text': u'Another post!'} 索引 🍀 创建索引 >>> result = db.profiles.create_index([('user_id', pymongo.ASCENDING)], ... unique=True) >>> sorted(list(db.profiles.index_information())) [u'_id_', u'user_id_1'] 更多 pymongo "},"06-Redis/Python操作Redis.html":{"url":"06-Redis/Python操作Redis.html","title":"Python操作Redis","keywords":"","body":"Python使用Redis流程 安装redis-py 🍀 $ pip install redis 创建Redis接口对象 🍀 创建 Redis 接口对象实例 , 将通过实例对 Redis 进行操作 有两种创建方式 : Redis : 继承 StrictRedis 类 , 用于向后兼容旧版本的 redis-py StrictRedis : 实现大部分官方的命令 , 并使用官方的语法和命令 import redis r = redis.Redis(host='127.0.0.1', port=6379) r = redis.StrictRedis(host='127.0.0.1', port=6379) 使用连接池 🍀 通过连接池管理 Redis 对象 默认每个 Redis 实例都会维护一个自己的连接池 , 可以建立一个连接池 , 然后作为参数创建 Redis 实例 , 以此实现 Redis 实例共享连接池 import redis pool = redis.ConnectionPool(host='127.0.0.1', port=6379) r = redis.Redis(connection_pool=pool) String操作 🍀 def set(name, value, ex=None, px=None, nx=False, xx=False): \"\"\" 设置值 , 默认不存在则创建 , 存在则修改 ex , 过期时间 (秒) px , 过期时间 (毫秒) nx , 如果设置为True , 则只有name不存在时 , 当前set操作才执行 xx , 如果设置为True , 则只有name存在时 , 岗前set操作才执行 \"\"\" def setnx(name, value): \"\"\" 设置值 , 只有name不存在时 , 执行设置操作 \"\"\" def setex(name, value, time): \"\"\" 设置值 time , 过期时间 (数字秒 或 timedelta对象) \"\"\" def psetex(name, time_ms, value): \"\"\" 设置值 time_ms , 过期时间 (数字毫秒 或 timedelta对象) \"\"\" def mset(*args, **kwargs): \"\"\" 批量设置值,参数为关键字或字典 \"\"\" def get(name): \"\"\" 获取值 \"\"\" def mget(keys, *args): \"\"\" 批量获取,如: mget('1', '2') mget(['1', '2']) \"\"\" def getset(name, value): \"\"\" 设置新值并获取原来的值 \"\"\" def getrange(key, start, end): \"\"\" 获取子序列 (根据字节获取 , 非字符) name , Redis 的 name start , 起始位置 (字节) end , 结束位置 (字节) \"\"\" def setrange(name, offset, value): \"\"\" 修改字符串内容 , 从指定字符串索引开始向后替换 (新值太长时 , 则向后添加) offset , 字符串的索引 , 字节 (一个汉字三个字节) value , 要设置的值 \"\"\" def setbit(name, offset, value): \"\"\" 对name对应值的二进制表示的位进行操作 \"\"\" def getbit(name, offset): \"\"\" 获取name对应的值的二进制表示中的某位的值 (0或1) \"\"\" def bitcount(key, start=None, end=None): \"\"\" 获取name对应的值的二进制表示中 1 的个数 key , Redis的name start , 位起始位置 end , 位结束位置 \"\"\" def bitop(operation, dest, *keys): \"\"\" 获取多个值 , 并将值做位运算 , 将最后的结果保存至新的name对应的值 operation,AND (并) 、 OR (或) 、 NOT (非) 、 XOR (异或) dest, 新的Redis的name *keys,要查找的Redis的name \"\"\" def strlen(name): \"\"\" 返回name对应值的字节长度 (一个汉字3个字节) \"\"\" def incr(self, name, amount=1): \"\"\" 自增 name对应的值 , 当name不存在时 , 则创建name＝amount , 否则 , 则自增。 amount,自增数 (必须是整数) \"\"\" def incrbyfloat(self, name, amount=1.0): \"\"\" 自增 name对应的值 , 当name不存在时 , 则创建name＝amount , 否则 , 则自增。 amount,自增数 (浮点型) \"\"\" def decr(self, name, amount=1): \"\"\" 自减 name对应的值 , 当name不存在时 , 则创建name＝amount , 否则 , 则自减 amount,自减数 (整数) \"\"\" def append(key, value): \"\"\" 在redis name对应的值后面追加内容 \"\"\" Hash操作 🍀 def hset(name, key, value): \"\"\" name对应的hash中设置一个键值对 (不存在 , 则创建；否则 , 修改) \"\"\" def hsetnx(name, key, value): \"\"\" 当name对应的hash中不存在当前key时则创建 (相当于添加) \"\"\" def hmset(name, mapping): \"\"\" 在name对应的hash中批量设置键值对 name , redis的name mapping , 字典 , 如 : hmset('xx', {'k1':'v1', 'k2': 'v2'}) \"\"\" def hget(name,key): \"\"\" 在name对应的hash中获取根据key获取value \"\"\" def hmget(name, keys, *args): \"\"\" 在name对应的hash中获取多个key的值 name , reids对应的name keys , 要获取key集合 , 如 : ['k1', 'k2', 'k3'] *args , 要获取的key , 如 : k1,k2,k3 r.mget('xx', ['k1', 'k2']) 或 r.hmget('xx', 'k1', 'k2') \"\"\" def hgetall(name): \"\"\" 获取name对应hash的所有键值 \"\"\" def hlen(name): \"\"\" 获取name对应的hash中键值对的个数 \"\"\" def hkeys(name): \"\"\" 获取name对应的hash中所有的key的值 \"\"\" def hvals(name): \"\"\" 获取name对应的hash中所有的key的值 \"\"\" def hexists(name, key): \"\"\" 检查name对应的hash是否存在当前传入的key \"\"\" def hdel(name,*keys): \"\"\" 将name对应的hash中指定key的键值对删除 \"\"\" def hincrby(name, key, amount=1): \"\"\" 自增name对应的hash中的指定key的值 , 不存在则创建key=amount name , redis中的name key , hash对应的key amount , 自增数 (整数) \"\"\" def hincrbyfloat(name, key, amount=1.0): \"\"\" 自增name对应的hash中的指定key的值 , 不存在则创建key=amount name , redis中的name key , hash对应的key amount , 自增数 (浮点数) \"\"\" def hscan(name, cursor=0, match=None, count=None): \"\"\" 增量式迭代获取 , 对于数据大的数据非常有用 , hscan可以实现分片的获取数据 , 并非一次性将数据全部获取完 , 从而放置内存被撑爆 name , redis的name cursor , 游标 (基于游标分批取获取数据) match , 匹配指定key , 默认None 表示所有的key count , 每次分片最少获取个数 , 默认None表示采用Redis的默认分片个数 如 : 第一次 : cursor1, data1 = r.hscan('xx', cursor=0, match=None, count=None) 第二次 : cursor2, data1 = r.hscan('xx', cursor=cursor1, match=None, count=None) ... 直到返回值cursor的值为0时 , 表示数据已经通过分片获取完毕 \"\"\" def hscan_iter(name, match=None, count=None): \"\"\" 利用yield封装hscan创建生成器 , 实现分批去redis中获取数据 match , 匹配指定key , 默认None 表示所有的key count , 每次分片最少获取个数 , 默认None表示采用Redis的默认分片个数 \"\"\" List操作 🍀 def lpush(name,values): \"\"\" 在name对应的list中添加元素 , 每个新的元素都添加到列表的最左边 \"\"\" def rpush(name, values): \"\"\" 表示从右向左操作 \"\"\" def lpushx(name,value): \"\"\" 在name对应的list中添加元素 , 只有name已经存在时 , 值添加到列表的最左边 \"\"\" def rpushx(name, value): \"\"\" 表示从右向左操作 \"\"\" def llen(name): \"\"\" 返回list的长度 \"\"\" def linsert(name, where, refvalue, value): \"\"\" 在name对应的列表的某一个值前或后插入一个新值 name , redis的name where , BEFORE或AFTER refvalue , 标杆值 , 即 : 在它前后插入数据 value , 要插入的数据 \"\"\" def lset(name, index, value): \"\"\" 对name对应的list中的某一个索引位置重新赋值 name , redis的name index , list的索引位置 value , 要设置的值 \"\"\" def lrem(name, value, num): \"\"\" 在name对应的list中删除指定的值 name , redis的name value , 要删除的值 num , num=0删除列表中所有的指定值 num=2,从前到后 , 删除2个 num=-2,从后向前 , 删除2个 \"\"\" def lpop(name): \"\"\" 在name对应的列表的左侧获取第一个元素并在列表中移除 , 返回值则是第一个元素 \"\"\" def rpop(name): \"\"\" 表示从右向左操作 \"\"\" def lindex(name, index): \"\"\" 在name对应的列表中根据索引获取列表元素 \"\"\" def lrange(name, start, end): \"\"\" 在name对应的列表分片获取数据 name , redis的name start , 索引的起始位置 end , 索引结束位置 \"\"\" def ltrim(name, start, end): \"\"\" 在name对应的列表中移除没有在start-end索引之间的值 name , redis的name start , 索引的起始位置 end , 索引结束位置 \"\"\" def rpoplpush(src, dst): \"\"\" 从一个列表取出最右边的元素 , 同时将其添加至另一个列表的最左边 src , 要取数据的列表的name dst , 要添加数据的列表的name \"\"\" def blpop(keys, timeout): \"\"\" 将多个列表排列 , 按照从左到右去pop对应列表的元素 keys , redis的name的集合 timeout , 超时时间 , 当元素所有列表的元素获取完之后 , 阻塞等待列表内有数据的时间 (秒), 0 表示永远阻塞 \"\"\" def brpop(keys, timeout): \"\"\" 从右向左获取数据 \"\"\" def brpoplpush(src, dst, timeout=0): \"\"\" 从一个列表的右侧移除一个元素并将其添加到另一个列表的左侧 src , 取出并要移除元素的列表对应的name dst , 要插入元素的列表对应的name timeout , 当src对应的列表中没有数据时 , 阻塞等待其有数据的超时时间 (秒) , 0 表示永远阻塞 \"\"\" 自定义增量迭代 # 由于redis类库中没有提供对列表元素的增量迭代 , 如果想要循环name对应的列表的所有元素 , 那么就需要 : # 1、获取name对应的所有列表 # 2、循环列表 # 但是 , 如果列表非常大 , 那么就有可能在第一步时就将程序的内容撑爆 , 所有有必要自定义一个增量迭代的功能 : def list_iter(name): \"\"\" 自定义redis列表增量迭代 :param name: redis中的name , 即 : 迭代name对应的列表 :return: yield 返回列表元素 \"\"\" list_count = r.llen(name) for index in xrange(list_count): yield r.lindex(name, index) # 使用 for item in list_iter('pp'): print(item) Set操作 🍀 def sadd(name,values): \"\"\" name对应的集合中添加元素 \"\"\" def scard(name): \"\"\" 获取name对应的集合中元素个数 \"\"\" def sdiff(keys, *args): \"\"\" 在第一个name对应的集合中且不在其他name对应的集合的元素集合 \"\"\" def sdiffstore(dest, keys, *args): \"\"\" 获取第一个name对应的集合中且不在其他name对应的集合 , 再将其新加入到dest对应的集合中 \"\"\" def sinter(keys, *args): \"\"\" 获取多一个name对应集合的并集 \"\"\" def sinterstore(dest, keys, *args): \"\"\" 获取多一个name对应集合的并集 , 再讲其加入到dest对应的集合中 \"\"\" def sismember(name, value): \"\"\" 检查value是否是name对应的集合的成员 \"\"\" def smembers(name): \"\"\" 获取name对应的集合的所有成员 \"\"\" def smove(src, dst, value): \"\"\" 将某个成员从一个集合中移动到另外一个集合 \"\"\" def spop(name): \"\"\" 从集合的右侧 (尾部)移除一个成员 , 并将其返回 \"\"\" def srandmember(name, numbers): \"\"\" 从name对应的集合中随机获取 numbers 个元素 \"\"\" def srem(name, values): \"\"\" 在name对应的集合中删除某些值 \"\"\" def sunion(keys, *args): \"\"\" 获取多一个name对应的集合的并集 \"\"\" def sunionstore(dest,keys, *args): \"\"\" 获取多一个name对应的集合的并集 , 并将结果保存到dest对应的集合中 \"\"\" def sscan(name, cursor=0, match=None, count=None): sscan_iter(name, match=None, count=None): \"\"\" 同字符串的操作 , 用于增量迭代分批获取元素 , 避免内存消耗太大 \"\"\" Zset操作 🍀 def zadd(name, *args, **kwargs): \"\"\" 在name对应的有序集合中添加元素 zadd('zz', 'n1', 1, 'n2', 2) 或 zadd('zz', n1=11, n2=22) \"\"\" def zcard(name): \"\"\" 获取name对应的有序集合元素的数量 \"\"\" def zcount(name, min, max): \"\"\" 获取name对应的有序集合中分数 在 [min,max] 之间的个数 \"\"\" def zincrby(name, value, amount): \"\"\" 自增name对应的有序集合的 name 对应的分数 \"\"\" def zrange( name, start, end, desc=False, withscores=False, score_cast_func=float): \"\"\" 按照索引范围获取name对应的有序集合的元素 name , redis的name start , 有序集合索引起始位置 (非分数) end , 有序集合索引结束位置 (非分数) desc , 排序规则 , 默认按照分数从小到大排序 withscores , 是否获取元素的分数 , 默认只获取元素的值 score_cast_func , 对分数进行数据转换的函数 \"\"\" def zrevrange(name, start, end, withscores=False, score_cast_func=float): \"\"\" 按照索引范围从大到小排序 \"\"\" def zrangebyscore(name, min, max, start=None, num=None, withscores=False, score_cast_func=float): \"\"\" 按照分数范围获取name对应的有序集合的元素 \"\"\" zrevrangebyscore(name, max, min, start=None, num=None, withscores=False, score_cast_func=float) \"\"\" 按照分数范围从大到小排列 \"\"\" def zrank(name, value): \"\"\" 获取某个值在 name对应的有序集合中的排行 (从 0 开始) \"\"\" def zrevrank(name, value): \"\"\" zrank从大到小排序 \"\"\" def zrangebylex(name, min, max, start=None, num=None): \"\"\" 当有序集合的所有成员都具有相同的分值时 , 有序集合的元素会根据成员的值 (lexicographical ordering)来进行排序 , 而这个命令则可以返回给定的有序集合键 key 中 , 元素的值介于 min 和 max 之间的成员, 对集合中的每个成员进行逐个字节的对比 (byte-by-byte compare) , 并按照从低到高的顺序 , 返回排序后的集合成员, 如果两个字符串有一部分内容是相同的话 , 那么命令会认为较长的字符串比较短的字符串要大 name , redis的name min , 左区间 (值)。 + 表示正无限； - 表示负无限； ( 表示开区间； [ 则表示闭区间 min , 右区间 (值) start , 对结果进行分片处理 , 索引位置 num , 对结果进行分片处理 , 索引后面的num个元素 如 : ZADD myzset 0 aa 0 ba 0 ca 0 da 0 ea 0 fa 0 ga zrangebylex('myzset', \"-\", \"[ca\") 结果为 : ['aa', 'ba', 'ca'] \"\"\" def zrevrangebylex(name, max, min, start=None, num=None): \"\"\" zrangebylex从大到小排序 \"\"\" def zrem(name, values): \"\"\" 删除name对应的有序集合中值是values的成员 如 : zrem('zz', ['s1', 's2']) \"\"\" def zremrangebyrank(name, min, max): \"\"\" 根据排行范围删除 \"\"\" def zremrangebyscore(name, min, max): \"\"\" 根据排行范围删除 \"\"\" def zremrangebylex(name, min, max): \"\"\" 根据值返回删除 \"\"\" def zscore(name, value): \"\"\" 获取name对应有序集合中 value 对应的分数 \"\"\" def zinterstore(dest, keys, aggregate=None): \"\"\" 获取两个有序集合的交集 , 如果遇到相同值不同分数 , 则按照aggregate进行操作 aggregate的值为: SUM MIN MAX \"\"\" def zunionstore(dest, keys, aggregate=None): \"\"\" 获取两个有序集合的并集 , 如果遇到相同值不同分数 , 则按照aggregate进行操作 aggregate的值为: SUM MIN MAX \"\"\" def zscan(name, cursor=0, match=None, count=None, score_cast_func=float): zscan_iter(name, match=None, count=None,score_cast_func=float): \"\"\" 同字符串相似 , 相较于字符串新增score_cast_func , 用来对分数进行操作 \"\"\" 其他操作 🍀 def delete(*names): \"\"\" 根据删除redis中的任意数据类型 \"\"\" def exists(name): \"\"\" 检测redis的name是否存在 \"\"\" def keys(pattern='*'): \"\"\" 根据模型获取redis的name KEYS * 匹配数据库中所有 key 。 KEYS h?llo 匹配 hello , hallo 和 hxllo 等。 KEYS h*llo 匹配 hllo 和 heeeeello 等。 KEYS h[ae]llo 匹配 hello 和 hallo , 但不匹配 hillo \"\"\" def expire(name ,time): \"\"\" 为某个redis的某个name设置超时时间 \"\"\" def rename(src, dst): \"\"\" 对redis的name重命名为 \"\"\" def move(name, db): \"\"\" 将redis的某个值移动到指定的db下 \"\"\" def randomkey(): \"\"\" 随机获取一个redis的name (不删除) \"\"\" def type(name): \"\"\" 获取name对应值的类型 \"\"\" def scan(cursor=0, match=None, count=None): scan_iter(match=None, count=None): \"\"\" 同字符串操作 , 用于增量迭代获取key \"\"\" 管道 🍀 Pipelines 是基 Redis 类的子类 , 它支持在单个请求中缓冲多个命令到服务器 , 它们可以通过减少客户端和服务器之间来回 TCP 数据包的数量来显着地提高命令组的性能 管道的使用非常简单 : >>> r = redis.Redis(...) >>> r.set('bing', 'baz') >>> # Use the pipeline() method to create a pipeline instance >>> pipe = r.pipeline() >>> # The following SET commands are buffered >>> pipe.set('foo', 'bar') >>> pipe.get('bing') >>> # the EXECUTE call sends all buffered commands to the server, returning >>> # a list of responses, one for each command. >>> pipe.execute() [True, 'baz'] 为了便于使用 , 所有被缓冲到管道中的命令都返回管道对象本身 , 因此 , 调用可以如下 : >>> pipe.set('foo', 'bar').sadd('faz', 'baz').incr('auto_number').execute() [True, True, 6] 此外 , 管道还可以确保缓冲命令作为一个组以原子形式执行 , 默认情况下会发生这种情况 , 如果希望禁用管道的原子性质 , 但仍然希望缓冲命令 , 则可以关闭事务 >>> pipe = r.pipeline(transaction=False) 当需要原子事务时 , 需要在 Redis 中检索值以便在事务中使用时 , 就会出现一个常见的问题 , 例如 , 让我们假设 incr 命令不存在 , 我们需要在 Python 中构建 incr 的原子版本 完全天真的实现可以获得值 , 在 Python 中增加值 , 并将新值设置回原来的值 . 但是 , 这不是原子性的 , 因为多个客户端可以同时执行此操作 , 每个客户端从 get 获得相同的值 输入监视命令 , WATCH 命令提供了在启动事务之前监视一个或多个键的能力 , 如果这些键中的任何一个在该事务执行之前发生更改 , 则整个事务将被取消并引发 WatchError , 为了实现我们自己的客户端 incr 命令 , 我们可以这样做 : >>> with r.pipeline() as pipe: ... while 1: ... try: ... # put a WATCH on the key that holds our sequence value ... pipe.watch('OUR-SEQUENCE-KEY') ... # after WATCHing, the pipeline is put into immediate execution ... # mode until we tell it to start buffering commands again. ... # this allows us to get the current value of our sequence ... current_value = pipe.get('OUR-SEQUENCE-KEY') ... next_value = int(current_value) + 1 ... # now we can put the pipeline back into buffered mode with MULTI ... pipe.multi() ... pipe.set('OUR-SEQUENCE-KEY', next_value) ... # and finally, execute the pipeline (the set command) ... pipe.execute() ... # if a WatchError wasn't raised during execution, everything ... # we just did happened atomically. ... break ... except WatchError: ... # another client must have changed 'OUR-SEQUENCE-KEY' between ... # the time we started WATCHing it and the pipeline's execution. ... # our best bet is to just retry. ... continue 注意 , 由于管道必须在监视期间绑定到单个连接 , 因此必须注意通过调用 Reset() 方法确保连接返回到连接池 . 如果管道被用作上下文管理器(如上面的示例所示) , 则将自动调用 Reset() , 当然 , 您可以通过显式调用 Reset() 来手动完成此操作 : >>> pipe = r.pipeline() >>> while 1: ... try: ... pipe.watch('OUR-SEQUENCE-KEY') ... ... ... pipe.execute() ... break ... except WatchError: ... continue ... finally: ... pipe.reset() 存在一个名为transaction 的方便方法 , 用于处理所有处理和重试手表错误的样板 , 它需要一个可调用的 , 应该期望有一个参数 , 一个管道对象和任何数量的键来监视 , 上面的客户端 incr 命令可以这样编写 , 这更容易阅读 : >>> def client_side_incr(pipe): ... current_value = pipe.get('OUR-SEQUENCE-KEY') ... next_value = int(current_value) + 1 ... pipe.multi() ... pipe.set('OUR-SEQUENCE-KEY', next_value) >>> >>> r.transaction(client_side_incr, 'OUR-SEQUENCE-KEY') [True] 利用管道实现计数器 🍀 import redis conn = redis.Redis(host='192.168.1.41',port=6379) conn.set('count',1000) with conn.pipeline() as pipe: # 先监视 , 自己的值没有被修改过 conn.watch('count') # 事务开始 pipe.multi() old_count = conn.get('count') count = int(old_count) if count > 0: # 有库存 pipe.set('count', count - 1) # 执行 , 把所有命令一次性推送过去 pipe.execute() 发布订阅 🍀 发布者 : 服务器 订阅者 : Dashboard和数据处理 示例如下 : helprs.py import redis class RedisHelper: def __init__(self): self.__conn = redis.Redis(host='10.211.55.4') self.chan_sub = 'fm104.5' self.chan_pub = 'fm104.5' def public(self, msg): self.__conn.publish(self.chan_pub, msg) return True def subscribe(self): pub = self.__conn.pubsub() pub.subscribe(self.chan_sub) pub.parse_response() return pub 订阅者 from helpers import RedisHelper obj = RedisHelper() redis_sub = obj.subscribe() while True: msg= redis_sub.parse_response() print(msg) 发布者 from helpers import RedisHelper obj = RedisHelper() obj.public('hello') Sentinel 🍀 redis重的sentinel主要用于在redis主从复制中 , 如果master顾上 , 则自动将slave替换成master from redis.sentinel import Sentinel # 连接哨兵服务器(主机名也可以用域名) sentinel = Sentinel([('10.211.55.20', 26379), ('10.211.55.20', 26380), ], socket_timeout=0.5) # 获取主服务器地址 # master = sentinel.discover_master('mymaster') # print(master) # 获取从服务器地址 # slave = sentinel.discover_slaves('mymaster') # print(slave) # 获取主服务器进行写入 # master = sentinel.master_for('mymaster') # master.set('foo', 'bar') # 获取从服务器进行读取 (默认是round-roubin) # slave = sentinel.slave_for('mymaster', password='redis_auth_pass') # r_ret = slave.get('foo') # print(r_ret) 更多参见 : Redis for GitHub , Doc "},"07-设计模式/":{"url":"07-设计模式/","title":"设计模式","keywords":"","body":"设计模式 "},"07-设计模式/01-六大原则.html":{"url":"07-设计模式/01-六大原则.html","title":"六大原则","keywords":"","body":"六大原则 前言 🍀 设计模式是一个我们编写程序的标准 , 也就是一种规范 , 有时候不能够盲目的追求规范而不理会真实情景 , 因为它可能会适得其反 单一职责原则 🍀 单一职责原则 (Single Responsibility Principle , 简称 SRP ) 定义 : 应该有且仅有一个原因引起类的变更 (原话 : There should never be more than one reason for a class to change. ) 作用 : 降低类的复杂性 , 职责具有清晰明确的定义 提高可读性 提供可维护性 降低变更引起的风险 实例 : 以通话为例 , 我们需要两个操作来实现通话 建立连接 信息传递 伪代码示例 class Phone(object): \"\"\" 未区分职责, converse既负责连接, 也负责信息传递 \"\"\" def converse(self, phone, message): 连接 开始通话 挂断电话 class Phone(object): \"\"\" 区分职责, dial负责连接, chat负责信息传递, hangup负责关闭连接 \"\"\" def dial(self, phone): pass def chat(self, message): pass def hangup(): pass 变更的出现会使你的项目工作量增大 , 所以单一职责原则可以有效的提高你的工作效率 , 但是通常你可能感觉不到它的存在 , 第一是因为你可能会不自觉的这么去做 , 即使它不完全符合这一原则 ; 第二是因为你的项目不允许去深究它 , 总之 , 单一职责原则可以在一定程度上使你的代码更加从容面对项目遇到的变更风险 扩展 : 在面向对象中, 除了继承, 还有另一种方式来实现抽象, 那就是组合, 但是组合是一种强耦合关系, 所以不到迫不得已还是不要使用组合的好 里氏替换原则 🍀 里氏替换原则 (Liskov substitution Principle , 简称 LSP ) 定义 : 如果对每一个类型为 S 的对象 o1 , 都有类型为 T 的对象 o2 , 使得以 T 定义的所有程序 P 在所有的对象 o1 都代换成 o2 时, 程序 P 的行为没有发生变化, 那么类型 S 是类型 T 的子类型 (原话 : If for each object o1 of type S there is an object o2 of type T such that for all programs P defined in terms of T, the behavior of P is unchanged when o1 is substituted for o2 then S is a subtype of T.) 大致意思就是 , 父类能出现的地方子类也可以出现 , 而且替换将父类替换成子类也不会产生任何错误或异常 , 使用者可能根本就不需要知道是父类还是子类 , 但是 , 反过来子类能出现的地方父类却不一定能出现 , 它的含义如下 : 子类必须完全实现父类的方法 (但是如果子类中的某些方法发生了畸变 , 建议将方法进行独立) 子类可以有自己的个性 覆盖或实现父类的方法时输入参数可以被放大 覆盖或实现父类的方法时输出结果可以被缩小 关于第一点和第二点 , 这几乎就是基本的规则 , 不过在 Python 中并没有接口的概念 , 当然而第三点和第四点则是需要注意的 , 因为一旦参数被缩小 , 或者结果被放大 , 那你在写代码时就得小心了 , 因为你要顾及你的子类是否能正常完成你的任务 作用 : 代码共享 , 减少创建类的工作量 , 每个子类都拥有父类的方法和属性 提高代码的重用性 子类可以形似父类 , 但又异于父类 提高代码的可扩展性 提高产品或项目的开放性 实例 : class Foo(object): def say_hello(self, name): print(name, 'hello~') return self class SubOne(Foo): # 重载, 放大参数 def say_hello(self, name, desc=''): print(name, 'hello', '') return self # 异于父类 def say_hi(self, name): print(name, 'hi') class SubTwo(Foo): # 覆盖 def say_hello(self, name): print('hello', name) return self 这个例子可以说是用来 \"凑数\" 的 , 因为在 Python 中 , 来表达里氏替换原则所有的含义可能会不太像 Python 了 , 因为Python 天生就是多态 , 所以也不需要接口 ; 但是覆盖和重载我们应该遵循里氏替换原则 , 为了保证更好的兼容性 , 扩展性 扩展 : 覆盖(Override) 和重载 (Overload) : 覆盖就意味着它的外观是没有任何变化的 , 使用起来也没有变化 , 但是它其中的内容却已经被改变 ; 重载则是它的名字还是一样的 , 但是也仅仅是名字 , 它的其他都已经被重新塑造 ; 就比如 , 我们写了一个方法( Python 注解形式) a(n: int, m: str) -> str , 子类覆盖你所看到的还是 a(n: int, m: str) -> str , 而重载 a(n: tuple) -> str , 它只是名字还叫 a , 但是它的参数等等已经发生了改变 依赖倒置原则 🍀 依赖倒置原则 (Dependence Inversion Principle , 简称 DIP ) 定义 : 高层模块不应该依赖底层模块 , 两者应该依赖其抽象 ; 抽象不应该依赖于细节 , 细节应该依赖抽象 ( 原话 : High level modules should not depend upon low level modules.Both should depend upon abstractions.Abstractions should not depend upon details.Details should depend upon abstractions. ) 依赖倒置原则是 \"面向接口编程\" OOD (Object-Oriented Design , 面向对象设计) 的精髓之一 作用 : 减少类之间的耦合性 提高系统的稳定性 降低并行开发引起的风险 提高代码的可读性和可维护性 实例 : # 不符合依赖倒置原则 class Benz(object): def run(self): print('奔驰启动...滴滴滴') class BMW(object): def run(self): print('宝马启动...滴滴滴') class Driver(object): \"\"\"驾驶者\"\"\" def drive(self, benz_ojbect): \"\"\"开奔驰\"\"\" benz_object.run() def drive_BMW(self, bmw_object): \"\"\"为了保证兼容性, \"\"\" bmw_object.run() # 符合依赖倒置原则 class Car(object): \"\"\"抽象类\"\"\" def run(self): \"\"\"细节实现应该依赖于抽象\"\"\" raise NotImplementedError('车必须实现run方法') class Benz(Car): def run(self): print('奔驰启动...滴滴滴') class BMW(Car): def run(self): print('宝马启动...滴滴滴') class Driver(object): \"\"\"根据实际需要, 司机也可以抽象出来\"\"\" def drive(self, car): car.run() \"\"\" 抽象不依赖于细节, 即 Car 不应该依赖于 Benz 和 BMW \"\"\" 依赖有三种写法 , 分别为 : 构造函数传递依赖对象 , 在创建对象时进行限制 方法传递依赖对象 , 在使用过程中进行限制 接口传递依赖对象 , 直接在定义上限制 上述例子所使用的是接口传递依赖对象 依赖倒置原则的本职就是通过抽象 , 使各个类或模块的实现彼此独立 , 不互相影响 , 实现模块间的松耦合 接口隔离原则 🍀 接口隔离原则 (Interface Segregation Principle , 简称 ISP ) 定义 : 客户端不应该依赖它不需要的接口 ; 类之间的依赖关系应该建立在最小的接口上 (原话 : “Clients should not be forced to depend upon interfaces that they don't use. The dependency of one class to another one should depend on the smallest possible interface. ) 注意 , 接口隔离原则和单一职责原则审视的角度是不一样的 , 单一职责是要求类或接口职责单一 , 注重的是职责 , 而接口隔离则要求接口的方法尽量少 , 如 : 一个接口的职责可能包含了 10 个方法 , 这10个方法都放在一个接口中 , 并提供给多个模块访问 , 各个模块按照规定的权限来访问 作用 : 提高代码的灵活性和可维护性 提高系统的内聚性 , 降低系统的耦合性 提高代码重用性 , 减少代码冗余 接口隔离原则是对接口进行规范约束 , 其包含以下四层含义 : 接口要尽量小 接口要高内聚 (高内聚: 提高接口、类、模块的处理能力 , 减少对外的交互 ; 高内聚的标准是既符合接口隔离原则又符合单一职责原则) 定制服务 (只提供访问者需要的方法) 接口设计是有限度的 在进行接口隔离时 , 首先必须要满足单一职责原则 实例 : # 未进行接口隔离 class Worker(object): \"\"\"工人\"\"\" def work(self): \"\"\"需要按顺序完成四道工序\"\"\" step1 step2 step3 step4 # 进行了接口隔离 class Worker(object): \"\"\"工人\"\"\" def work(self): self.finish_step1() self.finish_step2() self.finish_step3() self.finish_step4() def finish_step1(self): pass def finish_step2(self): pass def finish_step3(self): pass def finish_step4(self): pass \"\"\" 场景一: 由于材料更加精细, 已经不需要进行第1道工序了, 只需完成2,3,4道即算完成 场景二: 为了能够让员工更加专注, 每个工人将只负责一道工序 工人A负责第一道工序 工人B负责第二道工序 工人C负责第三道工序 工人D负责第四道工序 场景三: 公司研发出了新的产品P1和P2, 工作流程如下: - P1: 工序数量不变, 但是工作顺序需要倒序, 即 4, 3, 2, 1 - P2: 只需要经过第3道工序, 1,2,4皆不需要 隔离与未隔离哪一种更加能适应以上所有场景? \"\"\" 如果大量的重复代码出现在你的程序中 , 那么你就应该反思了 , 因为你没有进行接口隔离 , 或者隔离得还不够细 , 导致代码无法重用 在进行接口隔离时 , 粒度大小不能过大 , 也不能过小 ; 定义太大 , 会降低灵活性 , 无法提供定制服务 , 给整体项目带来无法预料的风险 ; 定义太小 , 则会造成接口数量过多 , 使设计复杂化 迪米特法则 🍀 迪米特法则 (Law of Demeter , 简称 LoD ) 也称最少知识原则 (Least Knowledge Principle , 简称 LKP) 定义 : 一个对象应该对其他对象有最少的了解 , 即 一个类应该对自己需要耦合或调用的类知道得最少 (原话 : Only talk to your immediate friends ) 他强调以下两点 : 从依赖者的角度来说 , 只依赖应该依赖的对象 从被依赖者的角度来说 , 只暴露应该暴露的方法 迪米特法则的核心观念就是类间解耦 , 弱耦合 , 只有弱耦合了以后 , 类的复用率才可以提高 ; 但是其要求的结果就是产生了大量的中转或跳转类 , 导致系统的复杂性提高 , 同时也为维护带来了难度 , 所以在采用迪米特法则时需要反复权衡 , 既做到让结果清晰 , 又做到高内聚低耦合 作用 : 降低类之间的耦合度 , 提高模块的相对独立性 提高类的可复用率和系统的扩展性 实例 : # 对于明星来说, 经纪人是明星的朋友, 而粉丝是陌生人 class Agent(object): \"\"\"经纪人\"\"\" def set_star(self, star_obj): self.star = star_obj def set_fans(self, fans_obj): self.fans = fans_obj def meeting(self): out_string = ''.join(['粉丝', self.fans.get_name(), '与明星', self.star.get_name(), '见面了.']) print(out_string) class Star(object): \"\"\"明星\"\"\" def __init__(self, name): self.name = name def get_name(self): return self.name class Fans(object): \"\"\"粉丝\"\"\" def __init__(self, name): self.name = name def get_name(self): return self.name 总之 , 迪米特法则的作用在就是解耦 , 但是解耦的程度需要我们格外小心 开闭原则 🍀 开闭原则 定义 : 软件实体应该对扩展开放 , 对修改关闭 . 其含义是说一个软件实体应该通过扩展来实现变化 , 而不是通过修改已有的代码来实现变化 (原话 : Software entities like classes,modules and functions should be open for extension but closed for modifications. ) 开闭原则是面向对象程序设计的终极目标 所有已经投产的代码都是有意义的 , 并且都受系统规则的约束 , 这样的代码都要经过 “千锤百炼” 的测试过程，不仅保证逻辑是正确的，还要保证苛刻条件（高压力、异常、错误）下不产生 “有毒代码” , 因此有变化提出时 , 我们就需要考虑一下 , 原有的健壮代码是否可以不修改 , 仅仅通过扩展实现变化呢 ? 否则 , 就需要把原有的测试过程回笼一遍 , 需要进行单元测试 , 功能测试 , 集成测试甚至是验收测试 作用 : 提高代码的可复用性 提高软件的可维护性 前面5个原则是对开闭原则的具体解释 , 但是开闭原则并不局限于这么多 , 它没有边界 , 我们要把它应用到实际工作中需要注意以下几点 : 抽象约束 , 抽象层尽量保持稳定 元数据控制模块行为 (元数据 : 用来描述环境和数据的数据 , 通常说的就是配置参数) 指定项目章程 , 约定优于配置 封装变化 , 将相同的变化封装到一个接口或抽象类中 , 将不同的变化封装到不同的接口或抽象中 "},"07-设计模式/02-单例模式.html":{"url":"07-设计模式/02-单例模式.html","title":"单例模式","keywords":"","body":"单例模式 🍀 定义 🍀 单例模式 ( Singleton Pattern ) 确保某一个类只有一个实例 , 而且自行实例化并向整个系统提供这个实例 ( Ensure a class has only one instance, and provide a global point of access to it. ) 场景 🍀 在一个系统中 , 要求一个类有且仅有一个对象 , 如果出现多个对象就会出现 \"不良反应\" , 可以采用单例模式 如 : 在整个项目中需要一个共享访问点或共享数据 要生成唯一数据 创建一个对象需要消耗的资源过多 , 如要访问 IO 和数据库等资源 需要定义大量的静态常量和静态方法 (如工具类) 的环境 我们可能最多见的就是需要共享数据 , 比如在项目中的配置数据 , 又比如 Web 框架中的路由 实例 🍀 要实现单例模式 , 即保证一个类仅有一个实例 , 并提供一个访问它的全局访问点 Module 🍀 Python 中的 module 天生就是单例 , 至于为什么 , 你应该去看看 compiled-python-file singleton.py class Singleton(object): pass singleton = Singleton() 使用 from singleton import singleton __new__ 🍀 Python 中的对象将有 __new__ 来开辟空间创建实例 import threading class Singleton(object): _threading_lock = threading.RLock() def __new__(cls, *args, **kwargs): if not hasattr(cls, \"_instance\"): with cls._threading_lock: if not hasattr(cls, \"_instance\"): cls._instance = object.__new__(cls) return cls._instance Python 是支持多线程的 , 所以为了线程安全 , 加上锁 Metaclass 🍀 使用元类来实现单例模式 , 实际上就是控制 class() 的行为 , 也就是 __call__ 魔术方法 如果对于 metaclass 不懂 , 你可以看我的另一篇博客 《Python之路 - 元类》 class SingletonMeta(type): _instances = {} def __call__(self, *args, **kwargs): if self not in self._instances: self._instances[self] = super(SingletonMeta, self).__call__(*args, **kwargs) return self._instances[self] class Singleton(metaclass=SingletonMeta): pass singleton = Singleton() 元类创建类本身就是线程安全的 , 所以你并不需要担心抢占资源的问题 类装饰器 🍀 def singleton(cls): _instance = {} def _singleton(*args, **kargs): if cls not in _instance: _instance[cls] = cls(*args, **kargs) return _instance[cls] return _singleton @singleton class Singleton: pass 使用类装饰器 , 实际上就是把类转换成一个函数对象 , 因此跟实例的创建关系不大 , 因为从始至终也就实例化了一次 , 而且它是线程安全的 类方法 🍀 通过我们自定义的方法来获取对象 , 而不通过实例化的途径 class Singleton(object): @classmethod def instance(cls, *args, **kwargs): if not hasattr(cls, \"_instance\"): cls._instance = cls(*args, **kwargs) return cls._instance singleton = Singleton.instance() 虽然这种方式也能实现单例模式 , 但是它不是线程安全的 , 就算在方法里加了锁 , 也不是线程安全的 , 这里可能跟 Python 的类的加载机制有关 , 不深究了 注意 : 在测试过程中 , 千万要把 Python 的垃圾回收这一问题隔离 , 也就是说实例不要一实例化之后就丢弃 , 否则可能会出现无效的结果 "},"08-算法/":{"url":"08-算法/","title":"算法","keywords":"","body":"Algorithms 更多内容待后期推送... "},"08-算法/01-算法基础.html":{"url":"08-算法/01-算法基础.html","title":"算法基础","keywords":"","body":"算法基础 介绍 🍀 定义 算法是解决特定问题求解步骤的描述 , 在计算机中表现为指令的有限序列 , 并且每条指令表示一个或多个操作 算法的特性 输入输出 算法具有零个或多个输入 , 算法至少有一个或多个输出 有穷性 算法在执行有限的步骤之后 , 自动结束而不会出现无限循环 , 并且每一个步骤在可接受的时间内完成 确定性 算法的每一步骤都具有确定的含义 可行性 算法的每一步都必须是可行的 , 也就是说 , 每一步都能够通过执行有限次数完成 设计要求 🍀 解决一个问题的途径可以有非常多种 , 掌握好的算法 , 对我们解决问题很有帮助 , 而一个好的算法应该具备以下要求 正确性 算法的正确性是指算法至少应该具有输入 , 输出和加工处理无歧义性 , 能正确反应问题的需求 , 能够得到问题的正确答案 正确性应该符合以下四点 : 算法程序没有语法错误 算法程序对于合法的输入数据能够产生满足要求的输出结果 算法程序对于非法的输入数据能够得出满足规格说明的结果 算法程序对于精心选择的 , 甚至刁难的测试数据都有满足要求的输出结果 健壮性 一个好的算法还应该能对输入数据不合法的情况做合适的处理 , 比如输入的时间或者距离不应该是负数等 健壮性就是当输入数据不合法时 , 算法也能作出相关处理 , 而不是产生异常或者莫名奇妙的结果 时间效率高和存储量低 时间效率是指算法的执行时间 , 对于同一个问题 , 如果有多个算法能够解决 , 执行时间短的算法效率高 , 执行时间长的效率低 存储量需求值的是在执行过程中需要的最大存储空间 , 主要指算法程序运行时所占用的内存或外部硬盘空间 设计算法应该尽量满足时间效率和存储量低的要求 效率的度量方法 🍀 事后统计方法 这种方法主要是通过设计好的测试程序和数据 , 利用计算机计时器对不同算法编程的程序的运行时间进行比较 , 从而确定算法效率的高低 但是这种方法是有很大的缺陷的 : 必须依据算法事先编制好程序 , 这通常需要花费大量的时间和精力 , 并且一旦编制出来发现它根本是很糟糕的算法 , 那就白忙活了 时间的比较依赖计算机硬件和软件等环境因素 , 有时会掩盖算法本身的优劣 算法的测试数据设计困难 , 并且程序的运行时间往往还与测试数据的规模有很大的关系 , 效率高的算法在小的测试数据面前往往得不到体现 ; 比如10个数据的排序 , 不管用什么算法 , 差异几乎是零 , 而如果有一百万个随机数据排序 , 那不同的算法的差异就非常大了 , 所以用多少数据来测试我们的算法 , 这是一个很难判断的问题 事前分析估算方法 事前分析估算方法就是在计算机程序编制前 , 依据统计方法对算法进行估算 一个用高级程序语言编写的程序在计算机上运行时所消耗的时间取决于下列因素 : 算法采用的策略 , 方法 编译产生的代码质量 问题的输入规模 机器执行指令的速度 抛开与计算机硬件 , 软件有关的因素 , 一个程序的运行时间 , 依赖于算法的好坏和问题的输入规模 时间复杂度 🍀 在进行算法分析时 , 语句总的执行次数T(n)是关于问题规模n的函数 , 进而分析T(n)随n的变化情况并确定T(n)的数量级 算法的时间复杂度 , 也就是算法的时间量度 , 记作 : T(n)=O(f(n)) ; 它表示岁问题规模n 的增大 , 算法执行时间的增长率和f(n)的增长率相同 , 称作算法的渐进时间复杂度 , 简称为时间复杂度 , 其中f(n)是问题规模n的某个函数 我们用大写O() 来体现算法时间复杂度的记法 , 称之为大O记法 推导大O阶 🍀 分析一个算法的时间复杂度 , 推导大O阶时有以下方法 : 用常数1取代运行时间的所有加法常数 在修改后的运行次数函数中 , 只保留最高阶项 如果最高阶项存在且不是1 , 则去除与这个项相乘的常数 由此得到的结果就是大O阶 常数阶 🍀 首先介绍顺序结构的时间复杂度 , 现有如下算法 n = 100 # 执行一次 sum = (1+n)*n/2 # 执行一次 print(sum) # 执行一次 这个算法的运行次数函数是f(n)=3 , 根据推导大O阶的方法 , 直接把常数项改为1 , 在保留高阶项时发现 , 它根本没有最高阶项 , 所以这个算法的时间复杂度为O(1) 注意 : 不管这个常数是多少 , 我们都记作O(1) , 而不是O(3)等其他任意数字 对于分支结构而言 , 无论是真还是假 , 执行的次数都是恒定的 , 不会随着n的变大而发生变化 , 所以单纯的分支结构 (不包含在循环结构中) , 其时间复杂度也是O(1) 线性阶 🍀 线性阶的循环结构会复杂很多 , 要确定某个算法的阶次 , 我们常常需要确定某个特定语句或某个语句集运行的次数 ; 因此 , 我们要分析算法的复杂度 , 关键就是要分析循环结构的运行情况 , 如下 : for i in range(n): print(i) # 时间复杂度为O(1) 上面代码中 , print语句会执行n次 , 所以它的算法复杂度为O(n) 对数阶 🍀 count = 1 while count 上面代码中 , 每次count乘以2之后 , 就距离n更近了一分 , 也就是说 , 有多少个2想乘后大于n , 则会退出循环 , 由2^x = n 可以得到x = log2n , 所以这个循环的时间复杂度为O(logn) 平方阶 🍀 下面例子是一个循环嵌套 for i in range(n): for j in range(n): print(i,j) 对于外层的循环 , 时间复杂度为O(n) , 而内部循环时间复杂度也为O(n) , 所以这段代码的时间复杂度为O(n²) , 如果将外层循环改成m , 那么时间复杂度就会变成O(m×n) 常见时间复杂度 执行次数函数 阶 非正式术语 12 O(1) 常数阶 2n+3 O(n) 线性阶 3n²+2n+1 O(n²) 平方阶 5log2n + 20 O(logn) 对数阶 2n + 3nlog2n + 19 O(nlogn) nlogn阶 6n³ + 2n² + 3n +4 O(n³) 立方阶 2\" O(2\") 指数阶 常用时间复杂度所耗费的时间从小到大一次是 : O(1) 空间复杂度 🍀 算法的空间复杂度通过计算算法所需的存储空间实现 , 算法空间复杂度的计算公式记作 : S(n) = O(f(n)) , 其中n为问题的规模 , f(n)为语句关于n所占存储空间的函数 一般情况下 , 一个程序在机器上执行时 , 除了需要存储程序本身的指令 , 常数 , 变量和输入数据外 , 还需要存储对数据操作的存储单元 , 若输入数据所占空间值取决于问题本身 , 和算法无关 , 这样只需要分析该算法在实现时所需的辅助单元即可 若算法执行时所需的辅助空间相对于输入数据量而言是个常数 , 则称此算法为原地工作 , 空间复杂度为O(1) "},"08-算法/02-排序算法.html":{"url":"08-算法/02-排序算法.html","title":"排序算法","keywords":"","body":"排序算法 前言 🍀 排序问题是我们学习编程过程中最常见的 , 以Python中的列表为例 , 进行排序算法分析 , 在进行分析之前 , 我们先自己写一个时间测试装饰器 timewrap.py import time def cal_time(func): def wrapper(*args, **kwargs): t1 = time.time() result = func(*args, **kwargs) t2 = time.time() print(\"%s running time: %s secs.\" % (func.__name__, t2-t1)) return result return wrapper 这个装饰器只是为了进行简单的时间测试 , 因为影响一个算法的执行时间实在是太多 , 但对于我们学习算法确是够了 冒泡排序 🍀 工作流程 : 比较相邻的元素 , 如果第一个比第二个大 , 就交换它们 对每一对相邻元素作同样的工作 , 从列表的开始到结尾依次进行 , 如果列表长度为n , 那么总共走(n-1)躺 图解 : 代码实现 : import random from timewrap import * # 第一版 @cal_time def bubble_sort_1(li): # 总共走n-1躺 for n in range(len(li) - 1): # 每一躺比较(总长度-n-1次) for j in range(0, len(li) - n - 1): if li[j] > li[j+1]: li[j], li[j+1] = li[j+1], li[j] # 在第一版的基础进行优化 @cal_time def bubble_sort_2(li): # 总共走(n-1)躺 for n in range(len(li) - 1): # 没有改变说明元素位置正确,为了防止更多不必要的比较 change = False # 每一躺比较(总长度-n-1次) for j in range(0, len(li) - n - 1): if li[j] > li[j+1]: li[j], li[j+1] = li[j+1], li[j] change = True if not change: return li = list(range(10000)) random.shuffle(li) bubble_sort_1(li) bubble_sort_2(li) ''' 执行结果: bubble_sort_1 running time: 29.570897817611694 secs. bubble_sort_2 running time: 0.002001523971557617 secs. ''' 选择排序 🍀 工作流程 : 每次从待排序的数据元素中选出最小 (或最大) 的一个元素 , 存放在序列的起始位置 , 直到全部待排序的数据元素排完 代码实现 : import random from timewrap import * @cal_time def select_sort(li): # 总共走(n-1)躺 for n in range(len(li) - 1): # 最小数的位置 min_loc = n for j in range(n + 1, len(li) - 1): if li[j] 插入排序 🍀 工作流程 : 存在一个已经有序的数据序列 将后续数据按照要求依次一个个插入有序序列中 图解 : 代码实现 : import random from timewrap import * @cal_time def insert_sort(li): # 循环无序区进行排序 for n in range(1, len(li)): tmp = li[n] # 指向有序区最后位置 j = n - 1 while li[j] > tmp and j >= 0: li[j+1] = li[j] j -= 1 li[j+1] = tmp li = list(range(10000)) random.shuffle(li) insert_sort(li) ''' 执行结果: insert_sort running time: 18.230905055999756 secs. ''' 快速排序 🍀 工作流程 : 取一个元素P(第一个元素) , 使元素P归位 列表被P分成两部分 , 左边都小于P , 右边都大于P 递归完成排序 图解 : 代码实现 : import random from timewrap import * import copy import sys # 修改递归最大层数 sys.setrecursionlimit(100000) def partition(li, left, right): \"\"\" 进行分区 \"\"\" # 防止出现最坏情况 # ri = random.randint(left, right) # li[left], li[ri] = li[ri], li[left] tmp = li[left] while left = tmp: right -= 1 li[left] = li[right] while left 堆排序 🍀 堆分类 大根堆 : 一颗完全二叉树 , 满足任一节点都比其孩子节点大 小根堆 : 一颗完全二叉树 , 满足任一节点都比其孩子节点小 工作流程 : 建立堆 , 已完成调整 (以构建大根堆为例) 得到堆顶元素 , 为最大元素 去掉堆顶 , 将堆最后一个元素放到堆顶 , 随后重新调整 (挨个出数) 一直重复3 , 直到堆为空 挨个出数规则 : 找最后一个数作为棋子 , 然后取堆顶的值 , 存放最后 , 依次执行取出 图解 : 1.构建大根堆 , 索引按照从上倒下 , 从左到右依次递增 2.挨个出数 代码实现 : from timewrap import * import random def sift(li, low, high): \"\"\" :param li: :param low: 堆根节点的位置 :param high: 堆最有一个节点的位置 :return: \"\"\" # 父亲的位置 i = low # 孩子的位置 j = 2 * i + 1 # 原父亲 tmp = li[low] while j li[j]: j += 1 # 如果原父亲比孩子小 if tmp Python中有一个内置模块heapq可以帮助我们快速实现对排序 import heapq import random from timewrap import * @cal_time def heap_sort(li): heapq.heapify(li) n = len(li) new_li = [] for i in range(n): new_li.append(heapq.heappop(li)) return new_li li = list(range(10000)) random.shuffle(li) # 小根堆 heap_sort(li) # 大根堆,直接利用方法nlargest heapq.nlargest(100, li) 归并排序 🍀 假设现在的列表分成两段有序 , 如何将其合成为一个有序的列表 工作流程 : 分解列表 , 直至分解为一个个只有一个元素的列表 比较两段序列中索引相同的值的大小 , 符合条件就进行交换 , 如小的在左 , 大的在右 进行合并 , 重复2操作 , 直至合并为一个列表得出结果 图解 : 代码实现 : import random def merge(li, low, mid, high): i = low j = mid + 1 ltmp = [] while i 希尔排序 🍀 希尔排序是一种分组插入排序算法 工作流程 : 首先取一个整数d1=n/2 , 将元素分为d1个组 , 每组相邻两元素距离为d1 , 在各组内进行直接插入排序 取第二个整数d2=d1/2 , 重复上述分组排序过程 , 直到d1=1 , 即所有元素在同一组内进行直接插入排序 希尔排序每躺并不使某些元素有序 , 而是使整体数据越来越进阶有序 ; 最后一趟排序使得所有数据有序 代码实现 : import random def shell_sort(li): gap = int(len(li) // 2) while gap > 0: for i in range(gap, len(li)): tmp = li[i] print(i-gap) j = i - gap while j >= 0 and tmp 计数排序 🍀 现有一个列表 , 列表中的数范围都在0到100之间 , 列表长度大约为100万 , 设计算法在O(n)时间复杂度内将列表进行排序 工作流程 : 查找列表中最大和最小的元素 开辟一个新的空间存放统计的每个元素出现次数 反向填充目标列表 代码实现 : import random import copy from timewrap import * @cal_time def count_sort(li, max_num = 100): count = [0 for i in range(max_num+1)] for num in li: count[num]+=1 li.clear() for i, val in enumerate(count): for _ in range(val): li.append(i) @cal_time def sys_sort(li): li.sort() li = [random.randint(0,100) for i in range(100000)] li1 = copy.deepcopy(li) count_sort(li) ''' 执行结果: count_sort running time: 0.024517059326171875 secs. ''' 桶排序 🍀 桶排序的基本思想是将一个数据表分割成许多桶 , 然后每个桶各自排序 , 有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序 工作流程 : 建立一堆buckets 遍历原始数组 , 并将数据放入到各自的buckets当中 对非空的buckets进行排序 按照顺序遍历这些buckets并放回到原始数组中即可构成排序后的数组 代码实现 : import random from timewrap import * def list_to_buckets(li, iteration): \"\"\" :param li: 列表 :param iteration: 装桶是第几次迭代 :return: \"\"\" buckets = [[] for _ in range(10)] for num in li: digit = (num // (10 ** iteration)) % 10 buckets[digit].append(num) return buckets def buckets_to_list(buckets): return [num for bucket in buckets for num in bucket] @cal_time def radix_sort(li): maxval = max(li) it = 0 while 10 ** it 小结 🍀 排序方法 时间复杂度(平均) 时间复杂度(最坏) 时间复杂度(最好) 空间复杂度 稳定性 复杂性 冒泡排序 O(n²) O(n²) O(n) O(1) 稳定 简单 选择排序 O(n²) O(n²) O(n²) O(1) 不稳定 简单 插入排序 O(n²) O(n²) O(n²) O(1) 稳定 简单 快速排序 O(n²) O(nlogn) O(nlogn) 平均情况O(nlogn)最坏情况O(n) 不稳定 较复杂 堆排序 O(nlogn) O(nlogn) O(nlogn) O(1) 不稳定 复杂 归并排序 O(nlogn) O(nlogn) O(nlogn) O(n) 稳定 较复杂 希尔排序 O(nlogn) O(n²) O(n) O(1) 不稳定 较复杂 计数排序 O(n+k) O(n+k) O(n+k) O(n+k) 稳定 简单 桶排序 O(n+k) O(n²) O(n+k) O(n*k) 不稳定 简单 "},"09-Linux/":{"url":"09-Linux/","title":"Linux","keywords":"","body":""},"09-Linux/Celery.html":{"url":"09-Linux/Celery.html","title":"Celery","keywords":"","body":"Celery 介绍 🍀 Celery 是一个专注于实时处理和任务调度的分布式任务队列 , 所谓任务就是消息 , 消息中的有效载荷中包含要执行任务需要的全部数据 使用 Celery 的常见场景如下 : Web 应用 , 当用户触发的一个操作需要较长时间才能执行完成时 , 可以把它作为任务交给 Celery 去异步执行 , 执行完再返回给用户 , 这段时间用户不需要等待 , 提高了网站的整体吞吐量和响应时间 定时任务 , 生产环境经常会跑一些定时任务 , Celery 可以帮助我们快速在不同的机器设定不同中任务 其他可以异步执行的任务 , 为了充分提高网站性能 , 对于请求和响应之外的那些不要求必须同步完成的附加工作都可以异步完成 , 比如发送短信/邮件 , 推送消息 , 清理/设置缓存等 Celery 提供的特性 : 方便地查看定时任务的执行情况 , 比如执行是否成功 , 当前状态 , 执行任务花费的时间等 可以使用功能齐备的管理后台或者命令行添加 , 更新 , 删除任务 方便把任务和配置管理相关联 可选多进程 , Eventlet 和 Gevent 三种模式并发执行 提供错误处理机制 提供多种任务原语 , 方便实现任务分组 , 拆分和调用链 支持多种消息代理和存储后端 组件 🍀 Celery包含如下组件 : Celery Beat : 任务调度器 , Beat进程会读取配置文件的内容 , 周期性地将配置中到期需要执行的任务发送给任务队列 Celery Worker : 执行任务的消费者 , 通常会在多台服务器运行多个消费者来提高执行效率 Broker : 消息代理 , 或者叫作消息中间件 , 接受任务生产者发送过来的任务消息 , 存进队列再按序分发给任务消费方(通常是消息队列或者数据库) Producer : 调用了Celery提供的API、函数或者装饰器而产生任务并交给任务队列处理的都是任务生产者 Result Backend : 任务处理完后保存状态信息和结果 , 以供查询 , Celery默认已支持Redis、RabbitMQ、MongoDB、Django ORM、SQLAlchemy等方式 其工作流程如下 : 选择消息代理 🍀 Celery 目前支持 RabbitMQ , Redis , MongoDB , Beanstalk ,SQLAlchemy , Zookeeper 等作为消息代理 , 但适用于生产环境的只有 RabbitMQ 和 Redis Celery 官方推荐使用 RabbitMQ , Celery 作者 Ask Solem Hoel 最初在 VMware 就是为 RabbitMQ 工作的 , Celery 最初的设计就是基于 RabbitMQ , 所以使用 RabbitMQ 会非常稳定 Celery 序列化 🍀 在客户端和消费者之间传输数据需要序列化和反序列化 , Celery 支持方案如下 : 安装配置 Celery 🍀 为了提供更高的性能 , 选择方案如下 : 选择 RabbitMQ 作为消息代理 RabbitMQ 的 Python 客户端选择 librabbitmq 这个C库 选择Msgpack做序列化 选择Redis做结果存储 Celery 提供 bundles 的方式安装 , 也就是安装 Celery 的同时可以一起安装多种依赖 : $ pip install \"celery[librabbitmq,redis,msgpack]\" "},"09-Linux/Docker.html":{"url":"09-Linux/Docker.html","title":"Docker","keywords":"","body":"Docker 介绍 Docker 是一个开源的应用容器引擎 , 基于 Go 语言 并遵从 Apache2.0 协议开源 Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中 , 然后发布到任何流行的 Linux 机器上 , 也可以实现虚拟化 功能和组件 Docker 的实现引入了以下核心概念 : Docker 客户端 Docker daemon Docker 容器 Docker 镜像 Registry Docker客户端 Docker 是一个典型的 C/S 架构的应用程序 , 但在发布上 , Docker 将客户端和服务器端统一在同一个二进制文件中 , 不过 , 这只是对于 Linux 系统而言的 , 在其他平台如 Mac 上 , Docker 只提供了客户端 Docker 客户端一般通过 Docker command 来发起清楚 , 另外 , 也可以通过 Docker 提供的一整套 RESTful API 来发起请求 , 这种方式更多地被应用在应用程序的代码中 Docker daemon Docker daemon 也可以被理解为 Docker Server , 另外 , 人们也常常用 Docker Engine 来直接描述它 , 因为这实际上就是驱动整个 Docker 功能的核心引擎 简单地说 , Docker daemon 实现的功能就是接收客户端发来的请求 , 并实现请求所要求的功能 , 同时针对请求返回响应的结果 , 在功能的实现上 , 因为涉及了容器 , 镜像 , 存储等多方便的内容 , daemon 内部的机制会复杂很多 , 涉及了多个模块的实现和交互 Docker容器 在 Docker 的功能和概念中 , 容器是一个核心内容 , 相对于传统虚拟化 , 它作为一项基础技术在性能上给 Docker 带来了极大优势 在概念上 , 容器很好地诠释了 Docker 集装箱的理念 , 集装箱可以存放任何货物 , 可以通过邮轮将货物运输到世界各地 , 运输集装箱的邮轮和装载卸载集装箱的码头都不用关心集装箱里的货物 , 这是一种标准的集装和运输方式 ; 类似的 , Docker 的容器就是 \"软件界的集装箱\" , 它可以安装任意的软件和库文件 , 做任意的运行环境配置 , 开发及运维人员在转义和部署应用的时候 , 不用关心容器里装了什么软件 , 也不用了解它们是如何配置的 , 而管理容器的 Docker 引擎同样不关心容器里的内容 , 它只要像码头工人一样让这个容器运行起来就可以了 , 就像所有其他容器那样 Docker镜像 与容器相对应 , 如果说容器提供了一个完整的 , 隔离的运行环境 , 那么镜像则是这个运行环境的静态体现 , 是一个还没有运行起来的 \"运行环境\" 相对传统虚拟化中的 ISO 镜像 , Docker 镜像要轻量化很多 , 它只是一个可定制的 rootfs , Docker 镜像的另一个创新是它是层级的并且是可服用的 Docker 镜像通常是通过 Dockerfile 来创建的 , Dockerfile 提供了镜像内容的定制 , 同时也体现了层级关系的建立 , 另外 Docker 镜像也可以通过使用 docker commit 这样的命令来手动将修改后的内容生成镜像 Registry Registry 是一个存放镜像的仓库 , 它通常被部署在互联网服务或者云端 , 通常 , 集装箱是需要通过邮轮经行海洋运输到世界各地的 , 而互联网时代的传输则要方便很多 , 在镜像的传输过程中 , Registry 就是这个传输的重要中转站 ; 假如我们在公司将一个软件的运行环境作成镜像 , 并上传到 Registry 中 , 这时就可以很方便地在家里的笔记本上 , 或者在客户的生产环境上直接从 Registry 上下载并运行了 比较 跟传统VM比较 , Docker 具有如下优点 : 操作启动快 , 运行时的性能可以获取极大提升 , 管理操作(启动 , 停止 , 开始 , 重启等等) 都是以秒或毫秒为单位的 轻量级虚拟化 , 你会拥有足够的“操作系统” , 仅需添加或减小镜像即可 开源免费 , 开源的 , 免费的 , 低成本的 , 由现代Linux内核支持并驱动 前景及云支持 跟传统VM比较 , Docker 具有如下缺点 : 它是一项新型的技术 , 可能还不够稳定 Go 语言还没有完全成熟 "},"09-Linux/Git/":{"url":"09-Linux/Git/","title":"Git","keywords":"","body":"Git "},"09-Linux/Git/01-Git&GitHub.html":{"url":"09-Linux/Git/01-Git&GitHub.html","title":"Git&GitHub","keywords":"","body":"Git&Github 1. Git简介 🍀 1.1. Git 🍀 Git是一个免费并且开源的分布式版本控制系统 , 被设计用来快速 , 高效的管理一切从小到大的项目 1.2. 版本控制 🍀 我们所开发的软件在其整个生命周期 , 都需要进行不断的改进 , 比如 , 日常写bug改bug , 对业务的增删改查等 , 如果没有一个工具来帮助我们控制 , 那么日常开发将会是多么的坑 ... 一不小心删了个文件 , 一不小心提交了错误代码 , 一不小心整个项目就没了 ... 所以为了方便我们在开发软件中对各个软件版本的管理与控制 , 于是就有了如下版本控制系统 : CVS , (Concurrent Version System) 诞生于1985年 , 是由荷兰阿姆斯特丹VU大学的Dick Grune教授实现的 , 是有史以来第一个被大规模使用的版本控制工具 —— 开启版本控制大爆发 SVN , (Subversion) 诞生于2000年 , 由CollabNet公司资助并开始开发 , 由于其命令行工具名为svn , 因此通常被简称为SVN , 目的是取代CVS —— 集中式版本控制集大成者 Git 诞生于2005年 , 又Linux系统的创始人Linus开发而成 , 主要是因为在2005年Andrew Tridgell (大名鼎鼎的Samba的作者) 社团对BitKeeper进行反向工程 , 于是激怒了BitKeeper软件的所有者BitMover公司 , 收回了对Linux社区免费使用BitKeeper的授权 , 导致Linus第二个伟大作品 —— 分布式版本控制系统Git 1.3. 集中式与分布式 🍀 集中式 集中式版本控制系统 , 将所有数据集中存放在服务器中 , 有便于管理的优点 , 如SVN 集中式只存在一个仓库 , 如果开发者开发所处的环境不能连接到服务器 , 就无法获取最新的源代码 , 开发也就无法进行 ; 并且一旦服务器宕机 , 万一服务器故障导致数据消失 , 那么开发者就再也见不到最新的源代码了 分布式 分布式版本控制系统 , 每个人都有完整的版本库 , 开发者不必连接远程仓库 , 如Git 分布式中每个开发者都具有独立的完整的版本库 , 安全性高 ; 在分布式版本控制系统中通常会有一台服务器充当 \"中央服务器\" , 这个服务器的作用仅仅是用来方便 \"交换\" 开发者们之间的修改 , 当然这仅仅是为了使开发者们之间 \"交换\" 更加方便 所以集中式与分布式都具有各自的优缺点 , 在使用时 , 我们应该根据具体情况选择 不过随着Git与Github的普及 , 使用分布式的开发者会占绝大多数 ; 只要规则指定得当 , 分布式同样能够像集中式那样进行管理 2. GitHub简介 🍀 Github 与 Git 是两回事 GitHub 是为开发者提供Git仓库的托管服务 , 但是注意 Github并不只是 Git仓库的托管服务 在Git中 , 开发者将源代码存入名叫 \"Git仓库\" 的资料库中并加以使用 , 而Github则是在网络上提供Git仓库的一项服务 也就是说 , Github上公开的软件源代码全都是由Git进行管理 2.1. GitHub提供的主要功能 🍀 Git 仓库 我们可以免费建立任意个 GitHub 提供的 Git 仓库 , 但如果需要建立只对特定人物或只对自己公开的私有仓库 , 则需要依照套餐类型B支付每月最低 7 美元的使用费 Organization 企业导入 GitHub 时建议使用 Organization 账户 , 利用这一功能 , 可以让开发者们使用同一控制面板 , 还能够创建团队并统一管理权限 ; 另外这一账户还为企业提供了用户管理和支付等便捷功能 Issue Issue 功能 , 是将一个任务或问题分配给一个 Issue 进行追踪和管理的功能 Wiki 该功能常用在开发文档或手册的编写中 , Wiki 页也是作为 Git 仓库进行管理的 , 改版的历史记录会被切实保存下来 , 使用者可以放心改写 Pull Request 开发者向 GitHub 的仓库推送更改或功能添加后 , 可以通过 Pull Request 功能向别人的仓库提出申请 , 请求对方合并 Pull Request 送出后 , 目标仓库的管理者等人将能够查看 Pull Request 的内容及其中包含的代码更改 3. 安装Git 🍀 在 Linux 上 $ sudo apt-get install git 在 Windows 上 下载Git , 下载完成后之前安装就可以了 安装成功后我们可以在开始菜单里找到 Git Bash , 或者查看鼠标右键菜单中是否有Git Bash Here 3.1. 初始设置 🍀 显示当前配置 $ git config --list 设置姓名和邮箱地址 $ git config --global user.name \"lyon\" $ git config --global user.email \"lyon@xxxxx\" # lyon@xxx为邮箱地址 提高命令输出的可读性 $ git config --global color.ui auto 4. GitHub准备工作 🍀 4.1. 创建账户 🍀 进入注册页面完成注册 , 点我跳转注册页面 4.2. 设置SSH Key 🍀 GitHub上连接已有的仓库时的认证 , 是通过使用SSH的公开密钥认证方式进行的 , 所以我们需要创建一个SSH Key , 并将其添加至GitHub中 $ ssh-keygen -t rsa -C \"lyon@xxx\" # lyon@xxx为邮箱地址 Generating public/private rsa key pair. Enter file in which to save the key (/Users/your_user_directory/.ssh/id_rsa): # 回车 Enter passphrase (empty for no passphrase): # 输入密码 Enter same passphrase again: # 输入密码 创建完成后可以在你的User目录下可以看到一个.ssh的文件夹 : .ssh ├── id_rsa 私有密钥 ├── id_rsa.pub 公有密钥 ├── known_hosts └── qwe.ppk 4.3. 添加公钥 🍀 创建好密钥之后 , 我们需要在GitHub中添加公有密钥 , 这样就可以使用私有密钥进行认证了 进入头像下拉框中的settings , 添加公有密钥 , 即复制id_rsa.pub中的内容 添加完成之后 , 创建账号时所用的邮箱会接到一封邮件 , 提示 \"公有密钥添加完成\" 完成后 , 可以用手中的私有密钥与GitHub进行认证和通信 , 如下 : $ ssh -T git@github.com 出现如下结果即为成功 Hi hirocastest! You've successfully authenticated, but GitHub does not provide shell access. 5. 创建仓库 🍀 点击头像旁边的 \"+\" 下拉框 , 选择New repository Repository name 仓库名 Descriptiion 描述信息 Public , Private 选择创建公开仓库还是私有仓库 , 私有仓库是收费的 Initialize this repository with a README 选择自动完成初始化仓库 , 并设置README文件 如果想向GitHub添加手中已有的仓库 , 建议不要勾选 Add .gitignore 添加.gitignore文件 Add a license 添加的许可协议 "},"09-Linux/Git/02-Git基础命令.html":{"url":"09-Linux/Git/02-Git基础命令.html","title":"Git基础命令","keywords":"","body":"Git基础命令 1. 前言 🍀 1.1. 工作区 🍀 对于Git来说 , 版本库位于工作区根目录下的.git目录中 , 且仅此一处 , 在工作区的子目录下则没有任何其他跟踪文件或目录 而工作区就是我们进行版本控制的某个文件夹 , 我们初始化之后就可以利用Git来进行管理了 1.2. 暂存区 🍀 在.git 目录中有一个index文件 , 这个文件就是暂存区(stage) , 当我们执行git add命令时 , 我们的修改并不是直接添加到了master分支 , 而是添加到了暂存区 , 我们需要继续执行git commit命令才能将修改从暂存区移到master分支 , 这样才算完成了一次提交 2. 基本操作 🍀 2.1. 初始化仓库 🍀 我们要使用Git进行版本管理 , 必须先初始化仓库 Git 使用git init命令进行初始化 我们可以打开Git Bash后手动切换到仓库 , 或者到仓库目录点击右键选择Git Bash Here $ mkdir git-tutorial $ cd git-tutorial $ git init Initialized empty Git repository in /Users/github-book /git-tutorial/.git/ 初始化成功后 , 会自动生成.get目录 , 这个.git 存储着管理当前目录内容所需的仓库数据 , 在Git中 , 我们将这个目录的内容称为 \"附属于该仓库的工作区\" 2.2. 查看仓库状态 🍀 git status 命令用于显示Git仓库的状态 , 工作区和仓库在被操作的过程中 , 状态会不断发生变化 , 在Git操作过程中经常用git status命令查看 \"当前状态\" $ git status On branch master # 当前处于master分支 Initial commit nothing to commit (create/copy files and use \"git add\" to track) # 没有可提交的内容 2.3. 增删文件 🍀 我们一般创建一个GitHub远程仓库时 , 都会选择不自动初始化 , 而是自己来建立README.md文件作为管理对象 , 为第一次提交做前期准备 我们可以使用touch命令来创建文件 新建README.md到本地仓库 $ touch README.md # 创建一个新文件README.md $ git status # 查看仓库状态 On branch master Initial commit Untracked files: (use \"git add ...\" to include in what will be committed) README.md nothing added to commit but untracked files present (use \"git add\" to track) 我们可以看到在Untracked files中显示了README.md文件 , 类似地 , 只要对Git的工作区或仓库进行操作 , git status命令的显示结果就会发生改变 向暂存区中添加文件 如果只是用Git仓库的工作区创建了文件 , 那么该文件并不会被记入Git仓库的版本管理对象当中 , 因此我们用git status命令查看时 , 新增的README.md文件时 , 它会显示在Untracked files中 所以如果要想让文件成为Git仓库的管理对象 , 就需要用git add命令将其加入暂存区 (Stage或者Index) . 暂存区是提交之前的一个临时区域 $ git add README.md # 添加至暂存区 $ git status # 查看仓库状态 On branch master Initial commit Changes to be committed: (use \"git rm --cached ...\" to unstage) new file: README.md 将README.md文件加入暂存区后 , git status命令的显示结果发生了变化 , Changes to be committed: 中显示new file: README.md 如果想要删除暂存区中的文件 , 可以使用git rm [filename]命令进行删除 保存仓库的历史记录 当我们使用git add命令之后 , 需要使用git commit命令将当前暂存区中的文件实际保存到仓库的历史记录中 , 通过这些记录 , 我们就可以在工作区中复原文件 , 在git commit中有一个-m参数 , 为提交信息 , 是对这个提交的概述 $ git commit -m \"First commit\" [master (root-commit) 4733231] First commit 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 README.md $ git status On branch master nothing to commit, working tree clean 2.4. 查看日志 🍀 git log 命令可以查看以往仓库中提交的日志 , 包括可以查看什么人在什么时候进行了提交或合并 , 以及操作前后有怎样的差别 $ git log commit 4733231b262d9cd1d4449240735ed56edab65ca1 (HEAD -> master) Author: lyonyang Date: Mon May 29 22:56:50 2017 +0800 First commit 显示提交信息的第一行 可以在git log命令后加上--pretty=short来只查看提交信息的第一行 $ git log --pretty=short commit 4733231b262d9cd1d4449240735ed56edab65ca1 (HEAD -> master) Author: lyonyang First commit 显示指定目录或文件日志 只要在git log命令后加上目录名 , 就可以显示改目录下的日志 , 如果是文件名 , 就会只显示与该文件相关的日志 $ git log README.md commit 4733231b262d9cd1d4449240735ed56edab65ca1 (HEAD -> master) Author: lyonyang Date: Mon May 29 22:56:50 2017 +0800 First commit 显示文件的改动 如果想查看提交所带来的改动 , 可以加上-p参数 $ git log -p # 指定文件 $ git log -p README.md 2.5. 查看更改前后区别 🍀 git diff命令可以查看工作区 , 暂存区 , 最新提交至今的差别 通过vim命令修改README.md $ vim README.md +# edit README.md +# +# First 执行git diff命令 , 查看当前工作区与暂存区的差别 $ git diff diff --git a/README.md b/README.md index e69de29..88b52b3 100644 --- a/README.md +++ b/README.md @@ -0,0 +1,5 @@ +# edit README.md + +# First 如果工作区和暂存区的状态并无差别 , 那么我们在执行git commit命令之前先执行git diff HEAD命令 , 查看本次提交与上次提交之间有什么差别 , HEAD是指向当前分支中最新一次提交的指针 , 这是一个好习惯 3. 分支操作 🍀 在进行多个并行作业时 , 我们会用到分支 , 而在我们日常开发中 , 基本都会采用并发作业的方式 ; 在这类并行开发的过程中 , 往往同时存在多个最新代码状态 从master分支创建了feature-A分支和fix-B分支 在不同的分支中 , 可以同时进行完全不同的作业 , 等改分支的作业完成之后 , 再与master分支合并 , 如下 : 通过灵活的使用分支 , 可以让多个人同时高效地进行并行开发 , 并且使开发过程更加的安全 3.1. 显示分支 🍀 git branch命令可以将分支名列表显示 , 同时可以确认当前所在分支 $ git branch * master # 当前只有一个master分支 可以看到master分支左侧标有 * 号 , 这表示我们当前所在分支 , 也就是说 , 我们正在master分支下进行开发 3.2. 创建分支 🍀 git checkout -b命令可以用于我们以当前master分支为基础 , 创建一个新的分支 , 并切换到新建分支 $ git checkout -b feature-A # 创建分支并切换 Switched to a new branch 'feature-A' M README.md $ git branch # 显示分支 * feature-A master 创建并切换我们通过以下两条命令也能收到同样的效果 $ git branch feature-A # 创建分支feature-A $ git checkout feature-A # 切换到分支feature-A 在feature-A分支中修改文件并提交 $ vim README.md # 修改文件 +# +# branch feature-A $ git add README.md # 添加至暂存区 $ git commit -m \"Add feature-A\" # 提交 [feature-A 78c070a] Add feature-A 1 file changed, 5 insertions(+) 3.3. 切换分支 🍀 我们在feature-A分支下对文件进行了修改后 , 可以使用git checkout [branch]切分支 $ git checkout master # 切换到master分支 Switched to branch 'master' $ vim README.md # 进入文件,我们可以发现没有发生改变 因为我们的修改只是在feature-A分支上建立的 , 而各个分支都是相互独立的 , 所以在feature-A分支上做任何事情也不会影响到其他的分支 切换回上一个分支 如果想要切换到上一个分支 , 可以使用 - (连字符)代替分支名 $ git checkout - # 从master分支继续切换回feature-A分支 Switched to branch 'feature-A' 3.4. 合并分支 🍀 通过合并分支 , 可以将一个分支的内容合并到另一个分支中去 , 比如我们上面修改了feature-A分支 , 现在将其与master分支进行合并 git merge命令用来合并分支 , 首先切换到master分支 $ git checkout master Switched to branch 'master' Merge branch 'feature-A' # Please enter a commit message to explain why this merge is necessary, # especially if it merges an updated upstream into a topic branch. # # Lines starting with '#' will be ignored, and an empty message aborts # the commit. # 上述内容保存后关闭即可 $ git merge --no-ff feature-A Merge made by the 'recursive' strategy. README.md | 5 +++++ 1 file changed, 5 insertions(+) 为了在历史记录中明确记录下本次分支合并 , 我们需要创建合并提交 , 因此 , 在合并时加上 --no-ff参数 这样就完成了分支的合并了 用git log --graph命令可以以图表的形式查看分支提交的内容已被合并 $ git log --graph * commit a905c7028b96d2c003970b095a20b22a03ccc3ad (HEAD -> master) |\\ Merge: 4733231 78c070a | | Author: lyonyang | | Date: Mon May 29 23:31:47 2017 +0800 | | | | Merge branch 'feature-A' | | | * commit 78c070aeb464329116f1fc1bf7f84f8201bf7165 (feature-A) |/ Author: lyonyang | Date: Mon May 29 23:12:23 2017 +0800 | | Add feature-A | * commit 4733231b262d9cd1d4449240735ed56edab65ca1 Author: lyonyang Date: Mon May 29 22:56:50 2017 +0800 First commit 4. 版本回溯 🍀 4.1. 回溯 🍀 我们可以使用git rest --hard命令让仓库的HEAD , 暂存区 , 工作区回溯到指定状态 , 只要提供目标时间点的哈希值 , 就可以完全恢复至该时间点的状态 $ git reset --hard 78c070aeb464329116f1fc1bf7f84f8201bf7165 HEAD is now at 78c070a Add feature-A git log命令只能查看以当前状态为终点的历史日志 , 而git reflog命令可以查看当前仓库的操作日志 ; 所以如果我们想恢复到回溯之前的版本 , 可以先执行gitreflog命令, 查看当前仓库执行过的操作的日志 $ git reflog 78c070a (HEAD -> master, feature-A) HEAD@{0}: reset: moving to 78c070aeb464329116f1fc1bf7f84f8201bf7165 a905c70 HEAD@{1}: merge feature-A: Merge made by the 'recursive' strategy. 4733231 HEAD@{2}: checkout: moving from feature-A to master 78c070a (HEAD -> master, feature-A) HEAD@{3}: checkout: moving from master to feature-A 4733231 HEAD@{4}: checkout: moving from feature-A to master 78c070a (HEAD -> master, feature-A) HEAD@{5}: commit: Add feature-A 4733231 HEAD@{6}: checkout: moving from master to feature-A 4733231 HEAD@{7}: commit (initial): First commit 只要我们不进行Git的GC(Garbage Collection, 垃圾回收) , 就可以通过日志随意调去近期的历史状态 , 这样我们就可以在过去未来中自由穿梭 4.2. 消除冲突 🍀 合并分支有时会出现冲突的情况 , 我们创建一个新的分支来进行说明 在feature-B分支上进行修改 创建并切换feature-B分支 $ git checkout -b feature-B Switched to a new branch 'feature-B' 在feature-B分支上修改README.md文件内容 $ vim README.md # 在README.md最后添加内容 # +add this line to B branch 提交本次修改 $ git add README.md # 添加至暂存区 $ git commit -m \"add a line to the featrue-B branch\" # 将暂存区的内容提交到当前分支 [feature-B 89be876] add a line to the featrue-B branch 1 file changed, 1 insertions(+) 在master分支上进行修改 切换到master分支 $ git checkout master Switched to branch 'master' 在master分支上修改README.md文件内容 $ vim README.md # 在README.md最后添加内容 # +add this line to B branch 提交本次修改 $ git add README.md $ git commit -m \"add a line to the master branch\" [master 0abd9eb] add a line to the master branch 1 file changed, 1 insertions(+) 到这里 , 两个分支上的README.md文件中的内容就不一样了 , 接下来我们合并这两个分支 合并分支 # 当前在master分支 $ git merge feature-B Auto-merging README.md CONFLICT (content): Merge conflict in README.md Automatic merge failed; fix conflicts and then commit the result. Git返回的内容告诉我们 , README.md文件存在冲突 , 必须手动解决冲突后再提交 通过git status查看冲突 $ git status On branch master You have unmerged paths. (fix conflicts and run \"git commit\") (use \"git merge --abort\" to abort the merge) Unmerged paths: (use \"git add ...\" to mark resolution) both modified: README.md no changes added to commit (use \"git add\" and/or \"git commit -a\") 查看README.md文件 $ cat README.md # edit README.md # First # branch feature-A ... #>>>>>> feature-B Git用 , ======= , >>>>>>> 标记出不同分支的内容 , 为了解决冲突 , 我们需要修改一方来解决冲突 , 比如修改master分支或者feature-B分支中的README.md文件的内容 , 修改完成后保存 , 然后再提交 $ git add readme.txt $ git commit -m \"conflict fixed\" [master 1f4c296] conflict fixed 再合并分支 $ git merge feature-B Already up-to-date. 查看分支的合并情况 $ git log --graph --pretty=oneline --abbrev-commit * 1f4c296 (HEAD -> master) conflict fixed |\\ | * 89be876 (feature-B) add a line to the featrue-B branch * | 0abd9eb add a line to the master branch |/ * 78c070a (feature-A) Add feature-A * 4733231 First commit 最后 , 删除feature-B分支 $ git branch -d feature-B Deleted branch feature-B (was 89be876). 这样我们解决分支冲突问题 4.3. 分支管理 🍀 通常 , 合并分支时 , 如果课可能 , Git会使用Fast forward模式 , 但是这种模式下 , 一旦我们删除分支后 , 那么分支的信息也随之被丢掉了 , 所以为了保留历史的分支信息 , 我们可以强制禁用Fast forward模式 在合并分支时使用--no-f参数 , 就可以禁用Fast forward $ git merge --no-ff feature-A Already up-to-date. 本篇主要参考以下两本书籍 : GitHub入门与实践 Git权威指南 "},"09-Linux/Git/GitHub Pages&Gitbook&Travis CI持续构建博客.html":{"url":"09-Linux/Git/GitHub Pages&Gitbook&Travis CI持续构建博客.html","title":"GitHub Pages&Gitbook&Travis CI持续构建博客","keywords":"","body":"GitHub Pages&Gitbook&Travis CI持续构建博客 欢迎收藏交流 , 如需转载 , 请注明出处 1. 开始 🍀 如今程序猿没个个人站点或是博客 , 都不好意思出门了 所以在这里教大家如何构建一本书 (博客) : https://lyonyang.github.io/blogs/ 这是我的个人博客 , 样式就是这样的啦 那么 , 开始吧 1.1. 搭建准备 🍀 实际上 , 没什么要准备的 ... GitHub账号就不用说了 , 创建一个新的仓库吧 , 来存放个人博客笔记文件 1.2. 搭建要求 🍀 本博客 (更形象点 : 一本书) , 文件必须为.md文件 , 也就是MarkDown 文件 , 所以如果你不是这种格式 , 那么我建议你开始使用 , Markdown语法说明 , 当然还有.rst , 也就是reStructuredText 文件也是可以的 , 但是本文仅说明关于Markdown的构建 为什么用Markdown? Markdown是一种轻量级的「标记语言」 , 通常为程序员群体所用 , 适用于泡技术论坛、写博客日志、技术文稿、记录代码片段、起草邮件等场景 Markdown语法十分简单 , 常用的标记符号不超过十个 , 用于日常写作记录绰绰有余 纯文本编辑 , 可以转换成各种文档格式 , 如 : html , tex , pd等等 最重要的是 , Markdown能在GitHub上直接展示出来 , 所以你可以看到很多GitHub开源项目 (不开源你也看不到啊) 中的README都是.md文件 本地Markdown编辑可以使用Typora , VSCode , Atom等等 , 本人用的是Typora , 支持功能比较多 1.3. 搭建说明 🍀 本博客使用GitBook进行构建 , 如Hexo一样 , 我们并不是使用GitBook所有 , 而是仅仅使用它的一个功能 : GitBook和Hexo都能帮我们把Markdown格式文件转换成html文件 , 并且是附带了样式的html文件 当然这种构建对于我们只使用一两次还好 , 如果像我们的博客需要长期更新 , 那么手动构建就太麻烦了 , 所以我们使用一个持续集成工具 Travis CI , 它是开源的 , 所以放心 , 不要钱 也就是说 , 所有的准备如下 : GitHub + .md + GitBook + Travis CI 那么就开始了 2. 配置文件 🍀 创建仓库就不说了 , 创建完成之后 , 我们就先开始添加配置文件了 , 这是构建的重中之重 配置文件目录 . ├── .travis.yml -- 持续集成配置 ├── deploy.sh -- 构建脚本 ├── book.json -- gitbook样式文件 ├── summary_create.sh -- 自动创建SUMMARY.md文件 ├── SUMMARY.md -- 必须要有 └── README.md -- 必须要有 2.1. .travis.yml 🍀 当Travis CI发现你的仓库有更新时 , 就会来你仓库找到这个配置文件 , 并执行它 以node_js语言为例 language: \"node_js\" node_js: - \"node\" install: - \"npm install -g gitbook@3.2.3\" - \"npm install -g gitbook-cli@2.3.2\" branches: only: - master env: global: - GH_REF: github.com/用户名/仓库名.git script: - bash summary_create.sh - travis_wait 100 bash deploy.sh 注意GH_REF修改成各自的GitHub用户名和仓库 2.2. deploy.sh 🍀 该文件是.travis.yml中需要执行的脚本 #!/bin/bash git config user.name \"user\" git config user.email \"email@xxx.com\" git checkout -b gitbook git status git add . git commit -m \"[Travis] Update SUMMARY.md\" git push -f \"https://${GH_TOKEN}@${GH_REF}\" gitbook:gitbook gitbook install gitbook build . if [ $? -ne 0 ];then exit 1 fi cd _book git init git checkout --orphan gh-pages git status sleep 5 git add . git commit -m \"Update gh-pages\" git remote add origin git@github.com:用户名/仓库.git git push -f \"https://${GH_TOKEN}@${GH_REF}\" gh-pages:gh-pages 2.3. summary_create.sh 🍀 #!/bin/bash # 文件命名增加 [0-9][0-9]- 通过文件名对文章进行排序,生成目录 find `ls|egrep -v \"_book|_other|node_modules\"` -type f -name \"*.md\"|sed 's#README.md#00README.md#g'|sort|awk -F \"/\" '{if($NF!=\"00README.md\") print $0\"/\" ;else print $0}' OFS=\"/\"|sed 's#[^/]##g'|awk '{a=(length-1);while(a>0){printf \" \";a--}print \"* \"}' > /tmp/summary_1 find `ls|egrep -v \"_book|_other|node_modules\"` -type f -name \"*.md\"|sed \"s#README.md#00README.md#g\"|sort|awk -F \"[./]\" '{if($(NF-1) != \"00README\") print $(NF-1)\"](\"$0\")\" ;else print $(NF-2)\"](\"$0\")\"}' > /tmp/summary_2 paste -d \"[\" /tmp/summary_1 /tmp/summary_2 > tmp_SUMMARY.md sed 's#00README.md#README.md#g' tmp_SUMMARY.md|grep -v \"SUMMARY](SUMMARY\"|awk '{if(NR==1)print \"# Summary\\n\\n* [Introduction](README.md)\\n* [SUMMARY](SUMMARY.md)\";else print $0}' > SUMMARY.md && mv tmp_SUMMARY.md /tmp # 由于Mac下,sed -i参数必须要指定备份文件(虽然可以使用 -i \"\" 传递一个空字符,不备份,但是这种写法在Linux上会报错),所以这里不使用-i参数 # 文件名便于排序的时候会使用类似01-,开头, 在目录显示的时候删除这部分 # 调整目录显示, 在Mac 下使用需要调整参数 sed -ri 's#(\\S+* \\[)[0-9]+-(.*$)#\\1\\2#g' SUMMARY.md 2.4. book.json 🍀 GitBook样式文件 , 也就是生成html附带的样式 { \"title\": \"blog\", \"author\": \"author\", \"description\": \"desc\", \"extension\": null, \"generator\": \"site\", \"links\": { \"sharing\": { \"all\": null, \"facebook\": null, \"google\": null, \"twitter\": null, \"weibo\": null } }, \"pdf\": { \"fontSize\": 18, \"footerTemplate\": null, \"headerTemplate\": null, \"margin\": { \"bottom\": 36, \"left\": 62, \"right\": 62, \"top\": 36 }, \"pageNumbers\": false, \"paperSize\": \"a4\" }, \"plugins\": [ \"advanced-emoji\", \"toggle-chapters\", \"theme-comscore\", \"splitter\", \"github\", \"-sharing\", \"-lunr\", \"-search\", \"search-plus\", \"anchor-navigation-ex@1.0.10\", \"editlink\" ], \"pluginsConfig\": { \"anchor-navigation-ex\": { \"showLevel\": false, \"mode\": \"float\", \"float\": { \"showLevelIcon\": false, \"level1Icon\": \"fa fa-hand-o-right\", \"level2Icon\": \"fa fa-hand-o-right\", \"level3Icon\": \"fa fa-hand-o-right\" } } } } 2.5. README.md 🍀 项目根目录下必须要有README.md文件 , 并且所有需要构建的文件下 , 也必须要有README.md文件 如 : . ├── Python │ ├── ... │ ├── ... │ └── README.md -- 必须要有 ├── ... ├── ... └── README.md -- 必须要有 README.md中的内容就是页面上目录显示的内容 2.6. SUMMARY.md 🍀 必须要有 , 这个GitBook构建需要的 , 上面summary_create.sh脚本就是来自动帮我们生成目录的 3. 添加Personal access tokens 🍀 配置文件添加完成之后 , 我们就要将Travis CI 与GitHub建立连接了 点击你的GitHub头像 --> Settings --> Developer settings --> Personal access tokens --> Generate new token 进入如下图页面 : 我们只需给个repo权限就行了 接下来就会自动跳转到如下页面 : 注意 : 一定要先复制这个生成的token , 如果你还没来得及复制 , 那么对不起 , 重新添加一个再复制吧 这个token是用来配置Travis的环境变量的 4. 配置Travis CI 🍀 首先我们进入 : https://travis-ci.org/ 使用GitHub登录 接下来我们可以在Profile下面看到我们的GitHub仓库啦 , 注意https://travis-ci.org/ 搜索的我们的Public仓库 , 对于Private仓库 , 就需要进入https://travis-ci.com/ 勾选需要持续集成的仓库 接下来我们去做一些设置了 , 点击勾选右边的设置按钮 勾选General中的Build only if .travis.yml is present Environment Variables 现在我们需要用到上面生成的token了 , 将其复制到Environment Variables中的Value框中 , 并将Name设置为GH_TOKEN , 点击ADD添加 , 完成后如下 : 现在基本已经完成了 , 我们可以向我们的仓库做一点更新 , 或者直接点击More options选择Trigger build进行构建 , 等待几分钟后 (这是GitBook的一个缺点 , 构建有点慢) 待https://travis-ci.org/左侧 My Repositories 变成绿色 (黄色表示正在构建) , 我们就可以访问我们的博客啦 地址 : https://用户名.github.io/仓库名 这个地址使用的是每个仓库自带的GitHub Pages功能 , 在脚本自动创建了gh-pages分支 , 就是用于显示的 至此 , 搭建完成 ! 5. 注意事项 注意事项一 由于构建是从.md文件转到.html文件 , 所以如果文章中使用了模板语言的语法 , 请嵌入html代码块 , 并顶格写 , 示例 ​```html 内容{{ name }} 注意事项二 文章排序默认按英文字母排序 , 如果需要对文章进行排序 , 可以在文件名前添加需要 , 如 : 01- , 序号不会在文章页面显示 , 这一步是通过summary_create.sh中实现的 注意事项三 文件夹名称中不得包含空格 你可能需要的一些gitbook插件:插件 "},"09-Linux/Git/Travis  CI.html":{"url":"09-Linux/Git/Travis  CI.html","title":"Travis  CI","keywords":"","body":"Travis CI 介绍 🍀 Travis CI 是一款免费服务 , 专门托管面向开源开发组织的CI (Continuous Integration , 持续集成) CI是XP (Extreme Programming , 极限编程) 的实践之一 , 近年来人们普遍使用Jenkins等软件来实现这一目的 让CI软件监视仓库 , 可以在开发者发送提交后立刻执行自动测试或构建 ; 通过持续执行这样一个操作 , 可以检测出开发者意外发送的提交或无意的逻辑偏差 , 让代码保持在一定质量以上 所以当我们使用GitHub发布代码时 , 可以使用Travis CI ; Travis CI支持Ruby , PHP , Perl , Python , Java , JavaScript (node.js)等Web相关的语言 更多支持语言 , Support language 编写配置文件 🍀 我们如果想要仓库使用Travis CI , 一般情况下 , 我们只需要在仓库中添加.travis.yml这样一个Travis CI专用的文件 , Travis CI 就与GitHub集成了 以node.js为例 , 编写.travis.yml文件 language: \"node_js\" # 指定默认运行环境,这里是node_js node_js: # 指定node版本 - \"node\" install: # 指定安装脚本 - \"npm install gitbook -g\" - \"npm install -g gitbook-cli\" branches: # 指定分支 only: - master env: # 定义环境变量 global: - GH_REF: github.com/[username]/[repository].git - secure: [ssh_key] script: # 指定要运行的脚本 - bash summary_create.sh - travis_wait 100 bash deploy.sh 将这个文件放到本地仓库中 , 然后push给GitHub端 , 我们基本完成了使用Travis CI的准备工作 关于各种语言的配置参考 , 点击进入语言参考 检测配置文件 🍀 Travis CI专门提供了Travis WebLint提供用户检测.travis.yml文件是否存在问题 , 检测时只需要指定仓库即可 与GitHub集成 首先我们访问Travis CI , 点击右上角的Sign in with GitHub , 进行GitHub认证 登录完毕后 , Sign in with GitHub就会变成用户的GitHub信息了 , 点击头像的下拉框的Profile , 我们在下方就可以看到我们的GitHub仓库了 , 只需要将对应的仓库名旁边的开关设置为ON , 就可以对该仓库应用Travis CI了 至此 , 你再进入你的GitHub → → Settings → → Applications → → Authorized OAuth Apps , 我们就可以看到可以访问我们账户的应用程序信息了 , 这里就是Travis CI了 这样 , 我们只要向GitHub进行push操作 , 就会自动触发Travis CI端的自动测试了 集成的仓库在Travis CI端的URL为https://travis-ci.org/用户名/仓库名 , 用户可以在这个页面查看自动测试的执行情况 , 另外跳转至Travis CI首页直接收缩自己的 将Travis CI的结果添加至README.md 如果我们想要在我们的GitHub的README.md中看到我们的测试结果 , 只需在我们的README.md中添加如下信息 : # Markdown语法 [![Build Status](https://secure.travis-ci.org/用户名/仓库名.png?imageMogr2/blur/1x0/quality/75|watermark/2/text/bHlvbi55YW5nQHFxLmNvbQ==/font/YXBhcmFqaXRh/fontsize/560/fill/Izk0ODI4Mg==/dissolve/100/gravity/SouthEast/dx/10/dy/10)](http://travis-ci.org/用户名/仓库名) 这样 , 在我们查看README.md时 , 就能够通过图片观察测试是否通过了 ; 绿色的图片就表示仓库内代码顺利通过测试 , 灰色的图片表示仓库没有通过测试 , 证明仓库可能存在某种问题 , 这样既可以显示仓库的健全性 , 又可以防止自己遗漏Travis CI的结果 生成Access Token 🍀 与GitHub继承之后 , 此时Travis已经开始监控了 , 但是它却没有访问权限 , 所以我们需要生成一个Personal access tokens 进入我们的GitHub , 点击头像下的Settings → Developer settings → Personal access tokens 随后点击Generate new token , 进入New personal access token界面 , 在Token description中加入Travis , 随后选择该令牌所具有的权限范围 , 这里我们只需将repo勾上就可以了 最后Generate token 生成之后一定不要离开页面 , 我们需要快速复制这个token , 虽然添加到Travis的settings中 , 因为一旦页面刷新或者关掉 , 就会消失 , 那么你又得重新创建了 ..... "},"09-Linux/Linux基础命令.html":{"url":"09-Linux/Linux基础命令.html","title":"Linux基础命令","keywords":"","body":"Linux基础命令 ls 🍀 [root@lyonyang ~]# ls [aAdfFhilnrRSt] 目录名称 [root@lyonyang ~]# ls [--colo={never,auto,always}] 目录名称 [root@lyonyang ~]# ls [--full-times] 目录名称 # 参数 : -a : 全部的文件,连同隐藏文件(开头为 . 的文件)一起列出来 -A : 仅列出全部的文件(连同隐藏文件,但不包括 . 与 .. 这两个目录) -d : 仅列出目录本身,而不是列出目录内的文件数据 -f : 直接列出结果,而不进行排序(ls默认会以文件名排序) -F : 根据文件,目录等信息给予附加数据结构,例如: *:代表可执行文件; /:代表目录; =:代表socket文件; |:代表FIFO文件 -h : 将文件容量以较易读的方式(例如GB,KB等)列出来 -i : 列出inode号码 -l : 列出长数据串,包含文件的属性与权限等数据 -n : 列出UID与GID,而非用户与用户组的名称 -r : 将排序结果反向输出 -R : 连同子目录内容一起列出来,等于该目录下的所有文件都会显示出来 -S : 以文件容量大小排序,而不是用文件名排序 -t : 依时间排序,而不是用文件名 --color=never : 不要依据文件特性给予颜色显示 --color=always : 显示颜色 --color=auto : 让系统自行依据设置来判断是否给予颜色 --full-time : 以完整时间模式(包含年,月,日,时,分)输出 --time=(atime,ctime) : 输出访问时间或改变权限属性时间(ctime)而非内容梗概时间(modification time) cp 🍀 [root@lyonyang ~]# cp [-adfilprsu] 源文件(source) 目标文件(destination) [root@lyonyang ~]# cp [options] source1 source2 source3 ... directory # 参数 : -a : 相当于-pdr的意思 -d : 若源文件为连接文件的属性(link file),则复制连接文件属性而非文件本身 -f : 为强制(force)的意思,若目标文件已经存在且无法开启,则删除后再尝试一次 -i : 若目标文件(destination)已经存在时,在覆盖时会先查询问操作的进行 -l : 进行硬连接(hard link)的连接文件创建,而非复制文件本身 -p : 连同文件的属性一起复制过去,而非使用默认属性 -r : 递归持续复制,用于目录的复制行为 -s : 复制成功符号链接文件(symbolic link),即\"快捷方式\"文件 -u : 若destination比source旧才更新destination # 注意 : 如果源文件有两个以上,则最后一个目的文件一定要是\"目录\"才行 rm 🍀 [root@lyonyang ~]# rm [-fir] 文件或目录 # 参数 : -f : 就是force的意思,忽略不存在的文件,不会出现警告信息 -i : 互动模式,在删除前会询问用户是否操作 -r : 递归删除,最常用在目录的删除,此参数异常危险 mv 🍀 [root@lyonyang ~]# mv [-fiu] source destination [root@lyonyang ~]# mv [options] source1 source2 source3 ... directory # 参数 : -f : fource强制的意思,如果目标文件已经存在,不会询问而直接覆盖 -i : 若目标文件(destination)已经存在时,就会询问是否覆盖 -u : 若目标文件已经存在,且source比较新,才会更新 cat 🍀 [root@lyonyang ~]# cat [-AbenTv] # 参数 : -A : 相当于-vET的整合参数,可列出一些特殊字符,而不是空白而已 -b : 列出行号,仅针对非空白行做行号显示,空白行不标行号 -E : 将结尾的断行字符$显示出来 -n : 打印出行号,连同空白行也会有行号,与-b的参数不同 -T : 将[Tab]按键以^I显示出来 -v : 列出一些看不出来的特殊字符 tac 命令与 cat 命令恰好相反 nl 🍀 [root@lyonyang ~]# nl [-bnw] 文件 # 参数 : -b : 指定行号指定的方式,主要有两种: -b a : 表示不论是否为空行,也同样列出行号(类似cat -n) -b t : 如果有空行,空的那一行不要列出行号(默认值) -n : 列出行号表示的方法,主要有三种: -n ln : 行号在屏幕的最左方显示 -n rn : 行号在自己字段的最右方显示,且不加0 -n rz : 行号在自己字段的最右方显示,且加0 -w : 行号字段占用的位数 touch 🍀 [root@lyonyang ~]# touch [-acdmt] 文件 # 参数 : -a : 仅修改访问时间 -c : 仅修改文件的时间,若该文件不存在则不创建新文件 -d : 后面可以接欲修改的日期而不用目前的日期,也可以使用--date=\"日期或时间\" -m : 仅修改mtime -t : 后面可以接欲修改的时间而不用目前的时间,格式为[YYMMDDhhmm] which 🍀 [root@lyonyang ~]# which [-a] command # 参数 : -a : 将所有由 PATH 目录中可以找到的命令均列出 , 而不知第一个被找到的命令名称 whereis 🍀 [root@lyonyang ~]# whereis [-bmsu] 文件或目录名 # 参数 : -b : 只找二进制格式的文件 -m : 只找在说明文件manual路径下的文件 -s : 只找source源文件 -u : 查找不在上述三个选项当中的其他特殊文件 locate 🍀 该命令如果查找新文件 , 需要更新数据库 手动更新 updatedb [root@lyonyang ~]# locate [-ir] keyword # 参数 : -i : 忽略大小写的差异 -r : 后面可接正则表达式的显示方式 find 🍀 [root@lyonyang ~]# find [PATH] [option] [action] # 参数 : 1. 与时间有关的参数:共有-atime,-ctime与-mtime,下面以-mtime说明: -mtime n : n为数字,意义为在n天之前的\"一天之内\"被更改过的文件 -mtime +n : 列出在n天之前(不含n天本身)被更改过的文件名 -mtime -n : 列出在n天之内(含n天本身)被更改过的文件名 -newer file : file为一个存在的文件,列出比file还要新的文件 2. 与用户或用户组有关的参数: -uid n : n为数字,这个数字是用户的账号ID,即UID,这个UID是记录在 /etc/passwd里面与账号名称对应的数字 -gid n : n为数字,这个数字是用户组名的ID,即GID,这个GID记录在 /etc/group中 -user name : name为用户账号名称 -group name : name为用户组名 -nouser : 寻找文件的所有者不存在 /etc/passwd 的人 -nogroup : 寻找文件的所有用户组不存在于 /etc/group 中的文件 3. 与文件权限及名称有关的参数: -name filename : 查找文件名为filename的文件 -size [+-]SIZE : 查找比SIZE还要大(+)或小(-)的文件,SIZE规格有: c:代表byte;k:代表1024bytes; -type TYPE : 查找文件的类型为TYPE的,类型主要有: 一般正规文件(f),设备文件(b,c),目录(d),连接文件(l),socket(s),FIFO(p) -perm mode : 查找文件权限等于mode的文件,mode类似chmod的属性值,如-rwsr-xr-x属性值为4755 -perm -mode : 查找文件权限包括mode的文件 -perm +mode : 查找文件权限包含任一mode的权限的文件 4. 其他可进行的操作: -exec command : command为其他命令,-exec后面可再接其他的命令来处理查找到的结果 -print : 将结果打印到屏幕上,这个操作是默认的 压缩与打包 gzip,zcat 🍀 [root@lyonyang ~]# gzip [-cdtv#] 文件名 # 参数 : -c : 将压缩的数据输出到屏幕上,可通过数据流重定向来处理 -d : 解压缩的参数 -t : 可以用来检测一个压缩文件的一致性,看看文件有无错误 -v : 可以显示出源文件/压缩文件的压缩比等信息 -# : 压缩等级,-1最快,但是压缩比最差,-9最慢,但是压缩比最好,默认是-6 bzip2,bzcat 🍀 [root@lyonyang ~]# bzip2 [-cdkzv#] 文件名 # 参数 : -c : 将压缩的数据输出到屏幕上 -d : 解压缩的参数 -k : 保留原文件,而不会删除原始的文件 -z : 压缩的参数 -v : 可以显示出原文件/压缩文件的压缩比等信息 -# : 与gzip一样 dump 🍀 [root@lyonyang ~]# dump [-Suvj] [-level] [-f 备份文件] 待备份数据 [root@lyonyang ~]# dump -W # 参数 : -S : 仅列出后面的备份数据需要多少磁盘空间才能够备份完毕 -u : 将这次dump的时间记录到/etc/dumpdateS文件中 -v : 将dump的文件过程显示出来 -j : 加入bzip2的支持,将数据进行压缩,默认bzip2压缩等级为2 -level : 等级从0~9共10个等级 -f : 有点类似tar,后面接产生的文件,可接例如/dev/st0设备文件名 -w : 列出在/etc/fstab里面的具有dump设置的分区是否有备份过 restore 🍀 [root@lyonyang ~]# restore -t [-f dumpfile] [-h] # 查看dump文件 [root@lyonyang ~]# restore -C [-f dumpfile] [-D 挂载点] # 比较dump与实际文件 [root@lyonyang ~]# restore -i [-f dumpfile] # 进入互动模式 [root@lyonyang ~]# restore -r [-f dumpfile] # 还原整个文件系统 # 参数 : -t : 此模式用在查看dump起来的备份文件中含有什么重要数据 -C : 此模式可以将dump内的数据拿出来跟实际的文件系统做比较 最终会列出\"在dump文件内有记录的,且目前文件系统不一样\"的文件 -i : 进入互动模式,可以仅还原部分文件,用在dump目录时的还原 -r : 将整个文件系统还原的一种模式,用在还原针对文件系统的dump备份 -h : 查看完整备份数据中的inode与文件系统label等信息 -f : 后面就接你要处理的那个dump文件 -D : 与-C进行搭配,可以查出后面接的挂载点与dump内有不同的文件 tar 🍀 [root@lyonyang ~]# tar [-j|-z] [cv] [-f 新建的文件名] filename # 打包与压缩 [root@lyonyang ~]# tar [-j|-z] [tv] [-f 新建的文件名] # 查看文件名 [root@lyonyang ~]# tar [-j|-z] [xv] [-f 新建的文件名] # 解压缩 # 参数 : -c : 新建打包文件,可搭配-v来查看过程中被打包的文件名 -t : 查看打包文件的内容含有哪些文件名,重点在查看文件名 -x : 解打包或解压缩的功能,可以搭配-C在特定目录解开 -c,-t,-x不可同时出现在一串命令中 -j : 通过bzip2的支持进行压缩/解压缩,此时文件名最好为 *.tar.bz2 -z : 通过gzip的支持进行压缩/解压缩,此时文件名最好为 *.tar.gz -v : 在压缩/解压缩的过程中,将正在处理的文件名显示出来 -f filename : -f后面要接被处理的文件名,建议-f单独写一个参数 -C 目录 : 这个参数用在解压缩时,若要在特定目录解压缩,可以使用这个参数 -P : 保留备份数据的原本权限与属性,常用于备份(-c)重要的配置文件 -p : 保留绝对路径,即允许不备份数据中含有根目录存在之意 --exclude=FILE : 在压缩的过程中,不要将FILE打包 简单使用记忆 : 压缩 : tar -jcv -f filename.tar.bz2 要被压缩的文件或目录名称 查询 : tar -jtv -f filename.tar.bz2 解压缩 : tar -jxv -f filename.tar.bz2 -C 欲解压缩的目录 dd 🍀 [root@lyonyang ~]# dd if=\"input file\" of=\"output file\" bs=\"block size\" count=\"number\" # 参数 : if : 就是input file ,也可以是设备 of : 就是output file ,也可以是设备 bs : 规划的一个block的大小,若未指定则默认为512bytes(一个扇区的大小) count : 多少个bs的意思 ps 🍀 [root@lyonyang ~]# ps aux # 查看系统所有的进程数据 [root@lyonyang ~]# ps -lA # 同上 [root@lyonyang ~]# ps axjf # 连同部分进程树的状态 # 参数 : -A : 所有的进程均显示出来,与-e具有同样的作用 -a : 不与terminal有关的所有进程 -u : 有效用户相关的进程 x : 通常与a这个参数一起使用,可列出较完整信息 l : 较长,较详细地将该PID的信息列出 j : 工作的格式 -f : 做一个更为完整的输出 free 🍀 [root@lyonyang ~]# free [-b|-k|-m|-g] [-t] # 参数 : -b : 直接输入free时,显示的单位是 -t : 在输出的最终结果中显示物理内存与swap的总量 uname 🍀 [root@lyonyang ~]# uname [-asrmpi] # 参数 : -a : 所有系统相关的信息,包括下面的数据都会被列出来 -s : 系统内核名称 -r : 内核的版本 -m : 本系统的硬件名称 -p : CPU的类型 -i : 硬件的平台 netstat 🍀 [root@lyonyang ~]# netstat -[atunlp] # 参数 : -a : 将目前系统上所有的连接,监听,Socket数据都列出来 -t : 列出tcp网络数据包的数据 -u : 列出udp网络数据包的数据 -n : 不列出进程的服务名称 -l : 列出目前正在网络监听的服务 -p : 列出该网络服务的进程PID rpm 🍀 [root@lyonyang ~]# rpm -ivh package_name # 参数 : -i : install 的意思 -v : 查看更详细的安装信息画面 -h : 以安装信息栏显示安装进度 [root@lyonyang ~]# rpm -qa [root@lyonyang ~]# rpm -q[licdR] 已安装的软件名称 [root@lyonyang ~]# rpm -qf 存在于系统上面的某个文件名 [root@lyonyang ~]# rpm -qp[licdR] 未安装的某个文件名称 # 参数 : -q : 仅查询,后面接的软件名称是否有安装 -qa : 列出所有的已经安装在本机Linux系统上面的所有软件名称 -qi : 列出该软件的详细信息,包含开发商,版本与说明 -ql : 列出该软件所有的文件与目录所在完整文件名 -qc : 列出该软件的所有设置文件 -qd : 列出该软件的所有帮助文件 -qR : 列出与该软件有关的依赖软件所含的文件 -qf : 由后面接的文件名称找出该文件属于哪一个已安装的软件 "},"09-Linux/RabbitMQ.html":{"url":"09-Linux/RabbitMQ.html","title":"RabbitMQ","keywords":"","body":"RabbitMQ 介绍 🍀 RabbitMQ 是一个实现了 AMQP 协议标准的开源消息代理和队列服务器 , 和 Beanstalkd 不同的是 , 它是企业级消息系统 , 自带了集群 , 管理 , 插件系统等特性 , 在高可用性 , 可扩展性性 , 易用性等方面做得很好 , 现在被互联网公司广泛使用 安装服务端 $ sudo apt-get install rabbitmq-server -yq 安装客户端 $ pip install pika AMQP 🍀 AMQP (Advanced Message Queuing Protocol , 高级消息队列协议) 是一个异步消息传递所使用的应用层协议规范 , 它的设计初衷是为了摆脱商业 MQ 高额费用和不同 MQ 供应商的接口不统一的问题 , 所以一开始就设计成开放标准 , 以解决企业复杂的消息队列需求问题 基本概念 : 消息 : 消息实际包含两部分内容 : 有效载荷 , 也就是传输的数据 , 数据类型可以纯文本也可以是 JSON 标签 , 它包含交换机的名字和可选的主题标记等 , AMQP 仅仅描述了标签 , 而RabbitMQ 决定了把这个消息发给哪个消费者 发布者 : 也就是生产者 , 它创建消息并且设置标签 消费者 : 消费者连接到代理服务器上 , 接收消息的有效载荷 (注意 , 消费者并不需要消息中的标签) 在 AMQP 模块中 , 为了保证消息被正确取出并执行 , 消息投递失败后会重发 , 于是有了一个消息确认的概念 : 当一个消息从队列中投递给消费者后 , 消费者会通知消息代理 (Broker) , 这个通知可以是自动完成的 , 也可以由处理消息的应用来执行 , 当消息确认 (Ack) 被启用的时候 , 消息代理不会完全将消息从队列中删除 , 除非收到来自消费者的确认回执 AMQP 工作流程如下 : 消息发布者发送消息 , 交换机拿到消息后会将它路由给队列 , 它使用哪种路由算法是由交换机类型和被称作 \"绑定\" 的规则所决定的 , 目前 RabbitMQ 提供了如下四种交换机 : 直接交换机 : 根据消息携带的路由建将消息投递给对应队列 主题交换机 : 通过对消息的路由建和队列到交换机的绑定模式之间的匹配 , 将消息路由给一个或多个队列 扇形交换机 : 将消息路由给绑定到它身上的所有队列 , 且不理会绑定的路由建 , 扇形交换机用来处理消息的广播路由 头交换机 : 一般用不到 , 允许匹配 AMQP 的头而非路由建 , 和直接交换机差不多 , 但是性能差很多 简单示例 🍀 发布者 import sys import pika # %2F是被转义的/,这里使用了默认的虚拟主机,默认的guest这个账号和密码 parameters = pika.URLParameters('amqp://guest:guest@localhost:5672/%2F') # connection就是所谓的消息代理 connection = pika.BlockingConnection(parameters) # 获得信道 channel = connection.channel() # 声明交换机,指定交换类型为直接交换,最后2个参数表示想要持久化的交换机 channel.exchange_declare(exchange='web_develop', exchange_type='direct', passive=False, durable=True, auto_delete=False) if len(sys.argv) != 1: # 使用命令行参数作为消息体 msg = sys.argv[1] else: msg = 'hah' # 创建一个消息, delivery_mode为2表示让这个消息持久化, 重启RabbitMQ也不会丢失 props = pika.BasicProperties(content_type='text/plain', delivery_mode=2) # basic_publish表示发送路由键为xxx_routing_key,消息体为haha的消息给web_develop这个交换机 channel.basic_publish('web_develop', 'xxx_routing_key', msg, properties=props) # 关闭连接 connection.close() 消费者 import pika # 处理接收到的消息的回调函数 # method_frame携带了投递标记, header_frame表示AMQP信息头的对象 # body为消息实体 def on_message(channel, method_frame, header_frame, body): # 消息确认, 确认之后才会删除消息并给消费者发送新的消息 channel.basic_ack(delivery_tag=method_frame.delivery_tag) print body parameters = pika.URLParameters('amqp://guest:guest@localhost:5672/%2F') connection = pika.BlockingConnection(parameters) channel = connection.channel() channel.exchange_declare(exchange='web_develop', exchange_type='direct', passive=False, durable=True, auto_delete=False) # 声明队列, 如果没有就创建 channel.queue_declare(queue='standard', auto_delete=True) # 通过路由键将队列和交换机绑定 channel.queue_bind(queue='standard', exchange='web_develop', routing_key='xxx_routing_key') # 订阅队列 channel.basic_consume(on_message, 'standard') try: # 开始消费 channel.start_consuming() except KeyboardInterrupt: # 退出消费 channel.stop_consuming() connection.close() 官方教程 "},"09-Linux/vim.html":{"url":"09-Linux/vim.html","title":"vim","keywords":"","body":"vim 介绍 🍀 基本上 vi 共分为 3 种模式 , 分别是一般模式 , 编辑模式与命令行模式 一般模式 🍀 以 vi 代开一个文件就直接进入一般模式了 (这是默认的模式) , 在这个模式中 , 你可以使用上下左右按键来移动光标 , 你可以删除字符或删除整行 , 也可以复制 , 粘贴你的文件数据 编辑模式 🍀 在一般模式中可以进行删除 , 复制 , 粘贴等的操作 , 但是却无法编辑文件内容 , 要等待你按下 \"i,I,o,O,a,A,r,R\" 等任何一个字母之后才进入编辑模式 , 通常在 Linux 中 , 按下这些按键时 , 在界面的左下方会出现 INSERT 或 REPLACE 的字样 , 此时才可以进行编辑 , 而如果要回到一般模式时 , 则必须要按下 [Esc] 键即可退出编辑模式 命令行模式 🍀 在一般模式中 , 输入 \":,/,?\" 3 个中的任何一个按钮 , 就可以将光标移动到最下面那一行 , 在这个模式当中 , 可以提供你查找数据的操作 , 而读取 , 保存 , 大量替换字符 , 离开 vi , 显示行号等的操作则是在此模式下完成的 简单使用 🍀 使用 vi 进入一般模式 [root@lyonyang ~]# vi test.txt 按 i 进入编辑模式 , 开始编辑文字 按 [Esc] 回到一般模式 在一般模式中输入 \":wq\" 保存后离开 vi 按键说明 🍀 第一部分 🍀 一般模式可用的按键说明 , 光标移动 , 复制粘贴 , 查找替换等 按键 说明 h 或 向左箭头键 (←) 光标向左移动一个字符 j 或 向下箭头键 (↓) 光标向下移动一个字符 k 或 向上箭头键 (↑) 光标向上移动一个字符 l 或 向右箭头键 (→) 光标向右移动一个字符 如果你将右手放在键盘上的话 , 你会发现 hjkl 是排列在一起的 , 因此可以使用这四个按钮来移动光标 . 如果想要进行多次移动的话 , 例如向下移动 30 行 , 可以使用 \"30j\" 或 \"30↓\" 的组合按键 , 亦即加上想要进行的次数 (数字) 后 , 按下动作即可 按键 说明 [Ctrl] + [f] 屏幕 向下 移动一页 , 相当于 [Page Down]按键 (常用) [Ctrl] + [b] 屏幕 向上 移动一页 , 相当于 [Page Up] 按键 (常用) [Ctrl] + [d] 屏幕 向下 移动半页 [Ctrl] + [u] 屏幕 向上 移动半页 + 光标移动到非空格符的下一列 - 光标移动到非空格符的上一列 n 那个 n 表示 数字 , 例如 20 ; 按下数字后再按空格键 , 光标会向右移动这一行的 n 个字符 . 例如 20 则光标会向后面移动 20 个字符距离 0 或功能键[Home] 这是数字 0 : 移动到这一行的最前面字符处 (常用) $ 或功能键[End] 移动到这一行的最后面字符处 (常用) H 光标移动到这个屏幕的最上方那一行的第一个字符 M 光标移动到这个屏幕的中央那一行的第一个字符 L 光标移动到这个屏幕的最下方那一行的第一个字符 G 移动到这个档案的最后一行(常用) nG n 为数字 . 移动到这个档案的第 n 行 . 例如 20G 则会移动到这个档案的第 20 行(可配合 :set nu) gg 移动到这个档案的第一行 , 相当于 1G (常用) n n 为数字 . 光标向下移动 n 行 (常用) 查找与替换 按键 说明 /word 向光标之下寻找一个名称为 word 的字符串 . 例如要在档案内搜寻 lyon 这个字符串 , 就输入 /lyon 即可 (常用) ?word 向光标之上寻找一个字符串名称为 word 的字符串 n 这个 n 是英文按键 . 代表 重复前一个搜寻的动作 . 举例来说 , 如果刚刚我们执行 /lyon 去向下搜寻 lyon 这个字符串 , 则按下 n 后 , 会向下继续搜寻下一个名称为 lyon 的字符串 . 如果是执行 ?lyon 的话 , 那么按下 n 则会向上继续搜寻名称为 lyon 的字符串 N 这个 N 是英文按键 . 与 n 刚好相反 , 为 反向 进行前一个搜寻动作 . 例如 /lyon 后 , 按下 N 则表示 向上 搜寻 lyon . :n1,n2s/word1/word2/g n1 与 n2 为数字 . 在第 n1 与 n2 行之间寻找 word1 这个字符串 , 并将该字符串取代为 word2 , 举例来说 , 在 100 到 200 行之间搜寻 lyon 并取代为 lyon 则 : :100,200s/lyon/lyon/g (常用) :1,$s/word1/word2/g 从第一行到最后一行寻找 word1 字符串 , 并将该字符串取代为 word2 (常用) :1,$s/word1/word2/gc 从第一行到最后一行寻找 word1 字符串 , 并将该字符串取代为 word2 , 且在取代前显示提示字符给用户确认 (confirm) 是否需要取代 (常用) 删除 , 复制与粘帖 按键 说明 x, X 在一行字当中 , x 为向后删除一个字符 (相当于 [del] 按键) , X 为向前删除一个字符(相当于 [backspace] 亦即是退格键) (常用) nx n 为数字 , 连续向后删除 n 个字符 . 举例来说 , 我要连续删除 10 个字符 , 10x . dd 删除游标所在的那一整列(常用) ndd n 为数字 . 删除光标所在的向下 n 列 , 例如 20dd 则是删除 20 列 (常用) d1G 删除光标所在到第一行的所有数据 dG 删除光标所在到最后一行的所有数据 d$ 删除游标所在处 , 到该行的最后一个字符 d0 那个是数字的 0 , 删除游标所在处 , 到该行的最前面一个字符 yy 复制游标所在的那一行(常用) nyy n 为数字 . 复制光标所在的向下 n 列 , 例如 20yy 则是复制 20 列 (常用) y1G 复制游标所在列到第一列的所有数据 yG 复制游标所在列到最后一列的所有数据 y0 复制光标所在的那个字符到该行行首的所有数据 y$ 复制光标所在的那个字符到该行行尾的所有数据 p, P p 为将已复制的数据在光标下一行贴上 , P 则为贴在游标上一行 , 举例来说 , 我目前光标在第 20 行 , 且已经复制了 10 行数据 . 则按下 p 后 , 那 10 行数据会贴在原本的 20 行之后 , 亦即由 21 行开始贴 . 但如果是按下 P , 那么原本的第 20 行会被推到变成 30 行 (常用) J 将光标所在列与下一列的数据结合成同一列 c 重复删除多个数据 , 例如向下删除 10 行 , [ 10cj ] u 复原前一个动作 (常用) [Ctrl]+r 重做上一个动作 (常用) . 不要怀疑 , 这就是小数点 , 意思是重复前一个动作的意思 . 如果你想要重复删除、重复贴上等等动作 , 按下小数点 . 就好了 (常用) 第二部分 🍀 一般模式切换到编辑模式的可用的按钮说明 按键 说明 i, I 进入插入模式(Insert mode) : i 为 从目前光标所在处插入 , I 为 在目前所在行的第一个非空格符处开始插入 (常用) a, A 进入插入模式(Insert mode) : a 为 从目前光标所在的下一个字符处开始插入 , A 为 从光标所在行的最后一个字符处开始插入 (常用) o, O 进入插入模式(Insert mode) : 这是英文字母 o 的大小写 . o 为 在目前光标所在的下一行处插入新的一行 ； O 为在目前光标所在处的上一行插入新的一行 (常用) r, R 进入取代模式(Replace mode) : r 只会取代光标所在的那一个字符一次；R会一直取代光标所在的文字 , 直到按下 ESC 为止 (常用) [Esc] 退出编辑模式 , 回到一般模式中(常用) 第三部分 🍀 一般模式切换到命令行模式的可用的按钮说明 按键 说明 :w 将编辑的数据写入硬盘档案中 (常用) :w! 若文件属性为 只读 时 , 强制写入该档案 . 不过 , 到底能不能写入 , 还是跟你对该档案的档案权限有关啊 :q 离开 vi (常用) :q! 若曾修改过档案 , 又不想储存 , 使用 ! 为强制离开不储存档案 :wq 储存后离开 , 若为 :wq! 则为强制储存后离开 (常用) ZZ 这是大写的 Z 喔 , 若档案没有更动 , 则不储存离开 , 若档案已经被更动过 , 则储存后离开 :w [filename] 将编辑的数据储存成另一个档案（类似另存新档） :r [filename] 在编辑的数据中 , 读入另一个档案的数据 . 亦即将 filename 这个档案内容加到游标所在行后面 :n1,n2 w [filename] 将 n1 到 n2 的内容储存成 filename 这个档案 :! command 暂时离开 vi 到指令列模式下执行 command 的显示结果 , 例如 :! ls /home 即可在 vi 当中察看 /home 底下以 ls 输出的档案信息 vim 环境的变更 按键 说明 :set nu 显示行号 , 设定之后 , 会在每一行的前缀显示该行的行号 :set nonu 与 set nu 相反 , 为取消行号 "},"Go入门指南/":{"url":"Go入门指南/","title":"Go入门指南","keywords":"","body":"the-way-to-go_ZH_CN 方便暂时看, 生成在线的, 后期删除 原文地址 : https://github.com/unknwon/the-way-to-go_ZH_CN 目录 前言 第一部分：学习 Go 语言 第1章：Go 语言的起源，发展与普及 1.1 起源与发展 1.2 语言的主要特性与发展的环境和影响因素 第2章：安装与运行环境 2.1 平台与架构 2.2 Go 环境变量 2.3 在 Linux 上安装 Go 2.4 在 Mac OS X 上安装 Go 2.5 在 Windows 上安装 Go 2.6 安装目录清单 2.7 Go 运行时（runtime） 2.8 Go 解释器 第3章：编辑器、集成开发环境与其它工具 3.1 Go 开发环境的基本要求 3.2 编辑器和集成开发环境 3.3 调试器 3.4 构建并运行 Go 程序 3.5 格式化代码 3.6 生成代码文档 3.7 其它工具 3.8 Go 性能说明 3.9 与其它语言进行交互 第二部分：语言的核心结构与技术 第4章：基本结构和基本数据类型 4.1 文件名、关键字与标识符 4.2 Go 程序的基本结构和要素 4.3 常量 4.4 变量 4.5 基本类型和运算符 4.6 字符串 4.7 strings 和 strconv 包 4.8 时间和日期 4.9 指针 第5章：控制结构 5.1 if-else 结构 5.2 测试多返回值函数的错误 5.3 switch 结构 5.4 for 结构 5.5 Break 与 continue 5.6 标签与 goto 第6章：函数（function） 6.1 介绍 6.2 函数参数与返回值 6.3 传递变长参数 6.4 defer 和追踪 6.5 内置函数 6.6 递归函数 6.7 将函数作为参数 6.8 闭包 6.9 应用闭包：将函数作为返回值 6.10 使用闭包调试 6.11 计算函数执行时间 6.12 通过内存缓存来提升性能 第7章：数组与切片 7.1 声明和初始化 7.2 切片 7.3 For-range 结构 7.4 切片重组（reslice） 7.5 切片的复制与追加 7.6 字符串、数组和切片的应用 第8章：Map 8.1 声明、初始化和 make 8.2 测试键值对是否存在及删除元素 8.3 for-range 的配套用法 8.4 map 类型的切片 8.5 map 的排序 8.6 将 map 的键值对调 第9章：包（package） 9.1 标准库概述 9.2 regexp 包 9.3 锁和 sync 包 9.4 精密计算和 big 包 9.5 自定义包和可见性 9.6 为自定义包使用 godoc 9.7 使用 go install 安装自定义包 9.8 自定义包的目录结构、go install 和 go test 9.9 通过 Git 打包和安装 9.10 Go 的外部包和项目 9.11 在 Go 程序中使用外部库 第10章：结构（struct）与方法（method） 10.1 结构体定义 10.2 使用工厂方法创建结构体实例 10.3 使用自定义包中的结构体 10.4 带标签的结构体 10.5 匿名字段和内嵌结构体 10.6 方法 10.7 类型的 String() 方法和格式化描述符 10.8 垃圾回收和 SetFinalizer 第11章：接口（interface）与反射（reflection） 11.1 接口是什么 11.2 接口嵌套接口 11.3 类型断言：如何检测和转换接口变量的类型 11.4 类型判断：type-switch 11.5 测试一个值是否实现了某个接口 11.6 使用方法集与接口 11.7 第一个例子：使用 Sorter 接口排序 11.8 第二个例子：读和写 11.9 空接口 11.10 反射包 11.11 Printf 和反射 11.12 接口与动态类型 11.13 总结：Go 中的面向对象 11.14 结构体、集合和高阶函数 第三部分：Go 高级编程 第12章：读写数据 12.1 读取用户的输入 12.2 文件读写 12.3 文件拷贝 12.4 从命令行读取参数 12.5 用 buffer 读取文件 12.6 用切片读写文件 12.7 用 defer 关闭文件 12.8 使用接口的实际例子：fmt.Fprintf 12.9 格式化 JSON 数据 12.10 XML 数据格式 12.11 用 Gob 传输数据 12.12 Go 中的密码学 第13章：错误处理与测试 13.1 错误处理 13.2 运行时异常和 panic 13.3 从 panic 中恢复（Recover） 13.4 自定义包中的错误处理和 panicking 13.5 一种用闭包处理错误的模式 13.6 启动外部命令和程序 13.7 Go 中的单元测试和基准测试 13.8 测试的具体例子 13.9 用（测试数据）表驱动测试 13.10 性能调试：分析并优化 Go 程序 第14章：协程（goroutine）与通道（channel） 14.1 并发、并行和协程 14.2 使用通道进行协程间通信 14.3 协程同步：关闭通道-对阻塞的通道进行测试 14.4 使用 select 切换协程 14.5 通道，超时和计时器（Ticker） 14.6 协程和恢复（recover） 14.7 新旧模型对比：任务和worker 14.8 惰性生成器的实现 14.9 实现 Futures 模式 第15章：网络、模版与网页应用 15.1 tcp服务器 15.2 一个简单的web服务器 15.3 访问并读取页面数据 15.4 写一个简单的网页应用 第四部分：实际应用 第16章：常见的陷阱与错误 16.1 误用短声明导致变量覆盖 16.2 误用字符串 16.3 发生错误时使用defer关闭一个文件 16.4 何时使用new()和make() 16.5 不需要将一个指向切片的指针传递给函数 16.6 使用指针指向接口类型 16.7 使用值类型时误用指针 16.8 误用协程和通道 16.9 闭包和协程的使用 16.10 糟糕的错误处理 第17章：模式 17.1 关于逗号ok模式 第18章：出于性能考虑的实用代码片段 18.1 字符串 18.2 数组和切片 18.3 映射 18.4 结构体 18.5 接口 18.6 函数 18.7 文件 18.8 协程（goroutine）与通道（channel） 18.9 网络和网页应用 18.10 其他 18.11 出于性能考虑的最佳实践和建议 第19章：构建一个完整的应用程序 第20章：Go 语言在 Google App Engine 的使用 第21章：实际部署案例 附录 A 代码引用 B 有趣的 Go 引用 C 代码示例列表 D 书中的包引用 E 书中的工具引用 F 常见问题解答 G 习题答案 H 参考文献 索引 "},"Go入门指南/01.1.html":{"url":"Go入门指南/01.1.html","title":"1","keywords":"","body":"1.1 起源与发展 Go 语言起源 2007 年，并于 2009 年正式对外发布。它从 2009 年 9 月 21 日开始作为谷歌公司 20% 兼职项目，即相关员工利用 20% 的空余时间来参与 Go 语言的研发工作。该项目的三位领导者均是著名的 IT 工程师：Robert Griesemer，参与开发 Java HotSpot 虚拟机；Rob Pike，Go 语言项目总负责人，贝尔实验室 Unix 团队成员，参与的项目包括 Plan 9，Inferno 操作系统和 Limbo 编程语言；Ken Thompson，贝尔实验室 Unix 团队成员，C 语言、Unix 和 Plan 9 的创始人之一，与 Rob Pike 共同开发了 UTF-8 字符集规范。自 2008 年 1 月起，Ken Thompson 就开始研发一款以 C 语言为目标结果的编译器来拓展 Go 语言的设计思想。 这是一个由计算机领域 “发明之父” 所组成的黄金团队，他们对系统编程语言，操作系统和并行都有着非常深刻的见解 图 1.1 Go 语言设计者：Griesemer、Thompson 和 Pike 在 2008 年年中，Go 语言的设计工作接近尾声，一些员工开始以全职工作状态投入到这个项目的编译器和运行实现上。Ian Lance Taylor 也加入到了开发团队中，并于 2008 年 5 月创建了一个 gcc 前端。 Russ Cox 加入开发团队后着手语言和类库方面的开发，也就是 Go 语言的标准包。在 2009 年 10 月 30 日，Rob Pike 以 Google Techtalk 的形式第一次向人们宣告了 Go 语言的存在。 直到 2009 年 11 月 10 日，开发团队将 Go 语言项目以 BSD-style 授权（完全开源）正式公布了 Linux 和 Mac OS X 平台上的版本。Hector Chu 于同年 11 月 22 日公布了 Windows 版本。 作为一个开源项目，Go 语言借助开源社区的有生力量达到快速地发展，并吸引更多的开发者来使用并改善它。自该开源项目发布以来，超过 200 名非谷歌员工的贡献者对 Go 语言核心部分提交了超过 1000 个修改建议。在过去的 18 个月里，又有 150 开发者贡献了新的核心代码。这俨然形成了世界上最大的开源团队，并使该项目跻身 Ohloh 前 2% 的行列。大约在 2011 年 4 月 10 日，谷歌开始抽调员工进入全职开发 Go 语言项目。开源化的语言显然能够让更多的开发者参与其中并加速它的发展速度。Andrew Gerrand 在 2010 年加入到开发团队中成为共同开发者与支持者。 在 Go 语言在 2010 年 1 月 8 日被 Tiobe（闻名于它的编程语言流行程度排名）宣布为 “2009 年年度语言” 后，引起各界很大的反响。目前 Go 语言在这项排名中的最高记录是在 2017 年 1 月创下的第13名，流行程度 2.325%。 时间轴： 2007 年 9 月 21 日：雏形设计 2009 年 11 月 10日：首次公开发布 2010 年 1 月 8 日：当选 2009 年年度语言 2010 年 5 月：谷歌投入使用 2011 年 5 月 5 日：Google App Engine 支持 Go 语言 从 2010 年 5 月起，谷歌开始将 Go 语言投入到后端基础设施的实际开发中，例如开发用于管理后端复杂环境的项目。有句话叫 “吃你自己的狗食”，这也体现了谷歌确实想要投资这门语言，并认为它是有生产价值的。 Go 语言的官方网站是 golang.org，这个站点采用 Python 作为前端，并且使用 Go 语言自带的工具 godoc 运行在 Google App Engine 上来作为 Web 服务器提供文本内容。在官网的首页有一个功能叫做 Go Playground，是一个 Go 代码的简单编辑器的沙盒，它可以在没有安装 Go 语言的情况下在你的浏览器中编译并运行 Go，它提供了一些示例，其中包括国际惯例 “Hello, World!”。 更多的信息详见 github.com/golang/go，Go 项目 Bug 追踪和功能预期详见 github.com/golang/go/issues。 Go 通过以下的 Logo 来展示它的速度，并以囊地鼠（Gopher）作为它的吉祥物。 图1.2 Go 语言 Logo 谷歌邮件列表 golang-nuts 非常活跃，每天的讨论和问题解答数以百计。 关于 Go 语言在 Google App Engine 的应用，这里有一个单独的邮件列表 google-appengine-go，不过 2 个邮件列表的讨论内容并不是分得很清楚，都会涉及到相关的话题。go-lang.cat-v.org/ 是 Go 语言开发社区的资源站，irc.freenode.net 的#go-nuts 是官方的 Go IRC 频道。 @golang 是 Go 语言在 Twitter 的官方帐号，大家一般使用 #golang 作为话题标签。 这里还有一个在 Linked-in 的小组：www.linkedin.com/groups?gid=2524765&trk=myg_ugrp_ovr。 Go 编程语言的维基百科：en.wikipedia.org/wiki/Go_(programming_language)) Go 语言相关资源的搜索引擎页面：gowalker.org Go 语言还有一个运行在 Google App Engine 上的 Go Tour，你也可以通过执行命令 go install go-tour.googlecode.com/hg/gotour 安装到你的本地机器上。对于中文读者，可以访问该指南的 中文版本，或通过命令 go install https://bitbucket.org/mikespook/go-tour-zh/gotour 进行安装。 链接 目录 上一部分：前言 下一节: 语言的主要特性与发展的环境和影响因素 "},"Go入门指南/01.2.html":{"url":"Go入门指南/01.2.html","title":"2","keywords":"","body":"1.2 语言的主要特性与发展的环境和影响因素 1.2.1 影响 Go 语言发展的早期编程语言 正如 “21 世纪的 C 语言” 这句话所说，Go 语言并不是凭空而造的，而是和 C++、Java 和 C# 一样属于 C 系。不仅如此，设计者们还汲取了其它编程语言的精粹部分融入到 Go 语言当中。 在声明和包的设计方面，Go 语言受到 Pascal、Modula 和 Oberon 系语言的影响；在并发原理的设计上，Go 语言从同样受到 Tony Hoare 的 CSP（通信序列进程 Communicating Squential Processes）理论影响的 Limbo 和 Newsqueak 的实践中借鉴了一些经验，并使用了和 Erlang 类似的机制。 这是一门完全开源的编程语言，因为它使用 BSD 授权许可，所以任何人都可以进行商业软件的开发而不需要支付任何费用。 尽管为了能够让目前主流的开发者们能够对 Go 语言中的类 C 语言的语法感到非常亲切而易于转型，但是它在极大程度上简化了这些语法，使得它们比 C/C++ 的语法更加简洁和干净。同时，Go 语言也拥有一些动态语言的特性，这使得使用 Python 和 Ruby 的开发者们在使用 Go 语言的时候感觉非常容易上手。 下图展示了一些其它编程语言对 Go 语言的影响： 图 1.3 其它编程语言对 Go 语言的影响 1.2.2 为什么要创造一门编程语言 C/C++ 的发展速度无法跟上计算机发展的脚步，十多年来也没有出现一门与时代相符的主流系统编程语言，因此人们需要一门新的系统编程语言来弥补这个空缺，尤其是在计算机信息时代。 对比计算机性能的提升，软件开发领域不被认为发展地足够快或者比硬件发展更加成功（有许多项目均以失败告终），同时应用程序的体积始终在不断地扩大，这就迫切地需要一门具备更高层次概念的低级语言来突破现状。 在 Go 语言出现之前，开发者们总是面临非常艰难的抉择，究竟是使用执行速度快但是编译速度并不理想的语言（如：C++），还是使用编译速度较快但执行效率不佳的语言（如：.NET、Java），或者说开发难度较低但执行速度一般的动态语言呢？显然，Go 语言在这 3 个条件之间做到了最佳的平衡：快速编译，高效执行，易于开发。 1.2.3 Go 语言的发展目标 Go 语言的主要目标是将静态语言的安全性和高效性与动态语言的易开发性进行有机结合，达到完美平衡，从而使编程变得更加有乐趣，而不是在艰难抉择中痛苦前行。 因此，Go 语言是一门类型安全和内存安全的编程语言。虽然 Go 语言中仍有指针的存在，但并不允许进行指针运算。 Go 语言的另一个目标是对于网络通信、并发和并行编程的极佳支持，从而更好地利用大量的分布式和多核的计算机，这一点对于谷歌内部的使用来说就非常重要了。设计者通过 goroutine 这种轻量级线程的概念来实现这个目标，然后通过 channel 来实现各个 goroutine 之间的通信。他们实现了分段栈增长和 goroutine 在线程基础上多路复用技术的自动化。 这个特性显然是 Go 语言最强有力的部分，不仅支持了日益重要的多核与多处理器计算机，也弥补了现存编程语言在这方面所存在的不足。 Go 语言中另一个非常重要的特性就是它的构建速度（编译和链接到机器代码的速度），一般情况下构建一个程序的时间只需要数百毫秒到几秒。作为大量使用 C++ 来构建基础设施的谷歌来说，无疑从根本上摆脱了 C++ 在构建速度上非常不理想的噩梦。这不仅极大地提升了开发者的生产力，同时也使得软件开发过程中的代码测试环节更加紧凑，而不必浪费大量的时间在等待程序的构建上。 依赖管理是现今软件开发的一个重要组成部分，但是 C 语言中“头文件”的概念却导致越来越多因为依赖关系而使得构建一个大型的项目需要长达几个小时的时间。人们越来越需要一门具有严格的、简洁的依赖关系分析系统从而能够快速编译的编程语言。这正是 Go 语言采用包模型的根本原因，这个模型通过严格的依赖关系检查机制来加快程序构建的速度，提供了非常好的可量测性。 整个 Go 语言标准库的编译时间一般都在 20 秒以内，其它的常规项目也只需要半秒钟的时间来完成编译工作。这种闪电般的编译速度甚至比编译 C 语言或者 Fortran 更加快，使得编译这一环节不再成为在软件开发中困扰开发人员的问题。在这之前，动态语言将快速编译作为自身的一大亮点，像 C++ 那样的静态语言一般都有非常漫长的编译和链接工作。而同样作为静态语言的 Go 语言，通过自身优良的构建机制，成功地去除了这个弊端，使得程序的构建过程变得微不足道，拥有了像脚本语言和动态语言那样的高效开发的能力。 另外，Go 语言在执行速度方面也可以与 C/C++ 相提并论。 由于内存问题（通常称为内存泄漏）长期以来一直伴随着 C++ 的开发者们，Go 语言的设计者们认为内存管理不应该是开发人员所需要考虑的问题。因此尽管 Go 语言像其它静态语言一样执行本地代码，但它依旧运行在某种意义上的虚拟机，以此来实现高效快速的垃圾回收（使用了一个简单的标记-清除算法）。 尽管垃圾回收并不容易实现，但考虑这将是未来并发应用程序发展的一个重要组成部分，Go 语言的设计者们还是完成了这项艰难的任务。 Go 语言还能够在运行时进行反射相关的操作。 使用 go install 能够很轻松地对第三方包进行部署。 此外，Go 语言还支持调用由 C 语言编写的海量库文件（第 3.9 节），从而能够将过去开发的软件进行快速迁移。 1.2.4 指导设计原则 Go语言通过减少关键字的数量（25 个）来简化编码过程中的混乱和复杂度。干净、整齐和简洁的语法也能够提高程序的编译速度，因为这些关键字在编译过程中少到甚至不需要符号表来协助解析。 这些方面的工作都是为了减少编码的工作量，甚至可以与 Java 的简化程度相比较。 Go 语言有一种极简抽象艺术家的感觉，因为它只提供了一到两种方法来解决某个问题，这使得开发者们的代码都非常容易阅读和理解。众所周知，代码的可读性是软件工程里最重要的一部分（ 译者注：代码是写给人看的，不是写给机器看的 ）。 这些设计理念没有建立其它概念之上，所以并不会因为牵扯到一些概念而将某个概念复杂化，他们之间是相互独立的。 Go 语言有一套完整的编码规范，你可以在 Go 语言编码规范 页面进行查看。 它不像 Ruby 那样通过实现过程来定义编码规范。作为一门具有明确编码规范的语言，它要求可以采用不同的编译器如 gc 和 gccgo（第 2.1 节）进行编译工作，这对语言本身拥有更好的编码规范起到很大帮助。 LALR 是 Go 语言的语法标准，你也可以在 src/cmd/internal/gc/go.y 中查看到，这种语法标准在编译时不需要符号表来协助解析。 1.2.5 语言的特性 Go 语言从本质上（程序和结构方面）来实现并发编程。 因为 Go 语言没有类和继承的概念，所以它和 Java 或 C++ 看起来并不相同。但是它通过接口（interface）的概念来实现多态性。Go 语言有一个清晰易懂的轻量级类型系统，在类型之间也没有层级之说。因此可以说这是一门混合型的语言。 在传统的面向对象语言中，使用面向对象编程技术显得非常臃肿，它们总是通过复杂的模式来构建庞大的类型层级，这违背了编程语言应该提升生产力的宗旨。 函数是 Go 语言中的基本构件，它们的使用方法非常灵活。在第六章，我们会看到 Go 语言在函数式编程方面的基本概念。 Go 语言使用静态类型，所以它是类型安全的一门语言，加上通过构建到本地代码，程序的执行速度也非常快。 作为强类型语言，隐式的类型转换是不被允许的，记住一条原则：让所有的东西都是显式的。 Go 语言其实也有一些动态语言的特性（通过关键字 var），所以它对那些逃离 Java 和 .Net 世界而使用 Python、Ruby、PHP 和 JavaScript 的开发者们也具有很大的吸引力。 Go 语言支持交叉编译，比如说你可以在运行 Linux 系统的计算机上开发运行下 Windows 下运行的应用程序。这是第一门完全支持 UTF-8 的编程语言，这不仅体现在它可以处理使用 UTF-8 编码的字符串，就连它的源码文件格式都是使用的 UTF-8 编码。Go 语言做到了真正的国际化！ 1.2.6 语言的用途 Go 语言被设计成一门应用于搭载 Web 服务器，存储集群或类似用途的巨型中央服务器的系统编程语言。对于高性能分布式系统领域而言，Go 语言无疑比大多数其它语言有着更高的开发效率。它提供了海量并行的支持，这对于游戏服务端的开发而言是再好不过了。 Go 语言一个非常好的目标就是实现所谓的复杂事件处理（CEP），这项技术要求海量并行支持，高度的抽象化和高性能。当我们进入到物联网时代，CEP 必然会成为人们关注的焦点。 但是 Go 语言同时也是一门可以用于实现一般目标的语言，例如对于文本的处理，前端展现，甚至像使用脚本一样使用它。 值得注意的是，因为垃圾回收和自动内存分配的原因，Go 语言不适合用来开发对实时性要求很高的软件。 越来越多的谷歌内部的大型分布式应用程序都开始使用 Go 语言来开发，例如谷歌地球的一部分代码就是由 Go 语言完成的。 如果你想知道一些其它组织使用Go语言开发的实际应用项目，你可以到 使用 Go 的组织 页面进行查看。出于隐私保护的考虑，许多公司的项目都没有展示在这个页面。我们将会在第 21 章讨论到一个使用 Go 语言开发的大型存储区域网络（SAN）案例。 在 Chrome 浏览器中内置了一款 Go 语言的编译器用于本地客户端（NaCl），这很可能会被用于在 Chrome OS 中执行 Go 语言开发的应用程序。 Go 语言可以在 Intel 或 ARM 处理器上运行，因此它也可以在安卓系统下运行，例如 Nexus 系列的产品。 在 Google App Engine 中使用 Go 语言：2011 年 5 月 5 日，官方发布了用于开发运行在 Google App Engine 上的 Web 应用的 Go SDK，在此之前，开发者们只能选择使用 Python 或者 Java。这主要是 David Symonds 和 Nigel Tao 努力的成果。目前最新的稳定版是基于 Go 1.4 的 SDK 1.9.18，于 2015 年 2 月 18 日发布。当前 Go 语言的稳定版本是 Go 1.4.2。 1.2.7 关于特性缺失 许多能够在大多数面向对象语言中使用的特性 Go 语言都没有支持，但其中的一部分可能会在未来被支持。 为了简化设计，不支持函数重载和操作符重载 为了避免在 C/C++ 开发中的一些 Bug 和混乱，不支持隐式转换 Go 语言通过另一种途径实现面向对象设计（第 10-11 章）来放弃类和类型的继承 尽管在接口的使用方面（第 11 章）可以实现类似变体类型的功能，但本身不支持变体类型 不支持动态加载代码 不支持动态链接库 不支持泛型 通过 recover 和 panic 来替代异常机制（第 13.2-3 节） 不支持断言 不支持静态变量 关于 Go 语言开发团队对于这些方面的讨论，你可以通过 Go 常见问题 页面查看。 1.2.8 使用 Go 语言编程 如果你有其它语言的编程经历（面向对象编程语言，如：Java、C#、Object-C、Python、Ruby），在你进入到 Go 语言的世界之后，你将会像迷恋你的 X 语言一样无法自拔。Go 语言使用了与其它语言不同的设计模式，所以当你尝试将你的X语言的代码迁移到 Go 语言时，你将会非常失望，所以你需要从头开始，用 Go 的理念来思考。 如果你在至高点使用 Go 的理念来重新审视和分析一个问题，你通常会找到一个适用于 Go 语言的优雅的解决方案。 1.2.9 小结 这里列举一些 Go 语言的必杀技： 简化问题，易于学习 内存管理，简洁语法，易于使用 快速编译，高效开发 高效执行 并发支持，轻松驾驭 静态类型 标准类库，规范统一 易于部署 文档全面 免费开源 链接 目录 上一节：起源与发展 下一章：安装与运行环境 "},"Go入门指南/02.1.html":{"url":"Go入门指南/02.1.html","title":"1","keywords":"","body":"2.1 平台与架构 Go 语言开发团队开发了适用于以下操作系统的编译器： Linux FreeBSD Mac OS X（也称为 Darwin） 目前有2个版本的编译器：Go 原生编译器 gc 和非原生编译器 gccgo，这两款编译器都是在类 Unix 系统下工作 。其中，gc 版本的编译器已经被移植到 Windows 平台上，并集成在主要发行版中，你也可以通过安装 MinGW 从而在 Windows 平台下使用 gcc 编译器。这两个编译器都是以单通道的形式工作。 你可以获取以下平台上的 Go 1.4 源码和二进制文件： Linux 2.6+：amd64、386 和 arm 架构 Mac OS X（Snow Leopard + Lion）：amd64 和 386 架构 Windows 2000+：amd64 和 386 架构 对于非常底层的纯 Go 语言代码或者包而言，在各个操作系统平台上的可移植性是非常强的，只需要将源码拷贝到相应平台上进行编译即可，或者可以使用交叉编译来构建目标平台的应用程序（第 2.2 节）。但如果你打算使用 cgo 或者类似文件监控系统的软件，就需要根据实际情况进行相应地修改了。 Go 原生编译器 gc： 主要基于 Ken Thompson 先前在 Plan 9 操作系统上使用的 C 工具链。 Go 语言的编译器和链接器都是使用 C 语言编写并产生本地代码，Go 不存在自我引导之类的功能。因此如果使用一个有不同指令集的编译器来构建 Go 程序，就需要针对操作系统和处理器架构（32 位操作系统或 64 位操作系统）进行区别对待。 这款编译器使用非分代、无压缩和并行的方式进行编译，它的编译速度要比 gccgo 更快，产生更好的本地代码，但编译后的程序不能够使用 gcc 进行链接。 编译器目前支持以下基于 Intel 或 AMD 处理器架构的程序构建。 图2.1 gc 编译器支持的处理器架构 当你第一次看到这套命名系统的时候你会觉得很奇葩，不过这些命名都是来自于 Plan 9 项目。 g = 编译器：将源代码编译为项目代码（程序文本） l = 链接器：将项目代码链接到可执行的二进制文件（机器代码） （相关的 C 编译器名称为 6c、8c 和 5c，相关的汇编器名称为 6a、8a 和 5a） 标记（Flags） 是指可以通过命令行设置可选参数来影响编译器或链接器的构建过程或得到一个特殊的目标结果。 可用的编译器标记如下： flags: -I 针对包的目录搜索 -d 打印声明信息 -e 不限制错误打印的个数 -f 打印栈结构 -h 发生错误时进入恐慌（panic）状态 -o 指定输出文件名 // 详见第3.4节 -S 打印产生的汇编代码 -V 打印编译器版本 // 详见第2.3节 -u 禁止使用 unsafe 包中的代码 -w 打印归类后的语法解析树 -x 打印 lex tokens 从 Go 1.0.3 版本开始，不再使用 8g，8l 之类的指令进行程序的构建，取而代之的是统一的 go build 和 go install 等命令，而这些指令会自动调用相关的编译器或链接器。 如果你想获得更深层次的信息，你可以在目录 $GOROOT/src/cmd 下找到编译器和链接器的源代码。Go 语言本身是由 C 语言开发的，而不是 Go 语言（Go 1.5 开始自举）。词法分析程序是 GNU bison，语法分析程序是名为 $GOROOT/src/cmd/gc/go.y 的 yacc 文件，它会在同一目录输出 y.tab.{c,h} 文件。如果你想知道更多有关构建过程的信息，你可以在 $GOROOT/src/make.bash 中找到。 大部分的目录都包含了名为 doc.go 的文件，这个文件提供了更多详细的信息。 gccgo 编译器： 一款相对于 gc 而言更加传统的编译器，使用 GCC 作为后端。GCC 是一款非常流行的 GNU 编译器，它能够构建基于众多处理器架构的应用程序。编译速度相对 gc 较慢，但产生的本地代码运行要稍微快一点。它同时也提供一些与 C 语言之间的互操作性。 从 Go 1 版本开始，gc 和 gccgo 在编译方面都有等价的功能。 文件扩展名与包（package）： Go 语言源文件的扩展名很显然就是 .go。 C 文件使用后缀名 .c，汇编文件使用后缀名 .s。所有的源代码文件都是通过包（packages）来组织。包含可执行代码的包文件在被压缩后使用扩展名 .a（AR 文档）。 Go 语言的标准库（第 9.1 节）包文件在被安装后就是使用这种格式的文件。 注意 当你在创建目录时，文件夹名称永远不应该包含空格，而应该使用下划线 \"_\" 或者其它一般符号代替。 链接 目录 上一章：语言的主要特性与发展的环境和影响因素 下一节：Go 环境变量 "},"Go入门指南/02.2.html":{"url":"Go入门指南/02.2.html","title":"2","keywords":"","body":"2.2 Go 环境变量 Go 开发环境依赖于一些操作系统环境变量，你最好在安装 Go 之间就已经设置好他们。如果你使用的是 Windows 的话，你完全不用进行手动设置，Go 将被默认安装在目录 c:/go 下。这里列举几个最为重要的环境变量： $GOROOT 表示 Go 在你的电脑上的安装位置，它的值一般都是 $HOME/go，当然，你也可以安装在别的地方。 $GOARCH 表示目标机器的处理器架构，它的值可以是 386、amd64 或 arm。 $GOOS 表示目标机器的操作系统，它的值可以是 darwin、freebsd、linux 或 windows。 $GOBIN 表示编译器和链接器的安装位置，默认是 $GOROOT/bin，如果你使用的是 Go 1.0.3 及以后的版本，一般情况下你可以将它的值设置为空，Go 将会使用前面提到的默认值。 目标机器是指你打算运行你的 Go 应用程序的机器。 Go 编译器支持交叉编译，也就是说你可以在一台机器上构建运行在具有不同操作系统和处理器架构上运行的应用程序，也就是说编写源代码的机器可以和目标机器有完全不同的特性（操作系统与处理器架构）。 为了区分本地机器和目标机器，你可以使用 $GOHOSTOS 和 $GOHOSTARCH 设置本地机器的操作系统名称和编译体系结构，这两个变量只有在进行交叉编译的时候才会用到，如果你不进行显示设置，他们的值会和本地机器（$GOOS 和 $GOARCH）一样。 $GOPATH 默认采用和 $GOROOT 一样的值，但从 Go 1.1 版本开始，你必须修改为其它路径。它可以包含多个包含 Go 语言源码文件、包文件和可执行文件的路径，而这些路径下又必须分别包含三个规定的目录：src、pkg 和 bin，这三个目录分别用于存放源码文件、包文件和可执行文件。 $GOARM 专门针对基于 arm 架构的处理器，它的值可以是 5 或 6，默认为 6。 $GOMAXPROCS 用于设置应用程序可使用的处理器个数与核数，详见第 14.1.3 节。 在接下来的章节中，我们将会讨论如何在 Linux、Mac OS X 和 Windows 上安装 Go 语言。在 FreeBSD 上的安装和 Linux 非常类似。开发团队正在尝试将 Go 语言移植到其它例如 OpenBSD、DragonFlyBSD、NetBSD、Plan 9、Haiku 和 Solaris 操作系统上，你可以在这个页面找到最近的动态：Go Porting Efforts。 链接 目录 上一节：平台与架构 下一节：在 Linux 上安装 Go "},"Go入门指南/02.3.html":{"url":"Go入门指南/02.3.html","title":"3","keywords":"","body":"2.3 在 Linux 上安装 Go 如果你能够自己下载并编译 Go 的源代码来说是非常有教育意义的，你可以根据这个页面找到安装指南和下载地址：Download the Go distribution。 我们接下来也会带你一步步的完成安装过程。 设置 Go 环境变量 我们在 Linux 系统下一般通过文件 $HOME/.bashrc 配置自定义环境变量，根据不同的发行版也可能是文件 $HOME/.profile，然后使用 gedit 或 vi 来编辑文件内容。 export GOROOT=$HOME/go 为了确保相关文件在文件系统的任何地方都能被调用，你还需要添加以下内容： export PATH=$PATH:$GOROOT/bin 在开发 Go 项目时，你还需要一个环境变量来保存你的工作目录。 export GOPATH=$HOME/Applications/Go $GOPATH 可以包含多个工作目录，取决于你的个人情况。如果你设置了多个工作目录，那么当你在之后使用 go get（远程包安装命令）时远程包将会被安装在第一个目录下。 在完成这些设置后，你需要在终端输入指令 source .bashrc 以使这些环境变量生效。然后重启终端，输入 go env 和 env 来检查环境变量是否设置正确。 安装 C 工具 Go 的工具链是用 C 语言编写的，因此在安装 Go 之前你需要先安装相关的 C 工具。如果你使用的是 Ubuntu 的话，你可以在终端输入以下指令（ 译者注：由于网络环境的特殊性，你可能需要将每个工具分开安装 ）。 sudo apt-get install bison ed gawk gcc libc6-dev make 你可以在其它发行版上使用 RPM 之类的工具。 获取 Go 源代码 从 官方页面 或 国内镜像 下载 Go 的源码包到你的计算机上，然后将解压后的目录 go 通过命令移动到 $GOROOT 所指向的位置。 wget https://storage.googleapis.com/golang/go.src.tar.gz tar -zxvf go.src.tar.gz sudo mv go $GOROOT 构建 Go 在终端使用以下指令来进行编译工作。 cd $GOROOT/src ./all.bash 在完成编译之后（通常在 1 分钟以内，如果你在 B 型树莓派上编译，一般需要 1 个小时），你会在终端看到如下信息被打印： 图 2.3 完成编译后在终端打印的信息 注意事项 在测试 net/http 包时有一个测试会尝试连接 google.com，你可能会看到如下所示的一个无厘头的错误报告： ‘make[2]: Leaving directory `/localusr/go/src/pkg/net’ 如果你正在使用一个带有防火墙的机器，我建议你可以在编译过程中暂时关闭防火墙，以避免不必要的错误。 解决这个问题的另一个办法是通过设置环境变量 $DISABLE_NET_TESTS 来告诉构建工具忽略 net/http 包的相关测试： export DISABLE_NET_TESTS=1 如果你完全不想运行包的测试，你可以直接运行 ./make.bash 来进行单纯的构建过程。 测试安装 使用你最喜爱的编辑器来输入以下内容，并保存为文件名 test.go。 示例 2.1 hello_world1.go package main func main() { println(\"Hello\", \"world\") } 切换相关目录到下，然后执行指令 go run hello_world1.go，将会打印信息：Hello, world。 验证安装版本 你可以通过在终端输入指令 go version 来打印 Go 的版本信息。 如果你想要通过 Go 代码在运行时检测版本，可以通过以下例子实现。 示例 2.2 version.go package main import ( \"fmt\" \"runtime\" ) func main() { fmt.Printf(\"%s\", runtime.Version()) } 这段代码将会输出 go1.4.2 或类似字符串。 更新版本 你可以在 发布历史 页面查看到最新的稳定版。 当前最新的稳定版 Go 1 系列于 2012 年 3 月 28 日发布。 Go 的源代码有以下三个分支： - Go release：最新稳定版，实际开发最佳选择 - Go weekly：包含最近更新的版本，一般每周更新一次 - Go tip：永远保持最新的版本，相当于内测版 当你在使用不同的版本时，注意官方博客发布的信息，因为你所查阅的文档可能和你正在使用的版本不相符。 链接 目录 上一节：Go 环境变量 下一节：在 Mac OS X 上安装 Go "},"Go入门指南/02.4.html":{"url":"Go入门指南/02.4.html","title":"4","keywords":"","body":"2.4 在 Mac OS X 上安装 Go 如果你想要在你的 Mac 系统上安装 Go，则必须使用 Intel 64 位处理器，Go 不支持 PowerPC 处理器。 你可以通过该页面查看有关在 PowerPC 处理器上的移植进度：https://codedr-go-ppc.googlecode.com/hg/。 注意事项 在 Mac 系统下使用到的 C 工具链是 Xcode 的一部分，因此你需要通过安装 Xcode 来完成这些工具的安装。你并不需要安装完整的 Xcode，而只需要安装它的命令行工具部分。 你可以在 下载页面 页面下载到 Mac 系统下的一键安装包或源代码自行编译。 通过源代码编译安装的过程与环境变量的配置与在 Linux 系统非常相似，因此不再赘述。 链接 目录 上一节：在 Linux 上安装 Go 下一节：在 Windows 上安装 Go "},"Go入门指南/02.5.html":{"url":"Go入门指南/02.5.html","title":"5","keywords":"","body":"2.5 在 Windows 上安装 Go 你可以在 下载页面 页面下载到 Windows 系统下的一键安装包。 前期的 Windows 移植工作由 Hector Chu 完成，但目前的发行版已经由 Joe Poirier 全职维护。 在完成安装包的安装之后，你只需要配置 $GOPATH 这一个环境变量就可以开始使用 Go 语言进行开发了，其它的环境变量安装包均会进行自动设置。在默认情况下，Go 将会被安装在目录 c:\\go 下，但如果你在安装过程中修改安装目录，则可能需要手动修改所有的环境变量的值。 如果你想要测试安装，则可以使用指令 go run 运行 hello_world1.go。 如果发生错误 fatal error: can’t find import: fmt 则说明你的环境变量没有配置正确。 如果你想要在 Windows 下使用 cgo （调用 C 语言写的代码），则需要安装 MinGW，一般推荐安装 TDM-GCC。如果你使用的是 64 位操作系统，请务必安装 64 位版本的 MinGW。安装完成进行环境变量等相关配置即可使用。 在 Windows 下运行在虚拟机里的 Linux 系统上安装 Go： 如果你想要在 Windows 下的虚拟机里的 Linux 系统上安装 Go，你可以选择使用虚拟机软件 VMware，下载 VMware player，搜索并下载一个你喜欢的 Linux 发行版镜像，然后安装到虚拟机里，安装 Go 的流程参考第 2.3 节中的内容。 链接 目录 上一节：在 Mac OS X 上安装 Go 下一节：安装目录清单 "},"Go入门指南/02.6.html":{"url":"Go入门指南/02.6.html","title":"6","keywords":"","body":"2.6 安装目录清单 你的 Go 安装目录（$GOROOT）的文件夹结构应该如下所示： README.md, AUTHORS, CONTRIBUTORS, LICENSE /bin：包含可执行文件，如：编译器，Go 工具 /doc：包含示例程序，代码工具，本地文档等 /lib：包含文档模版 /misc：包含与支持 Go 编辑器有关的配置文件以及 cgo 的示例 /os_arch：包含标准库的包的对象文件（.a） /src：包含源代码构建脚本和标准库的包的完整源代码（Go 是一门开源语言） /src/cmd：包含 Go 和 C 的编译器和命令行脚本 链接 目录 上一节：在 Windows 上安装 Go 下一节：Go 运行时（runtime） "},"Go入门指南/02.7.html":{"url":"Go入门指南/02.7.html","title":"7","keywords":"","body":"2.7 Go 运行时（runtime） 尽管 Go 编译器产生的是本地可执行代码，这些代码仍旧运行在 Go 的 runtime（这部分的代码可以在 runtime 包中找到）当中。这个 runtime 类似 Java 和 .NET 语言所用到的虚拟机，它负责管理包括内存分配、垃圾回收（第 10.8 节）、栈处理、goroutine、channel、切片（slice）、map 和反射（reflection）等等。 runtime 主要由 C 语言编写（Go 1.5 开始自举），并且是每个 Go 包的最顶级包。你可以在目录 $GOROOT/src/runtime 中找到相关内容。 垃圾回收器 Go 拥有简单却高效的标记-清除回收器。它的主要思想来源于 IBM 的可复用垃圾回收器，旨在打造一个高效、低延迟的并发回收器。目前 gccgo 还没有回收器，同时适用 gc 和 gccgo 的新回收器正在研发中。使用一门具有垃圾回收功能的编程语言不代表你可以避免内存分配所带来的问题，分配和回收内容都是消耗 CPU 资源的一种行为。 Go 的可执行文件都比相对应的源代码文件要大很多，这恰恰说明了 Go 的 runtime 嵌入到了每一个可执行文件当中。当然，在部署到数量巨大的集群时，较大的文件体积也是比较头疼的问题。但总得来说，Go 的部署工作还是要比 Java 和 Python 轻松得多。因为 Go 不需要依赖任何其它文件，它只需要一个单独的静态文件，这样你也不会像使用其它语言一样在各种不同版本的依赖文件之间混淆。 链接 目录 上一节：安装目录清单 下一节：Go 解释器 "},"Go入门指南/02.8.html":{"url":"Go入门指南/02.8.html","title":"8","keywords":"","body":"2.8 Go 解释器 因为 Go 具有像动态语言那样快速编译的能力，自然而然地就有人会问 Go 语言能否在 REPL（read-eval-print loop）编程环境下实现。Sebastien Binet 已经使用这种环境实现了一个 Go 解释器，你可以在这个页面找到：https://github.com/sbinet/igo。 链接 目录 上一节：Go 运行时（runtime） 下一章：编辑器、集成开发环境与其它工具 "},"Go入门指南/03.0.html":{"url":"Go入门指南/03.0.html","title":"0","keywords":"","body":"3.0 编辑器、集成开发环境与其它工具 因为 Go 语言还是一门相对年轻的编程语言，所以不管是在集成开发环境（IDE）还是相关的插件方面，发展都不是很成熟。不过目前还是有一些 IDE 能够较好地支持 Go 的开发，有些开发工具甚至是跨平台的，你可以在 Linux、Mac OS X 或者 Windows 下工作。 你可以通过查阅 编辑器和 IDE 扩展 页面来获取 Go 开发工具的最新信息。 链接 目录 上一章：Go 解释器 下一节：Go 开发环境的基本要求 "},"Go入门指南/03.1.html":{"url":"Go入门指南/03.1.html","title":"1","keywords":"","body":"3.1 Go 开发环境的基本要求 这里有一个你可以期待你用来开发 Go 的集成开发环境有哪些特性的列表，从而替代你使用文本编辑器写代码和命令行编译与链接程序的方式。 语法高亮是必不可少的功能，这也是为什么每个开发工具都提供配置文件来实现自定义配置的原因。 可以自动保存代码，至少在每次编译前都会保存。 可以显示代码所在的行数。 拥有较好的项目文件纵览和导航能力，可以同时编辑多个源文件并设置书签，能够匹配括号，能够跳转到某个函数或类型的定义部分。 完美的查找和替换功能，替换之前最好还能预览结果。 可以注释或取消注释选中的一行或多行代码。 当有编译错误时，双击错误提示可以跳转到发生错误的位置。 跨平台，能够在 Linux、Mac OS X 和 Windows 下工作，这样就可以专注于一个开发环境。 最好是免费的，不过有些开发者还是希望能够通过支付一定金额以获得更好的开发环境。 最好是开源的。 能够通过插件架构来轻易扩展和替换某个功能。 尽管集成开发环境本身就是非常复杂的，但一定要让人感觉操作方便。 能够通过代码模版来简化编码过程从而提升编码速度。 使用 Go 项目的概念来浏览和管理项目中的文件，同时还要拥有构建系统的概念，这样才能更加方便的构建、清理或运行我们建立的程序或项目。构建出的程序需要能够通过命令行或 IDE 内部的控制台运行。 拥有断点、检查变量值、单步执行、逐过程执行标识库中代码的能力。 能够方便的存取最近使用过的文件或项目。 拥有对包、类型、变量、函数和方法的智能代码补全的功能。 能够对项目或包中的代码建立抽象语法树视图（AST-view）。 内置 Go 的相关工具。 能够方便完整地查阅 Go 文档。 能够方便地在不同的 Go 环境之间切换。 能够导出不同格式的代码文件，如：PDF，HTML 或格式化后的代码。 针对一些特定的项目有项目模板，如：Web 应用，App Engine 项目，从而能够更快地开始开发工作。 具备代码重构的能力。 集成像 hg 或 git 这样的版本控制工具。 集成 Google App Engine 开发及调试的功能。 链接 目录 上一节：编辑器、集成开发环境与其它工具 下一节：编辑器和集成开发环境 "},"Go入门指南/03.2.html":{"url":"Go入门指南/03.2.html","title":"2","keywords":"","body":"3.2 编辑器和集成开发环境 这些编辑器包含了代码高亮和其它与 Go 有关的一些使用工具：Emacs、Vim、Xcode 6、KD Kate、TextWrangler、BBEdit、McEdit、TextMate、TextPad、JEdit、SciTE、Nano、Notepad++、Geany、SlickEdit、IntelliJ IDEA 和 Sublime Text 2。 你可以将 Linux 的文本编辑器 GEdit 改造成一个很好的 Go 开发工具，详见页面：http://gohelp.wordpress.com/。 Sublime Text 是一个革命性的跨平台（Linux、Mac OS X、Windows）文本编辑器，它支持编写非常多的编程语言代码。对于 Go 而言，它有一个插件叫做 GoSublime 来支持代码补全和代码模版。 这里还有一些更加高级的 Go 开发工具，其中一些是以插件的形式利用本身是作为开发 Java 的工具。 IntelliJ Idea Plugin 是一个 IntelliJ IDEA 的插件，具有很好的操作体验和代码补全功能。 LiteIDE 这是一款专门针对 Go 开发的集成开发环境，在编辑、编译和运行 Go 程序和项目方面都有非常好的支持。同时还包括了对源代码的抽象语法树视图和一些内置工具（此开发环境由国人 vfc 大叔开发）。 GoClipse 是一款 Eclipse IDE 的插件，拥有非常多的特性以及通过 GoCode 来实现代码补全功能。 如果你对集成开发环境都不是很熟悉，那就使用 LiteIDE 吧，另外使用 GoClipse 或者 IntelliJ Idea Plugin 也是不错的选择。 代码补全 一般都是通过内置 GoCode 实现的（如：LieteIDE、GoClipse），如果需要手动安装 GoCode，在命令行输入指令 go get -u github.com/nsf/gocode 即可（务必事先配置好 Go 环境变量） 。 接下来会对这三个集成开发环境做更加详细的说明。 3.2.1 LiteIDE 这款 IDE 的当前最新版本号为 X27，你可以从 GitHub 页面获取详情。 LiteIDE 是一款非常好用的轻量级 Go 集成开发环境（基于 QT、Kate 和 SciTE），包含了跨平台开发及其它必要的特性，对代码编写、自动补全和运行调试都有极佳的支持。它采用了 Go 项目的概念来对项目文件进行浏览和管理，它还支持在各个 Go 开发环境之间随意切换以及交叉编译的功能。 同时，它具备了抽象语法树视图的功能，可以清楚地纵览项目中的常量、变量、函数、不同类型以及他们的属性和方法。 图 3.1 LiteIDE 代码编辑界面和抽象语法树视图 3.2.2 GoClipse 该款插件的当前最新版本号为 0.9.1，你可以从 GitHub 页面获取详情。 其依附于著名的 Eclipse 这个大型开发环境，虽然需要安装 JVM 运行环境，但却可以很容易地享有 Eclipse 本身所具有的诸多功能。这是一个非常好的编辑器，完善的代码补全、抽象语法树视图、项目管理和程序调试功能。 图 3.2 GoClipse 代码编辑界面、抽象语法树视图和项目管理 链接 目录 上一节：Go 开发环境的基本要求 下一节：调试器 "},"Go入门指南/03.3.html":{"url":"Go入门指南/03.3.html","title":"3","keywords":"","body":"3.3 调试器 应用程序的开发过程中调试是必不可少的一个环节，因此有一个好的调试器是非常重要的，可惜的是，Go 在这方面的发展还不是很完善。目前可用的调试器是 gdb，最新版均以内置在集成开发环境 LiteIDE 和 GoClipse 中，但是该调试器的调试方式并不灵活且操作难度较大。 如果你不想使用调试器，你可以按照下面的一些有用的方法来达到基本调试的目的： 在合适的位置使用打印语句输出相关变量的值（print/println 和 fmt.Print/fmt.Println/fmt.Printf）。 在 fmt.Printf 中使用下面的说明符来打印有关变量的相关信息： %+v 打印包括字段在内的实例的完整信息 %#v 打印包括字段和限定类型名称在内的实例的完整信息 %T 打印某个类型的完整说明 使用 panic 语句（第 13.2 节）来获取栈跟踪信息（直到 panic 时所有被调用函数的列表）。 使用关键字 defer 来跟踪代码执行过程（第 6.4 节）。 链接 目录 上一节：编辑器和集成开发环境 下一节：构建并运行 Go 程序 "},"Go入门指南/03.4.html":{"url":"Go入门指南/03.4.html","title":"4","keywords":"","body":"3.4 构建并运行 Go 程序 在大多数 IDE 中，每次构建程序之前都会自动调用源码格式化工具 gofmt 并保存格式化后的源文件。如果构建成功则不会输出任何信息，而当发生编译时错误时，则会指明源码中具体第几行出现了什么错误，如：a declared and not used。一般情况下，你可以双击 IDE 中的错误信息直接跳转到发生错误的那一行。 如果程序执行一切顺利并成功退出后，将会在控制台输出 Program exited with code 0。 从 Go 1 版本开始，使用 Go 自带的更加方便的工具来构建应用程序： go build 编译并安装自身包和依赖包 go install 安装自身包和依赖包 链接 目录 上一节：调试器 下一节：格式化代码 "},"Go入门指南/03.5.html":{"url":"Go入门指南/03.5.html","title":"5","keywords":"","body":"3.5 格式化代码 Go 开发团队不想要 Go 语言像许多其它语言那样总是在为代码风格而引发无休止的争论，浪费大量宝贵的开发时间，因此他们制作了一个工具：go fmt（gofmt）。这个工具可以将你的源代码格式化成符合官方统一标准的风格，属于语法风格层面上的小型重构。遵循统一的代码风格是 Go 开发中无可撼动的铁律，因此你必须在编译或提交版本管理系统之前使用 gofmt 来格式化你的代码。 尽管这种做法也存在一些争论，但使用 gofmt 后你不再需要自成一套代码风格而是和所有人使用相同的规则。这不仅增强了代码的可读性，而且在接手外部 Go 项目时，可以更快地了解其代码的含义。此外，大多数开发工具也都内置了这一功能。 Go 对于代码的缩进层级方面使用 tab 还是空格并没有强制规定，一个 tab 可以代表 4 个或 8 个空格。在实际开发中，1 个 tab 应该代表 4 个空格，而在本身的例子当中，每个 tab 代表 8 个空格。至于开发工具方面，一般都是直接使用 tab 而不替换成空格。 在命令行输入 gofmt –w program.go 会格式化该源文件的代码然后将格式化后的代码覆盖原始内容（如果不加参数 -w 则只会打印格式化后的结果而不重写文件）；gofmt -w *.go 会格式化并重写所有 Go 源文件；gofmt map1 会格式化并重写 map1 目录及其子目录下的所有 Go 源文件。 gofmt 也可以通过在参数 -r 后面加入用双引号括起来的替换规则实现代码的简单重构，规则的格式： -> 。 实例： gofmt -r '(a) -> a' –w *.go 上面的代码会将源文件中没有意义的括号去掉。 gofmt -r 'a[n:len(a)] -> a[n:]' –w *.go 上面的代码会将源文件中多余的 len(a) 去掉。（ 译者注：了解切片（slice）之后就明白这为什么是多余的了 ） gofmt –r 'A.Func1(a,b) -> A.Func2(b,a)' –w *.go 上面的代码会将源文件中符合条件的函数的参数调换位置。 如果想要了解有关 gofmt 的更多信息，请访问该页面：http://golang.org/cmd/gofmt/。 链接 目录 上一节：构建并运行 Go 程序 下一节：生成代码文档 "},"Go入门指南/03.6.html":{"url":"Go入门指南/03.6.html","title":"6","keywords":"","body":"3.6 生成代码文档 go doc 工具会从 Go 程序和包文件中提取顶级声明的首行注释以及每个对象的相关注释，并生成相关文档。 它也可以作为一个提供在线文档浏览的 web 服务器，http://golang.org 就是通过这种形式实现的。 一般用法 go doc package 获取包的文档注释，例如：go doc fmt 会显示使用 godoc 生成的 fmt 包的文档注释。 go doc package/subpackage 获取子包的文档注释，例如：go doc container/list。 go doc package function 获取某个函数在某个包中的文档注释，例如：go doc fmt Printf 会显示有关 fmt.Printf() 的使用说明。 这个工具只能获取在 Go 安装目录下 ../go/src 中的注释内容。此外，它还可以作为一个本地文档浏览 web 服务器。在命令行输入 godoc -http=:6060，然后使用浏览器打开 http://localhost:6060 后，你就可以看到本地文档浏览服务器提供的页面。 godoc 也可以用于生成非标准库的 Go 源码文件的文档注释（第 9.6 章）。 如果想要获取更多有关 godoc 的信息，请访问该页面：http://golang.org/cmd/godoc/（在线版的第三方包 godoc 可以使用 Go Walker）。 链接 目录 上一节：格式化代码 下一节：其它工具 "},"Go入门指南/03.7.html":{"url":"Go入门指南/03.7.html","title":"7","keywords":"","body":"3.7 其它工具 Go 自带的工具集主要使用脚本和 Go 语言自身编写的，目前版本的 Go 实现了以下三个工具： go install 是安装 Go 包的工具，类似 Ruby 中的 rubygems。主要用于安装非标准库的包文件，将源代码编译成对象文件。 go fix 用于将你的 Go 代码从旧的发行版迁移到最新的发行版，它主要负责简单的、重复的、枯燥无味的修改工作，如果像 API 等复杂的函数修改，工具则会给出文件名和代码行数的提示以便让开发人员快速定位并升级代码。Go 开发团队一般也使用这个工具升级 Go 内置工具以及 谷歌内部项目的代码。go fix 之所以能够正常工作是因为 Go 在标准库就提供生成抽象语法树和通过抽象语法树对代码进行还原的功能。该工具会尝试更新当前目录下的所有 Go 源文件，并在完成代码更新后在控制台输出相关的文件名称。 go test 是一个轻量级的单元测试框架（第 13 章）。 链接 目录 上一节：生成代码文档 下一节：Go 性能说明 "},"Go入门指南/03.8.html":{"url":"Go入门指南/03.8.html","title":"8","keywords":"","body":"3.8 Go 性能说明 根据 Go 开发团队和基本的算法测试，Go 语言与 C 语言的性能差距大概在 10%~20% 之间（ 译者注：由于出版时间限制，该数据应为 2013 年 3 月 28 日之前产生 ）。虽然没有官方的性能标准，但是与其它各个语言相比已经拥有非常出色的表现。 如果说 Go 语言的执行效率大约比 C++ 慢 20% 也许更有实际意义。保守估计在相同的环境和执行目标的情况下，Go 程序比 Java 或 Scala 应用程序要快上 2 倍，并比这两门语言占用的内存降低了 70% 。在很多情况下这种比较是没有意义的，而像谷歌这样拥有成千上万台服务器的公司都抛弃 C++ 而开始将 Go 用于生产环境才足够说明它本身所具有的优势。 时下流行的语言大都是运行在虚拟机上，如：Java 和 Scala 使用的 JVM，C# 和 VB.NET 使用的 .NET CLR。尽管虚拟机的性能已经有了很大的提升，但任何使用 JIT 编译器和脚本语言解释器的编程语言（Ruby、Python、Perl 和 JavaScript）在 C 和 C++ 的绝对优势下甚至都无法在性能上望其项背。 如果说 Go 比 C++ 要慢 20%，那么 Go 就要比任何非静态和编译型语言快 2 到 10 倍，并且能够更加高效地使用内存。 其实比较多门语言之间的性能是一种非常猥琐的行为，因为任何一种语言都有其所擅长和薄弱的方面。例如在处理文本方面，那些只处理纯字节的语言显然要比处理 Unicode 这种更为复杂编码的语言要出色的多。有些人可能认为使用两种不同的语言实现同一个目标能够得出正确的结论，但是很多时候测试者可能对一门语言非常了解而对另一门语言只是大概明白，测试者对程序编写的手法在一定程度也会影响结果的公平性，因此测试程序应该分别由各自语言的擅长者来编写，这样才能得到具有可比性的结果。另外，像在统计学方面，人们很难避免人为因素对结果的影响，所以这在严格意义上并不是科学。还要注意的是，测试结果的可比性还要根据测试目标来区别，例如很多发展十多年的语言已经针对各类问题拥有非常成熟的类库，而作为一门新生语言的 Go 语言，并没有足够的时间来推导各类问题的最佳解决方案。如果你想获取更多有关性能的资料，请访问 Computer Language Benchmark Game（详见引用 27）。 这里有一些评测结果： 比较 Go 和 Python 在简单的 web 服务器方面的性能，单位为传输量每秒： 原生的 Go http 包要比 web.py 快 7 至 8 倍，如果使用 web.go 框架则稍微差点，比 web.py 快 6 至 7 倍。在 Python 中被广泛使用的 tornado 异步服务器和框架在 web 环境下要比 web.py 快很多，Go 大概只比它快 1.2 至 1.5 倍（详见引用 26）。 Go 和 Python 在一般开发的平均水平测试中，Go 要比 Python 3 快 25 倍左右，少占用三分之二的内存，但比 Python 大概多写一倍的代码（详见引用 27）。 根据 Robert Hundt（2011 年 6 月，详见引用 28）的文章对 C++、Java、Go 和 Scala，以及 Go 开发团队的反应（详见引用 29），可以得出以下结论： Go 和 Scala 之间具有更多的可比性（都使用更少的代码），而 C++ 和 Java 都使用非常冗长的代码。 Go 的编译速度要比绝大多数语言都要快，比 Java 和 C++ 快 5 至 6 倍，比 Scala 快 10 倍。 Go 的二进制文件体积是最大的（每个可执行文件都包含 runtime）。 在最理想的情况下，Go 能够和 C++ 一样快，比 Scala 快 2 至 3 倍，比 Java 快 5 至 10 倍。 Go 在内存管理方面也可以和 C++ 相媲美，几乎只需要 Scala 所使用的一半，比 Java 少 4 倍左右。 链接 目录 上一节：其它工具 下一节：与其它语言进行交互 "},"Go入门指南/03.9.html":{"url":"Go入门指南/03.9.html","title":"9","keywords":"","body":"3.9 与其它语言进行交互 3.9.1 与 C 进行交互 工具 cgo 提供了对 FFI（外部函数接口）的支持，能够使用 Go 代码安全地调用 C 语言库，你可以访问 cgo 文档主页：http://golang.org/cmd/cgo。cgo 会替代 Go 编译器来产生可以组合在同一个包中的 Go 和 C 代码。在实际开发中一般使用 cgo 创建单独的 C 代码包。 如果你想要在你的 Go 程序中使用 cgo，则必须在单独的一行使用 import \"C\" 来导入，一般来说你可能还需要 import \"unsafe\"。 然后，你可以在 import \"C\" 之前使用注释（单行或多行注释均可）的形式导入 C 语言库（甚至有效的 C 语言代码），它们之间没有空行，例如： // #include // #include import \"C\" 名称 \"C\" 并不属于标准库的一部分，这只是 cgo 集成的一个特殊名称用于引用 C 的命名空间。在这个命名空间里所包含的 C 类型都可以被使用，例如 C.uint、C.long 等等，还有 libc 中的函数 C.random() 等也可以被调用。 当你想要使用某个类型作为 C 中函数的参数时，必须将其转换为 C 中的类型，反之亦然，例如： var i int C.uint(i) // 从 Go 中的 int 转换为 C 中的无符号 int int(C.random()) // 从 C 中 random() 函数返回的 long 转换为 Go 中的 int 下面的 2 个 Go 函数 Random() 和 Seed() 分别调用了 C 中的 C.random() 和 C.srandom()。 示例 3.2 c1.go package rand // #include import \"C\" func Random() int { return int(C.random()) } func Seed(i int) { C.srandom(C.uint(i)) } C 当中并没有明确的字符串类型，如果你想要将一个 string 类型的变量从 Go 转换到 C 时，可以使用 C.CString(s)；同样，可以使用 C.GoString(cs) 从 C 转换到 Go 中的 string 类型。 Go 的内存管理机制无法管理通过 C 代码分配的内存。 开发人员需要通过手动调用 C.free 来释放变量的内存： defer C.free(unsafe.Pointer(Cvariable)) 这一行最好紧跟在使用 C 代码创建某个变量之后，这样就不会忘记释放内存了。下面的代码展示了如何使用 cgo 创建变量、使用并释放其内存： 示例 3.3 c2.go package print // #include // #include import \"C\" import \"unsafe\" func Print(s string) { cs := C.CString(s) defer C.free(unsafe.Pointer(cs)) C.fputs(cs, (*C.FILE)(C.stdout)) } 构建 cgo 包 你可以在使用将会在第 9.5 节讲到的 Makefile 文件（因为我们使用了一个独立的包），除了使用变量 GOFILES 之外，还需要使用变量 CGOFILES 来列出需要使用 cgo 编译的文件列表。例如，示例 3.2 中的代码就可以使用包含以下内容的 Makefile 文件来编译，你可以使用 gomake 或 make： include $(GOROOT)/src/Make.inc TARG=rand CGOFILES=\\ c1.go\\ include $(GOROOT)/src/Make.pkg 3.9.2 与 C++ 进行交互 SWIG（简化封装器和接口生成器）支持在 Linux 系统下使用 Go 代码调用 C 或者 C++ 代码。这里有一些使用 SWIG 的注意事项： 编写需要封装的库的 SWIG 接口。 SWIG 会产生 C 的存根函数。 这些库可以使用 cgo 来调用。 相关的 Go 文件也可以被自动生成。 这类接口支持方法重载、多重继承以及使用 Go 代码实现 C++ 的抽象类。 目前使用 SWIG 存在的一个问题是它无法支持所有的 C++ 库，比如说它就无法解析 TObject.h。 链接 目录 上一节：Go 性能说明 下一部分：语言的核心结构与技术 "},"Go入门指南/04.1.html":{"url":"Go入门指南/04.1.html","title":"1","keywords":"","body":"4.1 文件名、关键字与标识符 Go 的源文件以 .go 为后缀名存储在计算机中，这些文件名均由小写字母组成，如 scanner.go 。如果文件名由多个部分组成，则使用下划线 _ 对它们进行分隔，如 scanner_test.go 。文件名不包含空格或其他特殊字符。 一个源文件可以包含任意多行的代码，Go 本身没有对源文件的大小进行限制。 你会发现在 Go 代码中的几乎所有东西都有一个名称或标识符。另外，Go 语言也是区分大小写的，这与 C 家族中的其它语言相同。有效的标识符必须以字符（可以使用任何 UTF-8 编码的字符或 _）开头，然后紧跟着 0 个或多个字符或 Unicode 数字，如：X56、group1、_x23、i、өԑ12。 以下是无效的标识符： 1ab（以数字开头） case（Go 语言的关键字） a+b（运算符是不允许的） _ 本身就是一个特殊的标识符，被称为空白标识符。它可以像其他标识符那样用于变量的声明或赋值（任何类型都可以赋值给它），但任何赋给这个标识符的值都将被抛弃，因此这些值不能在后续的代码中使用，也不可以使用这个标识符作为变量对其它变量进行赋值或运算。 在编码过程中，你可能会遇到没有名称的变量、类型或方法。虽然这不是必须的，但有时候这样做可以极大地增强代码的灵活性，这些变量被统称为匿名变量。 下面列举了 Go 代码中会使用到的 25 个关键字或保留字： break default func interface select case defer go map struct chan else goto package switch const fallthrough if range type continue for import return var 之所以刻意地将 Go 代码中的关键字保持的这么少，是为了简化在编译过程第一步中的代码解析。和其它语言一样，关键字不能够作标识符使用。 除了以上介绍的这些关键字，Go 语言还有 36 个预定义标识符，其中包含了基本类型的名称和一些基本的内置函数（第 6.5 节），它们的作用都将在接下来的章节中进行进一步地讲解。 append bool byte cap close complex complex64 complex128 uint16 copy false float32 float64 imag int int8 int16 uint32 int32 int64 iota len make new nil panic uint64 print println real recover string true uint uint8 uintptr 程序一般由关键字、常量、变量、运算符、类型和函数组成。 程序中可能会使用到这些分隔符：括号 ()，中括号 [] 和大括号 {}。 程序中可能会使用到这些标点符号：.、,、;、: 和 …。 程序的代码通过语句来实现结构化。每个语句不需要像 C 家族中的其它语言一样以分号 ; 结尾，因为这些工作都将由 Go 编译器自动完成。 如果你打算将多个语句写在同一行，它们则必须使用 ; 人为区分，但在实际开发中我们并不鼓励这种做法。 链接 目录 上一部分：与其它语言进行交互 下一节：Go 程序的基本结构和要素 "},"Go入门指南/04.2.html":{"url":"Go入门指南/04.2.html","title":"2","keywords":"","body":"4.2 Go 程序的基本结构和要素 示例 4.1 hello_world.go package main import \"fmt\" func main() { fmt.Println(\"hello, world\") } 4.2.1 包的概念、导入与可见性 包是结构化代码的一种方式：每个程序都由包（通常简称为 pkg）的概念组成，可以使用自身的包或者从其它包中导入内容。 如同其它一些编程语言中的类库或命名空间的概念，每个 Go 文件都属于且仅属于一个包。一个包可以由许多以 .go 为扩展名的源文件组成，因此文件名和包名一般来说都是不相同的。 你必须在源文件中非注释的第一行指明这个文件属于哪个包，如：package main。package main表示一个可独立执行的程序，每个 Go 应用程序都包含一个名为 main 的包。 一个应用程序可以包含不同的包，而且即使你只使用 main 包也不必把所有的代码都写在一个巨大的文件里：你可以用一些较小的文件，并且在每个文件非注释的第一行都使用 package main 来指明这些文件都属于 main 包。如果你打算编译包名不是为 main 的源文件，如 pack1，编译后产生的对象文件将会是 pack1.a 而不是可执行程序。另外要注意的是，所有的包名都应该使用小写字母。 标准库 在 Go 的安装文件里包含了一些可以直接使用的包，即标准库。在 Windows 下，标准库的位置在 Go 根目录下的子目录 pkg\\windows_386 中；在 Linux 下，标准库在 Go 根目录下的子目录 pkg\\linux_amd64 中（如果是安装的是 32 位，则在 linux_386 目录中）。一般情况下，标准包会存放在 $GOROOT/pkg/$GOOS_$GOARCH/ 目录下。 Go 的标准库包含了大量的包（如：fmt 和 os），但是你也可以创建自己的包（第 8 章）。 如果想要构建一个程序，则包和包内的文件都必须以正确的顺序进行编译。包的依赖关系决定了其构建顺序。 属于同一个包的源文件必须全部被一起编译，一个包即是编译时的一个单元，因此根据惯例，每个目录都只包含一个包。 如果对一个包进行更改或重新编译，所有引用了这个包的客户端程序都必须全部重新编译。 Go 中的包模型采用了显式依赖关系的机制来达到快速编译的目的，编译器会从后缀名为 .o 的对象文件（需要且只需要这个文件）中提取传递依赖类型的信息。 如果 A.go 依赖 B.go，而 B.go 又依赖 C.go： 编译 C.go, B.go, 然后是 A.go. 为了编译 A.go, 编译器读取的是 B.o 而不是 C.o. 这种机制对于编译大型的项目时可以显著地提升编译速度。 每一段代码只会被编译一次 一个 Go 程序是通过 import 关键字将一组包链接在一起。 import \"fmt\" 告诉 Go 编译器这个程序需要使用 fmt 包（的函数，或其他元素），fmt 包实现了格式化 IO（输入/输出）的函数。包名被封闭在半角双引号 \"\" 中。如果你打算从已编译的包中导入并加载公开声明的方法，不需要插入已编译包的源代码。 如果需要多个包，它们可以被分别导入： import \"fmt\" import \"os\" 或： import \"fmt\"; import \"os\" 但是还有更短且更优雅的方法（被称为因式分解关键字，该方法同样适用于 const、var 和 type 的声明或定义）： import ( \"fmt\" \"os\" ) 它甚至还可以更短的形式，但使用 gofmt 后将会被强制换行： import (\"fmt\"; \"os\") 当你导入多个包时，最好按照字母顺序排列包名，这样做更加清晰易读。 如果包名不是以 . 或 / 开头，如 \"fmt\" 或者 \"container/list\"，则 Go 会在全局文件进行查找；如果包名以 ./ 开头，则 Go 会在相对目录中查找；如果包名以 / 开头（在 Windows 下也可以这样使用），则会在系统的绝对路径中查找。 导入包即等同于包含了这个包的所有的代码对象。 除了符号 _，包中所有代码对象的标识符必须是唯一的，以避免名称冲突。但是相同的标识符可以在不同的包中使用，因为可以使用包名来区分它们。 包通过下面这个被编译器强制执行的规则来决定是否将自身的代码对象暴露给外部文件： 可见性规则 当标识符（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，如：Group1，那么使用这种形式的标识符的对象就可以被外部包的代码所使用（客户端程序需要先导入这个包），这被称为导出（像面向对象语言中的 public）；标识符如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用的（像面向对象语言中的 private ）。 （大写字母可以使用任何 Unicode 编码的字符，比如希腊文，不仅仅是 ASCII 码中的大写字母）。 因此，在导入一个外部包后，能够且只能够访问该包中导出的对象。 假设在包 pack1 中我们有一个变量或函数叫做 Thing（以 T 开头，所以它能够被导出），那么在当前包中导入 pack1 包，Thing 就可以像面向对象语言那样使用点标记来调用：pack1.Thing（pack1 在这里是不可以省略的）。 因此包也可以作为命名空间使用，帮助避免命名冲突（名称冲突）：两个包中的同名变量的区别在于他们的包名，例如 pack1.Thing 和 pack2.Thing。 你可以通过使用包的别名来解决包名之间的名称冲突，或者说根据你的个人喜好对包名进行重新设置，如：import fm \"fmt\"。下面的代码展示了如何使用包的别名： 示例 4.2 alias.go package main import fm \"fmt\" // alias3 func main() { fm.Println(\"hello, world\") } 注意事项 如果你导入了一个包却没有使用它，则会在构建程序时引发错误，如 imported and not used: os，这正是遵循了 Go 的格言：“没有不必要的代码！“。 包的分级声明和初始化 你可以在使用 import 导入包之后定义或声明 0 个或多个常量（const）、变量（var）和类型（type），这些对象的作用域都是全局的（在本包范围内），所以可以被本包中所有的函数调用（如 gotemplate.go 源文件中的 c 和 v），然后声明一个或多个函数（func）。 4.2.2 函数 这是定义一个函数最简单的格式： func functionName() 你可以在括号 () 中写入 0 个或多个函数的参数（使用逗号 , 分隔），每个参数的名称后面必须紧跟着该参数的类型。 main 函数是每一个可执行程序所必须包含的，一般来说都是在启动后第一个执行的函数（如果有 init() 函数则会先执行该函数）。如果你的 main 包的源代码没有包含 main 函数，则会引发构建错误 undefined: main.main。main 函数既没有参数，也没有返回类型（与 C 家族中的其它语言恰好相反）。如果你不小心为 main 函数添加了参数或者返回类型，将会引发构建错误： func main must have no arguments and no return values results. 在程序开始执行并完成初始化后，第一个调用（程序的入口点）的函数是 main.main()（如：C 语言），该函数一旦返回就表示程序已成功执行并立即退出。 函数里的代码（函数体）使用大括号 {} 括起来。 左大括号 { 必须与方法的声明放在同一行，这是编译器的强制规定，否则你在使用 gofmt 时就会出现错误提示： `build-error: syntax error: unexpected semicolon or newline before {` （这是因为编译器会产生 func main() ; 这样的结果，很明显这错误的） Go 语言虽然看起来不使用分号作为语句的结束，但实际上这一过程是由编译器自动完成，因此才会引发像上面这样的错误 右大括号 } 需要被放在紧接着函数体的下一行。如果你的函数非常简短，你也可以将它们放在同一行： func Sum(a, b int) int { return a + b } 对于大括号 {} 的使用规则在任何时候都是相同的（如：if 语句等）。 因此符合规范的函数一般写成如下的形式： func functionName(parameter_list) (return_value_list) { … } 其中： parameter_list 的形式为 (param1 type1, param2 type2, …) return_value_list 的形式为 (ret1 type1, ret2 type2, …) 只有当某个函数需要被外部包调用的时候才使用大写字母开头，并遵循 Pascal 命名法；否则就遵循骆驼命名法，即第一个单词的首字母小写，其余单词的首字母大写。 下面这一行调用了 fmt 包中的 Println 函数，可以将字符串输出到控制台，并在最后自动增加换行字符 \\n： fmt.Println（\"hello, world\"） 使用 fmt.Print(\"hello, world\\n\") 可以得到相同的结果。 Print 和 Println 这两个函数也支持使用变量，如：fmt.Println(arr)。如果没有特别指定，它们会以默认的打印格式将变量 arr 输出到控制台。 单纯地打印一个字符串或变量甚至可以使用预定义的方法来实现，如：print、println：print(\"ABC\")、println(\"ABC\")、println(i)（带一个变量 i）。 这些函数只可以用于调试阶段，在部署程序的时候务必将它们替换成 fmt 中的相关函数。 当被调用函数的代码执行到结束符 } 或返回语句时就会返回，然后程序继续执行调用该函数之后的代码。 程序正常退出的代码为 0 即 Program exited with code 0；如果程序因为异常而被终止，则会返回非零值，如：1。这个数值可以用来测试是否成功执行一个程序。 4.2.3 注释 示例 4.2 hello_world2.go package main import \"fmt\" // Package implementing formatted I/O. func main() { fmt.Printf(\"Καλημέρα κόσμε; or こんにちは 世界\\n\") } 上面这个例子通过打印 Καλημέρα κόσμε; or こんにちは 世界 展示了如何在 Go 中使用国际化字符，以及如何使用注释。 注释不会被编译，但可以通过 godoc 来使用（第 3.6 节）。 单行注释是最常见的注释形式，你可以在任何地方使用以 // 开头的单行注释。多行注释也叫块注释，均已以 /* 开头，并以 */ 结尾，且不可以嵌套使用，多行注释一般用于包的文档描述或注释成块的代码片段。 每一个包应该有相关注释，在 package 语句之前的块注释将被默认认为是这个包的文档说明，其中应该提供一些相关信息并对整体功能做简要的介绍。一个包可以分散在多个文件中，但是只需要在其中一个进行注释说明即可。当开发人员需要了解包的一些情况时，自然会用 godoc 来显示包的文档说明，在首行的简要注释之后可以用成段的注释来进行更详细的说明，而不必拥挤在一起。另外，在多段注释之间应以空行分隔加以区分。 示例： // Package superman implements methods for saving the world. // // Experience has shown that a small number of procedures can prove // helpful when attempting to save the world. package superman 几乎所有全局作用域的类型、常量、变量、函数和被导出的对象都应该有一个合理的注释。如果这种注释（称为文档注释）出现在函数前面，例如函数 Abcd，则要以 \"Abcd...\" 作为开头。 示例： // enterOrbit causes Superman to fly into low Earth orbit, a position // that presents several possibilities for planet salvation. func enterOrbit() error { ... } godoc 工具（第 3.6 节）会收集这些注释并产生一个技术文档。 4.2.4 类型 可以包含数据的变量（或常量），可以使用不同的数据类型或类型来保存数据。使用 var 声明的变量的值会自动初始化为该类型的零值。类型定义了某个变量的值的集合与可对其进行操作的集合。 类型可以是基本类型，如：int、float、bool、string；结构化的（复合的），如：struct、array、slice、map、channel；只描述类型的行为的，如：interface。 结构化的类型没有真正的值，它使用 nil 作为默认值（在 Objective-C 中是 nil，在 Java 中是 null，在 C 和 C++ 中是NULL或 0）。值得注意的是，Go 语言中不存在类型继承。 函数也可以是一个确定的类型，就是以函数作为返回类型。这种类型的声明要写在函数名和可选的参数列表之后，例如： func FunctionName (a typea, b typeb) typeFunc 你可以在函数体中的某处返回使用类型为 typeFunc 的变量 var： return var 一个函数可以拥有多返回值，返回类型之间需要使用逗号分割，并使用小括号 () 将它们括起来，如： func FunctionName (a typea, b typeb) (t1 type1, t2 type2) 示例： 函数 Atoi (第 4.7 节)：func Atoi(s string) (i int, err error) 返回的形式： return var1, var2 这种多返回值一般用于判断某个函数是否执行成功（true/false）或与其它返回值一同返回错误消息（详见之后的并行赋值）。 使用 type 关键字可以定义你自己的类型，你可能想要定义一个结构体(第 10 章)，但是也可以定义一个已经存在的类型的别名，如： type IZ int 这里并不是真正意义上的别名，因为使用这种方法定义之后的类型可以拥有更多的特性，且在类型转换时必须显式转换。 然后我们可以使用下面的方式声明变量： var a IZ = 5 这里我们可以看到 int 是变量 a 的底层类型，这也使得它们之间存在相互转换的可能（第 4.2.6 节）。 如果你有多个类型需要定义，可以使用因式分解关键字的方式，例如： type ( IZ int FZ float64 STR string ) 每个值都必须在经过编译后属于某个类型（编译器必须能够推断出所有值的类型），因为 Go 语言是一种静态类型语言。 4.2.5 Go 程序的一般结构 下面的程序可以被顺利编译但什么都做不了，不过这很好地展示了一个 Go 程序的首选结构。这种结构并没有被强制要求，编译器也不关心 main 函数在前还是变量的声明在前，但使用统一的结构能够在从上至下阅读 Go 代码时有更好的体验。 所有的结构将在这一章或接下来的章节中进一步地解释说明，但总体思路如下： 在完成包的 import 之后，开始对常量、变量和类型的定义或声明。 如果存在 init 函数的话，则对该函数进行定义（这是一个特殊的函数，每个含有该函数的包都会首先执行这个函数）。 如果当前包是 main 包，则定义 main 函数。 然后定义其余的函数，首先是类型的方法，接着是按照 main 函数中先后调用的顺序来定义相关函数，如果有很多函数，则可以按照字母顺序来进行排序。 示例 4.4 gotemplate.go package main import ( \"fmt\" ) const c = \"C\" var v int = 5 type T struct{} func init() { // initialization of package } func main() { var a int Func1() // ... fmt.Println(a) } func (t T) Method1() { //... } func Func1() { // exported function Func1 //... } Go 程序的执行（程序启动）顺序如下： 按顺序导入所有被 main 包引用的其它包，然后在每个包中执行如下流程： 如果该包又导入了其它的包，则从第一步开始递归执行，但是每个包只会被导入一次。 然后以相反的顺序在每个包中初始化常量和变量，如果该包含有 init 函数的话，则调用该函数。 在完成这一切之后，main 也执行同样的过程，最后调用 main 函数开始执行程序。 4.2.6 类型转换 在必要以及可行的情况下，一个类型的值可以被转换成另一种类型的值。由于 Go 语言不存在隐式类型转换，因此所有的转换都必须显式说明，就像调用一个函数一样（类型在这里的作用可以看作是一种函数）： valueOfTypeB = typeB(valueOfTypeA) 类型 B 的值 = 类型 B(类型 A 的值) 示例： a := 5.0 b := int(a) 但这只能在定义正确的情况下转换成功，例如从一个取值范围较小的类型转换到一个取值范围较大的类型（例如将 int16 转换为 int32）。当从一个取值范围较大的转换到取值范围较小的类型时（例如将 int32 转换为 int16 或将 float32 转换为 int），会发生精度丢失（截断）的情况。当编译器捕捉到非法的类型转换时会引发编译时错误，否则将引发运行时错误。 具有相同底层类型的变量之间可以相互转换： var a IZ = 5 c := int(a) d := IZ(c) 4.2.7 Go 命名规范 干净、可读的代码和简洁性是 Go 追求的主要目标。通过 gofmt 来强制实现统一的代码风格。Go 语言中对象的命名也应该是简洁且有意义的。像 Java 和 Python 中那样使用混合着大小写和下划线的冗长的名称会严重降低代码的可读性。名称不需要指出自己所属的包，因为在调用的时候会使用包名作为限定符。返回某个对象的函数或方法的名称一般都是使用名词，没有 Get... 之类的字符，如果是用于修改某个对象，则使用 SetName。有必须要的话可以使用大小写混合的方式，如 MixedCaps 或 mixedCaps，而不是使用下划线来分割多个名称。 链接 目录 上一节：文件名、关键字与标识符 下一节：常量 "},"Go入门指南/04.3.html":{"url":"Go入门指南/04.3.html","title":"3","keywords":"","body":"4.3 常量 常量使用关键字 const 定义，用于存储不会改变的数据。 存储在常量中的数据类型只可以是布尔型、数字型（整数型、浮点型和复数）和字符串型。 常量的定义格式：const identifier [type] = value，例如： const Pi = 3.14159 在 Go 语言中，你可以省略类型说明符 [type]，因为编译器可以根据变量的值来推断其类型。 显式类型定义： const b string = \"abc\" 隐式类型定义： const b = \"abc\" 一个没有指定类型的常量被使用时，会根据其使用环境而推断出它所需要具备的类型。换句话说，未定义类型的常量会在必要时刻根据上下文来获得相关类型。 var n int f(n + 5) // 无类型的数字型常量 “5” 它的类型在这里变成了 int 常量的值必须是能够在编译时就能够确定的；你可以在其赋值表达式中涉及计算过程，但是所有用于计算的值必须在编译期间就能获得。 正确的做法：const c1 = 2/3 错误的做法：const c2 = getNumber() // 引发构建错误: getNumber() used as value 因为在编译期间自定义函数均属于未知，因此无法用于常量的赋值，但内置函数可以使用，如：len()。 数字型的常量是没有大小和符号的，并且可以使用任何精度而不会导致溢出： const Ln2= 0.693147180559945309417232121458\\ 176568075500134360255254120680009 const Log2E= 1/Ln2 // this is a precise reciprocal const Billion = 1e9 // float constant const hardEight = (1 > 97 根据上面的例子我们可以看到，反斜杠 \\ 可以在常量表达式中作为多行的连接符使用。 与各种类型的数字型变量相比，你无需担心常量之间的类型转换问题，因为它们都是非常理想的数字。 不过需要注意的是，当常量赋值给一个精度过小的数字型变量时，可能会因为无法正确表达常量所代表的数值而导致溢出，这会在编译期间就引发错误。另外，常量也允许使用并行赋值的形式： const beef, two, c = \"eat\", 2, \"veg\" const Monday, Tuesday, Wednesday, Thursday, Friday, Saturday = 1, 2, 3, 4, 5, 6 const ( Monday, Tuesday, Wednesday = 1, 2, 3 Thursday, Friday, Saturday = 4, 5, 6 ) 常量还可以用作枚举： const ( Unknown = 0 Female = 1 Male = 2 ) 现在，数字 0、1 和 2 分别代表未知性别、女性和男性。这些枚举值可以用于测试某个变量或常量的实际值，比如使用 switch/case 结构 (第 5.3 节). 在这个例子中，iota 可以被用作枚举值： const ( a = iota b = iota c = iota ) 第一个 iota 等于 0，每当 iota 在新的一行被使用时，它的值都会自动加 1；所以 a=0, b=1, c=2 可以简写为如下形式： const ( a = iota b c ) （ 译者注：关于 iota 的使用涉及到非常复杂多样的情况，这里作者解释的并不清晰，因为很难对 iota 的用法进行直观的文字描述。如希望进一步了解，请观看视频教程 《Go编程基础》 第四课：常量与运算符 ） iota 也可以用在表达式中，如：iota + 50。在每遇到一个新的常量块或单个常量声明时， iota 都会重置为 0（ 简单地讲，每遇到一次 const 关键字，iota 就重置为 0 ）。 当然，常量之所以为常量就是恒定不变的量，因此我们无法在程序运行过程中修改它的值；如果你在代码中试图修改常量的值则会引发编译错误。 引用 time 包中的一段代码作为示例：一周中每天的名称。 const ( Sunday = iota Monday Tuesday Wednesday Thursday Friday Saturday ) 你也可以使用某个类型作为枚举常量的类型： type Color int const ( RED Color = iota // 0 ORANGE // 1 YELLOW // 2 GREEN // .. BLUE INDIGO VIOLET // 6 ) 链接 目录 上一节：Go 程序的基本结构和要素 下一节：变量 "},"Go入门指南/04.4.html":{"url":"Go入门指南/04.4.html","title":"4","keywords":"","body":"4.4 变量 4.4.1 简介 声明变量的一般形式是使用 var 关键字：var identifier type。 需要注意的是，Go 和许多编程语言不同，它在声明变量时将变量的类型放在变量的名称之后。Go 为什么要选择这么做呢？ 首先，它是为了避免像 C 语言中那样含糊不清的声明形式，例如：int* a, b;。在这个例子中，只有 a 是指针而 b 不是。如果你想要这两个变量都是指针，则需要将它们分开书写（你可以在 Go 语言的声明语法 页面找到有关于这个话题的更多讨论）。 而在 Go 中，则可以很轻松地将它们都声明为指针类型： var a, b *int 其次，这种语法能够按照从左至右的顺序阅读，使得代码更加容易理解。 示例： var a int var b bool var str string 你也可以改写成这种形式： var ( a int b bool str string ) 这种因式分解关键字的写法一般用于声明全局变量。 当一个变量被声明之后，系统自动赋予它该类型的零值：int 为 0，float 为 0.0，bool 为 false，string 为空字符串，指针为 nil。记住，所有的内存在 Go 中都是经过初始化的。 变量的命名规则遵循骆驼命名法，即首个单词小写，每个新单词的首字母大写，例如：numShips 和 startDate。 但如果你的全局变量希望能够被外部包所使用，则需要将首个单词的首字母也大写（第 4.2 节：可见性规则）。 一个变量（常量、类型或函数）在程序中都有一定的作用范围，称之为作用域。如果一个变量在函数体外声明，则被认为是全局变量，可以在整个包甚至外部包（被导出后）使用，不管你声明在哪个源文件里或在哪个源文件里调用该变量。 在函数体内声明的变量称之为局部变量，它们的作用域只在函数体内，参数和返回值变量也是局部变量。在第 5 章，我们将会学习到像 if 和 for 这些控制结构，而在这些结构中声明的变量的作用域只在相应的代码块内。一般情况下，局部变量的作用域可以通过代码块（用大括号括起来的部分）判断。 尽管变量的标识符必须是唯一的，但你可以在某个代码块的内层代码块中使用相同名称的变量，则此时外部的同名变量将会暂时隐藏（结束内部代码块的执行后隐藏的外部同名变量又会出现，而内部同名变量则被释放），你任何的操作都只会影响内部代码块的局部变量。 变量可以编译期间就被赋值，赋值给变量使用运算符等号 =，当然你也可以在运行时对变量进行赋值操作。 示例： a = 15 b = false 一般情况下，当变量a和变量b之间类型相同时，才能进行如a = b的赋值。 声明与赋值（初始化）语句也可以组合起来。 示例： var identifier [type] = value var a int = 15 var i = 5 var b bool = false var str string = \"Go says hello to the world!\" 但是 Go 编译器的智商已经高到可以根据变量的值来自动推断其类型，这有点像 Ruby 和 Python 这类动态语言，只不过它们是在运行时进行推断，而 Go 是在编译时就已经完成推断过程。因此，你还可以使用下面的这些形式来声明及初始化变量： var a = 15 var b = false var str = \"Go says hello to the world!\" 或： var ( a = 15 b = false str = \"Go says hello to the world!\" numShips = 50 city string ) 不过自动推断类型并不是任何时候都适用的，当你想要给变量的类型并不是自动推断出的某种类型时，你还是需要显式指定变量的类型，例如： var n int64 = 2 然而，var a 这种语法是不正确的，因为编译器没有任何可以用于自动推断类型的依据。变量的类型也可以在运行时实现自动推断，例如： var ( HOME = os.Getenv(\"HOME\") USER = os.Getenv(\"USER\") GOROOT = os.Getenv(\"GOROOT\") ) 这种写法主要用于声明包级别的全局变量，当你在函数体内声明局部变量时，应使用简短声明语法 :=，例如： a := 1 下面这个例子展示了如何通过runtime包在运行时获取所在的操作系统类型，以及如何通过 os 包中的函数 os.Getenv() 来获取环境变量中的值，并保存到 string 类型的局部变量 path 中。 示例 4.5 goos.go package main import ( \"fmt\" \"runtime\" \"os\" ) func main() { var goos string = runtime.GOOS fmt.Printf(\"The operating system is: %s\\n\", goos) path := os.Getenv(\"PATH\") fmt.Printf(\"Path is %s\\n\", path) } 如果你在 Windows 下运行这段代码，则会输出 The operating system is: windows 以及相应的环境变量的值；如果你在 Linux 下运行这段代码，则会输出 The operating system is: linux 以及相应的的环境变量的值。 这里用到了 Printf 的格式化输出的功能（第 4.4.3 节）。 4.4.2 值类型和引用类型 程序中所用到的内存在计算机中使用一堆箱子来表示（这也是人们在讲解它的时候的画法），这些箱子被称为 “ 字 ”。根据不同的处理器以及操作系统类型，所有的字都具有 32 位（4 字节）或 64 位（8 字节）的相同长度；所有的字都使用相关的内存地址来进行表示（以十六进制数表示）。 所有像 int、float、bool 和 string 这些基本类型都属于值类型，使用这些类型的变量直接指向存在内存中的值： 另外，像数组（第 7 章）和结构（第 10 章）这些复合类型也是值类型。 当使用等号 = 将一个变量的值赋值给另一个变量时，如：j = i，实际上是在内存中将 i 的值进行了拷贝： 你可以通过 &i 来获取变量 i 的内存地址（第 4.9 节），例如：0xf840000040（每次的地址都可能不一样）。值类型的变量的值存储在栈中。 内存地址会根据机器的不同而有所不同，甚至相同的程序在不同的机器上执行后也会有不同的内存地址。因为每台机器可能有不同的存储器布局，并且位置分配也可能不同。 更复杂的数据通常会需要使用多个字，这些数据一般使用引用类型保存。 一个引用类型的变量 r1 存储的是 r1 的值所在的内存地址（数字），或内存地址中第一个字所在的位置。 这个内存地址被称之为指针（你可以从上图中很清晰地看到，第 4.9 节将会详细说明），这个指针实际上也被存在另外的某一个字中。 同一个引用类型的指针指向的多个字可以是在连续的内存地址中（内存布局是连续的），这也是计算效率最高的一种存储形式；也可以将这些字分散存放在内存中，每个字都指示了下一个字所在的内存地址。 当使用赋值语句 r2 = r1 时，只有引用（地址）被复制。 如果 r1 的值被改变了，那么这个值的所有引用都会指向被修改后的内容，在这个例子中，r2 也会受到影响。 在 Go 语言中，指针（第 4.9 节）属于引用类型，其它的引用类型还包括 slices（第 7 章），maps（第 8 章）和 channel（第 13 章）。被引用的变量会存储在堆中，以便进行垃圾回收，且比栈拥有更大的内存空间。 4.4.3 打印 函数 Printf 可以在 fmt 包外部使用，这是因为它以大写字母 P 开头，该函数主要用于打印输出到控制台。通常使用的格式化字符串作为第一个参数： func Printf(format string, list of variables to be printed) 在示例 4.5 中，格式化字符串为：\"The operating system is: %s\\n\"。 这个格式化字符串可以含有一个或多个的格式化标识符，例如：%..，其中 .. 可以被不同类型所对应的标识符替换，如 %s 代表字符串标识符、%v 代表使用类型的默认输出格式的标识符。这些标识符所对应的值从格式化字符串后的第一个逗号开始按照相同顺序添加，如果参数超过 1 个则同样需要使用逗号分隔。使用这些占位符可以很好地控制格式化输出的文本。 函数 fmt.Sprintf 与 Printf 的作用是完全相同的，不过前者将格式化后的字符串以返回值的形式返回给调用者，因此你可以在程序中使用包含变量的字符串，具体例子可以参见示例 15.4 simple_tcp_server.go。 函数 fmt.Print 和 fmt.Println 会自动使用格式化标识符 %v 对字符串进行格式化，两者都会在每个参数之间自动增加空格，而后者还会在字符串的最后加上一个换行符。例如： fmt.Print(\"Hello:\", 23) 将输出：Hello: 23。 4.4.4 简短形式，使用 := 赋值操作符 我们知道可以在变量的初始化时省略变量的类型而由系统自动推断，而这个时候再在 Example 4.4.1 的最后一个声明语句写上 var 关键字就显得有些多余了，因此我们可以将它们简写为 a := 50 或 b := false。 a 和 b 的类型（int 和 bool）将由编译器自动推断。 这是使用变量的首选形式，但是它只能被用在函数体内，而不可以用于全局变量的声明与赋值。使用操作符 := 可以高效地创建一个新的变量，称之为初始化声明。 注意事项 如果在相同的代码块中，我们不可以再次对于相同名称的变量使用初始化声明，例如：a := 20 就是不被允许的，编译器会提示错误 no new variables on left side of :=，但是 a = 20 是可以的，因为这是给相同的变量赋予一个新的值。 如果你在定义变量 a 之前使用它，则会得到编译错误 undefined: a。 如果你声明了一个局部变量却没有在相同的代码块中使用它，同样会得到编译错误，例如下面这个例子当中的变量 a： func main() { var a string = \"abc\" fmt.Println(\"hello, world\") } 尝试编译这段代码将得到错误 a declared and not used。 此外，单纯地给 a 赋值也是不够的，这个值必须被使用，所以使用 fmt.Println(\"hello, world\", a) 会移除错误。 但是全局变量是允许声明但不使用。 其他的简短形式为： 同一类型的多个变量可以声明在同一行，如： var a, b, c int (这是将类型写在标识符后面的一个重要原因) 多变量可以在同一行进行赋值，如： a, b, c = 5, 7, \"abc\" 上面这行假设了变量 a，b 和 c 都已经被声明，否则的话应该这样使用： a, b, c := 5, 7, \"abc\" 右边的这些值以相同的顺序赋值给左边的变量，所以 a 的值是 5， b 的值是 7，c 的值是 \"abc\"。 这被称为 并行 或 同时 赋值。 如果你想要交换两个变量的值，则可以简单地使用 a, b = b, a。 (在 Go 语言中，这样省去了使用交换函数的必要) 空白标识符 _ 也被用于抛弃值，如值 5 在：_, b = 5, 7 中被抛弃。 _ 实际上是一个只写变量，你不能得到它的值。这样做是因为 Go 语言中你必须使用所有被声明的变量，但有时你并不需要使用从一个函数得到的所有返回值。 并行赋值也被用于当一个函数返回多个返回值时，比如这里的 val 和错误 err 是通过调用 Func1 函数同时得到：val, err = Func1(var1)。 4.4.5 init 函数 变量除了可以在全局声明中初始化，也可以在 init 函数中初始化。这是一类非常特殊的函数，它不能够被人为调用，而是在每个包完成初始化后自动执行，并且执行优先级比 main 函数高。 每个源文件都只能包含一个 init 函数。初始化总是以单线程执行，并且按照包的依赖关系顺序执行。 一个可能的用途是在开始执行程序之前对数据进行检验或修复，以保证程序状态的正确性。 示例 4.6 init.go: package trans import \"math\" var Pi float64 func init() { Pi = 4 * math.Atan(1) // init() function computes Pi } 在它的 init 函数中计算变量 Pi 的初始值。 示例 4.7 user_init.go 中导入了包 trans（需要init.go目录为./trans/init.go）并且使用到了变量 Pi： package main import ( \"fmt\" \"./trans\" ) var twoPi = 2 * trans.Pi func main() { fmt.Printf(\"2*Pi = %g\\n\", twoPi) // 2*Pi = 6.283185307179586 } init 函数也经常被用在当一个程序开始之前调用后台执行的 goroutine，如下面这个例子当中的 backend()： func init() { // setup preparations go backend() } 练习 推断以下程序的输出，并解释你的答案，然后编译并执行它们。 练习 4.1 local_scope.go: package main var a = \"G\" func main() { n() m() n() } func n() { print(a) } func m() { a := \"O\" print(a) } 练习 4.2 global_scope.go: package main var a = \"G\" func main() { n() m() n() } func n() { print(a) } func m() { a = \"O\" print(a) } 练习 4.3 function_calls_function.go package main var a string func main() { a = \"G\" print(a) f1() } func f1() { a := \"O\" print(a) f2() } func f2() { print(a) } 链接 目录 上一节：常量 下一节：基本类型和运算符 "},"Go入门指南/04.5.html":{"url":"Go入门指南/04.5.html","title":"5","keywords":"","body":"4.5 基本类型和运算符 我们将在这个部分讲解有关布尔型、数字型和字符型的相关知识。 表达式是一种特定的类型的值，它可以由其它的值以及运算符组合而成。每个类型都定义了可以和自己结合的运算符集合，如果你使用了不在这个集合中的运算符，则会在编译时获得编译错误。 一元运算符只可以用于一个值的操作（作为后缀），而二元运算符则可以和两个值或者操作数结合（作为中缀）。 只有两个类型相同的值才可以和二元运算符结合，另外要注意的是，Go 是强类型语言，因此不会进行隐式转换，任何不同类型之间的转换都必须显式说明（第 4.2 节）。Go 不存在像 C 和 Java 那样的运算符重载，表达式的解析顺序是从左至右。 你可以在第 4.5.3 节找到有关运算符优先级的相关信息，优先级越高的运算符在条件相同的情况下将被优先执行。但是你可以通过使用括号将其中的表达式括起来，以人为地提升某个表达式的运算优先级。 4.5.1 布尔类型 bool 一个简单的例子：var b bool = true。 布尔型的值只可以是常量 true 或者 false。 两个类型相同的值可以使用相等 == 或者不等 != 运算符来进行比较并获得一个布尔型的值。 当相等运算符两边的值是完全相同的值的时候会返回 true，否则返回 false，并且只有在两个的值的类型相同的情况下才可以使用。 示例： var aVar = 10 aVar == 5 -> false aVar == 10 -> true 当不等运算符两边的值是不同的时候会返回 true，否则返回 false。 示例： var aVar = 10 aVar != 5 -> true aVar != 10 -> false Go 对于值之间的比较有非常严格的限制，只有两个类型相同的值才可以进行比较，如果值的类型是接口（interface，第 11 章），它们也必须都实现了相同的接口。如果其中一个值是常量，那么另外一个值的类型必须和该常量类型相兼容的。如果以上条件都不满足，则其中一个值的类型必须在被转换为和另外一个值的类型相同之后才可以进行比较。 布尔型的常量和变量也可以通过和逻辑运算符（非 !、和 &&、或 ||）结合来产生另外一个布尔值，这样的逻辑语句就其本身而言，并不是一个完整的 Go 语句。 逻辑值可以被用于条件结构中的条件语句（第 5 章），以便测试某个条件是否满足。另外，和 &&、或 || 与相等 == 或不等 != 属于二元运算符，而非 ! 属于一元运算符。在接下来的内容中，我们会使用 T 来代表条件符合的语句，用 F 来代表条件不符合的语句。 Go 语言中包含以下逻辑运算符： 非运算符：! !T -> false !F -> true 非运算符用于取得和布尔值相反的结果。 和运算符：&& T && T -> true T && F -> false F && T -> false F && F -> false 只有当两边的值都为 true 的时候，和运算符的结果才是 true。 或运算符：|| T || T -> true T || F -> true F || T -> true F || F -> false 只有当两边的值都为 false 的时候，或运算符的结果才是 false，其中任意一边的值为 true 就能够使得该表达式的结果为 true。 在 Go 语言中，&& 和 || 是具有快捷性质的运算符，当运算符左边表达式的值已经能够决定整个表达式的值的时候（&& 左边的值为 false，|| 左边的值为 true），运算符右边的表达式将不会被执行。利用这个性质，如果你有多个条件判断，应当将计算过程较为复杂的表达式放在运算符的右侧以减少不必要的运算。 利用括号同样可以升级某个表达式的运算优先级。 在格式化输出时，你可以使用 %t 来表示你要输出的值为布尔型。 布尔值（以及任何结果为布尔值的表达式）最常用在条件结构的条件语句中，例如：if、for 和 switch 结构（第 5 章）。 对于布尔值的好的命名能够很好地提升代码的可读性，例如以 is 或者 Is 开头的 isSorted、isFinished、isVisible，使用这样的命名能够在阅读代码的获得阅读正常语句一样的良好体验，例如标准库中的 unicode.IsDigit(ch)（第 4.5.5 节）。 4.5.2 数字类型 4.5.2.1 整型 int 和浮点型 float Go 语言支持整型和浮点型数字，并且原生支持复数，其中位的运算采用补码（详情参见 二的补码 页面）。 Go 也有基于架构的类型，例如：int、uint 和 uintptr。 这些类型的长度都是根据运行程序所在的操作系统类型所决定的： int 和 uint 在 32 位操作系统上，它们均使用 32 位（4 个字节），在 64 位操作系统上，它们均使用 64 位（8 个字节）。 uintptr 的长度被设定为足够存放一个指针即可。 Go 语言中没有 float 类型。 与操作系统架构无关的类型都有固定的大小，并在类型的名称中就可以看出来： 整数： int8（-128 -> 127） int16（-32768 -> 32767） int32（-2,147,483,648 -> 2,147,483,647） int64（-9,223,372,036,854,775,808 -> 9,223,372,036,854,775,807） 无符号整数： uint8（0 -> 255） uint16（0 -> 65,535） uint32（0 -> 4,294,967,295） uint64（0 -> 18,446,744,073,709,551,615） 浮点型（IEEE-754 标准）： float32（+- 1e-45 -> +- 3.4 * 1e38） float64（+- 5 1e-324 -> 107 1e308） int 型是计算最快的一种类型。 整型的零值为 0，浮点型的零值为 0.0。 float32 精确到小数点后 7 位，float64 精确到小数点后 15 位。由于精确度的缘故，你在使用 == 或者 != 来比较浮点数时应当非常小心。你最好在正式使用前测试对于精确度要求较高的运算。 你应该尽可能地使用 float64，因为 math 包中所有有关数学运算的函数都会要求接收这个类型。 你可以通过增加前缀 0 来表示 8 进制数（如：077），增加前缀 0x 来表示 16 进制数（如：0xFF），以及使用 e 来表示 10 的连乘（如： 1e3 = 1000，或者 6.022e23 = 6.022 x 1e23）。 你可以使用 a := uint64(0) 来同时完成类型转换和赋值操作，这样 a 的类型就是 uint64。 Go 中不允许不同类型之间的混合使用，但是对于常量的类型限制非常少，因此允许常量之间的混合使用，下面这个程序很好地解释了这个现象（该程序无法通过编译）： 示例 4.8 type_mixing.go package main func main() { var a int var b int32 a = 15 b = a + a // 编译错误 b = b + 5 // 因为 5 是常量，所以可以通过编译 } 如果你尝试编译该程序，则将得到编译错误 cannot use a + a (type int) as type int32 in assignment。 同样地，int16 也不能够被隐式转换为 int32。 下面这个程序展示了通过显式转换来避免这个问题（第 4.2 节）。 示例 4.9 casting.go package main import \"fmt\" func main() { var n int16 = 34 var m int32 // compiler error: cannot use n (type int16) as type int32 in assignment //m = n m = int32(n) fmt.Printf(\"32 bit int is: %d\\n\", m) fmt.Printf(\"16 bit int is: %d\\n\", n) } 输出： 32 bit int is: 34 16 bit int is: 34 格式化说明符 在格式化字符串里，%d 用于格式化整数（%x 和 %X 用于格式化 16 进制表示的数字），%g 用于格式化浮点型（%f 输出浮点数，%e 输出科学计数表示法），%0d 用于规定输出定长的整数，其中开头的数字 0 是必须的。 %n.mg 用于表示数字 n 并精确到小数点后 m 位，除了使用 g 之外，还可以使用 e 或者 f，例如：使用格式化字符串 %5.2e 来输出 3.4 的结果为 3.40e+00。 数字值转换 当进行类似 a32bitInt = int32(a32Float) 的转换时，小数点后的数字将被丢弃。这种情况一般发生当从取值范围较大的类型转换为取值范围较小的类型时，或者你可以写一个专门用于处理类型转换的函数来确保没有发生精度的丢失。下面这个例子展示如何安全地从 int 型转换为 int8： func Uint8FromInt(n int) (uint8, error) { if 0 或者安全地从 float64 转换为 int： func IntFromFloat64(x float64) int { if math.MinInt32 = 0.5 { whole++ } return int(whole) } panic(fmt.Sprintf(\"%g is out of the int32 range\", x)) } 不过如果你实际存的数字超出你要转换到的类型的取值范围的话，则会引发 panic（第 13.2 节）。 问题 4.1 int 和 int64 是相同的类型吗？ 4.5.2.2 复数 Go 拥有以下复数类型： complex64 (32 位实数和虚数) complex128 (64 位实数和虚数) 复数使用 re+imI 来表示，其中 re 代表实数部分，im 代表虚数部分，I 代表根号负 1。 示例： var c1 complex64 = 5 + 10i fmt.Printf(\"The value is: %v\", c1) // 输出： 5 + 10i 如果 re 和 im 的类型均为 float32，那么类型为 complex64 的复数 c 可以通过以下方式来获得： c = complex(re, im) 函数 real(c) 和 imag(c) 可以分别获得相应的实数和虚数部分。 在使用格式化说明符时，可以使用 %v 来表示复数，但当你希望只表示其中的一个部分的时候需要使用 %f。 复数支持和其它数字类型一样的运算。当你使用等号 == 或者不等号 != 对复数进行比较运算时，注意对精确度的把握。cmath 包中包含了一些操作复数的公共方法。如果你对内存的要求不是特别高，最好使用 complex128 作为计算类型，因为相关函数都使用这个类型的参数。 4.5.2.3 位运算 位运算只能用于整数类型的变量，且需当它们拥有等长位模式时。 %b 是用于表示位的格式化标识符。 二元运算符 按位与 &： 对应位置上的值经过和运算结果，具体参见和运算符，第 4.5.1 节，并将 T（true）替换为 1，将 F（false）替换为 0 1 & 1 -> 1 1 & 0 -> 0 0 & 1 -> 0 0 & 0 -> 0 按位或 |： 对应位置上的值经过或运算结果，具体参见或运算符，第 4.5.1 节，并将 T（true）替换为 1，将 F（false）替换为 0 1 | 1 -> 1 1 | 0 -> 1 0 | 1 -> 1 0 | 0 -> 0 按位异或 ^： 对应位置上的值根据以下规则组合： 1 ^ 1 -> 0 1 ^ 0 -> 1 0 ^ 1 -> 1 0 ^ 0 -> 0 位清除 &^：将指定位置上的值设置为 0。 一元运算符 按位补足 ^： 该运算符与异或运算符一同使用，即 m^x，对于无符号 x 使用“全部位设置为 1”，对于有符号 x 时使用 m=-1。例如： ^2 = ^10 = -01 ^ 10 = -11 位左移 ： 用法：bitP 。 bitP 的位向左移动 n 位，右侧空白部分使用 0 填充；如果 n 等于 2，则结果是 2 的相应倍数，即 2 的 n 次方。例如： 1 位右移 >>： 用法：bitP >> n。 bitP 的位向右移动 n 位，左侧空白部分使用 0 填充；如果 n 等于 2，则结果是当前值除以 2 的 n 次方。 当希望把结果赋值给第一个操作数时，可以简写为 a 或者 b ^= a & 0xffffffff。 位左移常见实现存储单位的用例 使用位左移与 iota 计数配合可优雅地实现存储单位的常量枚举： type ByteSize float64 const ( _ = iota // 通过赋值给空白标识符来忽略值 KB ByteSize = 1 在通讯中使用位左移表示标识的用例 type BitFlag int const ( Active BitFlag = 1 4.5.2.4 逻辑运算符 Go 中拥有以下逻辑运算符：==、!=（第 4.5.1 节）、、、>、>=。 它们之所以被称为逻辑运算符是因为它们的运算结果总是为布尔值 bool。例如： b3:= 10 > 5 // b3 is true 4.5.2.5 算术运算符 常见可用于整数和浮点数的二元运算符有 +、-、* 和 /。 （相对于一般规则而言，Go 在进行字符串拼接时允许使用对运算符 + 的重载，但 Go 本身不允许开发者进行自定义的运算符重载） / 对于整数运算而言，结果依旧为整数，例如：9 / 4 -> 2。 取余运算符只能作用于整数：9 % 4 -> 1。 整数除以 0 可能导致程序崩溃，将会导致运行时的恐慌状态（如果除以 0 的行为在编译时就能被捕捉到，则会引发编译错误）；第 13 章将会详细讲解如何正确地处理此类情况。 浮点数除以 0.0 会返回一个无穷尽的结果，使用 +Inf 表示。 练习 4.4 尝试编译 divby0.go。 你可以将语句 b = b + a 简写为 b+=a，同样的写法也可用于 -=、*=、/=、%=。 对于整数和浮点数，你可以使用一元运算符 ++（递增）和 --（递减），但只能用于后缀： i++ -> i += 1 -> i = i + 1 i-- -> i -= 1 -> i = i - 1 同时，带有 ++ 和 -- 的只能作为语句，而非表达式，因此 n = i++ 这种写法是无效的，其它像 f(i++) 或者 a[i]=b[i++] 这些可以用于 C、C++ 和 Java 中的写法在 Go 中也是不允许的。 在运算时 溢出 不会产生错误，Go 会简单地将超出位数抛弃。如果你需要范围无限大的整数或者有理数（意味着只被限制于计算机内存），你可以使用标准库中的 big 包，该包提供了类似 big.Int 和 big.Rat 这样的类型（第 9.4 节）。 4.5.2.6 随机数 一些像游戏或者统计学类的应用需要用到随机数。rand 包实现了伪随机数的生成。 示例 4.10 random.go 演示了如何生成 10 个非负随机数： package main import ( \"fmt\" \"math/rand\" \"time\" ) func main() { for i := 0; i 可能的输出： 816681689 / 1325201247 / 623951027 / 478285186 / 1654146165 / 1951252986 / 2029250107 / 762911244 / 1372544545 / 591415086 / / 3 / 0 / 6 / 4 / 2 /22.10 / 65.77 / 65.89 / 16.85 / 75.56 / 46.90 / 55.24 / 55.95 / 25.58 / 70.61 / 函数 rand.Float32 和 rand.Float64 返回介于 [0.0, 1.0) 之间的伪随机数，其中包括 0.0 但不包括 1.0。函数 rand.Intn 返回介于 [0, n) 之间的伪随机数。 你可以使用 Seed(value) 函数来提供伪随机数的生成种子，一般情况下都会使用当前时间的纳秒级数字（第 4.8 节）。 4.5.3 运算符与优先级 有些运算符拥有较高的优先级，二元运算符的运算方向均是从左至右。下表列出了所有运算符以及它们的优先级，由上至下代表优先级由高到低： 优先级 运算符 7 ^ ! 6 * / % > & &^ 5 + - | ^ 4 == != = > 3 当然，你可以通过使用括号来临时提升某个表达式的整体运算优先级。 4.5.4 类型别名 当你在使用某个类型时，你可以给它起另一个名字，然后你就可以在你的代码中使用新的名字（用于简化名称或解决名称冲突）。 在 type TZ int 中，TZ 就是 int 类型的新名称（用于表示程序中的时区），然后就可以使用 TZ 来操作 int 类型的数据。 示例 4.11 type.go package main import \"fmt\" type TZ int func main() { var a, b TZ = 3, 4 c := a + b fmt.Printf(\"c has the value: %d\", c) // 输出：c has the value: 7 } 实际上，类型别名得到的新类型并非和原类型完全相同，新类型不会拥有原类型所附带的方法（第 10 章）；TZ 可以自定义一个方法用来输出更加人性化的时区信息。 练习 4.5 定义一个 string 的类型别名 Rope，并声明一个该类型的变量。 4.5.5 字符类型 严格来说，这并不是 Go 语言的一个类型，字符只是整数的特殊用例。byte 类型是 uint8 的别名，对于只占用 1 个字节的传统 ASCII 编码的字符来说，完全没有问题。例如：var ch byte = 'A'；字符使用单引号括起来。 在 ASCII 码表中，A 的值是 65，而使用 16 进制表示则为 41，所以下面的写法是等效的： var ch byte = 65 或 var ch byte = '\\x41' （\\x 总是紧跟着长度为 2 的 16 进制数） 另外一种可能的写法是 \\ 后面紧跟着长度为 3 的八进制数，例如：\\377。 不过 Go 同样支持 Unicode（UTF-8），因此字符同样称为 Unicode 代码点或者 runes，并在内存中使用 int 来表示。在文档中，一般使用格式 U+hhhh 来表示，其中 h 表示一个 16 进制数。其实 rune 也是 Go 当中的一个类型，并且是 int32 的别名。 在书写 Unicode 字符时，需要在 16 进制数之前加上前缀 \\u 或者 \\U。 因为 Unicode 至少占用 2 个字节，所以我们使用 int16 或者 int 类型来表示。如果需要使用到 4 字节，则会加上 \\U 前缀；前缀 \\u 则总是紧跟着长度为 4 的 16 进制数，前缀 \\U 紧跟着长度为 8 的 16 进制数。 示例 4.12 char.go var ch int = '\\u0041' var ch2 int = '\\u03B2' var ch3 int = '\\U00101234' fmt.Printf(\"%d - %d - %d\\n\", ch, ch2, ch3) // integer fmt.Printf(\"%c - %c - %c\\n\", ch, ch2, ch3) // character fmt.Printf(\"%X - %X - %X\\n\", ch, ch2, ch3) // UTF-8 bytes fmt.Printf(\"%U - %U - %U\", ch, ch2, ch3) // UTF-8 code point 输出： 65 - 946 - 1053236 A - β - r 41 - 3B2 - 101234 U+0041 - U+03B2 - U+101234 格式化说明符 %c 用于表示字符；当和字符配合使用时，%v 或 %d 会输出用于表示该字符的整数；%U 输出格式为 U+hhhh 的字符串（另一个示例见第 5.4.4 节）。 包 unicode 包含了一些针对测试字符的非常有用的函数（其中 ch 代表字符）： 判断是否为字母：unicode.IsLetter(ch) 判断是否为数字：unicode.IsDigit(ch) 判断是否为空白符号：unicode.IsSpace(ch) 这些函数返回一个布尔值。包 utf8 拥有更多与 rune 相关的函数。 （ 译者注：关于类型的相关讲解，可参考视频教程 《Go编程基础》 第 3 课：类型与变量 ） 链接 目录 上一节：变量 下一节：字符串 "},"Go入门指南/04.6.html":{"url":"Go入门指南/04.6.html","title":"6","keywords":"","body":"4.6 字符串 字符串是 UTF-8 字符的一个序列（当字符为 ASCII 码时则占用 1 个字节，其它字符根据需要占用 2-4 个字节）。UTF-8 是被广泛使用的编码格式，是文本文件的标准编码，其它包括 XML 和 JSON 在内，也都使用该编码。由于该编码对占用字节长度的不定性，Go 中的字符串也可能根据需要占用 1 至 4 个字节（示例见第 4.6 节），这与其它语言如 C++、Java 或者 Python 不同（Java 始终使用 2 个字节）。Go 这样做的好处是不仅减少了内存和硬盘空间占用，同时也不用像其它语言那样需要对使用 UTF-8 字符集的文本进行编码和解码。 字符串是一种值类型，且值不可变，即创建某个文本后你无法再次修改这个文本的内容；更深入地讲，字符串是字节的定长数组。 Go 支持以下 2 种形式的字面值： 解释字符串： 该类字符串使用双引号括起来，其中的相关的转义字符将被替换，这些转义字符包括： \\n：换行符 \\r：回车符 \\t：tab 键 \\u 或 \\U：Unicode 字符 \\\\：反斜杠自身 非解释字符串： 该类字符串使用反引号括起来，支持换行，例如： `This is a raw string \\n` 中的 `\\n\\` 会被原样输出。 和 C/C++不一样，Go 中的字符串是根据长度限定，而非特殊字符\\0。 string 类型的零值为长度为零的字符串，即空字符串 \"\"。 一般的比较运算符（==、!=、、、>=、>）通过在内存中按字节比较来实现字符串的对比。你可以通过函数 len() 来获取字符串所占的字节长度，例如：len(str)。 字符串的内容（纯字节）可以通过标准索引法来获取，在中括号 [] 内写入索引，索引从 0 开始计数： 字符串 str 的第 1 个字节：str[0] 第 i 个字节：str[i - 1] 最后 1 个字节：str[len(str)-1] 需要注意的是，这种转换方案只对纯 ASCII 码的字符串有效。 注意事项 获取字符串中某个字节的地址的行为是非法的，例如：&str[i]。 字符串拼接符 + 两个字符串 s1 和 s2 可以通过 s := s1 + s2 拼接在一起。 s2 追加在 s1 尾部并生成一个新的字符串 s。 你可以通过以下方式来对代码中多行的字符串进行拼接： str := \"Beginning of the string \" + \"second part of the string\" 由于编译器行尾自动补全分号的缘故，加号 + 必须放在第一行。 拼接的简写形式 += 也可以用于字符串： s := \"hel\" + \"lo,\" s += \"world!\" fmt.Println(s) //输出 “hello, world!” 在循环中使用加号 + 拼接字符串并不是最高效的做法，更好的办法是使用函数 strings.Join()（第 4.7.10 节），有没有更好地办法了？有！使用字节缓冲（bytes.Buffer）拼接更加给力（第 7.2.6 节）！ 在第 7 章，我们会讲到通过将字符串看作是字节（byte）的切片（slice）来实现对其标准索引法的操作。会在第 5.4.1 节中讲到的 for 循环只会根据索引返回字符串中的纯字节，而在第 5.4.4 节（以及第 7.6.1 节的示例）将会展示如何使用 for-range 循环来实现对 Unicode 字符串的迭代操作。在下一节，我们会学习到许多有关字符串操作的函数和方法，同时 fmt 包中的 fmt.Sprint(x) 也可以格式化生成并返回你所需要的字符串（第 4.4.3 节）。 练习 4.6 count_characters.go 创建一个用于统计字节和字符（rune）的程序，并对字符串 asSASA ddd dsjkdsjs dk 进行分析，然后再分析 asSASA ddd dsjkdsjsこん dk，最后解释两者不同的原因（提示：使用 unicode/utf8 包）。 链接 目录 上一节：基本类型和运算符 下一节：strings 和 strconv 包 "},"Go入门指南/04.7.html":{"url":"Go入门指南/04.7.html","title":"7","keywords":"","body":"4.7 strings 和 strconv 包 作为一种基本数据结构，每种语言都有一些对于字符串的预定义处理函数。Go 中使用 strings 包来完成对字符串的主要操作。 4.7.1 前缀和后缀 HasPrefix 判断字符串 s 是否以 prefix 开头： strings.HasPrefix(s, prefix string) bool HasSuffix 判断字符串 s 是否以 suffix 结尾： strings.HasSuffix(s, suffix string) bool 示例 4.13 presuffix.go package main import ( \"fmt\" \"strings\" ) func main() { var str string = \"This is an example of a string\" fmt.Printf(\"T/F? Does the string \\\"%s\\\" have prefix %s? \", str, \"Th\") fmt.Printf(\"%t\\n\", strings.HasPrefix(str, \"Th\")) } 输出： T/F? Does the string \"This is an example of a string\" have prefix Th? true 这个例子同样演示了转义字符 \\ 和格式化字符串的使用。 4.7.2 字符串包含关系 Contains 判断字符串 s 是否包含 substr： strings.Contains(s, substr string) bool 4.7.3 判断子字符串或字符在父字符串中出现的位置（索引） Index 返回字符串 str 在字符串 s 中的索引（str 的第一个字符的索引），-1 表示字符串 s 不包含字符串 str： strings.Index(s, str string) int LastIndex 返回字符串 str 在字符串 s 中最后出现位置的索引（str 的第一个字符的索引），-1 表示字符串 s 不包含字符串 str： strings.LastIndex(s, str string) int 如果 ch 是非 ASCII 编码的字符，建议使用以下函数来对字符进行定位： strings.IndexRune(s string, r rune) int 示例 4.14 index_in_string.go package main import ( \"fmt\" \"strings\" ) func main() { var str string = \"Hi, I'm Marc, Hi.\" fmt.Printf(\"The position of \\\"Marc\\\" is: \") fmt.Printf(\"%d\\n\", strings.Index(str, \"Marc\")) fmt.Printf(\"The position of the first instance of \\\"Hi\\\" is: \") fmt.Printf(\"%d\\n\", strings.Index(str, \"Hi\")) fmt.Printf(\"The position of the last instance of \\\"Hi\\\" is: \") fmt.Printf(\"%d\\n\", strings.LastIndex(str, \"Hi\")) fmt.Printf(\"The position of \\\"Burger\\\" is: \") fmt.Printf(\"%d\\n\", strings.Index(str, \"Burger\")) } 输出： The position of \"Marc\" is: 8 The position of the first instance of \"Hi\" is: 0 The position of the last instance of \"Hi\" is: 14 The position of \"Burger\" is: -1 4.7.4 字符串替换 Replace 用于将字符串 str 中的前 n 个字符串 old 替换为字符串 new，并返回一个新的字符串，如果 n = -1 则替换所有字符串 old 为字符串 new： strings.Replace(str, old, new, n) string 4.7.5 统计字符串出现次数 Count 用于计算字符串 str 在字符串 s 中出现的非重叠次数： strings.Count(s, str string) int 示例 4.15 count_substring.go package main import ( \"fmt\" \"strings\" ) func main() { var str string = \"Hello, how is it going, Hugo?\" var manyG = \"gggggggggg\" fmt.Printf(\"Number of H's in %s is: \", str) fmt.Printf(\"%d\\n\", strings.Count(str, \"H\")) fmt.Printf(\"Number of double g's in %s is: \", manyG) fmt.Printf(\"%d\\n\", strings.Count(manyG, \"gg\")) } 输出： Number of H's in Hello, how is it going, Hugo? is: 2 Number of double g’s in gggggggggg is: 5 4.7.6 重复字符串 Repeat 用于重复 count 次字符串 s 并返回一个新的字符串： strings.Repeat(s, count int) string 示例 4.16 repeat_string.go package main import ( \"fmt\" \"strings\" ) func main() { var origS string = \"Hi there! \" var newS string newS = strings.Repeat(origS, 3) fmt.Printf(\"The new repeated string is: %s\\n\", newS) } 输出： The new repeated string is: Hi there! Hi there! Hi there! 4.7.7 修改字符串大小写 ToLower 将字符串中的 Unicode 字符全部转换为相应的小写字符： strings.ToLower(s) string ToUpper 将字符串中的 Unicode 字符全部转换为相应的大写字符： strings.ToUpper(s) string 示例 4.17 toupper_lower.go package main import ( \"fmt\" \"strings\" ) func main() { var orig string = \"Hey, how are you George?\" var lower string var upper string fmt.Printf(\"The original string is: %s\\n\", orig) lower = strings.ToLower(orig) fmt.Printf(\"The lowercase string is: %s\\n\", lower) upper = strings.ToUpper(orig) fmt.Printf(\"The uppercase string is: %s\\n\", upper) } 输出： The original string is: Hey, how are you George? The lowercase string is: hey, how are you george? The uppercase string is: HEY, HOW ARE YOU GEORGE? 4.7.8 修剪字符串 你可以使用 strings.TrimSpace(s) 来剔除字符串开头和结尾的空白符号；如果你想要剔除指定字符，则可以使用 strings.Trim(s, \"cut\") 来将开头和结尾的 cut 去除掉。该函数的第二个参数可以包含任何字符，如果你只想剔除开头或者结尾的字符串，则可以使用 TrimLeft 或者 TrimRight 来实现。 4.7.9 分割字符串 strings.Fields(s) 将会利用 1 个或多个空白符号来作为动态长度的分隔符将字符串分割成若干小块，并返回一个 slice，如果字符串只包含空白符号，则返回一个长度为 0 的 slice。 strings.Split(s, sep) 用于自定义分割符号来对指定字符串进行分割，同样返回 slice。 因为这 2 个函数都会返回 slice，所以习惯使用 for-range 循环来对其进行处理（第 7.3 节）。 4.7.10 拼接 slice 到字符串 Join 用于将元素类型为 string 的 slice 使用分割符号来拼接组成一个字符串： strings.Join(sl []string, sep string) string 示例 4.18 strings_splitjoin.go package main import ( \"fmt\" \"strings\" ) func main() { str := \"The quick brown fox jumps over the lazy dog\" sl := strings.Fields(str) fmt.Printf(\"Splitted in slice: %v\\n\", sl) for _, val := range sl { fmt.Printf(\"%s - \", val) } fmt.Println() str2 := \"GO1|The ABC of Go|25\" sl2 := strings.Split(str2, \"|\") fmt.Printf(\"Splitted in slice: %v\\n\", sl2) for _, val := range sl2 { fmt.Printf(\"%s - \", val) } fmt.Println() str3 := strings.Join(sl2,\";\") fmt.Printf(\"sl2 joined by ;: %s\\n\", str3) } 输出： Splitted in slice: [The quick brown fox jumps over the lazy dog] The - quick - brown - fox - jumps - over - the - lazy - dog - Splitted in slice: [GO1 The ABC of Go 25] GO1 - The ABC of Go - 25 - sl2 joined by ;: GO1;The ABC of Go;25 其它有关字符串操作的文档请参阅 官方文档（ 译者注：国内用户可访问 该页面 ）。 4.7.11 从字符串中读取内容 函数 strings.NewReader(str) 用于生成一个 Reader 并读取字符串中的内容，然后返回指向该 Reader 的指针，从其它类型读取内容的函数还有： Read() 从 []byte 中读取内容。 ReadByte() 和 ReadRune() 从字符串中读取下一个 byte 或者 rune。 4.7.12 字符串与其它类型的转换 与字符串相关的类型转换都是通过 strconv 包实现的。 该包包含了一些变量用于获取程序运行的操作系统平台下 int 类型所占的位数，如：strconv.IntSize。 任何类型 T 转换为字符串总是成功的。 针对从数字类型转换到字符串，Go 提供了以下函数： strconv.Itoa(i int) string 返回数字 i 所表示的字符串类型的十进制数。 strconv.FormatFloat(f float64, fmt byte, prec int, bitSize int) string 将 64 位浮点型的数字转换为字符串，其中 fmt 表示格式（其值可以是 'b'、'e'、'f' 或 'g'），prec 表示精度，bitSize 则使用 32 表示 float32，用 64 表示 float64。 将字符串转换为其它类型 tp 并不总是可能的，可能会在运行时抛出错误 parsing \"…\": invalid argument。 针对从字符串类型转换为数字类型，Go 提供了以下函数： strconv.Atoi(s string) (i int, err error) 将字符串转换为 int 型。 strconv.ParseFloat(s string, bitSize int) (f float64, err error) 将字符串转换为 float64 型。 利用多返回值的特性，这些函数会返回 2 个值，第 1 个是转换后的结果（如果转换成功），第 2 个是可能出现的错误，因此，我们一般使用以下形式来进行从字符串到其它类型的转换： val, err = strconv.Atoi(s) 在下面这个示例中，我们忽略可能出现的转换错误： 示例 4.19 string_conversion.go package main import ( \"fmt\" \"strconv\" ) func main() { var orig string = \"666\" var an int var newS string fmt.Printf(\"The size of ints is: %d\\n\", strconv.IntSize) an, _ = strconv.Atoi(orig) fmt.Printf(\"The integer is: %d\\n\", an) an = an + 5 newS = strconv.Itoa(an) fmt.Printf(\"The new string is: %s\\n\", newS) } 输出： 64 位系统： The size of ints is: 64 32 位系统： The size of ints is: 32 The integer is: 666 The new string is: 671 在第 5.1 节，我们将会利用 if 语句来对可能出现的错误进行分类处理。 更多有关该包的讨论，请参阅 官方文档（ 译者注：国内用户可访问 该页面 ）。 链接 目录 上一节：字符串 下一节：时间和日期 "},"Go入门指南/04.8.html":{"url":"Go入门指南/04.8.html","title":"8","keywords":"","body":"4.8 时间和日期 time 包为我们提供了一个数据类型 time.Time（作为值使用）以及显示和测量时间和日期的功能函数。 当前时间可以使用 time.Now() 获取，或者使用 t.Day()、t.Minute() 等等来获取时间的一部分；你甚至可以自定义时间格式化字符串，例如： fmt.Printf(\"%02d.%02d.%4d\\n\", t.Day(), t.Month(), t.Year()) 将会输出 21.07.2011。 Duration 类型表示两个连续时刻所相差的纳秒数，类型为 int64。Location 类型映射某个时区的时间，UTC 表示通用协调世界时间。 包中的一个预定义函数 func (t Time) Format(layout string) string 可以根据一个格式化字符串来将一个时间 t 转换为相应格式的字符串，你可以使用一些预定义的格式，如：time.ANSIC 或 time.RFC822。 一般的格式化设计是通过对于一个标准时间的格式化描述来展现的，这听起来很奇怪，但看下面这个例子你就会一目了然： fmt.Println(t.Format(\"02 Jan 2006 15:04\")) 输出： 21 Jul 2011 10:31 其它有关时间操作的文档请参阅 官方文档（ 译者注：国内用户可访问 该页面 ）。 示例 4.20 time.go package main import ( \"fmt\" \"time\" ) var week time.Duration func main() { t := time.Now() fmt.Println(t) // e.g. Wed Dec 21 09:52:14 +0100 RST 2011 fmt.Printf(\"%02d.%02d.%4d\\n\", t.Day(), t.Month(), t.Year()) // 21.12.2011 t = time.Now().UTC() fmt.Println(t) // Wed Dec 21 08:52:14 +0000 UTC 2011 fmt.Println(time.Now()) // Wed Dec 21 09:52:14 +0100 RST 2011 // calculating times: week = 60 * 60 * 24 * 7 * 1e9 // must be in nanosec week_from_now := t.Add(week) fmt.Println(week_from_now) // Wed Dec 28 08:52:14 +0000 UTC 2011 // formatting times: fmt.Println(t.Format(time.RFC822)) // 21 Dec 11 0852 UTC fmt.Println(t.Format(time.ANSIC)) // Wed Dec 21 08:56:34 2011 fmt.Println(t.Format(\"02 Jan 2006 15:04\")) // 21 Dec 2011 08:52 s := t.Format(\"20060102\") fmt.Println(t, \"=>\", s) // Wed Dec 21 08:52:14 +0000 UTC 2011 => 20111221 } 输出的结果已经写在每行 // 的后面。 如果你需要在应用程序在经过一定时间或周期执行某项任务（事件处理的特例），则可以使用 time.After 或者 time.Ticker：我们将会在第 14.5 节讨论这些有趣的事情。 另外，time.Sleep（Duration d） 可以实现对某个进程（实质上是 goroutine）时长为 d 的暂停。 链接 目录 上一节：strings 和 strconv 包 下一节：指针 "},"Go入门指南/04.9.html":{"url":"Go入门指南/04.9.html","title":"9","keywords":"","body":"4.9 指针 不像 Java 和 .NET，Go 语言为程序员提供了控制数据结构的指针的能力；但是，你不能进行指针运算。通过给予程序员基本内存布局，Go 语言允许你控制特定集合的数据结构、分配的数量以及内存访问模式，这些对构建运行良好的系统是非常重要的：指针对于性能的影响是不言而喻的，而如果你想要做的是系统编程、操作系统或者网络应用，指针更是不可或缺的一部分。 由于各种原因，指针对于使用面向对象编程的现代程序员来说可能显得有些陌生，不过我们将会在这一小节对此进行解释，并在未来的章节中展开深入讨论。 程序在内存中存储它的值，每个内存块（或字）有一个地址，通常用十六进制数表示，如：0x6b0820 或 0xf84001d7f0。 Go 语言的取地址符是 &，放到一个变量前使用就会返回相应变量的内存地址。 下面的代码片段（示例 4.9 pointer.go）可能输出 An integer: 5, its location in memory: 0x6b0820（这个值随着你每次运行程序而变化）。 var i1 = 5 fmt.Printf(\"An integer: %d, it's location in memory: %p\\n\", i1, &i1) 这个地址可以存储在一个叫做指针的特殊数据类型中，在本例中这是一个指向 int 的指针，即 i1：此处使用 *int 表示。如果我们想调用指针 intP，我们可以这样声明它： var intP *int 然后使用 intP = &i1 是合法的，此时 intP 指向 i1。 （指针的格式化标识符为 %p） intP 存储了 i1 的内存地址；它指向了 i1 的位置，它引用了变量 i1。 一个指针变量可以指向任何一个值的内存地址 它指向那个值的内存地址，在 32 位机器上占用 4 个字节，在 64 位机器上占用 8 个字节，并且与它所指向的值的大小无关。当然，可以声明指针指向任何类型的值来表明它的原始性或结构性；你可以在指针类型前面加上 号（前缀）来获取指针所指向的内容，这里的 号是一个类型更改器。使用一个指针引用一个值被称为间接引用。 当一个指针被定义后没有分配到任何变量时，它的值为 nil。 一个指针变量通常缩写为 ptr。 注意事项 在书写表达式类似 var p *type 时，切记在 号和指针名称间留有一个空格，因为 `- var ptype` 是语法正确的，但是在更复杂的表达式中，它容易被误认为是一个乘法表达式！ 符号 可以放在一个指针前，如 `intP`，那么它将得到这个指针指向地址上所存储的值；这被称为反引用（或者内容或者间接引用）操作符；另一种说法是指针转移。 对于任何一个变量 var， 如下表达式都是正确的：var == *(&var)。 现在，我们应当能理解 pointer.go 的全部内容及其输出： 示例 4.21 pointer.go: package main import \"fmt\" func main() { var i1 = 5 fmt.Printf(\"An integer: %d, its location in memory: %p\\n\", i1, &i1) var intP *int intP = &i1 fmt.Printf(\"The value at memory location %p is %d\\n\", intP, *intP) } 输出： An integer: 5, its location in memory: 0x24f0820 The value at memory location 0x24f0820 is 5 我们可以用下图来表示内存使用的情况： 程序 string_pointer.go 为我们展示了指针对string的例子。 它展示了分配一个新的值给 *p 并且更改这个变量自己的值（这里是一个字符串）。 示例 4.22 string_pointer.go package main import \"fmt\" func main() { s := \"good bye\" var p *string = &s *p = \"ciao\" fmt.Printf(\"Here is the pointer p: %p\\n\", p) // prints address fmt.Printf(\"Here is the string *p: %s\\n\", *p) // prints string fmt.Printf(\"Here is the string s: %s\\n\", s) // prints same string } 输出： Here is the pointer p: 0x2540820 Here is the string *p: ciao Here is the string s: ciao 通过对 *p 赋另一个值来更改“对象”，这样 s 也会随之更改。 内存示意图如下： 注意事项 你不能得到一个文字或常量的地址，例如： const i = 5 ptr := &i //error: cannot take the address of i ptr2 := &10 //error: cannot take the address of 10 所以说，Go 语言和 C、C++ 以及 D 语言这些低级（系统）语言一样，都有指针的概念。但是对于经常导致 C 语言内存泄漏继而程序崩溃的指针运算（所谓的指针算法，如：pointer+2，移动指针指向字符串的字节数或数组的某个位置）是不被允许的。Go 语言中的指针保证了内存安全，更像是 Java、C# 和 VB.NET 中的引用。 因此 c = *p++ 在 Go 语言的代码中是不合法的。 指针的一个高级应用是你可以传递一个变量的引用（如函数的参数），这样不会传递变量的拷贝。指针传递是很廉价的，只占用 4 个或 8 个字节。当程序在工作中需要占用大量的内存，或很多变量，或者两者都有，使用指针会减少内存占用和提高效率。被指向的变量也保存在内存中，直到没有任何指针指向它们，所以从它们被创建开始就具有相互独立的生命周期。 另一方面（虽然不太可能），由于一个指针导致的间接引用（一个进程执行了另一个地址），指针的过度频繁使用也会导致性能下降。 指针也可以指向另一个指针，并且可以进行任意深度的嵌套，导致你可以有多级的间接引用，但在大多数情况这会使你的代码结构不清晰。 如我们所见，在大多数情况下 Go 语言可以使程序员轻松创建指针，并且隐藏间接引用，如：自动反向引用。 对一个空指针的反向引用是不合法的，并且会使程序崩溃： 示例 4.23 testcrash.go: package main func main() { var p *int = nil *p = 0 } // in Windows: stops only with: // runtime error: invalid memory address or nil pointer dereference 问题 4.2 列举 Go 语言中 * 号的所有用法。 链接 目录 上一节：时间和日期 下一节：控制结构 "},"Go入门指南/05.0.html":{"url":"Go入门指南/05.0.html","title":"0","keywords":"","body":"5.0 控制结构 到目前为止，我们看到的都是 Go 程序都是从 main() 函数开始执行，然后按顺序执行该函数体中的代码。但我们经常会需要只有在满足一些特定情况时才执行某些代码，也就是说在代码里进行条件判断。针对这种需求，Go 提供了下面这些条件结构和分支结构： if-else 结构 switch 结构 select 结构，用于 channel 的选择（第 14.4 节） 可以使用迭代或循环结构来重复执行一次或多次某段代码（任务）： for (range) 结构 一些如 break 和 continue 这样的关键字可以用于中途改变循环的状态。 此外，你还可以使用 return 来结束某个函数的执行，或使用 goto 和标签来调整程序的执行位置。 Go 完全省略了 if、switch 和 for 结构中条件语句两侧的括号，相比 Java、C++ 和 C# 中减少了很多视觉混乱的因素，同时也使你的代码更加简洁。 链接 目录 上一章：指针 下一节：if-else 结构 "},"Go入门指南/05.1.html":{"url":"Go入门指南/05.1.html","title":"1","keywords":"","body":"5.1 if-else 结构 if 是用于测试某个条件（布尔型或逻辑型）的语句，如果该条件成立，则会执行 if 后由大括号括起来的代码块，否则就忽略该代码块继续执行后续的代码。 if condition { // do something } 如果存在第二个分支，则可以在上面代码的基础上添加 else 关键字以及另一代码块，这个代码块中的代码只有在条件不满足时才会执行。if 和 else 后的两个代码块是相互独立的分支，只可能执行其中一个。 if condition { // do something } else { // do something } 如果存在第三个分支，则可以使用下面这种三个独立分支的形式： if condition1 { // do something } else if condition2 { // do something else } else { // catch-all or default } else-if 分支的数量是没有限制的，但是为了代码的可读性，还是不要在 if 后面加入太多的 else-if 结构。如果你必须使用这种形式，则把尽可能先满足的条件放在前面。 即使当代码块之间只有一条语句时，大括号也不可被省略(尽管有些人并不赞成，但这还是符合了软件工程原则的主流做法)。 关键字 if 和 else 之后的左大括号 { 必须和关键字在同一行，如果你使用了 else-if 结构，则前段代码块的右大括号 } 必须和 else-if 关键字在同一行。这两条规则都是被编译器强制规定的。 非法的 Go 代码: if x{ } else { // 无效的 } 要注意的是，在你使用 gofmt 格式化代码之后，每个分支内的代码都会缩进 4 个或 8 个空格，或者是 1 个 tab，并且右大括号与对应的 if 关键字垂直对齐。 在有些情况下，条件语句两侧的括号是可以被省略的；当条件比较复杂时，则可以使用括号让代码更易读。条件允许是符合条件，需使用 &&、|| 或 !，你可以使用括号来提升某个表达式的运算优先级，并提高代码的可读性。 一种可能用到条件语句的场景是测试变量的值，在不同的情况执行不同的语句，不过将在第 5.3 节讲到的 switch 结构会更适合这种情况。 示例 5.1 booleans.go package main import \"fmt\" func main() { bool1 := true if bool1 { fmt.Printf(\"The value is true\\n\") } else { fmt.Printf(\"The value is false\\n\") } } 输出： The value is true 注意事项 这里不需要使用 if bool1 == true 来判断，因为 bool1 本身已经是一个布尔类型的值。 这种做法一般都用在测试 true 或者有利条件时，但你也可以使用取反 ! 来判断值的相反结果，如：if !bool1 或者 if !(condition)。后者的括号大多数情况下是必须的，如这种情况：if !(var1 == var2)。 当 if 结构内有 break、continue、goto 或者 return 语句时，Go 代码的常见写法是省略 else 部分（另见第 5.2 节）。无论满足哪个条件都会返回 x 或者 y 时，一般使用以下写法： if condition { return x } return y 注意事项 不要同时在 if-else 结构的两个分支里都使用 return 语句，这将导致编译报错 function ends without a return statement（你可以认为这是一个编译器的 Bug 或者特性）。（ 译者注：该问题已经在 Go 1.1 中被修复或者说改进 ） 这里举一些有用的例子： 判断一个字符串是否为空： if str == \"\" { ... } if len(str) == 0 {...} 判断运行 Go 程序的操作系统类型，这可以通过常量 runtime.GOOS 来判断(第 2.2 节)。 if runtime.GOOS == \"windows\" { . .. } else { // Unix-like . .. } 这段代码一般被放在 init() 函数中执行。这儿还有一段示例来演示如何根据操作系统来决定输入结束的提示： var prompt = \"Enter a digit, e.g. 3 \"+ \"or %s to quit.\" func init() { if runtime.GOOS == \"windows\" { prompt = fmt.Sprintf(prompt, \"Ctrl+Z, Enter\") } else { //Unix-like prompt = fmt.Sprintf(prompt, \"Ctrl+D\") } } 函数 Abs() 用于返回一个整型数字的绝对值: func Abs(x int) int { if x isGreater 用于比较两个整型数字的大小: func isGreater(x, y int) bool { if x > y { return true } return false } 在第四种情况中，if 可以包含一个初始化语句（如：给一个变量赋值）。这种写法具有固定的格式（在初始化语句后方必须加上分号）： if initialization; condition { // do something } 例如: val := 10 if val > max { // do something } 你也可以这样写: if val := 10; val > max { // do something } 但要注意的是，使用简短方式 := 声明的变量的作用域只存在于 if 结构中（在 if 结构的大括号之间，如果使用 if-else 结构则在 else 代码块中变量也会存在）。如果变量在 if 结构之前就已经存在，那么在 if 结构中，该变量原来的值会被隐藏。最简单的解决方案就是不要在初始化语句中声明变量（见 5.2 节的例 3 了解更多)。 示例 5.2 ifelse.go package main import \"fmt\" func main() { var first int = 10 var cond int if first 0 && first 10 { fmt.Printf(\"cond is greater than 10\\n\") } else { fmt.Printf(\"cond is not greater than 10\\n\") } } 输出： first is 5 or greater cond is not greater than 10 下面的代码片段展示了如何通过在初始化语句中获取函数 process() 的返回值，并在条件语句中作为判定条件来决定是否执行 if 结构中的代码： if value := process(data); value > max { ... } 链接 目录 上一节：控制结构 下一节：测试多返回值函数的错误 "},"Go入门指南/05.2.html":{"url":"Go入门指南/05.2.html","title":"2","keywords":"","body":"5.2 测试多返回值函数的错误 Go 语言的函数经常使用两个返回值来表示执行是否成功：返回某个值以及 true 表示成功；返回零值（或 nil）和 false 表示失败（第 4.4 节）。当不使用 true 或 false 的时候，也可以使用一个 error 类型的变量来代替作为第二个返回值：成功执行的话，error 的值为 nil，否则就会包含相应的错误信息（Go 语言中的错误类型为 error: var err error，我们将会在第 13 章进行更多地讨论）。这样一来，就很明显需要用一个 if 语句来测试执行结果；由于其符号的原因，这样的形式又称之为 comma,ok 模式（pattern）。 在第 4.7 节的程序 string_conversion.go 中，函数 strconv.Atoi 的作用是将一个字符串转换为一个整数。之前我们忽略了相关的错误检查： anInt, _ = strconv.Atoi(origStr) 如果 origStr 不能被转换为整数，anInt 的值会变成 0 而 _ 无视了错误，程序会继续运行。 这样做是非常不好的：程序应该在最接近的位置检查所有相关的错误，至少需要暗示用户有错误发生并对函数进行返回，甚至中断程序。 我们在第二个版本中对代码进行了改进： 示例 1： 示例 5.3 string_conversion2.go package main import ( \"fmt\" \"strconv\" ) func main() { var orig string = \"ABC\" // var an int var newS string // var err error fmt.Printf(\"The size of ints is: %d\\n\", strconv.IntSize) // anInt, err = strconv.Atoi(origStr) an, err := strconv.Atoi(orig) if err != nil { fmt.Printf(\"orig %s is not an integer - exiting with error\\n\", orig) return } fmt.Printf(\"The integer is %d\\n\", an) an = an + 5 newS = strconv.Itoa(an) fmt.Printf(\"The new string is: %s\\n\", newS) } 这是测试 err 变量是否包含一个真正的错误（if err != nil）的习惯用法。如果确实存在错误，则会打印相应的错误信息然后通过 return 提前结束函数的执行。我们还可以使用携带返回值的 return 形式，例如 return err。这样一来，函数的调用者就可以检查函数执行过程中是否存在错误了。 习惯用法 value, err := pack1.Function1(param1) if err != nil { fmt.Printf(\"An error occured in pack1.Function1 with parameter %v\", param1) return err } // 未发生错误，继续执行： 由于本例的函数调用者属于 main 函数，所以程序会直接停止运行。 如果我们想要在错误发生的同时终止程序的运行，我们可以使用 os 包的 Exit 函数： 习惯用法 if err != nil { fmt.Printf(\"Program stopping with error %v\", err) os.Exit(1) } （此处的退出代码 1 可以使用外部脚本获取到） 有时候，你会发现这种习惯用法被连续重复地使用在某段代码中。 当没有错误发生时，代码继续运行就是唯一要做的事情，所以 if 语句块后面不需要使用 else 分支。 示例 2：我们尝试通过 os.Open 方法打开一个名为 name 的只读文件： f, err := os.Open(name) if err != nil { return err } doSomething(f) // 当没有错误发生时，文件对象被传入到某个函数中 doSomething 练习 5.1 尝试改写 string_conversion2.go 中的代码，要求使用 := 方法来对 err 进行赋值，哪些地方可以被修改？ 示例 3：可以将错误的获取放置在 if 语句的初始化部分： 习惯用法 if err := file.Chmod(0664); err != nil { fmt.Println(err) return err } 示例 4：或者将 ok-pattern 的获取放置在 if 语句的初始化部分，然后进行判断： 习惯用法 if value, ok := readData(); ok { … } 注意事项 如果您像下面一样，没有为多返回值的函数准备足够的变量来存放结果： func mySqrt(f float64) (v float64, ok bool) { if f 您会得到一个编译错误：multiple-value mySqrt() in single-value context。 正确的做法是： t, ok := mySqrt(25.0) if ok { fmt.Println(t) } 注意事项 2 当您将字符串转换为整数时，且确定转换一定能够成功时，可以将 Atoi 函数进行一层忽略错误的封装： func atoi (s string) (n int) { n, _ = strconv.Atoi(s) return } 实际上，fmt 包（第 4.4.3 节）最简单的打印函数也有 2 个返回值： count, err := fmt.Println(x) // number of bytes printed, nil or 0, error 当打印到控制台时，可以将该函数返回的错误忽略；但当输出到文件流、网络流等具有不确定因素的输出对象时，应该始终检查是否有错误发生（另见练习 6.1b）。 链接 目录 上一节：if-else 结构 下一节：switch 结构 "},"Go入门指南/05.3.html":{"url":"Go入门指南/05.3.html","title":"3","keywords":"","body":"5.3 switch 结构 相比较 C 和 Java 等其它语言而言，Go 语言中的 switch 结构使用上更加灵活。它接受任意形式的表达式： switch var1 { case val1: ... case val2: ... default: ... } 变量 var1 可以是任何类型，而 val1 和 val2 则可以是同类型的任意值。类型不被局限于常量或整数，但必须是相同的类型；或者最终结果为相同类型的表达式。前花括号 { 必须和 switch 关键字在同一行。 您可以同时测试多个可能符合条件的值，使用逗号分割它们，例如：case val1, val2, val3。 每一个 case 分支都是唯一的，从上至下逐一测试，直到匹配为止。（ Go 语言使用快速的查找算法来测试 switch 条件与 case 分支的匹配情况，直到算法匹配到某个 case 或者进入 default 条件为止。） 一旦成功地匹配到某个分支，在执行完相应代码后就会退出整个 switch 代码块，也就是说您不需要特别使用 break 语句来表示结束。 因此，程序也不会自动地去执行下一个分支的代码。如果在执行完每个分支的代码后，还希望继续执行后续分支的代码，可以使用 fallthrough 关键字来达到目的。 因此： switch i { case 0: // 空分支，只有当 i == 0 时才会进入分支 case 1: f() // 当 i == 0 时函数不会被调用 } 并且： switch i { case 0: fallthrough case 1: f() // 当 i == 0 时函数也会被调用 } 在 case ...: 语句之后，您不需要使用花括号将多行语句括起来，但您可以在分支中进行任意形式的编码。当代码块只有一行时，可以直接放置在 case 语句之后。 您同样可以使用 return 语句来提前结束代码块的执行。当您在 switch 语句块中使用 return 语句，并且您的函数是有返回值的，您还需要在 switch 之后添加相应的 return 语句以确保函数始终会返回。 可选的 default 分支可以出现在任何顺序，但最好将它放在最后。它的作用类似与 if-else 语句中的 else，表示不符合任何已给出条件时，执行相关语句。 示例 5.4 switch1.go： package main import \"fmt\" func main() { var num1 int = 100 switch num1 { case 98, 99: fmt.Println(\"It's equal to 98\") case 100: fmt.Println(\"It's equal to 100\") default: fmt.Println(\"It's not equal to 98 or 100\") } } 输出： It's equal to 100 在第 12.1 节，我们会使用 switch 语句判断从键盘输入的字符（详见第 12.2 节的 switch.go）。switch 语句的第二种形式是不提供任何被判断的值（实际上默认为判断是否为 true），然后在每个 case 分支中进行测试不同的条件。当任一分支的测试结果为 true 时，该分支的代码会被执行。这看起来非常像链式的 if-else 语句，但是在测试条件非常多的情况下，提供了可读性更好的书写方式。 switch { case condition1: ... case condition2: ... default: ... } 例如： switch { case i 0: f3() } 任何支持进行相等判断的类型都可以作为测试表达式的条件，包括 int、string、指针等。 示例 5.4 switch2.go： package main import \"fmt\" func main() { var num1 int = 7 switch { case num1 0 && num1 输出： Number is between 0 and 10 switch 语句的第三种形式是包含一个初始化语句： switch initialization { case val1: ... case val2: ... default: ... } 这种形式可以非常优雅地进行条件判断： switch result := calculate(); { case result 0: ... default: // 0 } 在下面这个代码片段中，变量 a 和 b 被平行初始化，然后作为判断条件： switch a, b := x[i], y[j]; { case a b: t = 1 } switch 语句还可以被用于 type-switch（详见第 11.4 节）来判断某个 interface 变量中实际存储的变量类型。 问题 5.1： 请说出下面代码片段输出的结果： k := 6 switch k { case 4: fmt.Println(\"was 练习 5.2： season.go： 写一个 Season 函数，要求接受一个代表月份的数字，然后返回所代表月份所在季节的名称（不用考虑月份的日期）。 链接 目录 上一节：测试多返回值函数的错误 下一节：for 结构 "},"Go入门指南/05.4.html":{"url":"Go入门指南/05.4.html","title":"4","keywords":"","body":"5.4 for 结构 如果想要重复执行某些语句，Go 语言中您只有 for 结构可以使用。不要小看它，这个 for 结构比其它语言中的更为灵活。 注意事项 其它许多语言中也没有发现和 do while 完全对等的 for 结构，可能是因为这种需求并不是那么强烈。 5.4.1 基于计数器的迭代 文件 for1.go 中演示了最简单的基于计数器的迭代，基本形式为： for 初始化语句; 条件语句; 修饰语句 {} 示例 5.6 for1.go： package main import \"fmt\" func main() { for i := 0; i 输出： This is the 0 iteration This is the 1 iteration This is the 2 iteration This is the 3 iteration This is the 4 iteration 由花括号括起来的代码块会被重复执行已知次数，该次数是根据计数器（此例为 i）决定的。循环开始前，会执行且仅会执行一次初始化语句 i := 0;；这比在循环之前声明更为简短。紧接着的是条件语句 i ，在每次循环开始前都会进行判断，一旦判断结果为 false，则退出循环体。最后一部分为修饰语句 i++，一般用于增加或减少计数器。 这三部分组成的循环的头部，它们之间使用分号 ; 相隔，但并不需要括号 () 将它们括起来。例如：for (i = 0; i ，这是无效的代码！ 同样的，左花括号 { 必须和 for 语句在同一行，计数器的生命周期在遇到右花括号 } 时便终止。一般习惯使用 i、j、z 或 ix 等较短的名称命名计数器。 特别注意，永远不要在循环体内修改计数器，这在任何语言中都是非常差的实践！ 您还可以在循环中同时使用多个计数器： for i, j := 0, N; i 这得益于 Go 语言具有的平行赋值的特性（可以查看第 7 章 string_reverse.go 中反转数组的示例）。 您可以将两个 for 循环嵌套起来： for i:=0; i 如果您使用 for 循环迭代一个 Unicode 编码的字符串，会发生什么？ 示例 5.7 for_string.go： package main import \"fmt\" func main() { str := \"Go is a beautiful language!\" fmt.Printf(\"The length of str is: %d\\n\", len(str)) for ix :=0; ix 输出： The length of str is: 27 Character on position 0 is: G Character on position 1 is: o Character on position 2 is: Character on position 3 is: i Character on position 4 is: s Character on position 5 is: Character on position 6 is: a Character on position 7 is: Character on position 8 is: b Character on position 9 is: e Character on position 10 is: a Character on position 11 is: u Character on position 12 is: t Character on position 13 is: i Character on position 14 is: f Character on position 15 is: u Character on position 16 is: l Character on position 17 is: Character on position 18 is: l Character on position 19 is: a Character on position 20 is: n Character on position 21 is: g Character on position 22 is: u Character on position 23 is: a Character on position 24 is: g Character on position 25 is: e Character on position 26 is: ! The length of str2 is: 9 Character on position 0 is: æ Character on position 1 is:  Character on position 2 is: ¥ Character on position 3 is: æ Character on position 4 is:  Character on position 5 is: ¬ Character on position 6 is: è Character on position 7 is: ª Character on position 8 is:  如果我们打印 str 和 str2 的长度，会分别得到 27 和 9。 由此我们可以发现，ASCII 编码的字符占用 1 个字节，既每个索引都指向不同的字符，而非 ASCII 编码的字符（占有 2 到 4 个字节）不能单纯地使用索引来判断是否为同一个字符。我们会在第 5.4.4 节解决这个问题。 练习题 练习 5.4 for_loop.go 使用 for 结构创建一个简单的循环。要求循环 15 次然后使用 fmt 包来打印计数器的值。 使用 goto 语句重写循环，要求不能使用 for 关键字。 练习 5.5 for_character.go 创建一个程序，要求能够打印类似下面的结果（直到每行 25 个字符时为止）： G GG GGG GGGG GGGGG GGGGGG 使用 2 层嵌套 for 循环。 使用一层 for 循环以及字符串截断。 练习 5.6 bitwise_complement.go 使用按位补码从 0 到 10，使用位表达式 %b 来格式化输出。 练习 5.7 Fizz-Buzz 问题：fizzbuzz.go 写一个从 1 打印到 100 的程序，但是每当遇到 3 的倍数时，不打印相应的数字，但打印一次 \"Fizz\"。遇到 5 的倍数时，打印 Buzz 而不是相应的数字。对于同时为 3 和 5 的倍数的数，打印 FizzBuzz（提示：使用 switch 语句）。 练习 5.8 rectangle_stars.go 使用 * 符号打印宽为 20，高为 10 的矩形。 5.4.2 基于条件判断的迭代 for 结构的第二种形式是没有头部的条件判断迭代（类似其它语言中的 while 循环），基本形式为：for 条件语句 {}。 您也可以认为这是没有初始化语句和修饰语句的 for 结构，因此 ;; 便是多余的了。 Listing 5.8 for2.go： package main import \"fmt\" func main() { var i int = 5 for i >= 0 { i = i - 1 fmt.Printf(\"The variable i is now: %d\\n\", i) } } 输出： The variable i is now: 4 The variable i is now: 3 The variable i is now: 2 The variable i is now: 1 The variable i is now: 0 The variable i is now: -1 5.4.3 无限循环 条件语句是可以被省略的，如 i:=0; ; i++ 或 for { } 或 for ;; { }（;; 会在使用 gofmt 时被移除）：这些循环的本质就是无限循环。最后一个形式也可以被改写为 for true { }，但一般情况下都会直接写 for { }。 如果 for 循环的头部没有条件语句，那么就会认为条件永远为 true，因此循环体内必须有相关的条件判断以确保会在某个时刻退出循环。 想要直接退出循环体，可以使用 break 语句（第 5.5 节）或 return 语句直接返回（第 6.1 节）。 但这两者之间有所区别，break 只是退出当前的循环体，而 return 语句提前对函数进行返回，不会执行后续的代码。 无限循环的经典应用是服务器，用于不断等待和接受新的请求。 for t, err = p.Token(); err == nil; t, err = p.Token() { ... } 5.4.4 for-range 结构 这是 Go 特有的一种的迭代结构，您会发现它在许多情况下都非常有用。它可以迭代任何一个集合（包括数组和 map，详见第 7 和 8 章）。语法上很类似其它语言中 foreach 语句，但您依旧可以获得每次迭代所对应的索引。一般形式为：for ix, val := range coll { }。 要注意的是，val 始终为集合中对应索引的值拷贝，因此它一般只具有只读性质，对它所做的任何修改都不会影响到集合中原有的值（译者注：如果 val 为指针，则会产生指针的拷贝，依旧可以修改集合中的原值）。一个字符串是 Unicode 编码的字符（或称之为 rune）集合，因此您也可以用它迭代字符串： for pos, char := range str { ... } 每个 rune 字符和索引在 for-range 循环中是一一对应的。它能够自动根据 UTF-8 规则识别 Unicode 编码的字符。 示例 5.9 range_string.go： package main import \"fmt\" func main() { str := \"Go is a beautiful language!\" fmt.Printf(\"The length of str is: %d\\n\", len(str)) for pos, char := range str { fmt.Printf(\"Character on position %d is: %c \\n\", pos, char) } fmt.Println() str2 := \"Chinese: 日本語\" fmt.Printf(\"The length of str2 is: %d\\n\", len(str2)) for pos, char := range str2 { fmt.Printf(\"character %c starts at byte position %d\\n\", char, pos) } fmt.Println() fmt.Println(\"index int(rune) rune char bytes\") for index, rune := range str2 { fmt.Printf(\"%-2d %d %U '%c' % X\\n\", index, rune, rune, rune, []byte(string(rune))) } } 输出： The length of str is: 27 Character on position 0 is: G Character on position 1 is: o Character on position 2 is: Character on position 3 is: i Character on position 4 is: s Character on position 5 is: Character on position 6 is: a Character on position 7 is: Character on position 8 is: b Character on position 9 is: e Character on position 10 is: a Character on position 11 is: u Character on position 12 is: t Character on position 13 is: i Character on position 14 is: f Character on position 15 is: u Character on position 16 is: l Character on position 17 is: Character on position 18 is: l Character on position 19 is: a Character on position 20 is: n Character on position 21 is: g Character on position 22 is: u Character on position 23 is: a Character on position 24 is: g Character on position 25 is: e Character on position 26 is: ! The length of str2 is: 18 character C starts at byte position 0 character h starts at byte position 1 character i starts at byte position 2 character n starts at byte position 3 character e starts at byte position 4 character s starts at byte position 5 character e starts at byte position 6 character : starts at byte position 7 character starts at byte position 8 character 日 starts at byte position 9 character 本 starts at byte position 12 character 語 starts at byte position 15 index int(rune) rune char bytes 0 67 U+0043 'C' 43 1 104 U+0068 'h' 68 2 105 U+0069 'i' 69 3 110 U+006E 'n' 6E 4 101 U+0065 'e' 65 5 115 U+0073 's' 73 6 101 U+0065 'e' 65 7 58 U+003A ':' 3A 8 32 U+0020 ' ' 20 9 26085 U+65E5 '日' E6 97 A5 12 26412 U+672C '本' E6 9C AC 15 35486 U+8A9E '語' E8 AA 9E 请将输出结果和 Listing 5.7（for_string.go）进行对比。 我们可以看到，常用英文字符使用 1 个字节表示，而汉字（译者注：严格来说，“Chinese: 日本語”的Chinese应该是Japanese）使用 3 个字符表示。 练习 5.9 以下程序的输出结果是什么？ for i := 0; i 问题 5.2： 请描述以下 for 循环的输出结果： 1. for i := 0; ; i++ { fmt.Println(\"Value of i is now:\", i) } 2. for i := 0; i 3. s := \"\" for ; s != \"aaaaa\"; { fmt.Println(\"Value of s:\", s) s = s + \"a\" } 4. for i, j, s := 0, 5, \"a\"; i 链接 目录 上一节：switch 结构 下一节：Break 与 continue "},"Go入门指南/05.5.html":{"url":"Go入门指南/05.5.html","title":"5","keywords":"","body":"5.5 Break 与 continue 您可以使用 break 语句重写 for2.go 的代码： 示例 5.10 for3.go： for { i = i - 1 fmt.Printf(\"The variable i is now: %d\\n\", i) if i 因此每次迭代都会对条件进行检查（i 一个 break 的作用范围为该语句出现后的最内部的结构，它可以被用于任何形式的 for 循环（计数器、条件判断等）。但在 switch 或 select 语句中（详见第 13 章），break 语句的作用结果是跳过整个代码块，执行后续的代码。 下面的示例中包含了嵌套的循环体（for4.go），break 只会退出最内层的循环： 示例 5.11 for4.go： package main func main() { for i:=0; i5 { break } print(j) } print(\" \") } } 输出： 012345 012345 012345 关键字 continue 忽略剩余的循环体而直接进入下一次循环的过程，但不是无条件执行下一次循环，执行之前依旧需要满足循环的判断条件。 示例 5.12 for5.go： package main func main() { for i := 0; i 输出： 0 1 2 3 4 6 7 8 9 显然，5 被跳过了。 另外，关键字 continue 只能被用于 for 循环中。 链接 目录 上一节：for 结构 下一节：标签与 goto "},"Go入门指南/05.6.html":{"url":"Go入门指南/05.6.html","title":"6","keywords":"","body":"5.6 标签与 goto for、switch 或 select 语句都可以配合标签（label）形式的标识符使用，即某一行第一个以冒号（:）结尾的单词（gofmt 会将后续代码自动移至下一行）。 示例 5.13 for6.go： （标签的名称是大小写敏感的，为了提升可读性，一般建议使用全部大写字母） package main import \"fmt\" func main() { LABEL1: for i := 0; i 本例中，continue 语句指向 LABEL1，当执行到该语句的时候，就会跳转到 LABEL1 标签的位置。 您可以看到当 j==4 和 j==5 的时候，没有任何输出：标签的作用对象为外部循环，因此 i 会直接变成下一个循环的值，而此时 j 的值就被重设为 0，即它的初始值。如果将 continue 改为 break，则不会只退出内层循环，而是直接退出外层循环了。另外，还可以使用 goto 语句和标签配合使用来模拟循环。 示例 5.14 goto.go： package main func main() { i:=0 HERE: print(i) i++ if i==5 { return } goto HERE } 上面的代码会输出 01234。 使用逆向的 goto 会很快导致意大利面条式的代码，所以不应当使用而选择更好的替代方案。 特别注意 使用标签和 goto 语句是不被鼓励的：它们会很快导致非常糟糕的程序设计，而且总有更加可读的替代方案来实现相同的需求。 一个建议使用 goto 语句的示例会在第 15.1 章的 simple_tcp_server.go 中出现：示例中在发生读取错误时，使用 goto 来跳出无限读取循环并关闭相应的客户端链接。 定义但未使用标签会导致编译错误：label … defined and not used。 如果您必须使用 goto，应当只使用正序的标签（标签位于 goto 语句之后），但注意标签和 goto 语句之间不能出现定义新变量的语句，否则会导致编译失败。 示例 5.15 goto2.go： // compile error goto2.go:8: goto TARGET jumps over declaration of b at goto2.go:8 package main import \"fmt\" func main() { a := 1 goto TARGET // compile error b := 9 TARGET: b += a fmt.Printf(\"a is %v *** b is %v\", a, b) } 问题 5.3 请描述下面 for 循环的输出： 1. i := 0 for { //since there are no checks, this is an infinite loop if i >= 3 { break } //break out of this for loop when this condition is met fmt.Println(\"Value of i is:\", i) i++; } fmt.Println(\"A statement just after for loop.\") 2. for i := 0; i 链接 目录 上一节：Break 与 continue 下一章：函数 "},"Go入门指南/06.0.html":{"url":"Go入门指南/06.0.html","title":"0","keywords":"","body":"6.0 函数 函数是 Go 里面的基本代码块：Go 函数的功能非常强大，以至于被认为拥有函数式编程语言的多种特性。在这一章，我们将对 第 4.2.2 节 所简要描述的函数进行详细的讲解。 链接 目录 上一章：标签与 goto 下一节：介绍 "},"Go入门指南/06.10.html":{"url":"Go入门指南/06.10.html","title":"10","keywords":"","body":"6.10 使用闭包调试 当您在分析和调试复杂的程序时，无数个函数在不同的代码文件中相互调用，如果这时候能够准确地知道哪个文件中的具体哪个函数正在执行，对于调试是十分有帮助的。您可以使用 runtime 或 log 包中的特殊函数来实现这样的功能。包 runtime 中的函数 Caller() 提供了相应的信息，因此可以在需要的时候实现一个 where() 闭包函数来打印函数执行的位置： where := func() { _, file, line, _ := runtime.Caller(1) log.Printf(\"%s:%d\", file, line) } where() // some code where() // some more code where() 您也可以设置 log 包中的 flag 参数来实现： log.SetFlags(log.Llongfile) log.Print(\"\") 或使用一个更加简短版本的 where 函数： var where = log.Print func func1() { where() ... some code where() ... some code where() } 链接 目录 上一节：应用闭包：将函数作为返回值 下一节：计算函数执行时间 "},"Go入门指南/06.11.html":{"url":"Go入门指南/06.11.html","title":"11","keywords":"","body":"6.11 计算函数执行时间 有时候，能够知道一个计算执行消耗的时间是非常有意义的，尤其是在对比和基准测试中。最简单的一个办法就是在计算开始之前设置一个起始时候，再由计算结束时的结束时间，最后取出它们的差值，就是这个计算所消耗的时间。想要实现这样的做法，可以使用 time 包中的 Now() 和 Sub 函数： start := time.Now() longCalculation() end := time.Now() delta := end.Sub(start) fmt.Printf(\"longCalculation took this amount of time: %s\\n\", delta) 您可以查看示例 6.20 fibonacci.go 作为实例学习。 如果您对一段代码进行了所谓的优化，请务必对它们之间的效率进行对比再做出最后的判断。在接下来的章节中，我们会学习如何进行有价值的优化操作。 链接 目录 上一节：使用闭包调试 下一节：通过内存缓存来提升性能 "},"Go入门指南/06.12.html":{"url":"Go入门指南/06.12.html","title":"12","keywords":"","body":"6.12 通过内存缓存来提升性能 当在进行大量的计算时，提升性能最直接有效的一种方式就是避免重复计算。通过在内存中缓存和重复利用相同计算的结果，称之为内存缓存。最明显的例子就是生成斐波那契数列的程序（详见第 6.6 和 6.11 节）： 要计算数列中第 n 个数字，需要先得到之前两个数的值，但很明显绝大多数情况下前两个数的值都是已经计算过的。即每个更后面的数都是基于之前计算结果的重复计算，正如示例 6.11 fibonnaci.go 所展示的那样。 而我们要做就是将第 n 个数的值存在数组中索引为 n 的位置（详见第 7 章），然后在数组中查找是否已经计算过，如果没有找到，则再进行计算。 程序 Listing 6.17 - fibonacci_memoization.go 就是依照这个原则实现的，下面是计算到第 40 位数字的性能对比： 普通写法：4.730270 秒 内存缓存：0.001000 秒 内存缓存的优势显而易见，而且您还可以将它应用到其它类型的计算中，例如使用 map（详见第 7 章）而不是数组或切片（Listing 6.21 - fibonacci_memoization.go）： package main import ( \"fmt\" \"time\" ) const LIM = 41 var fibs [LIM]uint64 func main() { var result uint64 = 0 start := time.Now() for i := 0; i 内存缓存的技术在使用计算成本相对昂贵的函数时非常有用（不仅限于例子中的递归），譬如大量进行相同参数的运算。这种技术还可以应用于纯函数中，即相同输入必定获得相同输出的函数。 链接 目录 上一节：计算函数执行时间 下一章：数组与切片 "},"Go入门指南/06.1.html":{"url":"Go入门指南/06.1.html","title":"1","keywords":"","body":"6.1 介绍 每一个程序都包含很多的函数：函数是基本的代码块。 Go是编译型语言，所以函数编写的顺序是无关紧要的；鉴于可读性的需求，最好把 main() 函数写在文件的前面，其他函数按照一定逻辑顺序进行编写（例如函数被调用的顺序）。 编写多个函数的主要目的是将一个需要很多行代码的复杂问题分解为一系列简单的任务（那就是函数）来解决。而且，同一个任务（函数）可以被调用多次，有助于代码重用。 （事实上，好的程序是非常注意DRY原则的，即不要重复你自己（Don't Repeat Yourself），意思是执行特定任务的代码只能在程序里面出现一次。） 当函数执行到代码块最后一行（} 之前）或者 return 语句的时候会退出，其中 return 语句可以带有零个或多个参数；这些参数将作为返回值（参考 第 6.2 节）供调用者使用。简单的 return 语句也可以用来结束 for 死循环，或者结束一个协程（goroutine）。 Go 里面有三种类型的函数： 普通的带有名字的函数 匿名函数或者lambda函数（参考 第 6.8 节） 方法（Methods，参考 第 10.6 节） 除了main()、init()函数外，其它所有类型的函数都可以有参数与返回值。函数参数、返回值以及它们的类型被统称为函数签名。 作为提醒，提前介绍一个语法： 这样是不正确的 Go 代码： func g() { } 它必须是这样的： func g() { } 函数被调用的基本格式如下： pack1.Function(arg1, arg2, …, argn) Function 是 pack1 包里面的一个函数，括号里的是被调用函数的实参（argument）：这些值被传递给被调用函数的形参（parameter，参考 第 6.2 节）。函数被调用的时候，这些实参将被复制（简单而言）然后传递给被调用函数。函数一般是在其他函数里面被调用的，这个其他函数被称为调用函数（calling function）。函数能多次调用其他函数，这些被调用函数按顺序（简单而言）执行，理论上，函数调用其他函数的次数是无穷的（直到函数调用栈被耗尽）。 一个简单的函数调用其他函数的例子： 示例 6.1 greeting.go package main func main() { println(\"In main before calling greeting\") greeting() println(\"In main after calling greeting\") } func greeting() { println(\"In greeting: Hi!!!!!\") } 代码输出： In main before calling greeting In greeting: Hi!!!!! In main after calling greeting 函数可以将其他函数调用作为它的参数，只要这个被调用函数的返回值个数、返回值类型和返回值的顺序与调用函数所需求的实参是一致的，例如： 假设 f1 需要 3 个参数 f1(a, b, c int)，同时 f2 返回 3 个参数 f2(a, b int) (int, int, int)，就可以这样调用 f1：f1(f2(a, b))。 函数重载（function overloading）指的是可以编写多个同名函数，只要它们拥有不同的形参与/或者不同的返回值，在 Go 里面函数重载是不被允许的。这将导致一个编译错误： funcName redeclared in this book, previous declaration at lineno Go 语言不支持这项特性的主要原因是函数重载需要进行多余的类型匹配影响性能；没有重载意味着只是一个简单的函数调度。所以你需要给不同的函数使用不同的名字，我们通常会根据函数的特征对函数进行命名（参考 第 11.12.5 节）。 如果需要申明一个在外部定义的函数，你只需要给出函数名与函数签名，不需要给出函数体： func flushICache(begin, end uintptr) // implemented externally 函数也可以以申明的方式被使用，作为一个函数类型，就像： type binOp func(int, int) int 在这里，不需要函数体 {}。 函数是一等值（first-class value）：它们可以赋值给变量，就像 add := binOp 一样。 这个变量知道自己指向的函数的签名，所以给它赋一个具有不同签名的函数值是不可能的。 函数值（functions value）之间可以相互比较：如果它们引用的是相同的函数或者都是 nil 的话，则认为它们是相同的函数。函数不能在其它函数里面声明（不能嵌套），不过我们可以通过使用匿名函数（参考 第 6.8 节）来破除这个限制。 目前 Go 没有泛型（generic）的概念，也就是说它不支持那种支持多种类型的函数。不过在大部分情况下可以通过接口（interface），特别是空接口与类型选择（type switch，参考 第 11.12 节）与/或者通过使用反射（reflection，参考 第 6.8 节）来实现相似的功能。使用这些技术将导致代码更为复杂、性能更为低下，所以在非常注意性能的的场合，最好是为每一个类型单独创建一个函数，而且代码可读性更强。 链接 目录 上一节：函数（function） 下一节：函数参数与返回值 "},"Go入门指南/06.2.html":{"url":"Go入门指南/06.2.html","title":"2","keywords":"","body":"6.2 函数参数与返回值 函数能够接收参数供自己使用，也可以返回零个或多个值（我们通常把返回多个值称为返回一组值）。相比与 C、C++、Java 和 C#，多值返回是 Go 的一大特性，为我们判断一个函数是否正常执行（参考 第 5.2 节）提供了方便。 我们通过 return 关键字返回一组值。事实上，任何一个有返回值（单个或多个）的函数都必须以 return 或 panic（参考 第 13 章）结尾。 在函数块里面，return 之后的语句都不会执行。如果一个函数需要返回值，那么这个函数里面的每一个代码分支（code-path）都要有 return 语句。 问题 6.1：下面的函数将不会被编译，为什么呢？大家可以试着纠正过来。 func (st *Stack) Pop() int { v := 0 for ix := len(st) - 1; ix >= 0; ix-- { if v = st[ix]; v != 0 { st[ix] = 0 return v } } } 函数定义时，它的形参一般是有名字的，不过我们也可以定义没有形参名的函数，只有相应的形参类型，就像这样：func f(int, int, float64)。 没有参数的函数通常被称为 niladic 函数（niladic function），就像 main.main()。 6.2.1 按值传递（call by value） 按引用传递（call by reference） Go 默认使用按值传递来传递参数，也就是传递参数的副本。函数接收参数副本之后，在使用变量的过程中可能对副本的值进行更改，但不会影响到原来的变量，比如 Function(arg1)。 如果你希望函数可以直接修改参数的值，而不是对参数的副本进行操作，你需要将参数的地址（变量名前面添加&符号，比如 &variable）传递给函数，这就是按引用传递，比如 Function(&arg1)，此时传递给函数的是一个指针。如果传递给函数的是一个指针，指针的值（一个地址）会被复制，但指针的值所指向的地址上的值不会被复制；我们可以通过这个指针的值来修改这个值所指向的地址上的值。（译者注：指针也是变量类型，有自己的地址和值，通常指针的值指向一个变量的地址。所以，按引用传递也是按值传递。） 几乎在任何情况下，传递指针（一个32位或者64位的值）的消耗都比传递副本来得少。 在函数调用时，像切片（slice）、字典（map）、接口（interface）、通道（channel）这样的引用类型都是默认使用引用传递（即使没有显式的指出指针）。 有些函数只是完成一个任务，并没有返回值。我们仅仅是利用了这种函数的副作用，就像输出文本到终端，发送一个邮件或者是记录一个错误等。 但是绝大部分的函数还是带有返回值的。 如下，simple_function.go 里的 MultiPly3Nums 函数带有三个形参，分别是 a、b、c，还有一个 int 类型的返回值（被注释的代码具有和未注释部分同样的功能，只是多引入了一个本地变量）： 示例 6.2 simple_function.go package main import \"fmt\" func main() { fmt.Printf(\"Multiply 2 * 5 * 6 = %d\\n\", MultiPly3Nums(2, 5, 6)) // var i1 int = MultiPly3Nums(2, 5, 6) // fmt.Printf(\"MultiPly 2 * 5 * 6 = %d\\n\", i1) } func MultiPly3Nums(a int, b int, c int) int { // var product int = a * b * c // return product return a * b * c } 输出显示： Multiply 2 * 5 * 6 = 60 如果一个函数需要返回四到五个值，我们可以传递一个切片给函数（如果返回值具有相同类型）或者是传递一个结构体（如果返回值具有不同的类型）。因为传递一个指针允许直接修改变量的值，消耗也更少。 问题 6.2： 如下的两个函数调用有什么不同： (A) func DoSomething(a *A) { b = a } (B) func DoSomething(a A) { b = &a } 6.2.2 命名的返回值（named return variables） 如下，multiple_return.go 里的函数带有一个 int 参数，返回两个 int 值；其中一个函数的返回值在函数调用时就已经被赋予了一个初始零值。 getX2AndX3 与 getX2AndX3_2 两个函数演示了如何使用非命名返回值与命名返回值的特性。当需要返回多个非命名返回值时，需要使用 () 把它们括起来，比如 (int, int)。 命名返回值作为结果形参（result parameters）被初始化为相应类型的零值，当需要返回的时候，我们只需要一条简单的不带参数的return语句。需要注意的是，即使只有一个命名返回值，也需要使用 () 括起来（参考 第 6.6 节的 fibonacci.go 函数）。 示例 6.3 multiple_return.go package main import \"fmt\" var num int = 10 var numx2, numx3 int func main() { numx2, numx3 = getX2AndX3(num) PrintValues() numx2, numx3 = getX2AndX3_2(num) PrintValues() } func PrintValues() { fmt.Printf(\"num = %d, 2x num = %d, 3x num = %d\\n\", num, numx2, numx3) } func getX2AndX3(input int) (int, int) { return 2 * input, 3 * input } func getX2AndX3_2(input int) (x2 int, x3 int) { x2 = 2 * input x3 = 3 * input // return x2, x3 return } 输出结果： num = 10, 2x num = 20, 3x num = 30 num = 10, 2x num = 20, 3x num = 30 警告： return 或 return var 都是可以的。 不过 return var = expression（表达式） 会引发一个编译错误：syntax error: unexpected =, expecting semicolon or newline or }。 即使函数使用了命名返回值，你依旧可以无视它而返回明确的值。 任何一个非命名返回值（使用非命名返回值是很糟的编程习惯）在 return 语句里面都要明确指出包含返回值的变量或是一个可计算的值（就像上面警告所指出的那样）。 尽量使用命名返回值：会使代码更清晰、更简短，同时更加容易读懂。 练习 6.1 mult_returnval.go 编写一个函数，接收两个整数，然后返回它们的和、积与差。编写两个版本，一个是非命名返回值，一个是命名返回值。 练习 6.2 error_returnval.go 编写一个名字为 MySqrt 的函数，计算一个 float64 类型浮点数的平方根，如果参数是一个负数的话将返回一个错误。编写两个版本，一个是非命名返回值，一个是命名返回值。 6.2.3 空白符（blank identifier） 空白符用来匹配一些不需要的值，然后丢弃掉，下面的 blank_identifier.go 就是很好的例子。 ThreeValues 是拥有三个返回值的不需要任何参数的函数，在下面的例子中，我们将第一个与第三个返回值赋给了 i1 与 f1。第二个返回值赋给了空白符 _，然后自动丢弃掉。 示例 6.4 blank_identifier.go package main import \"fmt\" func main() { var i1 int var f1 float32 i1, _, f1 = ThreeValues() fmt.Printf(\"The int: %d, the float: %f \\n\", i1, f1) } func ThreeValues() (int, int, float32) { return 5, 6, 7.5 } 输出结果： The int: 5, the float: 7.500000 另外一个示例，函数接收两个参数，比较它们的大小，然后按小-大的顺序返回这两个数，示例代码为minmax.go。 示例 6.5 minmax.go package main import \"fmt\" func main() { var min, max int min, max = MinMax(78, 65) fmt.Printf(\"Minmium is: %d, Maximum is: %d\\n\", min, max) } func MinMax(a int, b int) (min int, max int) { if a 输出结果： Minimum is: 65, Maximum is 78 6.2.4 改变外部变量（outside variable） 传递指针给函数不但可以节省内存（因为没有复制变量的值），而且赋予了函数直接修改外部变量的能力，所以被修改的变量不再需要使用 return 返回。如下的例子，reply 是一个指向 int 变量的指针，通过这个指针，我们在函数内修改了这个 int 变量的数值。 示例 6.6 side_effect.go package main import ( \"fmt\" ) // this function changes reply: func Multiply(a, b int, reply *int) { *reply = a * b } func main() { n := 0 reply := &n Multiply(10, 5, reply) fmt.Println(\"Multiply:\", *reply) // Multiply: 50 } 这仅仅是个指导性的例子，当需要在函数内改变一个占用内存比较大的变量时，性能优势就更加明显了。然而，如果不小心使用的话，传递一个指针很容易引发一些不确定的事，所以，我们要十分小心那些可以改变外部变量的函数，在必要时，需要添加注释以便其他人能够更加清楚的知道函数里面到底发生了什么。 链接 目录 上一节：函数介绍 下一节：传递变长参数 "},"Go入门指南/06.3.html":{"url":"Go入门指南/06.3.html","title":"3","keywords":"","body":"6.3 传递变长参数 如果函数的最后一个参数是采用 ...type 的形式，那么这个函数就可以处理一个变长的参数，这个长度可以为 0，这样的函数称为变参函数。 func myFunc(a, b, arg ...int) {} 这个函数接受一个类似某个类型的 slice 的参数（详见第 7 章），该参数可以通过第 5.4.4 节中提到的 for 循环结构迭代。 示例函数和调用： func Greeting(prefix string, who ...string) Greeting(\"hello:\", \"Joe\", \"Anna\", \"Eileen\") 在 Greeting 函数中，变量 who 的值为 []string{\"Joe\", \"Anna\", \"Eileen\"}。 如果参数被存储在一个 slice 类型的变量 slice 中，则可以通过 slice... 的形式来传递参数，调用变参函数。 示例 6.7 varnumpar.go package main import \"fmt\" func main() { x := min(1, 3, 2, 0) fmt.Printf(\"The minimum is: %d\\n\", x) slice := []int{7,9,3,5,1} x = min(slice...) fmt.Printf(\"The minimum in the slice is: %d\", x) } func min(s ...int) int { if len(s)==0 { return 0 } min := s[0] for _, v := range s { if v 输出： The minimum is: 0 The minimum in the slice is: 1 练习 6.3 varargs.go 写一个函数，该函数接受一个变长参数并对每个元素进行换行打印。 一个接受变长参数的函数可以将这个参数作为其它函数的参数进行传递： func F1(s ...string) { F2(s...) F3(s) } func F2(s ...string) { } func F3(s []string) { } 变长参数可以作为对应类型的 slice 进行二次传递。 但是如果变长参数的类型并不是都相同的呢？使用 5 个参数来进行传递并不是很明智的选择，有 2 种方案可以解决这个问题： 使用结构（详见第 10 章）： 定义一个结构类型，假设它叫 Options，用以存储所有可能的参数： type Options struct { par1 type1, par2 type2, ... } 函数 F1 可以使用正常的参数 a 和 b，以及一个没有任何初始化的 Options 结构： F1(a, b, Options {})。如果需要对选项进行初始化，则可以使用 F1(a, b, Options {par1:val1, par2:val2})。 使用空接口： 如果一个变长参数的类型没有被指定，则可以使用默认的空接口 interface{}，这样就可以接受任何类型的参数（详见第 11.9 节）。该方案不仅可以用于长度未知的参数，还可以用于任何不确定类型的参数。一般而言我们会使用一个 for-range 循环以及 switch 结构对每个参数的类型进行判断： func typecheck(..,..,values … interface{}) { for _, value := range values { switch v := value.(type) { case int: … case float: … case string: … case bool: … default: … } } } 链接 目录 上一节：函数参数与返回值 下一节：defer 和追踪 "},"Go入门指南/06.4.html":{"url":"Go入门指南/06.4.html","title":"4","keywords":"","body":"6.4 defer 和追踪 关键字 defer 允许我们推迟到函数返回之前（或任意位置执行 return 语句之后）一刻才执行某个语句或函数（为什么要在返回之后才执行这些语句？因为 return 语句同样可以包含一些操作，而不是单纯地返回某个值）。 关键字 defer 的用法类似于面向对象编程语言 Java 和 C# 的 finally 语句块，它一般用于释放某些已分配的资源。 示例 6.8 defer.go： package main import \"fmt\" func main() { function1() } func function1() { fmt.Printf(\"In function1 at the top\\n\") defer function2() fmt.Printf(\"In function1 at the bottom!\\n\") } func function2() { fmt.Printf(\"Function2: Deferred until the end of the calling function!\") } 输出： In Function1 at the top In Function1 at the bottom! Function2: Deferred until the end of the calling function! 请将 defer 关键字去掉并对比输出结果。 使用 defer 的语句同样可以接受参数，下面这个例子就会在执行 defer 语句时打印 0： func a() { i := 0 defer fmt.Println(i) i++ return } 当有多个 defer 行为被注册时，它们会以逆序执行（类似栈，即后进先出）： func f() { for i := 0; i 上面的代码将会输出：4 3 2 1 0。 关键字 defer 允许我们进行一些函数执行完成后的收尾工作，例如： 关闭文件流 （详见 第 12.2 节） // open a file defer file.Close() 解锁一个加锁的资源 （详见 第 9.3 节） mu.Lock() defer mu.Unlock() 打印最终报告 printHeader() defer printFooter() 关闭数据库链接 // open a database connection defer disconnectFromDB() 合理使用 defer 语句能够使得代码更加简洁。 以下代码模拟了上面描述的第 4 种情况： package main import \"fmt\" func main() { doDBOperations() } func connectToDB() { fmt.Println(\"ok, connected to db\") } func disconnectFromDB() { fmt.Println(\"ok, disconnected from db\") } func doDBOperations() { connectToDB() fmt.Println(\"Defering the database disconnect.\") defer disconnectFromDB() //function called here with defer fmt.Println(\"Doing some DB operations ...\") fmt.Println(\"Oops! some crash or network error ...\") fmt.Println(\"Returning from function here!\") return //terminate the program // deferred function executed here just before actually returning, even if // there is a return or abnormal termination before } 输出： ok, connected to db Defering the database disconnect. Doing some DB operations ... Oops! some crash or network error ... Returning from function here! ok, disconnected from db 使用 defer 语句实现代码追踪 一个基础但十分实用的实现代码执行追踪的方案就是在进入和离开某个函数打印相关的消息，即可以提炼为下面两个函数： func trace(s string) { fmt.Println(\"entering:\", s) } func untrace(s string) { fmt.Println(\"leaving:\", s) } 以下代码展示了何时调用这两个函数： 示例 6.10 defer_tracing.go: package main import \"fmt\" func trace(s string) { fmt.Println(\"entering:\", s) } func untrace(s string) { fmt.Println(\"leaving:\", s) } func a() { trace(\"a\") defer untrace(\"a\") fmt.Println(\"in a\") } func b() { trace(\"b\") defer untrace(\"b\") fmt.Println(\"in b\") a() } func main() { b() } 输出： entering: b in b entering: a in a leaving: a leaving: b 上面的代码还可以修改为更加简便的版本（示例 6.11 defer_tracing2.go）： package main import \"fmt\" func trace(s string) string { fmt.Println(\"entering:\", s) return s } func un(s string) { fmt.Println(\"leaving:\", s) } func a() { defer un(trace(\"a\")) fmt.Println(\"in a\") } func b() { defer un(trace(\"b\")) fmt.Println(\"in b\") a() } func main() { b() } 使用 defer 语句来记录函数的参数与返回值 下面的代码展示了另一种在调试时使用 defer 语句的手法（示例 6.12 defer_logvalues.go）： package main import ( \"io\" \"log\" ) func func1(s string) (n int, err error) { defer func() { log.Printf(\"func1(%q) = %d, %v\", s, n, err) }() return 7, io.EOF } func main() { func1(\"Go\") } 输出： Output: 2011/10/04 10:46:11 func1(\"Go\") = 7, EOF 链接 目录 上一节：传递变长参数 下一节：内置函数 "},"Go入门指南/06.5.html":{"url":"Go入门指南/06.5.html","title":"5","keywords":"","body":"6.5 内置函数 Go 语言拥有一些不需要进行导入操作就可以使用的内置函数。它们有时可以针对不同的类型进行操作，例如：len、cap 和 append，或必须用于系统级的操作，例如：panic。因此，它们需要直接获得编译器的支持。 以下是一个简单的列表，我们会在后面的章节中对它们进行逐个深入的讲解。 名称 说明 close 用于管道通信 len、cap len 用于返回某个类型的长度或数量（字符串、数组、切片、map 和管道）；cap 是容量的意思，用于返回某个类型的最大容量（只能用于切片和 map） new、make new 和 make 均是用于分配内存：new 用于值类型和用户定义的类型，如自定义结构，make 用于内置引用类型（切片、map 和管道）。它们的用法就像是函数，但是将类型作为参数：new(type)、make(type)。new(T) 分配类型 T 的零值并返回其地址，也就是指向类型 T 的指针（详见第 10.1 节）。它也可以被用于基本类型：v := new(int)。make(T) 返回类型 T 的初始化之后的值，因此它比 new 进行更多的工作（详见第 7.2.3/4 节、第 8.1.1 节和第 14.2.1 节）new() 是一个函数，不要忘记它的括号 copy、append 用于复制和连接切片 panic、recover 两者均用于错误处理机制 print、println 底层打印函数（详见第 4.2 节），在部署环境中建议使用 fmt 包 complex、real imag 用于创建和操作复数（详见第 4.5.2.2 节） 链接 目录 上一节：defer 和追踪 下一节：递归函数 "},"Go入门指南/06.6.html":{"url":"Go入门指南/06.6.html","title":"6","keywords":"","body":"6.6 递归函数 当一个函数在其函数体内调用自身，则称之为递归。最经典的例子便是计算斐波那契数列，即前两个数为1，从第三个数开始每个数均为前两个数之和。 数列如下所示： 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, … 下面的程序可用于生成该数列（示例 6.13 fibonacci.go）： package main import \"fmt\" func main() { result := 0 for i := 0; i 输出： fibonacci(0) is: 1 fibonacci(1) is: 1 fibonacci(2) is: 2 fibonacci(3) is: 3 fibonacci(4) is: 5 fibonacci(5) is: 8 fibonacci(6) is: 13 fibonacci(7) is: 21 fibonacci(8) is: 34 fibonacci(9) is: 55 fibonacci(10) is: 89 许多问题都可以使用优雅的递归来解决，比如说著名的快速排序算法。 在使用递归函数时经常会遇到的一个重要问题就是栈溢出：一般出现在大量的递归调用导致的程序栈内存分配耗尽。这个问题可以通过一个名为懒惰求值的技术解决，在 Go 语言中，我们可以使用管道（channel）和 goroutine（详见第 14.8 节）来实现。练习 14.12 也会通过这个方案来优化斐波那契数列的生成问题。 Go 语言中也可以使用相互调用的递归函数：多个函数之间相互调用形成闭环。因为 Go 语言编译器的特殊性，这些函数的声明顺序可以是任意的。下面这个简单的例子展示了函数 odd 和 even 之间的相互调用（示例 6.14 mut_recurs.go）： package main import ( \"fmt\" ) func main() { fmt.Printf(\"%d is even: is %t\\n\", 16, even(16)) // 16 is even: is true fmt.Printf(\"%d is odd: is %t\\n\", 17, odd(17)) // 17 is odd: is true fmt.Printf(\"%d is odd: is %t\\n\", 18, odd(18)) // 18 is odd: is false } func even(nr int) bool { if nr == 0 { return true } return odd(RevSign(nr) - 1) } func odd(nr int) bool { if nr == 0 { return false } return even(RevSign(nr) - 1) } func RevSign(nr int) int { if nr 练习题 练习 6.4 重写本节中生成斐波那契数列的程序并返回两个命名返回值（详见第 6.2 节），即数列中的位置和对应的值，例如 5 与 4，89 与 10。 练习 6.5 使用递归函数从 10 打印到 1。 练习 6.6 实现一个输出前 30 个整数的阶乘的程序。 n! 的阶乘定义为：n! = n * (n-1)!, 0! = 1，因此它非常适合使用递归函数来实现。 然后，使用命名返回值来实现这个程序的第二个版本。 特别注意的是，使用 int 类型最多只能计算到 12 的阶乘，因为一般情况下 int 类型的大小为 32 位，继续计算会导致溢出错误。那么，如何才能解决这个问题呢？ 最好的解决方案就是使用 big 包（详见第 9.4 节）。 链接 目录 上一节：内置函数 下一节：将函数作为参数 "},"Go入门指南/06.7.html":{"url":"Go入门指南/06.7.html","title":"7","keywords":"","body":"6.7 将函数作为参数 函数可以作为其它函数的参数进行传递，然后在其它函数内调用执行，一般称之为回调。下面是一个将函数作为参数的简单例子（function_parameter.go）： package main import ( \"fmt\" ) func main() { callback(1, Add) } func Add(a, b int) { fmt.Printf(\"The sum of %d and %d is: %d\\n\", a, b, a+b) } func callback(y int, f func(int, int)) { f(y, 2) // this becomes Add(1, 2) } 输出： The sum of 1 and 2 is: 3 将函数作为参数的最好的例子是函数 strings.IndexFunc()： 该函数的签名是 func IndexFunc(s string, f func(c int) bool) int，它的返回值是在函数 f(c) 返回 true、-1 或从未返回时的索引值。 例如 strings.IndexFunc(line, unicode.IsSpace) 就会返回 line 中第一个空白字符的索引值。当然，您也可以书写自己的函数： func IsAscii(c int) bool { if c > 255 { return false } return true } 在第 14.10.1 节中，我们将会根据一个客户端/服务端程序作为示例对这个用法进行深入讨论。 type binOp func(a, b int) int func run(op binOp, req *Request) { … } 练习 6.7 包 strings 中的 Map 函数和 strings.IndexFunc() 一样都是非常好的使用例子。请学习它的源代码并基于该函数书写一个程序，要求将指定文本内的所有非 ASCII 字符替换成 ? 或空格。您需要怎么做才能删除这些字符呢？ 链接 目录 上一节：递归函数 下一节：闭包 "},"Go入门指南/06.8.html":{"url":"Go入门指南/06.8.html","title":"8","keywords":"","body":"6.8 闭包 当我们不希望给函数起名字的时候，可以使用匿名函数，例如：func(x, y int) int { return x + y }。 这样的一个函数不能够独立存在（编译器会返回错误：non-declaration statement outside function body），但可以被赋值于某个变量，即保存函数的地址到变量中：fplus := func(x, y int) int { return x + y }，然后通过变量名对函数进行调用：fplus(3,4)。 当然，您也可以直接对匿名函数进行调用：func(x, y int) int { return x + y } (3, 4)。 下面是一个计算从 1 到 1 百万整数的总和的匿名函数： func() { sum := 0 for i := 1; i 表示参数列表的第一对括号必须紧挨着关键字 func，因为匿名函数没有名称。花括号 {} 涵盖着函数体，最后的一对括号表示对该匿名函数的调用。 下面的例子展示了如何将匿名函数赋值给变量并对其进行调用（function_literal.go）： package main import \"fmt\" func main() { f() } func f() { for i := 0; i 输出： 0 - g is of type func(int) and has value 0x681a80 1 - g is of type func(int) and has value 0x681b00 2 - g is of type func(int) and has value 0x681ac0 3 - g is of type func(int) and has value 0x681400 我们可以看到变量 g 代表的是 func(int)，变量的值是一个内存地址。 所以我们实际上拥有的是一个函数值：匿名函数可以被赋值给变量并作为值使用。 练习 6.8 在 main 函数中写一个用于打印 Hello World 字符串的匿名函数并赋值给变量 fv，然后调用该函数并打印变量 fv 的类型。 匿名函数像所有函数一样可以接受或不接受参数。下面的例子展示了如何传递参数到匿名函数中： func (u string) { fmt.Println(u) … }(v) 请学习以下示例并思考（return_defer.go）：函数 f 返回时，变量 ret 的值是什么？ package main import \"fmt\" func f() (ret int) { defer func() { ret++ }() return 1 } func main() { fmt.Println(f()) } 变量 ret 的值为 2，因为 ret++ 是在执行 return 1 语句后发生的。 这可用于在返回语句之后修改返回的 error 时使用。 defer 语句和匿名函数 关键字 defer （详见第 6.4 节）经常配合匿名函数使用，它可以用于改变函数的命名返回值。 匿名函数还可以配合 go 关键字来作为 goroutine 使用（详见第 14 章和第 16.9 节）。 匿名函数同样被称之为闭包（函数式语言的术语）：它们被允许调用定义在其它环境下的变量。闭包可使得某个函数捕捉到一些外部状态，例如：函数被创建时的状态。另一种表示方式为：一个闭包继承了函数所声明时的作用域。这种状态（作用域内的变量）都被共享到闭包的环境中，因此这些变量可以在闭包中被操作，直到被销毁，详见第 6.9 节中的示例。闭包经常被用作包装函数：它们会预先定义好 1 个或多个参数以用于包装，详见下一节中的示例。另一个不错的应用就是使用闭包来完成更加简洁的错误检查（详见第 16.10.2 节）。 链接 目录 上一节：将函数作为参数 下一节：应用闭包：将函数作为返回值 "},"Go入门指南/06.9.html":{"url":"Go入门指南/06.9.html","title":"9","keywords":"","body":"6.9 应用闭包：将函数作为返回值 在程序 function_return.go 中我们将会看到函数 Add2 和 Adder 均会返回签名为 func(b int) int 的函数： func Add2() (func(b int) int) func Adder(a int) (func(b int) int) 函数 Add2 不接受任何参数，但函数 Adder 接受一个 int 类型的整数作为参数。 我们也可以将 Adder 返回的函数存到变量中（function_return.go）。 package main import \"fmt\" func main() { // make an Add2 function, give it a name p2, and call it: p2 := Add2() fmt.Printf(\"Call Add2 for 3 gives: %v\\n\", p2(3)) // make a special Adder function, a gets value 2: TwoAdder := Adder(2) fmt.Printf(\"The result is: %v\\n\", TwoAdder(3)) } func Add2() func(b int) int { return func(b int) int { return b + 2 } } func Adder(a int) func(b int) int { return func(b int) int { return a + b } } 输出： Call Add2 for 3 gives: 5 The result is: 5 下例为一个略微不同的实现（function_closure.go）： package main import \"fmt\" func main() { var f = Adder() fmt.Print(f(1), \" - \") fmt.Print(f(20), \" - \") fmt.Print(f(300)) } func Adder() func(int) int { var x int return func(delta int) int { x += delta return x } } 函数 Adder() 现在被赋值到变量 f 中（类型为 func(int) int）。 输出： 1 - 21 - 321 三次调用函数 f 的过程中函数 Adder() 中变量 delta 的值分别为：1、20 和 300。 我们可以看到，在多次调用中，变量 x 的值是被保留的，即 0 + 1 = 1，然后 1 + 20 = 21，最后 21 + 300 = 321：闭包函数保存并积累其中的变量的值，不管外部函数退出与否，它都能够继续操作外部函数中的局部变量。 这些局部变量同样可以是参数，例如之前例子中的 Adder(as int)。 这些例子清楚地展示了如何在 Go 语言中使用闭包。 在闭包中使用到的变量可以是在闭包函数体内声明的，也可以是在外部函数声明的： var g int go func(i int) { s := 0 for j := 0; j 这样闭包函数就能够被应用到整个集合的元素上，并修改它们的值。然后这些变量就可以用于表示或计算全局或平均值。 练习 6.9 不使用递归但使用闭包改写第 6.6 节中的斐波那契数列程序。 练习 6.10 学习并理解以下程序的工作原理： 一个返回值为另一个函数的函数可以被称之为工厂函数，这在您需要创建一系列相似的函数的时候非常有用：书写一个工厂函数而不是针对每种情况都书写一个函数。下面的函数演示了如何动态返回追加后缀的函数： func MakeAddSuffix(suffix string) func(string) string { return func(name string) string { if !strings.HasSuffix(name, suffix) { return name + suffix } return name } } 现在，我们可以生成如下函数： addBmp := MakeAddSuffix(“.bmp”) addJpeg := MakeAddSuffix(“.jpeg”) 然后调用它们： addBmp(\"file\") // returns: file.bmp addJpeg(\"file\") // returns: file.jpeg 可以返回其它函数的函数和接受其它函数作为参数的函数均被称之为高阶函数，是函数式语言的特点。我们已经在第 6.7 中得知函数也是一种值，因此很显然 Go 语言具有一些函数式语言的特性。闭包在 Go 语言中非常常见，常用于 goroutine 和管道操作（详见第 14.8-14.9 节）。在第 11.14 节的程序中，我们将会看到 Go 语言中的函数在处理混合对象时的强大能力。 链接 目录 上一节：闭包 下一节：使用闭包调试 "},"Go入门指南/07.0.html":{"url":"Go入门指南/07.0.html","title":"0","keywords":"","body":"7.0 数组与切片 这章我们开始剖析 容器, 它是可以包含大量条目（item）的数据结构, 例如数组、切片和 map。从这看到 Go 明显受到 Python 的影响。 以 [] 符号标识的数组类型几乎在所有的编程语言中都是一个基本主力。Go 语言中的数组也是类似的，只是有一些特点。Go 没有 C 那么灵活，但是拥有切片（slice）类型。这是一种建立在 Go 语言数组类型之上的抽象，要想理解切片我们必须先理解数组。数组有特定的用处，但是却有一些呆板，所以在 Go 语言的代码里并不是特别常见。相对的，切片确实随处可见的。它们构建在数组之上并且提供更强大的能力和便捷。 链接 目录 上一节：通过内存缓存来提升性能 下一节：声明和初始化 "},"Go入门指南/07.1.html":{"url":"Go入门指南/07.1.html","title":"1","keywords":"","body":"7.1 声明和初始化 7.1.1 概念 数组是具有相同 唯一类型 的一组已编号且长度固定的数据项序列（这是一种同构的数据结构）；这种类型可以是任意的原始类型例如整型、字符串或者自定义类型。数组长度必须是一个常量表达式，并且必须是一个非负整数。数组长度也是数组类型的一部分，所以[5]int和[10]int是属于不同类型的。数组的编译时值初始化是按照数组顺序完成的（如下）。 注意事项 如果我们想让数组元素类型为任意类型的话可以使用空接口作为类型（参考 第 11 章）。当使用值时我们必须先做一个类型判断（参考 第 11 章）。 数组元素可以通过 索引（位置）来读取（或者修改），索引从 0 开始，第一个元素索引为 0，第二个索引为 1，以此类推。（数组以 0 开始在所有类 C 语言中是相似的）。元素的数目，也称为长度或者数组大小必须是固定的并且在声明该数组时就给出（编译时需要知道数组长度以便分配内存）；数组长度最大为 2Gb。 声明的格式是： var identifier [len]type 例如： var arr1 [5]int 在内存中的结构是： 每个元素是一个整型值，当声明数组时所有的元素都会被自动初始化为默认值 0。 arr1 的长度是 5，索引范围从 0 到 len(arr1)-1。 第一个元素是 arr1[0]，第三个元素是 arr1[2]；总体来说索引 i 代表的元素是 arr1[i]，最后一个元素是 arr1[len(arr1)-1]。 对索引项为 i 的数组元素赋值可以这么操作：arr[i] = value，所以数组是 可变的。 只有有效的索引可以被使用，当使用等于或者大于 len(arr1) 的索引时：如果编译器可以检测到，会给出索引超限的提示信息；如果检测不到的话编译会通过而运行时会 panic:（参考 第 13 章） runtime error: index out of range 由于索引的存在，遍历数组的方法自然就是使用 for 结构: 通过 for 初始化数组项 通过 for 打印数组元素 通过 for 依次处理元素 示例 7.1 for_arrays.go package main import \"fmt\" func main() { var arr1 [5]int for i:=0; i 输出结果： Array at index 0 is 0 Array at index 1 is 2 Array at index 2 is 4 Array at index 3 is 6 Array at index 4 is 8 for 循环中的条件非常重要：i ，如果写成 i 的话会产生越界错误。 IDIOM: for i:=0; i 也可以使用 for-range 的生成方式： IDIOM: for i,_:= range arr1 { ... } 在这里i也是数组的索引。当然这两种 for 结构对于切片（slices）（参考 第 7 章）来说也同样适用。 问题 7.1 下面代码段的输出是什么？ a := [...]string{\"a\", \"b\", \"c\", \"d\"} for i := range a { fmt.Println(\"Array item\", i, \"is\", a[i]) } Go 语言中的数组是一种 值类型（不像 C/C++ 中是指向首元素的指针），所以可以通过 new() 来创建： var arr1 = new([5]int)。 那么这种方式和 var arr2 [5]int 的区别是什么呢？arr1 的类型是 *[5]int，而 arr2的类型是 [5]int。 这样的结果就是当把一个数组赋值给另一个时，需要在做一次数组内存的拷贝操作。例如： arr2 := *arr1 arr2[2] = 100 这样两个数组就有了不同的值，在赋值后修改 arr2 不会对 arr1 生效。 所以在函数中数组作为参数传入时，如 func1(arr2)，会产生一次数组拷贝，func1 方法不会修改原始的数组 arr2。 如果你想修改原数组，那么 arr2 必须通过&操作符以引用方式传过来，例如 func1(&arr2），下面是一个例子 示例 7.2 pointer_array.go: package main import \"fmt\" func f(a [3]int) { fmt.Println(a) } func fp(a *[3]int) { fmt.Println(a) } func main() { var ar [3]int f(ar) // passes a copy of ar fp(&ar) // passes a pointer to ar } 输出结果： [0 0 0] &[0 0 0] 另一种方法就是生成数组切片并将其传递给函数（详见第 7.1.4 节）。 练习 练习7.1：array_value.go: 证明当数组赋值时，发生了数组内存拷贝。 练习7.2：for_array.go: 写一个循环并用下标给数组赋值（从 0 到 15）并且将数组打印在屏幕上。 练习7.3：fibonacci_array.go: 在第 6.6 节我们看到了一个递归计算 Fibonacci 数值的方法。但是通过数组我们可以更快的计算出 Fibonacci 数。完成该方法并打印出前 50 个 Fibonacci 数字。 7.1.2 数组常量 如果数组值已经提前知道了，那么可以通过 数组常量 的方法来初始化数组，而不用依次使用 []= 方法（所有的组成元素都有相同的常量语法）。 示例 7.3 array_literals.go package main import \"fmt\" func main() { // var arrAge = [5]int{18, 20, 15, 22, 16} // var arrLazy = [...]int{5, 6, 7, 8, 22} // var arrLazy = []int{5, 6, 7, 8, 22} var arrKeyValue = [5]string{3: \"Chris\", 4: \"Ron\"} // var arrKeyValue = []string{3: \"Chris\", 4: \"Ron\"} for i:=0; i 第一种变化： var arrAge = [5]int{18, 20, 15, 22, 16} 注意 [5]int 可以从左边起开始忽略：[10]int {1, 2, 3} :这是一个有 10 个元素的数组，除了前三个元素外其他元素都为 0。 第二种变化： var arrLazy = [...]int{5, 6, 7, 8, 22} ... 可同样可以忽略，从技术上说它们其实变化成了切片。 第三种变化：key: value syntax var arrKeyValue = [5]string{3: \"Chris\", 4: \"Ron\"} 只有索引 3 和 4 被赋予实际的值，其他元素都被设置为空的字符串，所以输出结果为： Person at 0 is Person at 1 is Person at 2 is Person at 3 is Chris Person at 4 is Ron 在这里数组长度同样可以写成 ... 或者直接忽略。 你可以取任意数组常量的地址来作为指向新实例的指针。 示例 7.4 pointer_array2.go package main import \"fmt\" func fp(a *[3]int) { fmt.Println(a) } func main() { for i := 0; i 输出结果： &[0 0 0] &[1 1 1] &[2 4 8] 几何点（或者数学向量）是一个使用数组的经典例子。为了简化代码通常使用一个别名： type Vector3D [3]float32 var vec Vector3D 7.1.3 多维数组 数组通常是一维的，但是可以用来组装成多维数组，例如：[3][5]int，[2][2][2]float64。 内部数组总是长度相同的。Go 语言的多维数组是矩形式的（唯一的例外是切片的数组，参见第 7.2.5 节）。 示例 7.5 multidim_array.go package main const ( WIDTH = 1920 HEIGHT = 1080 ) type pixel int var screen [WIDTH][HEIGHT]pixel func main() { for y := 0; y 7.1.4 将数组传递给函数 把一个大数组传递给函数会消耗很多内存。有两种方法可以避免这种现象： 传递数组的指针 使用数组的切片 接下来的例子阐明了第一种方法： 示例 7.6 array_sum.go package main import \"fmt\" func main() { array := [3]float64{7.0, 8.5, 9.1} x := Sum(&array) // Note the explicit address-of operator // to pass a pointer to the array fmt.Printf(\"The sum of the array is: %f\", x) } func Sum(a *[3]float64) (sum float64) { for _, v := range a { // derefencing *a to get back to the array is not necessary! sum += v } return } 输出结果： The sum of the array is: 24.600000 但这在 Go 中并不常用，通常使用切片（参考 第 7.2 节）。 链接 目录 上一节：数组与切片 下一节：切片 "},"Go入门指南/07.2.html":{"url":"Go入门指南/07.2.html","title":"2","keywords":"","body":"7.2 切片 7.2.1 概念 切片（slice）是对数组一个连续片段的引用（该数组我们称之为相关数组，通常是匿名的），所以切片是一个引用类型（因此更类似于 C/C++ 中的数组类型，或者 Python 中的 list 类型）。这个片段可以是整个数组，或者是由起始和终止索引标识的一些项的子集。需要注意的是，终止索引标识的项不包括在切片内。切片提供了一个相关数组的动态窗口。 切片是可索引的，并且可以由 len() 函数获取长度。 给定项的切片索引可能比相关数组的相同元素的索引小。和数组不同的是，切片的长度可以在运行时修改，最小为 0 最大为相关数组的长度：切片是一个 长度可变的数组。 切片提供了计算容量的函数 cap() 可以测量切片最长可以达到多少：它等于切片的长度 + 数组除切片之外的长度。如果 s 是一个切片，cap(s) 就是从 s[0] 到数组末尾的数组长度。切片的长度永远不会超过它的容量，所以对于 切片 s 来说该不等式永远成立：0 。 多个切片如果表示同一个数组的片段，它们可以共享数据；因此一个切片和相关数组的其他切片是共享存储的，相反，不同的数组总是代表不同的存储。数组实际上是切片的构建块。 优点 因为切片是引用，所以它们不需要使用额外的内存并且比使用数组更有效率，所以在 Go 代码中 切片比数组更常用。 声明切片的格式是： var identifier []type（不需要说明长度）。 一个切片在未初始化之前默认为 nil，长度为 0。 切片的初始化格式是：var slice1 []type = arr1[start:end]。 这表示 slice1 是由数组 arr1 从 start 索引到 end-1 索引之间的元素构成的子集（切分数组，start:end 被称为 slice 表达式）。所以 slice1[0] 就等于 arr1[start]。这可以在 arr1 被填充前就定义好。 如果某个人写：var slice1 []type = arr1[:] 那么 slice1 就等于完整的 arr1 数组（所以这种表示方式是 arr1[0:len(arr1)] 的一种缩写）。另外一种表述方式是：slice1 = &arr1。 arr1[2:] 和 arr1[2:len(arr1)] 相同，都包含了数组从第三个到最后的所有元素。 arr1[:3] 和 arr1[0:3] 相同，包含了从第一个到第三个元素（不包括第三个）。 如果你想去掉 slice1 的最后一个元素，只要 slice1 = slice1[:len(slice1)-1]。 一个由数字 1、2、3 组成的切片可以这么生成：s := [3]int{1,2,3}[:] 甚至更简单的 s := []int{1,2,3}。 s2 := s[:] 是用切片组成的切片，拥有相同的元素，但是仍然指向相同的相关数组。 一个切片 s 可以这样扩展到它的大小上限：s = s[:cap(s)]，如果再扩大的话就会导致运行时错误（参见第 7.7 节）。 对于每一个切片（包括 string），以下状态总是成立的： s == s[:i] + s[i:] // i是一个整数且: 0 切片也可以用类似数组的方式初始化：var x = []int{2, 3, 5, 7, 11}。这样就创建了一个长度为 5 的数组并且创建了一个相关切片。 切片在内存中的组织方式实际上是一个有 3 个域的结构体：指向相关数组的指针，切片长度以及切片容量。下图给出了一个长度为 2，容量为 4 的切片y。 y[0] = 3 且 y[1] = 5。 切片 y[0:4] 由 元素 3，5，7 和 11 组成。 示例 7.7 array_slices.go package main import \"fmt\" func main() { var arr1 [6]int var slice1 []int = arr1[2:5] // item at index 5 not included! // load the array with integers: 0,1,2,3,4,5 for i := 0; i 输出： Slice at 0 is 2 Slice at 1 is 3 Slice at 2 is 4 The length of arr1 is 6 The length of slice1 is 3 The capacity of slice1 is 4 Slice at 0 is 2 Slice at 1 is 3 Slice at 2 is 4 Slice at 3 is 5 The length of slice1 is 4 The capacity of slice1 is 4 如果 s2 是一个 slice，你可以将 s2 向后移动一位 s2 = s2[1:]，但是末尾没有移动。切片只能向后移动，s2 = s2[-1:] 会导致编译错误。切片不能被重新分片以获取数组的前一个元素。 注意 绝对不要用指针指向 slice。切片本身已经是一个引用类型，所以它本身就是一个指针!! 问题 7.2： 给定切片 b:= []byte{'g', 'o', 'l', 'a', 'n', 'g'}，那么 b[1:4]、b[:2]、b[2:] 和 b[:] 分别是什么？ 7.2.2 将切片传递给函数 如果你有一个函数需要对数组做操作，你可能总是需要把参数声明为切片。当你调用该函数时，把数组分片，创建为一个 切片引用并传递给该函数。这里有一个计算数组元素和的方法: func sum(a []int) int { s := 0 for i := 0; i 7.2.3 用 make() 创建一个切片 当相关数组还没有定义时，我们可以使用 make() 函数来创建一个切片 同时创建好相关数组：var slice1 []type = make([]type, len)。 也可以简写为 slice1 := make([]type, len)，这里 len 是数组的长度并且也是 slice 的初始长度。 所以定义 s2 := make([]int, 10)，那么 cap(s2) == len(s2) == 10。 make 接受 2 个参数：元素的类型以及切片的元素个数。 如果你想创建一个 slice1，它不占用整个数组，而只是占用以 len 为个数个项，那么只要：slice1 := make([]type, len, cap)。 make 的使用方式是：func make([]T, len, cap)，其中 cap 是可选参数。 所以下面两种方法可以生成相同的切片: make([]int, 50, 100) new([100]int)[0:50] 下图描述了使用 make 方法生成的切片的内存结构： 示例 7.8 make_slice.go package main import \"fmt\" func main() { var slice1 []int = make([]int, 10) // load the array/slice: for i := 0; i 输出： Slice at 0 is 0 Slice at 1 is 5 Slice at 2 is 10 Slice at 3 is 15 Slice at 4 is 20 Slice at 5 is 25 Slice at 6 is 30 Slice at 7 is 35 Slice at 8 is 40 Slice at 9 is 45 The length of slice1 is 10 The capacity of slice1 is 10 因为字符串是纯粹不可变的字节数组，它们也可以被切分成 切片。 练习 7.4： fobinacci_funcarray.go: 为练习 7.3 写一个新的版本，主函数调用一个使用序列个数作为参数的函数，该函数返回一个大小为序列个数的 Fibonacci 切片。 7.2.4 new() 和 make() 的区别 看起来二者没有什么区别，都在堆上分配内存，但是它们的行为不同，适用于不同的类型。 new(T) 为每个新的类型T分配一片内存，初始化为 0 并且返回类型为*T的内存地址：这种方法 返回一个指向类型为 T，值为 0 的地址的指针，它适用于值类型如数组和结构体（参见第 10 章）；它相当于 &T{}。 make(T) 返回一个类型为 T 的初始值，它只适用于3种内建的引用类型：切片、map 和 channel（参见第 8 章，第 13 章）。 换言之，new 函数分配内存，make 函数初始化；下图给出了区别： 在图 7.3 的第一幅图中： var p *[]int = new([]int) // *p == nil; with len and cap 0 p := new([]int) 在第二幅图中， p := make([]int, 0) ，切片 已经被初始化，但是指向一个空的数组。 以上两种方式实用性都不高。下面的方法： var v []int = make([]int, 10, 50) 或者 v := make([]int, 10, 50) 这样分配一个有 50 个 int 值的数组，并且创建了一个长度为 10，容量为 50 的 切片 v，该 切片 指向数组的前 10 个元素。 问题 7.3 给定 s := make([]byte, 5)，len(s) 和 cap(s) 分别是多少？s = s[2:4]，len(s) 和 cap(s) 又分别是多少？问题 7.4 假设 s1 := []byte{'p', 'o', 'e', 'm'} 且 s2 := s1[2:]，s2 的值是多少？如果我们执行 s2[1] = 't'，s1 和 s2 现在的值又分别是多少？ 7.2.5 多维 切片 和数组一样，切片通常也是一维的，但是也可以由一维组合成高维。通过分片的分片（或者切片的数组），长度可以任意动态变化，所以 Go 语言的多维切片可以任意切分。而且，内层的切片必须单独分配（通过 make 函数）。 7.2.6 bytes 包 类型 []byte 的切片十分常见，Go 语言有一个 bytes 包专门用来解决这种类型的操作方法。 bytes 包和字符串包十分类似（参见第 4.7 节）。而且它还包含一个十分有用的类型 Buffer: import \"bytes\" type Buffer struct { ... } 这是一个长度可变的 bytes 的 buffer，提供 Read 和 Write 方法，因为读写长度未知的 bytes 最好使用 buffer。 Buffer 可以这样定义：var buffer bytes.Buffer。 或者使用 new 获得一个指针：var r *bytes.Buffer = new(bytes.Buffer)。 或者通过函数：func NewBuffer(buf []byte) *Buffer，创建一个 Buffer 对象并且用 buf 初始化好；NewBuffer 最好用在从 buf 读取的时候使用。 通过 buffer 串联字符串 类似于 Java 的 StringBuilder 类。 在下面的代码段中，我们创建一个 buffer，通过 buffer.WriteString(s) 方法将字符串 s 追加到后面，最后再通过 buffer.String() 方法转换为 string： var buffer bytes.Buffer for { if s, ok := getNextString(); ok { //method getNextString() not shown here buffer.WriteString(s) } else { break } } fmt.Print(buffer.String(), \"\\n\") 这种实现方式比使用 += 要更节省内存和 CPU，尤其是要串联的字符串数目特别多的时候。 练习 7.5 给定切片 sl，将一个 []byte 数组追加到 sl 后面。写一个函数 Append(slice, data []byte) []byte，该函数在 sl 不能存储更多数据的时候自动扩容。练习 7.6 把一个缓存 buf 分片成两个 切片：第一个是前 n 个 bytes，后一个是剩余的，用一行代码实现。 链接 目录 上一节：声明和初始化 下一节：For-range 结构 "},"Go入门指南/07.3.html":{"url":"Go入门指南/07.3.html","title":"3","keywords":"","body":"7.3 For-range 结构 这种构建方法可以应用于数组和切片: for ix, value := range slice1 { ... } 第一个返回值 ix 是数组或者切片的索引，第二个是在该索引位置的值；他们都是仅在 for 循环内部可见的局部变量。value 只是 slice1 某个索引位置的值的一个拷贝，不能用来修改 slice1 该索引位置的值。 示例 7.9 slices_forrange.go package main import \"fmt\" func main() { var slice1 []int = make([]int, 4) slice1[0] = 1 slice1[1] = 2 slice1[2] = 3 slice1[3] = 4 for ix, value := range slice1 { fmt.Printf(\"Slice at %d is: %d\\n\", ix, value) } } 示例 7.10 slices_forrange2.go package main import \"fmt\" func main() { seasons := []string{\"Spring\", \"Summer\", \"Autumn\", \"Winter\"} for ix, season := range seasons { fmt.Printf(\"Season %d is: %s\\n\", ix, season) } var season string for _, season = range seasons { fmt.Printf(\"%s\\n\", season) } } slicesforrange2.go 给出了一个关于字符串的例子， `` 可以用于忽略索引。 如果你只需要索引，你可以忽略第二个变量，例如： for ix := range seasons { fmt.Printf(\"%d\", ix) } // Output: 0 1 2 3 如果你需要修改 seasons[ix] 的值可以使用这个版本。 多维切片下的 for-range： 通过计算行数和矩阵值可以很方便的写出如（参考第 7.1.3 节）的 for 循环来，例如（参考第 7.5 节的例子 multidim_array.go）： for row := range screen { for column := range screen[row] { screen[row][column] = 1 } } 问题 7.5 假设我们有如下数组：items := [...]int{10, 20, 30, 40, 50} a) 如果我们写了如下的 for 循环，那么执行完 for 循环后的 items 的值是多少？如果你不确定的话可以测试一下:) for _, item := range items { item *= 2 } b) 如果 a) 无法正常工作，写一个 for 循环让值可以 double。 问题 7.6 通过使用省略号操作符 ... 来实现累加方法。 练习 7.7 sum_array.go a) 写一个 Sum 函数，传入参数为一个 32 位 float 数组成的数组 arrF，返回该数组的所有数字和。 如果把数组修改为切片的话代码要做怎样的修改？如果用切片形式方法实现不同长度数组的的和呢？ b) 写一个 SumAndAverage 方法，返回两个 int 和 float32 类型的未命名变量的和与平均值。 练习 7.8 min_max.go 写一个 minSlice 方法，传入一个 int 的切片并且返回最小值，再写一个 maxSlice 方法返回最大值。 链接 目录 上一节：切片 下一节：切片重组（reslice） "},"Go入门指南/07.4.html":{"url":"Go入门指南/07.4.html","title":"4","keywords":"","body":"7.4 切片重组（reslice） 我们已经知道切片创建的时候通常比相关数组小，例如： slice1 := make([]type, start_length, capacity) 其中 start_length 作为切片初始长度而 capacity 作为相关数组的长度。 这么做的好处是我们的切片在达到容量上限后可以扩容。改变切片长度的过程称之为切片重组 reslicing，做法如下：slice1 = slice1[0:end]，其中 end 是新的末尾索引（即长度）。 将切片扩展 1 位可以这么做： sl = sl[0:len(sl)+1] 切片可以反复扩展直到占据整个相关数组。 示例 7.11 reslicing.go package main import \"fmt\" func main() { slice1 := make([]int, 0, 10) // load the slice, cap(slice1) is 10: for i := 0; i 输出结果： The length of slice is 1 The length of slice is 2 The length of slice is 3 The length of slice is 4 The length of slice is 5 The length of slice is 6 The length of slice is 7 The length of slice is 8 The length of slice is 9 The length of slice is 10 Slice at 0 is 0 Slice at 1 is 1 Slice at 2 is 2 Slice at 3 is 3 Slice at 4 is 4 Slice at 5 is 5 Slice at 6 is 6 Slice at 7 is 7 Slice at 8 is 8 Slice at 9 is 9 另一个例子： var ar = [10]int{0,1,2,3,4,5,6,7,8,9} var a = ar[5:7] // reference to subarray {5,6} - len(a) is 2 and cap(a) is 5 将 a 重新分片： a = a[0:4] // ref of subarray {5,6,7,8} - len(a) is now 4 but cap(a) is still 5 问题 7.7 1) 如果 a 是一个切片，那么 s[n:n] 的长度是多少？ 2) s[n:n+1] 的长度又是多少？ 链接 目录 上一节：For-range 结构 下一节：切片的复制与追加 "},"Go入门指南/07.5.html":{"url":"Go入门指南/07.5.html","title":"5","keywords":"","body":"7.5 切片的复制与追加 如果想增加切片的容量，我们必须创建一个新的更大的切片并把原分片的内容都拷贝过来。下面的代码描述了从拷贝切片的 copy 函数和向切片追加新元素的 append 函数。 示例 7.12 copy_append_slice.go package main import \"fmt\" func main() { sl_from := []int{1, 2, 3} sl_to := make([]int, 10) n := copy(sl_to, sl_from) fmt.Println(sl_to) fmt.Printf(\"Copied %d elements\\n\", n) // n == 3 sl3 := []int{1, 2, 3} sl3 = append(sl3, 4, 5, 6) fmt.Println(sl3) } func append(s[]T, x ...T) []T 其中 append 方法将 0 个或多个具有相同类型 s 的元素追加到切片后面并且返回新的切片；追加的元素必须和原切片的元素同类型。如果 s 的容量不足以存储新增元素，append 会分配新的切片来保证已有切片元素和新增元素的存储。因此，返回的切片可能已经指向一个不同的相关数组了。append 方法总是返回成功，除非系统内存耗尽了。 如果你想将切片 y 追加到切片 x 后面，只要将第二个参数扩展成一个列表即可：x = append(x, y...)。 注意： append 在大多数情况下很好用，但是如果你想完全掌控整个追加过程，你可以实现一个这样的 AppendByte 方法： func AppendByte(slice []byte, data ...byte) []byte { m := len(slice) n := m + len(data) if n > cap(slice) { // if necessary, reallocate // allocate double what's needed, for future growth. newSlice := make([]byte, (n+1)*2) copy(newSlice, slice) slice = newSlice } slice = slice[0:n] copy(slice[m:n], data) return slice } func copy(dst, src []T) int copy 方法将类型为 T 的切片从源地址 src 拷贝到目标地址 dst，覆盖 dst 的相关元素，并且返回拷贝的元素个数。源地址和目标地址可能会有重叠。拷贝个数是 src 和 dst 的长度最小值。如果 src 是字符串那么元素类型就是 byte。如果你还想继续使用 src，在拷贝结束后执行 src = dst。 练习 7.9 给定 slice s[]int 和一个 int 类型的因子，扩展 s 使其长度为 len(s) * factor。 练习 7.10 用顺序函数过滤容器：s 是前 10 个整型的切片。构造一个函数 Filter，第一个参数是 s，第二个参数是一个 fn func(int) bool，返回满足函数 fn 的元素切片。通过 fn 测试方法测试当整型值是偶数时的情况。 练习 7.11 写一个函数 InsertStringSlice 将切片插入到另一个切片的指定位置。 练习 7.12 写一个函数 RemoveStringSlice 将从 start 到 end 索引的元素从切片 中移除。 链接 目录 上一节：切片重组（reslice） 下一节：字符串、数组和切片的应用 "},"Go入门指南/07.6.html":{"url":"Go入门指南/07.6.html","title":"6","keywords":"","body":"7.6 字符串、数组和切片的应用 7.6.1 从字符串生成字节切片 假设 s 是一个字符串（本质上是一个字节数组），那么就可以直接通过 c := []byte(s) 来获取一个字节的切片 c。另外，您还可以通过 copy 函数来达到相同的目的：copy(dst []byte, src string)。 同样的，还可以使用 for-range 来获得每个元素（Listing 7.13—for_string.go）： package main import \"fmt\" func main() { s := \"\\u00ff\\u754c\" for i, c := range s { fmt.Printf(\"%d:%c \", i, c) } } 输出： 0:ÿ 2:界 我们知道，Unicode 字符会占用 2 个字节，有些甚至需要 3 个或者 4 个字节来进行表示。如果发现错误的 UTF8 字符，则该字符会被设置为 U+FFFD 并且索引向前移动一个字节。和字符串转换一样，您同样可以使用 c := []int32(s) 语法，这样切片中的每个 int 都会包含对应的 Unicode 代码，因为字符串中的每次字符都会对应一个整数。类似的，您也可以将字符串转换为元素类型为 rune 的切片：r := []rune(s)。 可以通过代码 len([]int32(s)) 来获得字符串中字符的数量，但使用 utf8.RuneCountInString(s) 效率会更高一点。(参考count_characters.go) 您还可以将一个字符串追加到某一个字符数组的尾部： var b []byte var s string b = append(b, s...) 7.6.2 获取字符串的某一部分 使用 substr := str[start:end] 可以从字符串 str 获取到从索引 start 开始到 end-1 位置的子字符串。同样的，str[start:] 则表示获取从 start 开始到 len(str)-1 位置的子字符串。而 str[:end] 表示获取从 0 开始到 end-1 的子字符串。 7.6.3 字符串和切片的内存结构 在内存中，一个字符串实际上是一个双字结构，即一个指向实际数据的指针和记录字符串长度的整数（见图 7.4）。因为指针对用户来说是完全不可见，因此我们可以依旧把字符串看做是一个值类型，也就是一个字符数组。 字符串 string s = \"hello\" 和子字符串 t = s[2:3] 在内存中的结构可以用下图表示： 7.6.4 修改字符串中的某个字符 Go 语言中的字符串是不可变的，也就是说 str[index] 这样的表达式是不可以被放在等号左侧的。如果尝试运行 str[i] = 'D' 会得到错误：cannot assign to str[i]。 因此，您必须先将字符串转换成字节数组，然后再通过修改数组中的元素值来达到修改字符串的目的，最后将字节数组转换回字符串格式。 例如，将字符串 \"hello\" 转换为 \"cello\"： s := \"hello\" c := []byte(s) c[0] = 'c' s2 := string(c) // s2 == \"cello\" 所以，您可以通过操作切片来完成对字符串的操作。 7.6.5 字节数组对比函数 下面的 Compare 函数会返回两个字节数组字典顺序的整数对比结果，即 0 if a == b, -1 if a b。 func Compare(a, b[]byte) int { for i:=0; i b[i]: return 1 case a[i] len(b): return 1 } return 0 // 数组相等 } 7.6.6 搜索及排序切片和数组 标准库提供了 sort 包来实现常见的搜索和排序操作。您可以使用 sort 包中的函数 func Ints(a []int) 来实现对 int 类型的切片排序。例如 sort.Ints(arri)，其中变量 arri 就是需要被升序排序的数组或切片。为了检查某个数组是否已经被排序，可以通过函数 IntsAreSorted(a []int) bool 来检查，如果返回 true 则表示已经被排序。 类似的，可以使用函数 func Float64s(a []float64) 来排序 float64 的元素，或使用函数 func Strings(a []string) 排序字符串元素。 想要在数组或切片中搜索一个元素，该数组或切片必须先被排序（因为标准库的搜索算法使用的是二分法）。然后，您就可以使用函数 func SearchInts(a []int, n int) int 进行搜索，并返回对应结果的索引值。 当然，还可以搜索 float64 和字符串： func SearchFloat64s(a []float64, x float64) int func SearchStrings(a []string, x string) int 您可以通过查看 官方文档 来获取更详细的信息。 这就是如何使用 sort 包的方法，我们会在第 11.6 节对它的细节进行深入，并实现一个属于我们自己的版本。 7.6.7 append 函数常见操作 我们在第 7.5 节提到的 append 非常有用，它能够用于各种方面的操作： 将切片 b 的元素追加到切片 a 之后：a = append(a, b...) 复制切片 a 的元素到新的切片 b 上： b = make([]T, len(a)) copy(b, a) 删除位于索引 i 的元素：a = append(a[:i], a[i+1:]...) 切除切片 a 中从索引 i 至 j 位置的元素：a = append(a[:i], a[j:]...) 为切片 a 扩展 j 个元素长度：a = append(a, make([]T, j)...) 在索引 i 的位置插入元素 x：a = append(a[:i], append([]T{x}, a[i:]...)...) 在索引 i 的位置插入长度为 j 的新切片：a = append(a[:i], append(make([]T, j), a[i:]...)...) 在索引 i 的位置插入切片 b 的所有元素：a = append(a[:i], append(b, a[i:]...)...) 取出位于切片 a 最末尾的元素 x：x, a = a[len(a)-1], a[:len(a)-1] 将元素 x 追加到切片 a：a = append(a, x) 因此，您可以使用切片和 append 操作来表示任意可变长度的序列。 从数学的角度来看，切片相当于向量，如果需要的话可以定义一个向量作为切片的别名来进行操作。 如果您需要更加完整的方案，可以学习一下 Eleanor McHugh 编写的几个包：slices、chain 和 lists。 7.6.8 切片和垃圾回收 切片的底层指向一个数组，该数组的实际容量可能要大于切片所定义的容量。只有在没有任何切片指向的时候，底层的数组内存才会被释放，这种特性有时会导致程序占用多余的内存。 示例 函数 FindDigits 将一个文件加载到内存，然后搜索其中所有的数字并返回一个切片。 var digitRegexp = regexp.MustCompile(\"[0-9]+\") func FindDigits(filename string) []byte { b, _ := ioutil.ReadFile(filename) return digitRegexp.Find(b) } 这段代码可以顺利运行，但返回的 []byte 指向的底层是整个文件的数据。只要该返回的切片不被释放，垃圾回收器就不能释放整个文件所占用的内存。换句话说，一点点有用的数据却占用了整个文件的内存。 想要避免这个问题，可以通过拷贝我们需要的部分到一个新的切片中： func FindDigits(filename string) []byte { b, _ := ioutil.ReadFile(filename) b = digitRegexp.Find(b) c := make([]byte, len(b)) copy(c, b) return c } 事实上，上面这段代码只能找到第一个匹配正则表达式的数字串。要想找到所有的数字，可以尝试下面这段代码： func FindFileDigits(filename string) []byte { fileBytes, _ := ioutil.ReadFile(filename) b := digitRegexp.FindAll(fileBytes, len(fileBytes)) c := make([]byte, 0) for _, bytes := range b { c = append(c, bytes...) } return c } 练习 7.12 编写一个函数，要求其接受两个参数，原始字符串 str 和分割索引 i，然后返回两个分割后的字符串。 练习 7.13 假设有字符串 str，那么 str[len(str)/2:] + str[:len(str)/2] 的结果是什么？ 练习 7.14 编写一个程序，要求能够反转字符串，即将 “Google” 转换成 “elgooG”（提示：使用 []byte 类型的切片）。 如果您使用两个切片来实现反转，请再尝试使用一个切片（提示：使用交换法）。 如果您想要反转 Unicode 编码的字符串，请使用 []int32 类型的切片。 练习 7.15 编写一个程序，要求能够遍历一个数组的字符，并将当前字符和前一个字符不相同的字符拷贝至另一个数组。 练习 7.16 编写一个程序，使用冒泡排序的方法排序一个包含整数的切片（算法的定义可参考 维基百科）。 练习 7.17 在函数式编程语言中，一个 map-function 是指能够接受一个函数原型和一个列表，并使用列表中的值依次执行函数原型，公式为：map ( F(), (e1,e2, . . . ,en) ) = ( F(e1), F(e2), ... F(en) )。 编写一个函数 mapFunc 要求接受以下 2 个参数： 一个将整数乘以 10 的函数 一个整数列表 最后返回保存运行结果的整数列表。 链接 目录 上一节：切片的复制与追加 下一章：Map "},"Go入门指南/08.0.html":{"url":"Go入门指南/08.0.html","title":"0","keywords":"","body":"8.0 Map map 是一种特殊的数据结构：一种元素对（pair）的无序集合，pair 的一个元素是 key，对应的另一个元素是 value，所以这个结构也称为关联数组或字典。这是一种快速寻找值的理想结构：给定 key，对应的 value 可以迅速定位。 map 这种数据结构在其他编程语言中也称为字典（Python）、hash 和 HashTable 等。 链接 目录 上一节：字符串、数组和切片的应用 下一节：声明、初始化和 make "},"Go入门指南/08.1.html":{"url":"Go入门指南/08.1.html","title":"1","keywords":"","body":"8.1 声明、初始化和 make 8.1.1 概念 map 是引用类型，可以使用如下声明： var map1 map[keytype]valuetype var map1 map[string]int （[keytype] 和 valuetype 之间允许有空格，但是 gofmt 移除了空格） 在声明的时候不需要知道 map 的长度，map 是可以动态增长的。 未初始化的 map 的值是 nil。 key 可以是任意可以用 == 或者 != 操作符比较的类型，比如 string、int、float。所以数组、切片和结构体不能作为 key (译者注：含有数组切片的结构体不能作为 key，只包含内建类型的 struct 是可以作为 key 的），但是指针和接口类型可以。如果要用结构体作为 key 可以提供 Key() 和 Hash() 方法，这样可以通过结构体的域计算出唯一的数字或者字符串的 key。 value 可以是任意类型的；通过使用空接口类型（详见第 11.9 节），我们可以存储任意值，但是使用这种类型作为值时需要先做一次类型断言（详见第 11.3 节）。 map 传递给函数的代价很小：在 32 位机器上占 4 个字节，64 位机器上占 8 个字节，无论实际上存储了多少数据。通过 key 在 map 中寻找值是很快的，比线性查找快得多，但是仍然比从数组和切片的索引中直接读取要慢 100 倍；所以如果你很在乎性能的话还是建议用切片来解决问题。 map 也可以用函数作为自己的值，这样就可以用来做分支结构（详见第 5 章）：key 用来选择要执行的函数。 如果 key1 是 map1 的key，那么 map1[key1] 就是对应 key1 的值，就如同数组索引符号一样（数组可以视为一种简单形式的 map，key 是从 0 开始的整数）。 key1 对应的值可以通过赋值符号来设置为 val1：map1[key1] = val1。 令 v := map1[key1] 可以将 key1 对应的值赋值为 v；如果 map 中没有 key1 存在，那么 v 将被赋值为 map1 的值类型的空值。 常用的 len(map1) 方法可以获得 map 中的 pair 数目，这个数目是可以伸缩的，因为 map-pairs 在运行时可以动态添加和删除。 示例 8.1 make_maps.go package main import \"fmt\" func main() { var mapLit map[string]int //var mapCreated map[string]float32 var mapAssigned map[string]int mapLit = map[string]int{\"one\": 1, \"two\": 2} mapCreated := make(map[string]float32) mapAssigned = mapLit mapCreated[\"key1\"] = 4.5 mapCreated[\"key2\"] = 3.14159 mapAssigned[\"two\"] = 3 fmt.Printf(\"Map literal at \\\"one\\\" is: %d\\n\", mapLit[\"one\"]) fmt.Printf(\"Map created at \\\"key2\\\" is: %f\\n\", mapCreated[\"key2\"]) fmt.Printf(\"Map assigned at \\\"two\\\" is: %d\\n\", mapLit[\"two\"]) fmt.Printf(\"Map literal at \\\"ten\\\" is: %d\\n\", mapLit[\"ten\"]) } 输出结果： Map literal at \"one\" is: 1 Map created at \"key2\" is: 3.14159 Map assigned at \"two\" is: 3 Mpa literal at \"ten\" is: 0 mapLit 说明了 map literals 的使用方法： map 可以用 {key1: val1, key2: val2} 的描述方法来初始化，就像数组和结构体一样。 map 是 引用类型 的： 内存用 make 方法来分配。 map 的初始化：var map1 = make(map[keytype]valuetype)。 或者简写为：map1 := make(map[keytype]valuetype)。 上面例子中的 mapCreated 就是用这种方式创建的：mapCreated := make(map[string]float32)。 相当于：mapCreated := map[string]float32{}。 mapAssigned 也是 mapList 的引用，对 mapAssigned 的修改也会影响到 mapLit 的值。 不要使用 new，永远用 make 来构造 map 注意 如果你错误的使用 new() 分配了一个引用对象，你会获得一个空引用的指针，相当于声明了一个未初始化的变量并且取了它的地址： mapCreated := new(map[string]float32) 接下来当我们调用：mapCreated[\"key1\"] = 4.5 的时候，编译器会报错： invalid operation: mapCreated[\"key1\"] (index of type *map[string]float32). 为了说明值可以是任意类型的，这里给出了一个使用 func() int 作为值的 map： 示例 8.2 map_func.go package main import \"fmt\" func main() { mf := map[int]func() int{ 1: func() int { return 10 }, 2: func() int { return 20 }, 5: func() int { return 50 }, } fmt.Println(mf) } 输出结果为：map[1:0x10903be0 5:0x10903ba0 2:0x10903bc0]: 整形都被映射到函数地址。 8.1.2 map 容量 和数组不同，map 可以根据新增的 key-value 对动态的伸缩，因此它不存在固定长度或者最大限制。但是你也可以选择标明 map 的初始容量 capacity，就像这样：make(map[keytype]valuetype, cap)。例如： map2 := make(map[string]float32, 100) 当 map 增长到容量上限的时候，如果再增加新的 key-value 对，map 的大小会自动加 1。所以出于性能的考虑，对于大的 map 或者会快速扩张的 map，即使只是大概知道容量，也最好先标明。 这里有一个 map 的具体例子，即将音阶和对应的音频映射起来： noteFrequency := map[string]float32 { \"C0\": 16.35, \"D0\": 18.35, \"E0\": 20.60, \"F0\": 21.83, \"G0\": 24.50, \"A0\": 27.50, \"B0\": 30.87, \"A4\": 440} 8.1.3 用切片作为 map 的值 既然一个 key 只能对应一个 value，而 value 又是一个原始类型，那么如果一个 key 要对应多个值怎么办？例如，当我们要处理unix机器上的所有进程，以父进程（pid 为整形）作为 key，所有的子进程（以所有子进程的 pid 组成的切片）作为 value。通过将 value 定义为 []int 类型或者其他类型的切片，就可以优雅的解决这个问题。 这里有一些定义这种 map 的例子： mp1 := make(map[int][]int) mp2 := make(map[int]*[]int) 链接 目录 上一节：Map 下一节：测试键值对是否存在及删除元素 "},"Go入门指南/08.2.html":{"url":"Go入门指南/08.2.html","title":"2","keywords":"","body":"8.2 测试键值对是否存在及删除元素 测试 map1 中是否存在 key1： 在例子 8.1 中，我们已经见过可以使用 val1 = map1[key1] 的方法获取 key1 对应的值 val1。如果 map 中不存在 key1，val1 就是一个值类型的空值。 这就会给我们带来困惑了：现在我们没法区分到底是 key1 不存在还是它对应的 value 就是空值。 为了解决这个问题，我们可以这么用：val1, isPresent = map1[key1] isPresent 返回一个 bool 值：如果 key1 存在于 map1，val1 就是 key1 对应的 value 值，并且 isPresent为true；如果 key1 不存在，val1 就是一个空值，并且 isPresent 会返回 false。 如果你只是想判断某个 key 是否存在而不关心它对应的值到底是多少，你可以这么做： _, ok := map1[key1] // 如果key1存在则ok == true，否则ok为false 或者和 if 混合使用： if _, ok := map1[key1]; ok { // ... } 从 map1 中删除 key1： 直接 delete(map1, key1) 就可以。 如果 key1 不存在，该操作不会产生错误。 示例 8.4 map_testelement.go package main import \"fmt\" func main() { var value int var isPresent bool map1 := make(map[string]int) map1[\"New Delhi\"] = 55 map1[\"Beijing\"] = 20 map1[\"Washington\"] = 25 value, isPresent = map1[\"Beijing\"] if isPresent { fmt.Printf(\"The value of \\\"Beijing\\\" in map1 is: %d\\n\", value) } else { fmt.Printf(\"map1 does not contain Beijing\") } value, isPresent = map1[\"Paris\"] fmt.Printf(\"Is \\\"Paris\\\" in map1 ?: %t\\n\", isPresent) fmt.Printf(\"Value is: %d\\n\", value) // delete an item: delete(map1, \"Washington\") value, isPresent = map1[\"Washington\"] if isPresent { fmt.Printf(\"The value of \\\"Washington\\\" in map1 is: %d\\n\", value) } else { fmt.Println(\"map1 does not contain Washington\") } } 输出结果： The value of \"Beijing\" in map1 is: 20 Is \"Paris\" in map1 ?: false Value is: 0 map1 does not contain Washington 链接 目录 上一节：声明、初始化和 make 下一节：for-range 的配套用法 "},"Go入门指南/08.3.html":{"url":"Go入门指南/08.3.html","title":"3","keywords":"","body":"8.3 for-range 的配套用法 可以使用 for 循环构造 map： for key, value := range map1 { ... } 第一个返回值 key 是 map 中的 key 值，第二个返回值则是该 key 对应的 value 值；这两个都是仅 for 循环内部可见的局部变量。其中第一个返回值key值是一个可选元素。如果你只关心值，可以这么使用： for _, value := range map1 { ... } 如果只想获取 key，你可以这么使用： for key := range map1 { fmt.Printf(\"key is: %d\\n\", key) } 示例 8.5 maps_forrange.go： package main import \"fmt\" func main() { map1 := make(map[int]float32) map1[1] = 1.0 map1[2] = 2.0 map1[3] = 3.0 map1[4] = 4.0 for key, value := range map1 { fmt.Printf(\"key is: %d - value is: %f\\n\", key, value) } } 输出结果： key is: 3 - value is: 3.000000 key is: 1 - value is: 1.000000 key is: 4 - value is: 4.000000 key is: 2 - value is: 2.000000 注意 map 不是按照 key 的顺序排列的，也不是按照 value 的序排列的。 问题 8.1： 下面这段代码的输出是什么？ capitals := map[string] string {\"France\":\"Paris\", \"Italy\":\"Rome\", \"Japan\":\"Tokyo\" } for key := range capitals { fmt.Println(\"Map item: Capital of\", key, \"is\", capitals[key]) } 练习 8.1 创建一个 map 来保存每周 7 天的名字，将它们打印出来并且测试是否存在 Tuesday 和 Hollyday。 链接 目录 上一节：测试键值对是否存在及删除元素 下一节：map 类型的切片 "},"Go入门指南/08.4.html":{"url":"Go入门指南/08.4.html","title":"4","keywords":"","body":"8.4 map 类型的切片 假设我们想获取一个 map 类型的切片，我们必须使用两次 make() 函数，第一次分配切片，第二次分配 切片中每个 map 元素（参见下面的例子 8.4）。 示例 8.4 maps_forrange2.go： package main import \"fmt\" func main() { // Version A: items := make([]map[int]int, 5) for i:= range items { items[i] = make(map[int]int, 1) items[i][1] = 2 } fmt.Printf(\"Version A: Value of items: %v\\n\", items) // Version B: NOT GOOD! items2 := make([]map[int]int, 5) for _, item := range items2 { item = make(map[int]int, 1) // item is only a copy of the slice element. item[1] = 2 // This 'item' will be lost on the next iteration. } fmt.Printf(\"Version B: Value of items: %v\\n\", items2) } 输出结果： Version A: Value of items: [map[1:2] map[1:2] map[1:2] map[1:2] map[1:2]] Version B: Value of items: [map[] map[] map[] map[] map[]] 需要注意的是，应当像 A 版本那样通过索引使用切片的 map 元素。在 B 版本中获得的项只是 map 值的一个拷贝而已，所以真正的 map 元素没有得到初始化。 链接 目录 上一节：for-range 的配套用法 下一节：map 的排序 "},"Go入门指南/08.5.html":{"url":"Go入门指南/08.5.html","title":"5","keywords":"","body":"8.5 map 的排序 map 默认是无序的，不管是按照 key 还是按照 value 默认都不排序（详见第 8.3 节）。 如果你想为 map 排序，需要将 key（或者 value）拷贝到一个切片，再对切片排序（使用 sort 包，详见第 7.6.6 节），然后可以使用切片的 for-range 方法打印出所有的 key 和 value。 下面有一个示例： 示例 8.6 sort_map.go： // the telephone alphabet: package main import ( \"fmt\" \"sort\" ) var ( barVal = map[string]int{\"alpha\": 34, \"bravo\": 56, \"charlie\": 23, \"delta\": 87, \"echo\": 56, \"foxtrot\": 12, \"golf\": 34, \"hotel\": 16, \"indio\": 87, \"juliet\": 65, \"kili\": 43, \"lima\": 98} ) func main() { fmt.Println(\"unsorted:\") for k, v := range barVal { fmt.Printf(\"Key: %v, Value: %v / \", k, v) } keys := make([]string, len(barVal)) i := 0 for k, _ := range barVal { keys[i] = k i++ } sort.Strings(keys) fmt.Println() fmt.Println(\"sorted:\") for _, k := range keys { fmt.Printf(\"Key: %v, Value: %v / \", k, barVal[k]) } } 输出结果： unsorted: Key: bravo, Value: 56 / Key: echo, Value: 56 / Key: indio, Value: 87 / Key: juliet, Value: 65 / Key: alpha, Value: 34 / Key: charlie, Value: 23 / Key: delta, Value: 87 / Key: foxtrot, Value: 12 / Key: golf, Value: 34 / Key: hotel, Value: 16 / Key: kili, Value: 43 / Key: lima, Value: 98 / sorted: Key: alpha, Value: 34 / Key: bravo, Value: 56 / Key: charlie, Value: 23 / Key: delta, Value: 87 / Key: echo, Value: 56 / Key: foxtrot, Value: 12 / Key: golf, Value: 34 / Key: hotel, Value: 16 / Key: indio, Value: 87 / Key: juliet, Value: 65 / Key: kili, Value: 43 / Key: lima, Value: 98 / 但是如果你想要一个排序的列表你最好使用结构体切片，这样会更有效： type name struct { key string value int } 链接 目录 上一节：map 类型的切片 下一节：将 map 的键值对调 "},"Go入门指南/08.6.html":{"url":"Go入门指南/08.6.html","title":"6","keywords":"","body":"8.6 将 map 的键值对调 这里对调是指调换 key 和 value。如果 map 的值类型可以作为 key 且所有的 value 是唯一的，那么通过下面的方法可以简单的做到键值对调。 示例 8.7 invert_map.go： package main import ( \"fmt\" ) var ( barVal = map[string]int{\"alpha\": 34, \"bravo\": 56, \"charlie\": 23, \"delta\": 87, \"echo\": 56, \"foxtrot\": 12, \"golf\": 34, \"hotel\": 16, \"indio\": 87, \"juliet\": 65, \"kili\": 43, \"lima\": 98} ) func main() { invMap := make(map[int]string, len(barVal)) for k, v := range barVal { invMap[v] = k } fmt.Println(\"inverted:\") for k, v := range invMap { fmt.Printf(\"Key: %v, Value: %v / \", k, v) } } 输出结果： inverted: Key: 34, Value: golf / Key: 23, Value: charlie / Key: 16, Value: hotel / Key: 87, Value: delta / Key: 98, Value: lima / Key: 12, Value: foxtrot / Key: 43, Value: kili / Key: 56, Value: bravo / Key: 65, Value: juliet / 如果原始 value 值不唯一那么这么做肯定会出错；为了保证不出错，当遇到不唯一的 key 时应当立刻停止，这样可能会导致没有包含原 map 的所有键值对！一种解决方法就是仔细检查唯一性并且使用多值 map，比如使用 map[int][]string 类型。 练习 8.2 构造一个将英文饮料名映射为法语（或者任意你的母语）的集合；先打印所有的饮料，然后打印原名和翻译后的名字。接下来按照英文名排序后再打印出来。 链接 目录 上一节：map 的排序 下一章：包（package） "},"Go入门指南/09.0.html":{"url":"Go入门指南/09.0.html","title":"0","keywords":"","body":"9.0 包（package） 本章主要针对 Go 语言的包展开讲解。 链接 目录 上一节：将 map 的键值对调 下一节：标准库概述 "},"Go入门指南/09.10.html":{"url":"Go入门指南/09.10.html","title":"10","keywords":"","body":"9.10 Go 的外部包和项目 现在我们知道如何使用 Go 以及它的标准库了，但是 Go 的生态要比这大的多。当着手自己的 Go 项目时，最好先查找下是否有些存在的第三方的包或者项目能不能使用。大多数可以通过 go install 来进行安装。 Go Walker 支持根据包名在海量数据中查询。 目前已经有许多非常好的外部库，如： MySQL(GoMySQL), PostgreSQL(go-pgsql), MongoDB (mgo, gomongo), CouchDB (couch-go), ODBC (godbcl), Redis (redis.go) and SQLite3 (gosqlite) database drivers SDL bindings Google's Protocal Buffers(goprotobuf) XML-RPC(go-xmlrpc) Twitter(twitterstream) OAuth libraries(GoAuth) 链接 目录 上一节：通过 git 打包和安装 下一节：在 Go 程序中使用外部库 "},"Go入门指南/09.11.html":{"url":"Go入门指南/09.11.html","title":"11","keywords":"","body":"9.11 在 Go 程序中使用外部库 （本节我们将创建一个 Web 应用和它的 Google App Engine 版本,在第 19 和 21 章分别说明，当你阅读到这些章节时可以再回到这个例子。) 当开始一个新项目或增加新的功能到现有的项目，你可以通过在应用程序中使用已经存在的库来节省开发时间。为了做到这一点，你必须理解库的 API（应用编程接口），那就是：库中有哪些方法可以调用，如何调用。你可能没有这个库的源代码，但作者肯定有记载的 API 以及详细介绍了如何使用它。 作为一个例子，我们将使用谷歌的 API 的 urlshortener 编写一个小程序：你可以尝试一下在 http://goo.gl/ 输入一个像 \"http://www.destandaard.be\" 这样的URL，你会看到一个像 \"http://goo.gl/O9SUO\" 这样更短的 URL 返回，也就是说，在 Twitter 之类的服务中这是非常容易嵌入的。谷歌 urlshortener 服务的文档可以在 \"http://code.google.com/apis/urlshortener/\" 找到。(第 19 章，我们将开发自己版本的 urlshortener)。 谷歌将这项技术提供给其他开发者，作为 API 我们可以在我们自己的应用程序中调用（释放到指定的限制）。他们也生成了一个 Go 语言客户端库使其变得更容易。 备注：谷歌让通过使用 Google API Go 客户端服务的开发者生活变得更简单，Go 客户端程序自动生成于 Google 库的 JSON 描述。更多详情在 项目页面 查看。 下载并安装 Go 客户端库: 将通过 go install 实现。但是首先要验证环境变量中是否含有 GOPATH 变量，因为外部源码将被下载到 $GOPATH/src 目录下并被安装到 $GOPATH/PKG/\"machine_arch\"/ 目录下。 我们将通过在终端调用以下命令来安装 API: go install google-api-go-client.google.com/hg/urlshortener/v1 go install 将下载源码，编译并安装包 使用 urlshortener 服务的 web 程序: 现在我们可以通过导入并赋予别名来使用已安装的包： import urlshortener \"google-api-go-client.googlecode.com/hg/urlshortener/v1\" 现在我们写一个 Web 应用(参见第 15 章 4-8 节)通过表单实现短地址和长地址的相互转换。我们将使用 template 包并写三个处理函数：root 函数通过执行表单模板来展示表单。short 函数将长地址转换为短地址，long 函数逆向转换。 要调用 urlshortener 接口必须先通过 http 包中的默认客户端创建一个服务实例 urlshortenerSvc： urlshortenerSvc, _ := urlshortener.New(http.DefaultClient) 我们通过调用服务中的 Url.Insert 中的 Do 方法传入包含长地址的 Url 数据结构从而获取短地址： url, _ := urlshortenerSvc.Url.Insert(&urlshortener.Url{LongUrl: longUrl}).Do() 返回 url 的 Id 便是我们需要的短地址。 我们通过调用服务中的 Url.Get 中的 Do 方法传入包含短地址的Url数据结构从而获取长地址： url, error := urlshortenerSvc.Url.Get(shwortUrl).Do() 返回的长地址便是转换前的原始地址。 示例 9.9 urlshortener.go package main import ( \"fmt\" \"net/http\" \"text/template\" urlshortener \"google-api-go-client.googlecode.com/hg/urlshortener/v1\" ) func main() { http.HandleFunc(\"/\", root) http.HandleFunc(\"/short\", short) http.HandleFunc(\"/long\", long) http.ListenAndServe(\"localhost:8080\", nil) } // the template used to show the forms and the results web page to the user var rootHtmlTmpl = template.Must(template.New(\"rootHtml\").Parse(` URL SHORTENER {{if .}}{{.}}{{end}} Shorten this: Expand this: http://goo.gl/ `)) func root(w http.ResponseWriter, r *http.Request) { rootHtmlTmpl.Execute(w, nil) } func short(w http.ResponseWriter, r *http.Request) { longUrl := r.FormValue(\"longUrl\") urlshortenerSvc, _ := urlshortener.New(http.DefaultClient) url, _ := urlshortenerSvc.Url.Insert(&urlshortener.Url{LongUrl: longUrl,}).Do() rootHtmlTmpl.Execute(w, fmt.Sprintf(\"Shortened version of %s is : %s\", longUrl, url.Id)) } func long(w http.ResponseWriter, r *http.Request) { shortUrl := \"http://goo.gl/\" + r.FormValue(\"shortUrl\") urlshortenerSvc, _ := urlshortener.New(http.DefaultClient) url, err := urlshortenerSvc.Url.Get(shortUrl).Do() if err != nil { fmt.Println(\"error: %v\", err) return } rootHtmlTmpl.Execute(w, fmt.Sprintf(\"Longer version of %s is : %s\", shortUrl, url.LongUrl)) } 执行这段代码： go run urlshortener.go 通过浏览 http://localhost:8080/ 的页面来测试。 为了代码的简洁我们并没有检测返回的错误状态，但是在真实的生产环境的应用中一定要做检测。 将应用放入 Google App Engine，我们只需要在之前的代码中作出如下改变： package main -> package urlshort func main() -> func init() 创建一个和包同名的目录 urlshort，并将以下两个安装目录复制到这个目录： google-api-go-client.googlecode.com/hg/urlshortener google-api-go-client.googlecode.com/hg/google-api 此外还要配置下配置文件 app.yaml，内容如下： application: urlshort version: 0-1-test runtime: go api_version: 3 handlers: - url: /.* script: _go_app 现在你可以去到你的项目目录并在终端运行：dev_appserver.py urlshort 在浏览器打开你的 Web应用：http://localhost:8080。 链接 目录 上一节：Go 的外部包和项目 下一章：结构（struct）与方法（method） "},"Go入门指南/09.1.html":{"url":"Go入门指南/09.1.html","title":"1","keywords":"","body":"9.1 标准库概述 像 fmt、os 等这样具有常用功能的内置包在 Go 语言中有 150 个以上，它们被称为标准库，大部分(一些底层的除外)内置于 Go 本身。完整列表可以在 Go Walker 查看。 在贯穿本书的例子和练习中，我们都是用标准库的包。可以通过查阅第 350 页包中的内容快速找到相关的包的实例。这里我们只是按功能进行分组来介绍这些包的简单用途，我们不会深入讨论他们的内部结构。 unsafe: 包含了一些打破 Go 语言“类型安全”的命令，一般的程序中不会被使用，可用在 C/C++ 程序的调用中。 syscall-os-os/exec: os: 提供给我们一个平台无关性的操作系统功能接口，采用类Unix设计，隐藏了不同操作系统间差异，让不同的文件系统和操作系统对象表现一致。 os/exec: 提供我们运行外部操作系统命令和程序的方式。 syscall: 底层的外部包，提供了操作系统底层调用的基本接口。 通过一个 Go 程序让Linux重启来体现它的能力。 示例 9.1 reboot.go： package main import ( \"syscall\" ) const LINUX_REBOOT_MAGIC1 uintptr = 0xfee1dead const LINUX_REBOOT_MAGIC2 uintptr = 672274793 const LINUX_REBOOT_CMD_RESTART uintptr = 0x1234567 func main() { syscall.Syscall(syscall.SYS_REBOOT, LINUX_REBOOT_MAGIC1, LINUX_REBOOT_MAGIC2, LINUX_REBOOT_CMD_RESTART) } archive/tar 和 /zip-compress：压缩(解压缩)文件功能。 fmt-io-bufio-path/filepath-flag: fmt: 提供了格式化输入输出功能。 io: 提供了基本输入输出功能，大多数是围绕系统功能的封装。 bufio: 缓冲输入输出功能的封装。 path/filepath: 用来操作在当前系统中的目标文件名路径。 flag: 对命令行参数的操作。　　 strings-strconv-unicode-regexp-bytes: strings: 提供对字符串的操作。 strconv: 提供将字符串转换为基础类型的功能。 unicode: 为 unicode 型的字符串提供特殊的功能。 regexp: 正则表达式功能。 bytes: 提供对字符型分片的操作。 index/suffixarray: 子字符串快速查询。 math-math/cmath-math/big-math/rand-sort: math: 基本的数学函数。 math/cmath: 对复数的操作。 math/rand: 伪随机数生成。 sort: 为数组排序和自定义集合。 math/big: 大数的实现和计算。 　　 container-/list-ring-heap: 实现对集合的操作。 list: 双链表。 ring: 环形链表。 下面代码演示了如何遍历一个链表(当 l 是 *List)： for e := l.Front(); e != nil; e = e.Next() { //do something with e.Value } time-log: time: 日期和时间的基本操作。 log: 记录程序运行时产生的日志,我们将在后面的章节使用它。 encoding/json-encoding/xml-text/template: encoding/json: 读取并解码和写入并编码 JSON 数据。 encoding/xml:简单的 XML1.0 解析器,有关 JSON 和 XML 的实例请查阅第 12.9/10 章节。 text/template:生成像 HTML 一样的数据与文本混合的数据驱动模板（参见第 15.7 节）。 net-net/http-html:（参见第 15 章） net: 网络数据的基本操作。 http: 提供了一个可扩展的 HTTP 服务器和基础客户端，解析 HTTP 请求和回复。 html: HTML5 解析器。 runtime: Go 程序运行时的交互操作，例如垃圾回收和协程创建。 reflect: 实现通过程序运行时反射，让程序操作任意类型的变量。 exp 包中有许多将被编译为新包的实验性的包。它们将成为独立的包在下次稳定版本发布的时候。如果前一个版本已经存在了，它们将被作为过时的包被回收。然而 Go1.0 发布的时候并不包含过时或者实验性的包。 练习 9.1 使用 container/list 包实现一个双向链表，将 101、102 和 103 放入其中并打印出来。 练习 9.2 通过使用 unsafe 包中的方法来测试你电脑上一个整型变量占用多少个字节。 链接 目录 上一节：包（package） 下一节：regexp 包 "},"Go入门指南/09.2.html":{"url":"Go入门指南/09.2.html","title":"2","keywords":"","body":"9.2 regexp 包 正则表达式语法和使用的详细信息请参考 维基百科。 在下面的程序里，我们将在字符串中对正则表达式进行匹配。 如果是简单模式，使用 Match 方法便可： ok, _ := regexp.Match(pat, []byte(searchIn)) 变量 ok 将返回 true 或者 false,我们也可以使用 MatchString： ok, _ := regexp.MatchString(pat, searchIn) 更多方法中，必须先将正则通过 Compile 方法返回一个 Regexp 对象。然后我们将掌握一些匹配，查找，替换相关的功能。 示例 9.2 pattern.go： package main import ( \"fmt\" \"regexp\" \"strconv\" ) func main() { //目标字符串 searchIn := \"John: 2578.34 William: 4567.23 Steve: 5632.18\" pat := \"[0-9]+.[0-9]+\" //正则 f := func(s string) string{ v, _ := strconv.ParseFloat(s, 32) return strconv.FormatFloat(v * 2, 'f', 2, 32) } if ok, _ := regexp.Match(pat, []byte(searchIn)); ok { fmt.Println(\"Match Found!\") } re, _ := regexp.Compile(pat) //将匹配到的部分替换为\"##.#\" str := re.ReplaceAllString(searchIn, \"##.#\") fmt.Println(str) //参数为函数时 str2 := re.ReplaceAllStringFunc(searchIn, f) fmt.Println(str2) } 输出结果： Match Found! John: ##.# William: ##.# Steve: ##.# John: 5156.68 William: 9134.46 Steve: 11264.36 Compile 函数也可能返回一个错误，我们在使用时忽略对错误的判断是因为我们确信自己正则表达式是有效的。当用户输入或从数据中获取正则表达式的时候，我们有必要去检验它的正确性。另外我们也可以使用 MustCompile 方法，它可以像 Compile 方法一样检验正则的有效性，但是当正则不合法时程序将 panic（详情查看第 13.2 节)。 链接 目录 上一节：标准库概述 下一节：锁和 sync 包 "},"Go入门指南/09.3.html":{"url":"Go入门指南/09.3.html","title":"3","keywords":"","body":"9.3 锁和 sync 包 在一些复杂的程序中，通常通过不同线程执行不同应用来实现程序的并发。当不同线程要使用同一个变量时，经常会出现一个问题：无法预知变量被不同线程修改的顺序！(这通常被称为资源竞争,指不同线程对同一变量使用的竞争)显然这无法让人容忍，那我们该如何解决这个问题呢？ 经典的做法是一次只能让一个线程对共享变量进行操作。当变量被一个线程改变时(临界区)，我们为它上锁，直到这个线程执行完成并解锁后，其他线程才能访问它。 特别是我们之前章节学习的 map 类型是不存在锁的机制来实现这种效果(出于对性能的考虑)，所以 map 类型是非线程安全的。当并行访问一个共享的 map 类型的数据，map 数据将会出错。 在 Go 语言中这种锁的机制是通过 sync 包中 Mutex 来实现的。sync 来源于 \"synchronized\" 一词，这意味着线程将有序的对同一变量进行访问。 sync.Mutex 是一个互斥锁，它的作用是守护在临界区入口来确保同一时间只能有一个线程进入临界区。 假设 info 是一个需要上锁的放在共享内存中的变量。通过包含 Mutex 来实现的一个典型例子如下： import \"sync\" type Info struct { mu sync.Mutex // ... other fields, e.g.: Str string } 如果一个函数想要改变这个变量可以这样写: func Update(info *Info) { info.mu.Lock() // critical section: info.Str = // new value // end critical section info.mu.Unlock() } 还有一个很有用的例子是通过 Mutex 来实现一个可以上锁的共享缓冲器: type SyncedBuffer struct { lock sync.Mutex buffer bytes.Buffer } 在 sync 包中还有一个 RWMutex 锁：他能通过 RLock() 来允许同一时间多个线程对变量进行读操作，但是只能一个线程进行写操作。如果使用 Lock() 将和普通的 Mutex 作用相同。包中还有一个方便的 Once 类型变量的方法 once.Do(call)，这个方法确保被调用函数只能被调用一次。 相对简单的情况下，通过使用 sync 包可以解决同一时间只能一个线程访问变量或 map 类型数据的问题。如果这种方式导致程序明显变慢或者引起其他问题，我们要重新思考来通过 goroutines 和 channels 来解决问题，这是在 Go 语言中所提倡用来实现并发的技术。我们将在第 14 章对其深入了解，并在第 14.7 节中对这两种方式进行比较。 链接 目录 上一节：regexp 包 下一节：精密计算和 big 包 "},"Go入门指南/09.4.html":{"url":"Go入门指南/09.4.html","title":"4","keywords":"","body":"9.4 精密计算和 big 包 我们知道有些时候通过编程的方式去进行计算是不精确的。如果你使用 Go 语言中的 float64 类型进行浮点运算，返回结果将精确到 15 位，足以满足大多数的任务。当对超出 int64 或者 uint64 类型这样的大数进行计算时，如果对精度没有要求，float32 或者 float64 可以胜任，但如果对精度有严格要求的时候，我们不能使用浮点数，在内存中它们只能被近似的表示。 对于整数的高精度计算 Go 语言中提供了 big 包。其中包含了 math 包：有用来表示大整数的 big.Int 和表示大有理数的 big.Rat 类型（可以表示为 2/5 或 3.1416 这样的分数，而不是无理数或 π）。这些类型可以实现任意位类型的数字，只要内存足够大。缺点是更大的内存和处理开销使它们使用起来要比内置的数字类型慢很多。 大的整型数字是通过 big.NewInt(n) 来构造的，其中 n 为 int64 类型整数。而大有理数是用过 big.NewRat(N,D) 方法构造。N（分子）和 D（分母）都是 int64 型整数。因为 Go 语言不支持运算符重载，所以所有大数字类型都有像是 Add() 和 Mul() 这样的方法。它们作用于作为 receiver 的整数和有理数，大多数情况下它们修改 receiver 并以 receiver 作为返回结果。因为没有必要创建 big.Int 类型的临时变量来存放中间结果，所以这样的运算可通过内存链式存储。 示例 9.2 big.go： // big.go package main import ( \"fmt\" \"math\" \"math/big\" ) func main() { // Here are some calculations with bigInts: im := big.NewInt(math.MaxInt64) in := im io := big.NewInt(1956) ip := big.NewInt(1) ip.Mul(im, in).Add(ip, im).Div(ip, io) fmt.Printf(\"Big Int: %v\\n\", ip) // Here are some calculations with bigInts: rm := big.NewRat(math.MaxInt64, 1956) rn := big.NewRat(-1956, math.MaxInt64) ro := big.NewRat(19, 56) rp := big.NewRat(1111, 2222) rq := big.NewRat(1, 1) rq.Mul(rm, rn).Add(rq, ro).Mul(rq, rp) fmt.Printf(\"Big Rat: %v\\n\", rq) } /* Output: Big Int: 43492122561469640008497075573153004 Big Rat: -37/112 */ 输出结果： Big Int: 43492122561469640008497075573153004 Big Rat: -37/112 链接 目录 上一节：锁和 sync 包 下一节：自定义包和可见性 "},"Go入门指南/09.5.html":{"url":"Go入门指南/09.5.html","title":"5","keywords":"","body":"9.5 自定义包和可见性 包是 Go 语言中代码组织和代码编译的主要方式。关于它们的很多基本信息已经在 4.2 章节中给出，最引人注目的便是可见性。现在我们来看看具体如何来使用自己写的包。在下一节，我们将回顾一些标准库中的包，自定义的包和标准库以外的包。 当写自己包的时候，要使用短小的不含有 _(下划线)的小写单词来为文件命名。这里有个简单例子来说明包是如何相互调用以及可见性是如何实现的。 当前目录下（examples/chapter_9/book/）有一个名为 package_test.go 的程序, 它使用了自定义包 pack1 中 pack1.go 的代码。这段程序(连同编译链接生成的 pack1.a)存放在当前目录下一个名为 pack1 的文件夹下。所以链接器将包的对象和主程序对象链接在一起。 示例 9.4 pack1.go： package pack1 var Pack1Int int = 42 var PackFloat = 3.14 func ReturnStr() string { return \"Hello main!\" } 它包含了一个整型变量 Pack1Int 和一个返回字符串的函数 ReturnStr。这段程序在运行时不做任何的事情，因为它不包含有一个 main 函数。 在主程序 package_test.go 中这个包通过声明的方式被导入 import \"./pack1/pack1\" import 的一般格式如下: import \"包的路径或 URL 地址\" 例如： import \"github.com/org1/pack1” 路径是指当前目录的相对路径。 示例 9.5 package_test.go： package main import ( \"fmt\" \"./pack1/pack1\" ) func main() { var test1 string test1 = pack1.ReturnStr() fmt.Printf(\"ReturnStr from package1: %s\\n\", test1) fmt.Printf(\"Integer from package1: %d\\n\", pack1.Pack1Int) // fmt.Printf(\"Float from package1: %f\\n\", pack1.pack1Float) } 输出结果： ReturnStr from package1: Hello main! Integer from package1: 42 如果包 pack1 和我们的程序在同一路径下，我们可以通过 \"import ./pack1\" 这样的方式来引入，但这不被视为一个好的方法。 下面的代码试图访问一个未引用的变量或者函数，甚至没有编译。将会返回一个错误： fmt.Printf(“Float from package1: %f\\n”, pack1.pack1Float) 错误： cannot refer to unexported name pack1.pack1Float 主程序利用的包必须在主程序编写之前被编译。主程序中每个 pack1 项目都要通过包名来使用：pack1.Item。具体使用方法请参见示例 4.6 和 4.7。 因此，按照惯例,子目录和包之间有着密切的联系：为了区分,不同包存放在不同的目录下，每个包(所有属于这个包中的 go 文件)都存放在和包名相同的子目录下： Import with . : import . \"./pack1\" 当使用.来做为包的别名时，你可以不通过包名来使用其中的项目。例如：test := ReturnStr()。 在当前的命名空间导入 pack1 包，一般是为了具有更好的测试效果。 Import with _ : import _ \"./pack1/pack1\" pack1包只导入其副作用，也就是说，只执行它的init函数并初始化其中的全局变量。 导入外部安装包: 如果你要在你的应用中使用一个或多个外部包，首先你必须使用 go install（参见第 9.7 节）在你的本地机器上安装它们。 假设你想使用 http://codesite.ext/author/goExample/goex 这种托管在 Google Code、GitHub 和 Launchpad 等代码网站上的包。 你可以通过如下命令安装： go install codesite.ext/author/goExample/goex 将一个名为 codesite.ext/author/goExample/goex 的 map 安装在 $GOROOT/src/ 目录下。 通过以下方式，一次性安装，并导入到你的代码中： import goex \"codesite.ext/author/goExample/goex\" 因此该包的 URL 将用作导入路径。 在 http://golang.org/cmd/goinstall/ 的 go install 文档中列出了一些广泛被使用的托管在网络代码仓库的包的导入路径 包的初始化: 程序的执行开始于导入包，初始化 main 包然后调用 main 函数。 一个没有导入的包将通过分配初始值给所有的包级变量和调用源码中定义的包级 init 函数来初始化。一个包可能有多个 init 函数甚至在一个源码文件中。它们的执行是无序的。这是最好的例子来测定包的值是否只依赖于相同包下的其他值或者函数。 init 函数是不能被调用的。 导入的包在包自身初始化前被初始化，而一个包在程序执行中只能初始化一次。 编译并安装一个包(参见第 9.7 节): 在 Linux/OS X 下可以用类似第 3.9 节的 Makefile 脚本做到这一点： include $(GOROOT)/src/Make.inc TARG=pack1 GOFILES=\\ pack1.go\\ pack1b.go\\ include $(GOROOT)/src/Make.pkg 通过 chmod 777 ./Makefile确保它的可执行性。 上面脚本内的include语引入了相应的功能，将自动检测机器的架构并调用正确的编译器和链接器。 然后终端执行 make 或 gomake 工具：他们都会生成一个包含静态库 pack1.a 的 _obj 目录。 go install(参见第 9.7 节，从 Go1 的首选方式)同样复制 pack1.a 到本地的 $GOROOT/pkg 的目录中一个以操作系统为名的子目录下。像 import \"pack1\" 代替 import \"path to pack1\"，这样只通过名字就可以将包在程序中导入。 当第 13 章我们遇到使用测试工具进行测试的时候我们将重新回到自己的包的制作和编译这个话题。 问题 9.1 a）一个包能分成多个源文件么？ b）一个源文件是否能包含多个包？ 练习 9.3 创建一个程序 main_greetings.go 能够和用户说 \"Good Day\" 或者 \"Good Night\"。不同的问候应该放到 greetings 包中。 在同一个包中创建一个 ISAM 函数返回一个布尔值用来判断当前时间是 AM 还是 PM，同样创建 IsAfternoon 和 IsEvening 函数。 使用 main_greetings 作出合适的问候(提示：使用 time 包)。 练习 9.4 创建一个程序 main_oddven.go 判断前 100 个整数是不是偶数，包内同时包含测试的功能。 练习 9.5 使用第 6.6 节的斐波那契程序： 1）将斐波那契功能放入自己的 fibo 包中并通过主程序调用它，存储最后输入的值在函数的全局变量。 2）扩展 fibo 包将通过调用斐波那契的时候，操作也作为一个参数。实验 \"+\" 和 “*” main_fibo.go / fibonacci.go 链接 目录 上一节：精密计算和 big 包 下一节：为自定义包使用 godoc "},"Go入门指南/09.6.html":{"url":"Go入门指南/09.6.html","title":"6","keywords":"","body":"9.6 为自定义包使用 godoc godoc工具（第 3.6 节）在显示自定义包中的注释也有很好的效果：注释必须以 // 开始并无空行放在声明（包，类型，函数）前。godoc 会为每个文件生成一系列的网页。 例如： 在 doc_examples 目录下我们有第 11.7 节中的用来排序的 go 文件，文件中有一些注释（文件需要未编译） 命令行下进入目录下并输入命令： godoc -http=:6060 -goroot=\".\" （. 是指当前目录，-goroot 参数可以是 /path/to/my/package1 这样的形式指出 package1 在你源码中的位置或接受用冒号形式分隔的路径，无根目录的路径为相对于当前目录的相对路径） 在浏览器打开地址：http://localhost:6060 然后你会看到本地的 godoc 页面（详见第 3.6 节）从左到右一次显示出目录中的包： doc_example: doc_example | Packages | Commands | Specification 下面是链接到源码和所有对象时有序概述（所以是很好的浏览和查找源代码的方式），连同文件/注释： sort 包 func Float64sAreSorted type IntArray func IntsAreSortedfunc IsSortedfunc Sort func (IntArray) Len func SortFloat64s func (IntArray) Less func SortInts func (IntArray) Swap func SortStrings type Interface func StringsAreSorted type StringArray type Float64Array func (StringArray) Len func (Float64Array) Len func (StringArray) Less func (Float64Array) Less func (StringArray) Swap func (Float64Array) Swap // Other packages import \"doc_example\" 使用通用的接口排序: func Float64sAreSorted[Top] func Float64sAreSorted(a []float64) bool func IntsAreSorted[Top] func IntsAreSorted(a []int) bool func IsSorted[Top] func IsSorted(data Interface) bool Test if data is sorted func Sort[Top] func Sort(data Interface) General sort function func SortInts[Top] func SortInts(a []int) Convenience wrappers for common cases: type IntArray[Top] Convenience types for common cases: IntArray type IntArray []int 如果你在一个团队中工作，并在源代码树被存储在网络硬盘上，就可以使用 godoc 给所有团队成员连续文档的支持。通过设置 sync_minutes=n，你甚至可以让它每 n 分钟自动更新您的文档！ 链接 目录 上一节：自定义包和可见性 下一节：使用 go install 安装自定义包 "},"Go入门指南/09.7.html":{"url":"Go入门指南/09.7.html","title":"7","keywords":"","body":"9.7 使用 go install 安装自定义包 go install 是 Go 中自动包安装工具：如需要将包安装到本地它会从远端仓库下载包：检出、编译和安装一气呵成。 在包安装前的先决条件是要自动处理包自身依赖关系的安装。被依赖的包也会安装到子目录下，但是没有文档和示例：可以到网上浏览。 go install 使用了 GOPATH 变量(详见第 2.2 节)。 远端包(详见第 9.5 节)： 假设我们要安装一个有趣的包 tideland（它包含了许多帮助示例，参见 项目主页）。 因为我们需要创建目录在 Go 安装目录下，所以我们需要使用 root 或者 su 的身份执行命令。 确保 Go 环境变量已经设置在 root 用户下的 ./bashrc 文件中。 使用命令安装：go install tideland-cgl.googlecode.com/hg。 可执行文件 hg.a 将被放到 $GOROOT/pkg/linux_amd64/tideland-cgl.googlecode.com 目录下，源码文件被放置在 $GOROOT/src/tideland-cgl.googlecode.com/hg 目录下，同样有个 hg.a 放置在 _obj 的子目录下。 现在就可以在 go 代码中使用这个包中的功能了，例如使用包名 cgl 导入： import cgl \"tideland-cgl.googlecode.com/hg\" 从 Go1 起 go install 安装 Google Code 的导入路径形式是：\"code.google.com/p/tideland-cgl\" 升级到新的版本： 更新到新版本的 Go 之后本地安装包的二进制文件将全被删除。如果你想更新，重编译、重安装所有的go安装包可以使用：go install -a。 go 的版本发布的很频繁，所以需要注意发布版本和包的兼容性。go1 之后都是自己编译自己了。 go install 同样可以使用 go install 编译链接并安装本地自己的包（详见第 9.8.2 节）。 更多信息可以在 官方网站 找到。 链接 目录 上一节：为自定义包使用 godoc 下一节：自定义包的目录结构、go install 和 go test "},"Go入门指南/09.8.html":{"url":"Go入门指南/09.8.html","title":"8","keywords":"","body":"9.8 自定义包的目录结构、go install 和 go test 为了示范，我们创建了一个名为 uc 的简单包，它含有一个 UpperCase 函数将字符串的所有字母转换为大写。当然这并不值得创建一个自己包，同样的功能已被包含在 strings 包里，但是同样的技术也可以应用在更复杂的包中。 9.8.1 自定义包的目录结构 下面的结构给了你一个好的示范(uc 代表通用包名, 名字为粗体的代表目录，斜体代表可执行文件): /home/user/goprograms ucmain.go (uc包主程序) Makefile (ucmain的makefile) ucmain src/uc (包含uc包的go源码) uc.go uc_test.go Makefile (包的makefile) uc.a _obj uc.a _test uc.a bin (包含最终的执行文件) ucmain pkg/linux_amd64 uc.a (包的目标文件) 将你的项目放在 goprograms 目录下(你可以创建一个环境变量 GOPATH，详见第 2.2/3 章节：在 .profile 和 .bashrc 文件中添加 export GOPATH=/home/user/goprograms)，而你的项目将作为 src 的子目录。uc 包中的功能在 uc.go 中实现。 示例 9.6 uc.go： package uc import \"strings\" func UpperCase(str string) string { return strings.ToUpper(str) } 包通常附带一个或多个测试文件，在这我们创建了一个 uc_test.go 文件，如第 9.8 节所述。 示例 9.7 test.go package uc import \"testing\" type ucTest struct { in, out string } var ucTests = []ucTest { ucTest{\"abc\", \"ABC\"}, ucTest{\"cvo-az\", \"CVO-AZ\"}, ucTest{\"Antwerp\", \"ANTWERP\"}, } func TestUC(t *testing.T) { for _, ut := range ucTests { uc := UpperCase(ut.in) if uc != ut.out { t.Errorf(\"UpperCase(%s) = %s, must be %s\", ut.in, uc, ut.out) } } } 通过指令编译并安装包到本地：go install uc, 这会将 uc.a 复制到 pkg/linux_amd64 下面。 另外，使用 make ，通过以下内容创建一个包的 Makefile 在 src/uc 目录下: include $(GOROOT)/src/Make.inc TARG=uc GOFILES=\\ uc.go\\ include $(GOROOT)/src/Make.pkg 在该目录下的命令行调用: gomake 这将创建一个 _obj 目录并将包编译生成的存档 uc.a 放在该目录下。 这个包可以通过 go test 测试。 创建一个 uc.a 的测试文件在目录下，输出为 PASS 时测试通过。 在第 13.8 节我们将给出另外一个测试例子并进行深入研究。 备注：有可能你当前的用户不具有足够的资格使用 go　install(没有权限)。这种情况下，选择 root 用户 su。确保 Go 环境变量和 Go 源码路径也设置给 su，同样也适用你的普通用户(详见第 2.3 节)。 接下来我们创建主程序 ucmain.go: 示例 9.8 ucmain.go： package main import ( \"./uc/uc\" \"fmt\" ) func main() { str1 := \"USING package uc!\" fmt.Println(uc.UpperCase(str1)) } 然后在这个目录下输入 go install。 另外复制 uc.a 到 /home/user/goprograms 目录并创建一个 Makefile 并写入文本： include $(GOROOT)/src/Make.inc TARG=ucmain GOFILES=\\ ucmain.go\\ include $(GOROOT)/src/Make.cmd 执行 gomake 编译 ucmain.go 生成可执行文件ucmain 运行 ./ucmain 显示: USING PACKAGE UC!。 9.8.2 本地安装包 本地包在用户目录下，使用给出的目录结构，以下命令用来从源码安装本地包： go install /home/user/goprograms/src/uc # 编译安装uc cd /home/user/goprograms/uc go install ./uc # 编译安装uc（和之前的指令一样） cd .. go install . # 编译安装ucmain 安装到 $GOPATH 下： 如果我们想安装的包在系统上的其他 Go 程序中被使用，它一定要安装到 $GOPATH 下。 这样做，在 .profile 和 .bashrc 中设置 export GOPATH=/home/user/goprograms。 然后执行 go install uc 将会复制包存档到 $GOPATH/pkg/LINUX_AMD64/uc。 现在，uc 包可以通过 import \"uc\" 在任何 Go 程序中被引用。 9.8.3 依赖系统的代码 在不同的操作系统上运行的程序以不同的代码实现是非常少见的：绝大多数情况下语言和标准库解决了大部分的可移植性问题。 你有一个很好的理由去写平台特定的代码，例如汇编语言。这种情况下，按照下面的约定是合理的： prog1.go prog1_linux.go prog1_darwin.go prog1_windows.go prog1.go 定义了不同操作系统通用的接口，并将系统特定的代码写到 prog1os.go 中。 对于 Go 工具你可以指定 `prog1$GOOS.go或prog1$GOARCH.go或在平台 Makefile 中：prog1$(GOOS).go` 或 prog1_$(GOARCH).go\\。 链接 目录 上一节：使用 go install 安装自定义包 下一节：通过 Git 打包和安装 "},"Go入门指南/09.9.html":{"url":"Go入门指南/09.9.html","title":"9","keywords":"","body":"9.9 通过 Git 打包和安装 9.9.1 安装到 GitHub 以上的方式对于本地包来说是可以的，但是我们如何打包代码到开发者圈子呢？那么我们需要一个云端的源码的版本控制系统，比如著名的 Git。 在 Linux 和 OS X 的机器上 Git 是默认安装的，在 Windows 上你必须先自行安装，参见 GitHub 帮助页面。 这里将通过为第 9.8 节中的 uc 包创建一个 git 仓库作为演示 进入到 uc 包目录下并创建一个 Git 仓库在里面: git init。 信息提示: Initialized empty git repository in $PWD/uc。 每一个 Git 项目都需要一个对包进行描述的 README.md 文件，所以需要打开你的文本编辑器（gedit、notepad 或 LiteIde）并添加一些说明进去。 添加所有文件到仓库：git add README.md uc.go uc_test.go Makefile。 标记为第一个版本：git commit -m \"initial rivision\"。 现在必须登录 GitHub 网站。 如果您还没有账号，可以去注册一个开源项目的免费帐号。输入正确的帐号密码和有效的邮箱地址并进一步创建用户。然后你将获得一个 Git 命令的列表。本地仓库的操作命令已经完成。一个优秀的系统在你遇到任何问题的时候将 引导你。 在云端创建一个新的 uc 仓库;发布的指令为(NNNN 替代用户名): git remote add origin git@github.com:NNNN/uc.git git push -u origin master 操作完成后检查 GitHub 上的包页面: http://github.com/NNNN/uc。 9.9.2 从 GitHub 安装 如果有人想安装您的远端项目到本地机器，打开终端并执行（NNNN 是你在 GitHub 上的用户名）：go get github.com/NNNN/uc。 这样现在这台机器上的其他 Go 应用程序也可以通过导入路径：\"github.com/NNNN/uc\" 代替 \"./uc/uc\" 来使用。 也可以将其缩写为：import uc \"github.com/NNNN/uc\"。 然后修改 Makefile: 将 TARG=uc 替换为 TARG=github.com/NNNN/uc。 Gomake（和 go install）将通过 $GOPATH 下的本地版本进行工作。 网站和版本控制系统的其他的选择(括号中为网站所使用的版本控制系统)： BitBucket(hg/Git) GitHub(Git) Google Code(hg/Git/svn) Launchpad(bzr) 版本控制系统可以选择你熟悉的或者本地使用的代码版本控制。Go 核心代码的仓库是使用 Mercurial(hg) 来控制的，所以它是一个最可能保证你可以得到开发者项目中最好的软件。Git 也很出名，同样也适用。如果你从未使用过版本控制，这些网站有一些很好的帮助并且你可以通过在谷歌搜索 \"{name} tutorial\"，(name为你想要使用的版本控制系统),得到许多很好的教程。 链接 目录 上一节：自定义包的目录结构、go install 和 go test 下一节：Go 的外部包和项目 "},"Go入门指南/10.0.html":{"url":"Go入门指南/10.0.html","title":"0","keywords":"","body":"10 结构（struct）与方法（method） Go 通过类型别名（alias types）和结构体的形式支持用户自定义类型，或者叫定制类型。一个带属性的结构体试图表示一个现实世界中的实体。结构体是复合类型（composite types），当需要定义一个类型，它由一系列属性组成，每个属性都有自己的类型和值的时候，就应该使用结构体，它把数据聚集在一起。然后可以访问这些数据，就好像它是一个独立实体的一部分。结构体也是值类型，因此可以通过 new 函数来创建。 组成结构体类型的那些数据称为 字段（fields）。每个字段都有一个类型和一个名字；在一个结构体中，字段名字必须是唯一的。 结构体的概念在软件工程上旧的术语叫 ADT（抽象数据类型：Abstract Data Type），在一些老的编程语言中叫 记录（Record），比如 Cobol，在 C 家族的编程语言中它也存在，并且名字也是 struct，在面向对象的编程语言中，跟一个无方法的轻量级类一样。不过因为 Go 语言中没有类的概念，因此在 Go 中结构体有着更为重要的地位。 链接 目录 上一节：在 Go 程序中使用外部库 下一节：结构体定义 "},"Go入门指南/10.1.html":{"url":"Go入门指南/10.1.html","title":"1","keywords":"","body":"10.1 结构体定义 结构体定义的一般方式如下： type identifier struct { field1 type1 field2 type2 ... } type T struct {a, b int} 也是合法的语法，它更适用于简单的结构体。 结构体里的字段都有 名字，像 field1、field2 等，如果字段在代码中从来也不会被用到，那么可以命名它为 _。 结构体的字段可以是任何类型，甚至是结构体本身（参考第 10.5 节），也可以是函数或者接口（参考第 11 章）。可以声明结构体类型的一个变量，然后像下面这样给它的字段赋值： var s T s.a = 5 s.b = 8 数组可以看作是一种结构体类型，不过它使用下标而不是具名的字段。 使用 new 使用 new 函数给一个新的结构体变量分配内存，它返回指向已分配内存的指针：var t *T = new(T)，如果需要可以把这条语句放在不同的行（比如定义是包范围的，但是分配却没有必要在开始就做）。 var t *T t = new(T) 写这条语句的惯用方法是：t := new(T)，变量 t 是一个指向 T的指针，此时结构体字段的值是它们所属类型的零值。 声明 var t T 也会给 t 分配内存，并零值化内存，但是这个时候 t 是类型T。在这两种方式中，t 通常被称做类型 T 的一个实例（instance）或对象（object）。 示例 10.1 structs_fields.go 给出了一个非常简单的例子： package main import \"fmt\" type struct1 struct { i1 int f1 float32 str string } func main() { ms := new(struct1) ms.i1 = 10 ms.f1 = 15.5 ms.str= \"Chris\" fmt.Printf(\"The int is: %d\\n\", ms.i1) fmt.Printf(\"The float is: %f\\n\", ms.f1) fmt.Printf(\"The string is: %s\\n\", ms.str) fmt.Println(ms) } 输出： The int is: 10 The float is: 15.500000 The string is: Chris &{10 15.5 Chris} 使用 fmt.Println 打印一个结构体的默认输出可以很好的显示它的内容，类似使用 %v 选项。 就像在面向对象语言所作的那样，可以使用点号符给字段赋值：structname.fieldname = value。 同样的，使用点号符可以获取结构体字段的值：structname.fieldname。 在 Go 语言中这叫 选择器（selector）。无论变量是一个结构体类型还是一个结构体类型指针，都使用同样的 选择器符（selector-notation） 来引用结构体的字段： type myStruct struct { i int } var v myStruct // v是结构体类型变量 var p *myStruct // p是指向一个结构体类型变量的指针 v.i p.i 初始化一个结构体实例（一个结构体字面量：struct-literal）的更简短和惯用的方式如下： ms := &struct1{10, 15.5, \"Chris\"} // 此时ms的类型是 *struct1 或者： var ms struct1 ms = struct1{10, 15.5, \"Chris\"} 混合字面量语法（composite literal syntax）&struct1{a, b, c} 是一种简写，底层仍然会调用 new ()，这里值的顺序必须按照字段顺序来写。在下面的例子中能看到可以通过在值的前面放上字段名来初始化字段的方式。表达式 new(Type) 和 &Type{} 是等价的。 时间间隔（开始和结束时间以秒为单位）是使用结构体的一个典型例子： type Interval struct { start int end int } 初始化方式： intr := Interval{0, 3} (A) intr := Interval{end:5, start:1} (B) intr := Interval{end:5} (C) 在（A）中，值必须以字段在结构体定义时的顺序给出，& 不是必须的。（B）显示了另一种方式，字段名加一个冒号放在值的前面，这种情况下值的顺序不必一致，并且某些字段还可以被忽略掉，就像（C）中那样。 结构体类型和字段的命名遵循可见性规则（第 4.2 节），一个导出的结构体类型中有些字段是导出的，另一些不是，这是可能的。 下图说明了结构体类型实例和一个指向它的指针的内存布局： type Point struct { x, y int } 使用 new 初始化： 作为结构体字面量初始化： 类型 strcut1 在定义它的包 pack1 中必须是唯一的，它的完全类型名是：pack1.struct1。 下面的例子 Listing 10.2—person.go 显示了一个结构体 Person，一个方法，方法有一个类型为 *Person 的参数（因此对象本身是可以被改变的），以及三种调用这个方法的不同方式： package main import ( \"fmt\" \"strings\" ) type Person struct { firstName string lastName string } func upPerson(p *Person) { p.firstName = strings.ToUpper(p.firstName) p.lastName = strings.ToUpper(p.lastName) } func main() { // 1-struct as a value type: var pers1 Person pers1.firstName = \"Chris\" pers1.lastName = \"Woodward\" upPerson(&pers1) fmt.Printf(\"The name of the person is %s %s\\n\", pers1.firstName, pers1.lastName) // 2—struct as a pointer: pers2 := new(Person) pers2.firstName = \"Chris\" pers2.lastName = \"Woodward\" (*pers2).lastName = \"Woodward\" // 这是合法的 upPerson(pers2) fmt.Printf(\"The name of the person is %s %s\\n\", pers2.firstName, pers2.lastName) // 3—struct as a literal: pers3 := &Person{\"Chris\",\"Woodward\"} upPerson(pers3) fmt.Printf(\"The name of the person is %s %s\\n\", pers3.firstName, pers3.lastName) } 输出： The name of the person is CHRIS WOODWARD The name of the person is CHRIS WOODWARD The name of the person is CHRIS WOODWARD 在上面例子的第二种情况中，可以直接通过指针，像 pers2.lastName=\"Woodward\" 这样给结构体字段赋值，没有像 C++ 中那样需要使用 -> 操作符，Go 会自动做这样的转换。 注意也可以通过解指针的方式来设置值：(*pers2).lastName = \"Woodward\" 结构体的内存布局 Go 语言中，结构体和它所包含的数据在内存中是以连续块的形式存在的，即使结构体中嵌套有其他的结构体，这在性能上带来了很大的优势。不像 Java 中的引用类型，一个对象和它里面包含的对象可能会在不同的内存空间中，这点和 Go 语言中的指针很像。下面的例子清晰地说明了这些情况： type Rect1 struct {Min, Max Point } type Rect2 struct {Min, Max *Point } 递归结构体 结构体类型可以通过引用自身来定义。这在定义链表或二叉树的元素（通常叫节点）时特别有用，此时节点包含指向临近节点的链接（地址）。如下所示，链表中的 su，树中的 ri 和 le 分别是指向别的节点的指针。 链表： 这块的 data 字段用于存放有效数据（比如 float64），su 指针指向后继节点。 Go 代码： type Node struct { data float64 su *Node } 链表中的第一个元素叫 head，它指向第二个元素；最后一个元素叫 tail，它没有后继元素，所以它的 su 为 nil 值。当然真实的链接会有很多数据节点，并且链表可以动态增长或收缩。 同样地可以定义一个双向链表，它有一个前趋节点 pr 和一个后继节点 su： type Node struct { pr *Node data float64 su *Node } 二叉树： 二叉树中每个节点最多能链接至两个节点：左节点（le）和右节点（ri），这两个节点本身又可以有左右节点，依次类推。树的顶层节点叫根节点（root），底层没有子节点的节点叫叶子节点（leaves），叶子节点的 le 和 ri 指针为 nil 值。在 Go 中可以如下定义二叉树： type Tree strcut { le *Tree data float64 ri *Tree } 结构体转换 Go 中的类型转换遵循严格的规则。当为结构体定义了一个 alias 类型时，此结构体类型和它的 alias 类型都有相同的底层类型，它们可以如示例 10.3 那样互相转换，同时需要注意其中非法赋值或转换引起的编译错误。 示例 10.3： package main import \"fmt\" type number struct { f float32 } type nr number // alias type func main() { a := number{5.0} b := nr{5.0} // var i float32 = b // compile-error: cannot use b (type nr) as type float32 in assignment // var i = float32(b) // compile-error: cannot convert b (type nr) to type float32 // var c number = b // compile-error: cannot use b (type nr) as type number in assignment // needs a conversion: var c = number(b) fmt.Println(a, b, c) } 输出： {5} {5} {5} 练习 10.1 vcard.go： 定义结构体 Address 和 VCard，后者包含一个人的名字、地址编号、出生日期和图像，试着选择正确的数据类型。构建一个自己的 vcard 并打印它的内容。 提示： VCard 必须包含住址，它应该以值类型还是以指针类型放在 VCard 中呢？ 第二种会好点，因为它占用内存少。包含一个名字和两个指向地址的指针的 Address 结构体可以使用 %v 打印： {Kersschot 0x126d2b80 0x126d2be0} 练习 10.2 persionext1.go： 修改 persionext1.go，使它的参数 upPerson 不是一个指针，解释下二者的区别。 练习 10.3 point.go： 使用坐标 X、Y 定义一个二维 Point 结构体。同样地，对一个三维点使用它的极坐标定义一个 Polar 结构体。实现一个 Abs() 方法来计算一个 Point 表示的向量的长度，实现一个 Scale 方法，它将点的坐标乘以一个尺度因子（提示：使用 math 包里的 Sqrt 函数）（function Scale that multiplies the coordinates of a point with a scale factor）。 练习 10.3 rectangle.go： 定义一个 Rectangle 结构体，它的长和宽是 int 类型，并定义方法 Area() 和 Primeter()，然后进行测试。 链接 目录 上一节：结构（struct）与方法（method） 下一节：使用工厂方法创建结构体 "},"Go入门指南/10.2.html":{"url":"Go入门指南/10.2.html","title":"2","keywords":"","body":"10.2 使用工厂方法创建结构体实例 10.2.1 结构体工厂 Go 语言不支持面向对象编程语言中那样的构造子方法，但是可以很容易的在 Go 中实现 “构造子工厂”方法。为了方便通常会为类型定义一个工厂，按惯例，工厂的名字以 new 或 New 开头。假设定义了如下的 File 结构体类型： type File struct { fd int // 文件描述符 name string // 文件名 } 下面是这个结构体类型对应的工厂方法，它返回一个指向结构体实例的指针： func NewFile(fd int, name string) *File { if fd 然后这样调用它： f := NewFile(10, \"./test.txt\") 在 Go 语言中常常像上面这样在工厂方法里使用初始化来简便的实现构造函数。 如果 File 是一个结构体类型，那么表达式 new(File) 和 &File{} 是等价的。 这可以和大多数面向对象编程语言中笨拙的初始化方式做个比较：File f = new File(...)。 我们可以说是工厂实例化了类型的一个对象，就像在基于类的OO语言中那样。 如果想知道结构体类型T的一个实例占用了多少内存，可以使用：size := unsafe.Sizeof(T{})。 如何强制使用工厂方法 通过应用可见性规则参考4.2.1节、9.5 节就可以禁止使用 new 函数，强制用户使用工厂方法，从而使类型变成私有的，就像在面向对象语言中那样。 type matrix struct { ... } func NewMatrix(params) *matrix { m := new(matrix) // 初始化 m return m } 在其他包里使用工厂方法： package main import \"matrix\" ... wrong := new(matrix.matrix) // 编译失败（matrix 是私有的） right := matrix.NewMatrix(...) // 实例化 matrix 的唯一方式 10.2.2 map 和 struct vs new() 和 make() new 和 make 这两个内置函数已经在第 7.2.4 节通过切片的例子说明过一次。 现在为止我们已经见到了可以使用 make() 的三种类型中的其中两个： slices / maps / channels（见第 14 章） 下面的例子说明了在映射上使用 new 和 make 的区别以及可能发生的错误： 示例 10.4 new_make.go（不能编译） package main type Foo map[string]string type Bar struct { thingOne string thingTwo int } func main() { // OK y := new(Bar) (*y).thingOne = \"hello\" (*y).thingTwo = 1 // NOT OK z := make(Bar) // 编译错误：cannot make type Bar (*z).thingOne = \"hello\" (*z).thingTwo = 1 // OK x := make(Foo) x[\"x\"] = \"goodbye\" x[\"y\"] = \"world\" // NOT OK u := new(Foo) (*u)[\"x\"] = \"goodbye\" // 运行时错误!! panic: assignment to entry in nil map (*u)[\"y\"] = \"world\" } 试图 make() 一个结构体变量，会引发一个编译错误，这还不是太糟糕，但是 new() 一个映射并试图使用数据填充它，将会引发运行时错误！ 因为 new(Foo) 返回的是一个指向 nil 的指针，它尚未被分配内存。所以在使用 map 时要特别谨慎。 链接 目录 上一节：结构体定义 下一节：使用自定义包中的结构体 "},"Go入门指南/10.3.html":{"url":"Go入门指南/10.3.html","title":"3","keywords":"","body":"10.3 使用自定义包中的结构体 下面的例子中，main.go 使用了一个结构体，它来自 struct_pack 下的包 structPack。 示例 10.5 structPack.go： package structPack type ExpStruct struct { Mi1 int Mf1 float32 } 示例 10.6 main.go： package main import ( \"fmt\" \"./struct_pack/structPack\" ) func main() { struct1 := new(structPack.ExpStruct) struct1.Mi1 = 10 struct1.Mf1 = 16. fmt.Printf(\"Mi1 = %d\\n\", struct1.Mi1) fmt.Printf(\"Mf1 = %f\\n\", struct1.Mf1) } 输出： Mi1 = 10 Mf1 = 16.000000 链接 目录 上一节：使用工厂方法创建结构体实例 下一节：带标签的结构体 "},"Go入门指南/10.4.html":{"url":"Go入门指南/10.4.html","title":"4","keywords":"","body":"10.4 带标签的结构体 结构体中的字段除了有名字和类型外，还可以有一个可选的标签（tag）：它是一个附属于字段的字符串，可以是文档或其他的重要标记。标签的内容不可以在一般的编程中使用，只有包 reflect 能获取它。我们将在下一章（第 11.10 节）中深入的探讨 reflect包，它可以在运行时自省类型、属性和方法，比如：在一个变量上调用 reflect.TypeOf() 可以获取变量的正确类型，如果变量是一个结构体类型，就可以通过 Field 来索引结构体的字段，然后就可以使用 Tag 属性。 示例 10.7 struct_tag.go： package main import ( \"fmt\" \"reflect\" ) type TagType struct { // tags field1 bool \"An important answer\" field2 string \"The name of the thing\" field3 int \"How much there are\" } func main() { tt := TagType{true, \"Barak Obama\", 1} for i := 0; i 输出： An important answer The name of the thing How much there are 链接 目录 上一节：使用自定义包中的结构体 下一节：匿名字段和内嵌结构体 "},"Go入门指南/10.5.html":{"url":"Go入门指南/10.5.html","title":"5","keywords":"","body":"10.5 匿名字段和内嵌结构体 10.5.1 定义 结构体可以包含一个或多个 匿名（或内嵌）字段，即这些字段没有显式的名字，只有字段的类型是必须的，此时类型就是字段的名字。匿名字段本身可以是一个结构体类型，即 结构体可以包含内嵌结构体。 可以粗略地将这个和面向对象语言中的继承概念相比较，随后将会看到它被用来模拟类似继承的行为。Go 语言中的继承是通过内嵌或组合来实现的，所以可以说，在 Go 语言中，相比较于继承，组合更受青睐。 考虑如下的程序： 示例 10.8 structs_anonymous_fields.go： package main import \"fmt\" type innerS struct { in1 int in2 int } type outerS struct { b int c float32 int // anonymous field innerS //anonymous field } func main() { outer := new(outerS) outer.b = 6 outer.c = 7.5 outer.int = 60 outer.in1 = 5 outer.in2 = 10 fmt.Printf(\"outer.b is: %d\\n\", outer.b) fmt.Printf(\"outer.c is: %f\\n\", outer.c) fmt.Printf(\"outer.int is: %d\\n\", outer.int) fmt.Printf(\"outer.in1 is: %d\\n\", outer.in1) fmt.Printf(\"outer.in2 is: %d\\n\", outer.in2) // 使用结构体字面量 outer2 := outerS{6, 7.5, 60, innerS{5, 10}} fmt.Println(\"outer2 is:\", outer2) } 输出： outer.b is: 6 outer.c is: 7.500000 outer.int is: 60 outer.in1 is: 5 outer.in2 is: 10 outer2 is:{6 7.5 60 {5 10}} 通过类型 outer.int 的名字来获取存储在匿名字段中的数据，于是可以得出一个结论：在一个结构体中对于每一种数据类型只能有一个匿名字段。 10.5.2 内嵌结构体 同样地结构体也是一种数据类型，所以它也可以作为一个匿名字段来使用，如同上面例子中那样。外层结构体通过 outer.in1 直接进入内层结构体的字段，内嵌结构体甚至可以来自其他包。内层结构体被简单的插入或者内嵌进外层结构体。这个简单的“继承”机制提供了一种方式，使得可以从另外一个或一些类型继承部分或全部实现。 另外一个例子： 示例 10.9 embedd_struct.go： package main import \"fmt\" type A struct { ax, ay int } type B struct { A bx, by float32 } func main() { b := B{A{1, 2}, 3.0, 4.0} fmt.Println(b.ax, b.ay, b.bx, b.by) fmt.Println(b.A) } 输出： 1 2 3 4 {1 2} 练习 10.5 anonymous_struct.go： 创建一个结构体，它有一个具名的 float 字段，2 个匿名字段，类型分别是 int 和 string。通过结构体字面量新建一个结构体实例并打印它的内容。 10.5.3 命名冲突 当两个字段拥有相同的名字（可能是继承来的名字）时该怎么办呢？ 外层名字会覆盖内层名字（但是两者的内存空间都保留），这提供了一种重载字段或方法的方式； 如果相同的名字在同一级别出现了两次，如果这个名字被程序使用了，将会引发一个错误（不使用没关系）。没有办法来解决这种问题引起的二义性，必须由程序员自己修正。 例子： type A struct {a int} type B struct {a, b int} type C struct {A; B} var c C 规则 2：使用 c.a 是错误的，到底是 c.A.a 还是 c.B.a 呢？会导致编译器错误：ambiguous DOT reference c.a disambiguate with either c.A.a or c.B.a。 type D struct {B; b float32} var d D 规则1：使用 d.b 是没问题的：它是 float32，而不是 B 的 b。如果想要内层的 b 可以通过 d.B.b 得到。 链接 目录 上一节：带标签的结构体 下一节：方法 "},"Go入门指南/10.6.html":{"url":"Go入门指南/10.6.html","title":"6","keywords":"","body":"10.6 方法 10.6.1 方法是什么 在 Go 语言中，结构体就像是类的一种简化形式，那么面向对象程序员可能会问：类的方法在哪里呢？在 Go 中有一个概念，它和方法有着同样的名字，并且大体上意思相同：Go 方法是作用在接收者（receiver）上的一个函数，接收者是某种类型的变量。因此方法是一种特殊类型的函数。 接收者类型可以是（几乎）任何类型，不仅仅是结构体类型：任何类型都可以有方法，甚至可以是函数类型，可以是 int、bool、string 或数组的别名类型。但是接收者不能是一个接口类型（参考 第 11 章），因为接口是一个抽象定义，但是方法却是具体实现；如果这样做会引发一个编译错误：invalid receiver type…。 最后接收者不能是一个指针类型，但是它可以是任何其他允许类型的指针。 一个类型加上它的方法等价于面向对象中的一个类。一个重要的区别是：在 Go 中，类型的代码和绑定在它上面的方法的代码可以不放置在一起，它们可以存在在不同的源文件，唯一的要求是：它们必须是同一个包的。 类型 T（或 *T）上的所有方法的集合叫做类型 T（或 *T）的方法集。 因为方法是函数，所以同样的，不允许方法重载，即对于一个类型只能有一个给定名称的方法。但是如果基于接收者类型，是有重载的：具有同样名字的方法可以在 2 个或多个不同的接收者类型上存在，比如在同一个包里这么做是允许的： func (a *denseMatrix) Add(b Matrix) Matrix func (a *sparseMatrix) Add(b Matrix) Matrix 别名类型不能有它原始类型上已经定义过的方法。 定义方法的一般格式如下： func (recv receiver_type) methodName(parameter_list) (return_value_list) { ... } 在方法名之前，func 关键字之后的括号中指定 receiver。 如果 recv 是 receiver 的实例，Method1 是它的方法名，那么方法调用遵循传统的 object.name 选择器符号：recv.Method1()。 如果 recv 一个指针，Go 会自动解引用。 如果方法不需要使用 recv 的值，可以用 _ 替换它，比如： func (_ receiver_type) methodName(parameter_list) (return_value_list) { ... } recv 就像是面向对象语言中的 this 或 self，但是 Go 中并没有这两个关键字。随个人喜好，你可以使用 this 或 self 作为 receiver 的名字。下面是一个结构体上的简单方法的例子： 示例 10.10 method .go： package main import \"fmt\" type TwoInts struct { a int b int } func main() { two1 := new(TwoInts) two1.a = 12 two1.b = 10 fmt.Printf(\"The sum is: %d\\n\", two1.AddThem()) fmt.Printf(\"Add them to the param: %d\\n\", two1.AddToParam(20)) two2 := TwoInts{3, 4} fmt.Printf(\"The sum is: %d\\n\", two2.AddThem()) } func (tn *TwoInts) AddThem() int { return tn.a + tn.b } func (tn *TwoInts) AddToParam(param int) int { return tn.a + tn.b + param } 输出： The sum is: 22 Add them to the param: 42 The sum is: 7 下面是非结构体类型上方法的例子： 示例 10.11 method2.go： package main import \"fmt\" type IntVector []int func (v IntVector) Sum() (s int) { for _, x := range v { s += x } return } func main() { fmt.Println(IntVector{1, 2, 3}.Sum()) // 输出是6 } 练习 10.6 employee_salary.go 定义结构体 employee，它有一个 salary 字段，给这个结构体定义一个方法 giveRaise 来按照指定的百分比增加薪水。 练习 10.7 iteration_list.go 下面这段代码有什么错？ package main import \"container/list\" func (p *list.List) Iter() { // ... } func main() { lst := new(list.List) for _= range lst.Iter() { } } 类型和作用在它上面定义的方法必须在同一个包里定义，这就是为什么不能在 int、float 或类似这些的类型上定义方法。试图在 int 类型上定义方法会得到一个编译错误： cannot define new methods on non-local type int 比如想在 time.Time 上定义如下方法： func (t time.Time) first3Chars() string { return time.LocalTime().String()[0:3] } 类型在其他的，或是非本地的包里定义，在它上面定义方法都会得到和上面同样的错误。 但是有一个间接的方式：可以先定义该类型（比如：int 或 float）的别名类型，然后再为别名类型定义方法。或者像下面这样将它作为匿名类型嵌入在一个新的结构体中。当然方法只在这个别名类型上有效。 示例 10.12 method_on_time.go： package main import ( \"fmt\" \"time\" ) type myTime struct { time.Time //anonymous field } func (t myTime) first3Chars() string { return t.Time.String()[0:3] } func main() { m := myTime{time.Now()} // 调用匿名Time上的String方法 fmt.Println(\"Full time now:\", m.String()) // 调用myTime.first3Chars fmt.Println(\"First 3 chars:\", m.first3Chars()) } /* Output: Full time now: Mon Oct 24 15:34:54 Romance Daylight Time 2011 First 3 chars: Mon */ 10.6.2 函数和方法的区别 函数将变量作为参数：Function1(recv) 方法在变量上被调用：recv.Method1() 在接收者是指针时，方法可以改变接收者的值（或状态），这点函数也可以做到（当参数作为指针传递，即通过引用调用时，函数也可以改变参数的状态）。 不要忘记 Method1 后边的括号 ()，否则会引发编译器错误：method recv.Method1 is not an expression, must be called 接收者必须有一个显式的名字，这个名字必须在方法中被使用。 receiver_type 叫做 （接收者）基本类型，这个类型必须在和方法同样的包中被声明。 在 Go 中，（接收者）类型关联的方法不写在类型结构里面，就像类那样；耦合更加宽松；类型和方法之间的关联由接收者来建立。 方法没有和数据定义（结构体）混在一起：它们是正交的类型；表示（数据）和行为（方法）是独立的。 10.6.3 指针或值作为接收者 鉴于性能的原因，recv 最常见的是一个指向 receiver_type 的指针（因为我们不想要一个实例的拷贝，如果按值调用的话就会是这样），特别是在 receiver 类型是结构体时，就更是如此了。 如果想要方法改变接收者的数据，就在接收者的指针类型上定义该方法。否则，就在普通的值类型上定义方法。 下面的例子 pointer_value.go 作了说明：change()接受一个指向 B 的指针，并改变它内部的成员；write() 通过拷贝接受 B 的值并只输出B的内容。注意 Go 为我们做了探测工作，我们自己并没有指出是否在指针上调用方法，Go 替我们做了这些事情。b1 是值而 b2 是指针，方法都支持运行了。 示例 10.13 pointer_value.go： package main import ( \"fmt\" ) type B struct { thing int } func (b *B) change() { b.thing = 1 } func (b B) write() string { return fmt.Sprint(b) } func main() { var b1 B // b1是值 b1.change() fmt.Println(b1.write()) b2 := new(B) // b2是指针 b2.change() fmt.Println(b2.write()) } /* 输出： {1} {1} */ 试着在 write() 中改变接收者b的值：将会看到它可以正常编译，但是开始的 b 没有被改变。 我们知道方法将指针作为接收者不是必须的，如下面的例子，我们只是需要 Point3 的值来做计算： type Point3 struct { x, y, z float64 } // A method on Point3 func (p Point3) Abs() float64 { return math.Sqrt(p.x*p.x + p.y*p.y + p.z*p.z) } 这样做稍微有点昂贵，因为 Point3 是作为值传递给方法的，因此传递的是它的拷贝，这在 Go 中是合法的。也可以在指向这个类型的指针上调用此方法（会自动解引用）。 假设 p3 定义为一个指针：p3 := &Point{ 3, 4, 5}。 可以使用 p3.Abs() 来替代 (*p3).Abs()。 像例子 10.10（method1.go）中接收者类型是 *TwoInts 的方法 AddThem()，它能在类型 TwoInts 的值上被调用，这是自动间接发生的。 因此 two2.AddThem 可以替代 (&two2).AddThem()。 在值和指针上调用方法： 可以有连接到类型的方法，也可以有连接到类型指针的方法。 但是这没关系：对于类型 T，如果在 *T 上存在方法 Meth()，并且 t 是这个类型的变量，那么 t.Meth() 会被自动转换为 (&t).Meth()。 指针方法和值方法都可以在指针或非指针上被调用，如下面程序所示，类型 List 在值上有一个方法 Len()，在指针上有一个方法 Append()，但是可以看到两个方法都可以在两种类型的变量上被调用。 示例 10.14 methodset1.go： package main import ( \"fmt\" ) type List []int func (l List) Len() int { return len(l) } func (l *List) Append(val int) { *l = append(*l, val) } func main() { // 值 var lst List lst.Append(1) fmt.Printf(\"%v (len: %d)\", lst, lst.Len()) // [1] (len: 1) // 指针 plst := new(List) plst.Append(2) fmt.Printf(\"%v (len: %d)\", plst, plst.Len()) // &[2] (len: 1) } 10.6.4 方法和未导出字段 考虑 person2.go 中的 person 包：类型 Person 被明确的导出了，但是它的字段没有被导出。例如在 use_person2.go 中 p.firstName 就是错误的。该如何在另一个程序中修改或者只是读取一个 Person 的名字呢？ 这可以通过面向对象语言一个众所周知的技术来完成：提供 getter 和 setter 方法。对于 setter 方法使用 Set 前缀，对于 getter 方法只使用成员名。 示例 10.15 person2.go： package person type Person struct { firstName string lastName string } func (p *Person) FirstName() string { return p.firstName } func (p *Person) SetFirstName(newName string) { p.firstName = newName } 示例 10.16—use_person2.go： package main import ( \"./person\" \"fmt\" ) func main() { p := new(person.Person) // p.firstName undefined // (cannot refer to unexported field or method firstName) // p.firstName = \"Eric\" p.SetFirstName(\"Eric\") fmt.Println(p.FirstName()) // Output: Eric } 并发访问对象 对象的字段（属性）不应该由 2 个或 2 个以上的不同线程在同一时间去改变。如果在程序发生这种情况，为了安全并发访问，可以使用包 sync（参考第 9.3 节）中的方法。在第 14.17 节中我们会通过 goroutines 和 channels 探索另一种方式。 10.6.5 内嵌类型的方法和继承 当一个匿名类型被内嵌在结构体中时，匿名类型的可见方法也同样被内嵌，这在效果上等同于外层类型 继承 了这些方法：将父类型放在子类型中来实现亚型。这个机制提供了一种简单的方式来模拟经典面向对象语言中的子类和继承相关的效果，也类似 Ruby 中的混入（mixin）。 下面是一个示例（可以在练习 10.8 中进一步学习）：假定有一个 Engine 接口类型，一个 Car 结构体类型，它包含一个 Engine 类型的匿名字段： type Engine interface { Start() Stop() } type Car struct { Engine } 我们可以构建如下的代码： func (c *Car) GoToWorkIn() { // get in car c.Start() // drive to work c.Stop() // get out of car } 下面是 method3.go 的完整例子，它展示了内嵌结构体上的方法可以直接在外层类型的实例上调用： package main import ( \"fmt\" \"math\" ) type Point struct { x, y float64 } func (p *Point) Abs() float64 { return math.Sqrt(p.x*p.x + p.y*p.y) } type NamedPoint struct { Point name string } func main() { n := &NamedPoint{Point{3, 4}, \"Pythagoras\"} fmt.Println(n.Abs()) // 打印5 } 内嵌将一个已存在类型的字段和方法注入到了另一个类型里：匿名字段上的方法“晋升”成为了外层类型的方法。当然类型可以有只作用于本身实例而不作用于内嵌“父”类型上的方法， 可以覆写方法（像字段一样）：和内嵌类型方法具有同样名字的外层类型的方法会覆写内嵌类型对应的方法。 在示例 10.18 method4.go 中添加： func (n *NamedPoint) Abs() float64 { return n.Point.Abs() * 100. } 现在 fmt.Println(n.Abs()) 会打印 500。 因为一个结构体可以嵌入多个匿名类型，所以实际上我们可以有一个简单版本的多重继承，就像：type Child struct { Father; Mother}。在第 10.6.7 节中会进一步讨论这个问题。 结构体内嵌和自己在同一个包中的结构体时，可以彼此访问对方所有的字段和方法。 练习 10.8 inheritance_car.go 创建一个上面 Car 和 Engine 可运行的例子，并且给 Car 类型一个 wheelCount 字段和一个 numberOfWheels() 方法。 创建一个 Mercedes 类型，它内嵌 Car，并新建 Mercedes 的一个实例，然后调用它的方法。 然后仅在 Mercedes 类型上创建方法 sayHiToMerkel() 并调用它。 10.6.6 如何在类型中嵌入功能 主要有两种方法来实现在类型中嵌入功能： A：聚合（或组合）：包含一个所需功能类型的具名字段。 B：内嵌：内嵌（匿名地）所需功能类型，像前一节 10.6.5 所演示的那样。 为了使这些概念具体化，假设有一个 Customer 类型，我们想让它通过 Log 类型来包含日志功能，Log 类型只是简单地包含一个累积的消息（当然它可以是复杂的）。如果想让特定类型都具备日志功能，你可以实现一个这样的 Log 类型，然后将它作为特定类型的一个字段，并提供 Log()，它返回这个日志的引用。 方式 A 可以通过如下方法实现（使用了第 10.7 节中的 String() 功能）： 示例 10.19 embed_func1.go： package main import ( \"fmt\" ) type Log struct { msg string } type Customer struct { Name string log *Log } func main() { c := new(Customer) c.Name = \"Barak Obama\" c.log = new(Log) c.log.msg = \"1 - Yes we can!\" // shorter c = &Customer{\"Barak Obama\", &Log{\"1 - Yes we can!\"}} // fmt.Println(c) &{Barak Obama 1 - Yes we can!} c.Log().Add(\"2 - After me the world will be a better place!\") //fmt.Println(c.log) fmt.Println(c.Log()) } func (l *Log) Add(s string) { l.msg += \"\\n\" + s } func (l *Log) String() string { return l.msg } func (c *Customer) Log() *Log { return c.log } 输出： 1 - Yes we can! 2 - After me the world will be a better place! 相对的方式 B 可能会像这样： package main import ( \"fmt\" ) type Log struct { msg string } type Customer struct { Name string Log } func main() { c := &Customer{\"Barak Obama\", Log{\"1 - Yes we can!\"}} c.Add(\"2 - After me the world will be a better place!\") fmt.Println(c) } func (l *Log) Add(s string) { l.msg += \"\\n\" + s } func (l *Log) String() string { return l.msg } func (c *Customer) String() string { return c.Name + \"\\nLog:\" + fmt.Sprintln(c.Log) } 输出： Barak Obama Log:{1 - Yes we can! 2 - After me the world will be a better place!} 内嵌的类型不需要指针，Customer 也不需要 Add 方法，它使用 Log 的 Add 方法，Customer 有自己的 String 方法，并且在它里面调用了 Log 的 String 方法。 如果内嵌类型嵌入了其他类型，也是可以的，那些类型的方法可以直接在外层类型中使用。 因此一个好的策略是创建一些小的、可复用的类型作为一个工具箱，用于组成域类型。 10.6.7 多重继承 多重继承指的是类型获得多个父类型行为的能力，它在传统的面向对象语言中通常是不被实现的（C++ 和 Python 例外）。因为在类继承层次中，多重继承会给编译器引入额外的复杂度。但是在 Go 语言中，通过在类型中嵌入所有必要的父类型，可以很简单的实现多重继承。 作为一个例子，假设有一个类型 CameraPhone，通过它可以 Call()，也可以 TakeAPicture()，但是第一个方法属于类型 Phone，第二个方法属于类型 Camera。 只要嵌入这两个类型就可以解决这个问题，如下所示： package main import ( \"fmt\" ) type Camera struct{} func (c *Camera) TakeAPicture() string { return \"Click\" } type Phone struct{} func (p *Phone) Call() string { return \"Ring Ring\" } type CameraPhone struct { Camera Phone } func main() { cp := new(CameraPhone) fmt.Println(\"Our new CameraPhone exhibits multiple behaviors...\") fmt.Println(\"It exhibits behavior of a Camera: \", cp.TakeAPicture()) fmt.Println(\"It works like a Phone too: \", cp.Call()) } 输出： Our new CameraPhone exhibits multiple behaviors... It exhibits behavior of a Camera: Click It works like a Phone too: Ring Ring 练习 10.9 point_methods.go： 从 point.go 开始（第 10.1 节的练习）：使用方法来实现 Abs() 和 Scale()函数，Point 作为方法的接收者类型。也为 Point3 和 Polar 实现 Abs() 方法。完成了 point.go 中同样的事情，只是这次通过方法。 练习 10.10 inherit_methods.go： 定义一个结构体类型 Base，它包含一个字段 id，方法 Id() 返回 id，方法 SetId() 修改 id。结构体类型 Person 包含 Base，及 FirstName 和 LastName 字段。结构体类型 Employee 包含一个 Person 和 salary 字段。 创建一个 employee 实例，然后显示它的 id。 练习 10.11 magic.go： 首先预测一下下面程序的结果，然后动手实验下： package main import ( \"fmt\" ) type Base struct{} func (Base) Magic() { fmt.Println(\"base magic\") } func (self Base) MoreMagic() { self.Magic() self.Magic() } type Voodoo struct { Base } func (Voodoo) Magic() { fmt.Println(\"voodoo magic\") } func main() { v := new(Voodoo) v.Magic() v.MoreMagic() } 10.6.8 通用方法和方法命名 在编程中一些基本操作会一遍又一遍的出现，比如打开（Open）、关闭（Close）、读（Read）、写（Write）、排序（Sort）等等，并且它们都有一个大致的意思：打开（Open）可以作用于一个文件、一个网络连接、一个数据库连接等等。具体的实现可能千差万别，但是基本的概念是一致的。在 Go 语言中，通过使用接口（参考 第 11 章），标准库广泛的应用了这些规则，在标准库中这些通用方法都有一致的名字，比如 Open()、Read()、Write()等。想写规范的 Go 程序，就应该遵守这些约定，给方法合适的名字和签名，就像那些通用方法那样。这样做会使 Go 开发的软件更加具有一致性和可读性。比如：如果需要一个 convert-to-string 方法，应该命名为 String()，而不是 ToString()（参考第 10.7 节）。 10.6.9 和其他面向对象语言比较 Go 的类型和方法 在如 C++、Java、C# 和 Ruby 这样的面向对象语言中，方法在类的上下文中被定义和继承：在一个对象上调用方法时，运行时会检测类以及它的超类中是否有此方法的定义，如果没有会导致异常发生。 在 Go 语言中，这样的继承层次是完全没必要的：如果方法在此类型定义了，就可以调用它，和其他类型上是否存在这个方法没有关系。在这个意义上，Go 具有更大的灵活性。 下面的模式就很好的说明了这个问题： Go 不需要一个显式的类定义，如同 Java、C++、C# 等那样，相反地，“类”是通过提供一组作用于一个共同类型的方法集来隐式定义的。类型可以是结构体或者任何用户自定义类型。 比如：我们想定义自己的 Integer 类型，并添加一些类似转换成字符串的方法，在 Go 中可以如下定义： type Integer int func (i *Integer) String() string { return strconv.Itoa(int(*i)) } 在 Java 或 C# 中，这个方法需要和类 Integer 的定义放在一起，在 Ruby 中可以直接在基本类型 int 上定义这个方法。 总结 在 Go 中，类型就是类（数据和关联的方法）。Go 不知道类似面向对象语言的类继承的概念。继承有两个好处：代码复用和多态。 在 Go 中，代码复用通过组合和委托实现，多态通过接口的使用来实现：有时这也叫 组件编程（Component Programming）。 许多开发者说相比于类继承，Go 的接口提供了更强大、却更简单的多态行为。 备注 如果真的需要更多面向对象的能力，看一下 goop 包（Go Object-Oriented Programming），它由 Scott Pakin 编写: 它给 Go 提供了 JavaScript 风格的对象（基于原型的对象），并且支持多重继承和类型独立分派，通过它可以实现你喜欢的其他编程语言里的一些结构。 问题 10.1 我们在某个类型的变量上使用点号调用一个方法：variable.method()，在使用 Go 以前，在哪儿碰到过面向对象的点号？ 问题 10.2 a）假设定义： type Integer int，完成 get() 方法的方法体: func (p Integer) get() int { ... }。 b）定义： func f(i int) {}; var v Integer ，如何就 v 作为参数调用f？ c）假设 Integer 定义为 type Integer struct {n int}，完成 get() 方法的方法体：func (p Integer) get() int { ... }。 d）对于新定义的 Integer，和 b）中同样的问题。 链接 目录 上一节：匿名字段和内嵌结构体 下一节：类型的 String() 方法和格式化描述符 "},"Go入门指南/10.7.html":{"url":"Go入门指南/10.7.html","title":"7","keywords":"","body":"10.7 类型的 String() 方法和格式化描述符 当定义了一个有很多方法的类型时，十之八九你会使用 String() 方法来定制类型的字符串形式的输出，换句话说：一种可阅读性和打印性的输出。如果类型定义了 String() 方法，它会被用在 fmt.Printf() 中生成默认的输出：等同于使用格式化描述符 %v 产生的输出。还有 fmt.Print() 和 fmt.Println() 也会自动使用 String() 方法。 我们使用第 10.4 节中程序的类型来进行测试： 示例 10.22 method_string.go： package main import ( \"fmt\" \"strconv\" ) type TwoInts struct { a int b int } func main() { two1 := new(TwoInts) two1.a = 12 two1.b = 10 fmt.Printf(\"two1 is: %v\\n\", two1) fmt.Println(\"two1 is:\", two1) fmt.Printf(\"two1 is: %T\\n\", two1) fmt.Printf(\"two1 is: %#v\\n\", two1) } func (tn *TwoInts) String() string { return \"(\" + strconv.Itoa(tn.a) + \"/\" + strconv.Itoa(tn.b) + \")\" } 输出： two1 is: (12/10) two1 is: (12/10) two1 is: *main.TwoInts two1 is: &main.TwoInts{a:12, b:10} 当你广泛使用一个自定义类型时，最好为它定义 String()方法。从上面的例子也可以看到，格式化描述符 %T 会给出类型的完全规格，%#v 会给出实例的完整输出，包括它的字段（在程序自动生成 Go 代码时也很有用）。 备注 不要在 String() 方法里面调用涉及 String() 方法的方法，它会导致意料之外的错误，比如下面的例子，它导致了一个无限递归调用（TT.String() 调用 fmt.Sprintf，而 fmt.Sprintf 又会反过来调用 TT.String()...），很快就会导致内存溢出： type TT float64 func (t TT) String() string { return fmt.Sprintf(\"%v\", t) } t.String() 练习 10.12 type_string.go 给定结构体类型 T: type T struct { a int b float32 c string } 值 t: t := &T{7, -2.35, \"abc\\tdef\"}。给 T 定义 String()，使得 fmt.Printf(\"%v\\n\", t) 输出：7 / -2.350000 / \"abc\\tdef\"。 练习 10.13 celsius.go 为 float64 定义一个别名类型 Celsius，并给它定义 String()，它输出一个十进制数和 °C 表示的温度值。 练习 10.14 days.go 为 int 定义一个别名类型 Day，定义一个字符串数组它包含一周七天的名字，为类型 Day 定义 String() 方法，它输出星期几的名字。使用 iota 定义一个枚举常量用于表示一周的中每天（MO、TU...）。 练习 10.15 timezones.go 为 int 定义别名类型 TZ，定义一些常量表示时区，比如 UTC，定义一个 map，它将时区的缩写映射为它的全称，比如：UTC -> \"Universal Greenwich time\"。为类型 TZ 定义 String() 方法，它输出时区的全称。 练习 10.16 stack_arr.go/stack_struct.go 实现栈（stack）数据结构： 它的格子包含数据，比如整数 i、j、k 和 l 等等，格子从底部（索引 0）至顶部（索引 n）来索引。这个例子中假定 n=3，那么一共有 4 个格子。 一个新栈中所有格子的值都是 0。 push 将一个新值放到栈的最顶部一个非空（非零）的格子中。 pop 获取栈的最顶部一个非空（非零）的格子的值。现在可以理解为什么栈是一个后进先出（LIFO）的结构了吧。 为栈定义一 Stack 类型，并为它定义一个 Push 和 Pop 方法，再为它定义 String() 方法（用于调试）它输出栈的内容，比如：[0:i] [1:j] [2:k] [3:l]。 1）stack_arr.go：使用长度为 4 的 int 数组作为底层数据结构。 2）stack_struct.go：使用包含一个索引和一个 int 数组的结构体作为底层数据结构，索引表示第一个空闲的位置。 3）使用常量 LIMIT 代替上面表示元素个数的 4 重新实现上面的 1）和 2），使它们更具有一般性。 链接 目录 上一节：方法 下一节：垃圾回收和 SetFinalizer "},"Go入门指南/10.8.html":{"url":"Go入门指南/10.8.html","title":"8","keywords":"","body":"10.8 垃圾回收和 SetFinalizer Go 开发者不需要写代码来释放程序中不再使用的变量和结构占用的内存，在 Go 运行时中有一个独立的进程，即垃圾收集器（GC），会处理这些事情，它搜索不再使用的变量然后释放它们的内存。可以通过 runtime 包访问 GC 进程。 通过调用 runtime.GC() 函数可以显式的触发 GC，但这只在某些罕见的场景下才有用，比如当内存资源不足时调用 runtime.GC()，它会在此函数执行的点上立即释放一大片内存，此时程序可能会有短时的性能下降（因为 GC 进程在执行）。 如果想知道当前的内存状态，可以使用： // fmt.Printf(\"%d\\n\", runtime.MemStats.Alloc/1024) // 此处代码在 Go 1.5.1下不再有效，更正为 var m runtime.MemStats runtime.ReadMemStats(&m) fmt.Printf(\"%d Kb\\n\", m.Alloc / 1024) 上面的程序会给出已分配内存的总量，单位是 Kb。进一步的测量参考 文档页面。 如果需要在一个对象 obj 被从内存移除前执行一些特殊操作，比如写到日志文件中，可以通过如下方式调用函数来实现： runtime.SetFinalizer(obj, func(obj *typeObj)) func(obj *typeObj) 需要一个 typeObj 类型的指针参数 obj，特殊操作会在它上面执行。func 也可以是一个匿名函数。 在对象被 GC 进程选中并从内存中移除以前，SetFinalizer 都不会执行，即使程序正常结束或者发生错误。 练习 10.17 从练习 10.16 开始（它基于结构体实现了一个栈结构），为栈的实现（stack_struct.go）创建一个单独的包 stack，并从 main 包 main.stack.go 中调用它。 链接 目录 上一节：类型的 String() 方法和格式化描述符 下一章：接口（Interfaces）与反射（reflection） "},"Go入门指南/11.0.html":{"url":"Go入门指南/11.0.html","title":"0","keywords":"","body":"﻿# 11 接口（Interfaces）与反射（reflection） 本章介绍 Go 语言中接口和反射的相关内容。 链接 目录 上一章：垃圾回收和 SetFinalizer 下一节：接口是什么 "},"Go入门指南/11.10.html":{"url":"Go入门指南/11.10.html","title":"10","keywords":"","body":"11.10 反射包 11.10.1 方法和类型的反射 在 10.4 节我们看到可以通过反射来分析一个结构体。本节我们进一步探讨强大的反射功能。反射是用程序检查其所拥有的结构，尤其是类型的一种能力；这是元编程的一种形式。反射可以在运行时检查类型和变量，例如它的大小、方法和 动态 的调用这些方法。这对于没有源代码的包尤其有用。这是一个强大的工具，除非真得有必要，否则应当避免使用或小心使用。 变量的最基本信息就是类型和值：反射包的 Type 用来表示一个 Go 类型，反射包的 Value 为 Go 值提供了反射接口。 两个简单的函数，reflect.TypeOf 和 reflect.ValueOf，返回被检查对象的类型和值。例如，x 被定义为：var x float64 = 3.4，那么 reflect.TypeOf(x) 返回 float64，reflect.ValueOf(x) 返回 实际上，反射是通过检查一个接口的值，变量首先被转换成空接口。这从下面两个函数签名能够很明显的看出来： func TypeOf(i interface{}) Type func ValueOf(i interface{}) Value 接口的值包含一个 type 和 value。 反射可以从接口值反射到对象，也可以从对象反射回接口值。 reflect.Type 和 reflect.Value 都有许多方法用于检查和操作它们。一个重要的例子是 Value 有一个 Type 方法返回 reflect.Value 的 Type。另一个是 Type 和 Value 都有 Kind 方法返回一个常量来表示类型：Uint、Float64、Slice 等等。同样 Value 有叫做 Int 和 Float 的方法可以获取存储在内部的值（跟 int64 和 float64 一样） const ( Invalid Kind = iota Bool Int Int8 Int16 Int32 Int64 Uint Uint8 Uint16 Uint32 Uint64 Uintptr Float32 Float64 Complex64 Complex128 Array Chan Func Interface Map Ptr Slice String Struct UnsafePointer ) 对于 float64 类型的变量 x，如果 v:=reflect.ValueOf(x)，那么 v.Kind() 返回 reflect.Float64 ，所以下面的表达式是 true v.Kind() == reflect.Float64 Kind 总是返回底层类型： type MyInt int var m MyInt = 5 v := reflect.ValueOf(m) 方法 v.Kind() 返回 reflect.Int。 变量 v 的 Interface() 方法可以得到还原（接口）值，所以可以这样打印 v 的值：fmt.Println(v.Interface()) 尝试运行下面的代码： 示例 11.11 reflect1.go： // blog: Laws of Reflection package main import ( \"fmt\" \"reflect\" ) func main() { var x float64 = 3.4 fmt.Println(\"type:\", reflect.TypeOf(x)) v := reflect.ValueOf(x) fmt.Println(\"value:\", v) fmt.Println(\"type:\", v.Type()) fmt.Println(\"kind:\", v.Kind()) fmt.Println(\"value:\", v.Float()) fmt.Println(v.Interface()) fmt.Printf(\"value is %5.2e\\n\", v.Interface()) y := v.Interface().(float64) fmt.Println(y) } 输出： type: float64 value: 3.4 type: float64 kind: float64 value: 3.4 3.4 value is 3.40e+00 3.4 x 是一个 float64 类型的值，reflect.ValueOf(x).Float() 返回这个 float64 类型的实际值；同样的适用于 Int(), Bool(), Complex(), String() 11.10.2 通过反射修改(设置)值 继续前面的例子（参阅 11.9 reflect2.go），假设我们要把 x 的值改为 3.1415。Value 有一些方法可以完成这个任务，但是必须小心使用：v.SetFloat(3.1415)。 这将产生一个错误：reflect.Value.SetFloat using unaddressable value。 为什么会这样呢？问题的原因是 v 不是可设置的（这里并不是说值不可寻址）。是否可设置是 Value 的一个属性，并且不是所有的反射值都有这个属性：可以使用 CanSet() 方法测试是否可设置。 在例子中我们看到 v.CanSet() 返回 false： settability of v: false 当 v := reflect.ValueOf(x) 函数通过传递一个 x 拷贝创建了 v，那么 v 的改变并不能更改原始的 x。要想 v 的更改能作用到 x，那就必须传递 x 的地址 v = reflect.ValueOf(&x)。 通过 Type() 我们看到 v 现在的类型是 *float64 并且仍然是不可设置的。 要想让其可设置我们需要使用 Elem() 函数，这间接的使用指针：v = v.Elem() 现在 v.CanSet() 返回 true 并且 v.SetFloat(3.1415) 设置成功了！ 示例 11.12 reflect2.go： package main import ( \"fmt\" \"reflect\" ) func main() { var x float64 = 3.4 v := reflect.ValueOf(x) // setting a value: // v.SetFloat(3.1415) // Error: will panic: reflect.Value.SetFloat using unaddressable value fmt.Println(\"settability of v:\", v.CanSet()) v = reflect.ValueOf(&x) // Note: take the address of x. fmt.Println(\"type of v:\", v.Type()) fmt.Println(\"settability of v:\", v.CanSet()) v = v.Elem() fmt.Println(\"The Elem of v is: \", v) fmt.Println(\"settability of v:\", v.CanSet()) v.SetFloat(3.1415) // this works! fmt.Println(v.Interface()) fmt.Println(v) } 输出： settability of v: false type of v: *float64 settability of v: false The Elem of v is: settability of v: true 3.1415 反射中有些内容是需要用地址去改变它的状态的。 11.10.3 反射结构 有些时候需要反射一个结构类型。NumField() 方法返回结构内的字段数量；通过一个 for 循环用索引取得每个字段的值 Field(i)。 我们同样能够调用签名在结构上的方法，例如，使用索引 n 来调用：Method(n).Call(nil)。 示例 11.13 reflect_struct.go： package main import ( \"fmt\" \"reflect\" ) type NotknownType struct { s1, s2, s3 string } func (n NotknownType) String() string { return n.s1 + \" - \" + n.s2 + \" - \" + n.s3 } // variable to investigate: var secret interface{} = NotknownType{\"Ada\", \"Go\", \"Oberon\"} func main() { value := reflect.ValueOf(secret) // typ := reflect.TypeOf(secret) // main.NotknownType // alternative: //typ := value.Type() // main.NotknownType fmt.Println(typ) knd := value.Kind() // struct fmt.Println(knd) // iterate through the fields of the struct: for i := 0; i 输出： main.NotknownType struct Field 0: Ada Field 1: Go Field 2: Oberon [Ada - Go - Oberon] 但是如果尝试更改一个值，会得到一个错误： panic: reflect.Value.SetString using value obtained using unexported field 这是因为结构中只有被导出字段（首字母大写）才是可设置的；来看下面的例子： 示例 11.14 reflect_struct2.go： package main import ( \"fmt\" \"reflect\" ) type T struct { A int B string } func main() { t := T{23, \"skidoo\"} s := reflect.ValueOf(&t).Elem() typeOfT := s.Type() for i := 0; i 输出： 0: A int = 23 1: B string = skidoo t is now {77 Sunset Strip} 附录 37 深入阐述了反射概念。 链接 目录 上一节：空接口 下一节：Printf 和反射 "},"Go入门指南/11.11.html":{"url":"Go入门指南/11.11.html","title":"11","keywords":"","body":"11.11 Printf 和反射 在 Go 语言的标准库中，前几节所述的反射的功能被大量地使用。举个例子，fmt 包中的 Printf（以及其他格式化输出函数）都会使用反射来分析它的 ... 参数。 Printf 的函数声明为： func Printf(format string, args ... interface{}) (n int, err error) Printf 中的 ... 参数为空接口类型。Printf 使用反射包来解析这个参数列表。所以，Printf 能够知道它每个参数的类型。因此格式化字符串中只有%d而没有 %u 和 %ld，因为它知道这个参数是 unsigned 还是 long。这也是为什么 Print 和 Println 在没有格式字符串的情况下还能如此漂亮地输出。 为了让大家更加具体地了解 Printf 中的反射，我们实现了一个简单的通用输出函数。其中使用了 type-switch 来推导参数类型，并根据类型来输出每个参数的值（这里用了 10.7 节中练习 10.13 的部分代码） 示例 11.15 print.go： package main import ( \"os\" \"strconv\" ) type Stringer interface { String() string } type Celsius float64 func (c Celsius) String() string { return strconv.FormatFloat(float64(c),'f', 1, 64) + \" °C\" } type Day int var dayName = []string{\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"} func (day Day) String() string { return dayName[day] } func print(args ...interface{}) { for i, arg := range args { if i > 0 {os.Stdout.WriteString(\" \")} switch a := arg.(type) { // type switch case Stringer: os.Stdout.WriteString(a.String()) case int: os.Stdout.WriteString(strconv.Itoa(a)) case string: os.Stdout.WriteString(a) // more types default: os.Stdout.WriteString(\"???\") } } } func main() { print(Day(1), \"was\", Celsius(18.36)) // Tuesday was 18.4 °C } 在 12.8 节中我们将阐释 fmt.Fprintf() 是怎么运用同样的反射原则的。 链接 目录 上一节：反射包 下一节：接口和动态类型 "},"Go入门指南/11.12.html":{"url":"Go入门指南/11.12.html","title":"12","keywords":"","body":"11.12 接口与动态类型 11.12.1 Go 的动态类型 在经典的面向对象语言（像 C++，Java 和 C#）中数据和方法被封装为 类 的概念：类包含它们两者，并且不能剥离。 Go 没有类：数据（结构体或更一般的类型）和方法是一种松耦合的正交关系。 Go 中的接口跟 Java/C# 类似：都是必须提供一个指定方法集的实现。但是更加灵活通用：任何提供了接口方法实现代码的类型都隐式地实现了该接口，而不用显式地声明。 和其它语言相比，Go 是唯一结合了接口值，静态类型检查（是否该类型实现了某个接口），运行时动态转换的语言，并且不需要显式地声明类型是否满足某个接口。该特性允许我们在不改变已有的代码的情况下定义和使用新接口。 接收一个（或多个）接口类型作为参数的函数，其实参可以是任何实现了该接口的类型。 实现了某个接口的类型可以被传给任何以此接口为参数的函数 。 类似于 Python 和 Ruby 这类动态语言中的 动态类型（duck typing）；这意味着对象可以根据提供的方法被处理（例如，作为参数传递给函数），而忽略它们的实际类型：它们能做什么比它们是什么更重要。 这在程序 duck_dance.go 中得以阐明，函数 DuckDance 接受一个 IDuck 接口类型变量。仅当 DuckDance 被实现了 IDuck 接口的类型调用时程序才能编译通过。 示例 11.16 duck_dance.go： package main import \"fmt\" type IDuck interface { Quack() Walk() } func DuckDance(duck IDuck) { for i := 1; i 输出： I am quacking! I am walking! I am quacking! I am walking! I am quacking! I am walking! 如果 Bird 没有实现 Walk()（把它注释掉），会得到一个编译错误： cannot use b (type *Bird) as type IDuck in function argument: *Bird does not implement IDuck (missing Walk method) 如果对 cat 调用函数 DuckDance()，Go 会提示编译错误，但是 Python 和 Ruby 会以运行时错误结束。 11.12.2 动态方法调用 像 Python，Ruby 这类语言，动态类型是延迟绑定的（在运行时进行）：方法只是用参数和变量简单地调用，然后在运行时才解析（它们很可能有像 responds_to 这样的方法来检查对象是否可以响应某个方法，但是这也意味着更大的编码量和更多的测试工作） Go 的实现与此相反，通常需要编译器静态检查的支持：当变量被赋值给一个接口类型的变量时，编译器会检查其是否实现了该接口的所有函数。如果方法调用作用于像 interface{} 这样的“泛型”上，你可以通过类型断言（参见 11.3 节）来检查变量是否实现了相应接口。 例如，你用不同的类型表示 XML 输出流中的不同实体。然后我们为 XML 定义一个如下的“写”接口（甚至可以把它定义为私有接口）： type xmlWriter interface { WriteXML(w io.Writer) error } 现在我们可以实现适用于该流类型的任何变量的 StreamXML 函数，并用类型断言检查传入的变量是否实现了该接口；如果没有，我们就调用内建的 encodeToXML 来完成相应工作： // Exported XML streaming function. func StreamXML(v interface{}, w io.Writer) error { if xw, ok := v.(xmlWriter); ok { // It’s an xmlWriter, use method of asserted type. return xw.WriteXML(w) } // No implementation, so we have to use our own function (with perhaps reflection): return encodeToXML(v, w) } // Internal XML encoding function. func encodeToXML(v interface{}, w io.Writer) error { // ... } Go 在这里用了和 gob 相同的机制：定义了两个接口 GobEncoder 和 GobDecoder。这样就允许类型自己实现从流编解码的具体方式；如果没有实现就使用标准的反射方式。 因此 Go 提供了动态语言的优点，却没有其他动态语言在运行时可能发生错误的缺点。 对于动态语言非常重要的单元测试来说，这样即可以减少单元测试的部分需求，又可以发挥相当大的作用。 Go 的接口提高了代码的分离度，改善了代码的复用性，使得代码开发过程中的设计模式更容易实现。用 Go 接口还能实现 依赖注入模式。 11.12.3 接口的提取 提取接口 是非常有用的设计模式，可以减少需要的类型和方法数量，而且不需要像传统的基于类的面向对象语言那样维护整个的类层次结构。 Go 接口可以让开发者找出自己写的程序中的类型。假设有一些拥有共同行为的对象，并且开发者想要抽象出这些行为，这时就可以创建一个接口来使用。 我们来扩展 11.1 节的示例 11.2 interfaces_poly.go，假设我们需要一个新的接口 TopologicalGenus，用来给 shape 排序（这里简单地实现为返回 int）。我们需要做的是给想要满足接口的类型实现 Rank() 方法： 示例 11.17 multi_interfaces_poly.go： //multi_interfaces_poly.go package main import \"fmt\" type Shaper interface { Area() float32 } type TopologicalGenus interface { Rank() int } type Square struct { side float32 } func (sq *Square) Area() float32 { return sq.side * sq.side } func (sq *Square) Rank() int { return 1 } type Rectangle struct { length, width float32 } func (r Rectangle) Area() float32 { return r.length * r.width } func (r Rectangle) Rank() int { return 2 } func main() { r := Rectangle{5, 3} // Area() of Rectangle needs a value q := &Square{5} // Area() of Square needs a pointer shapes := []Shaper{r, q} fmt.Println(\"Looping through shapes for area ...\") for n, _ := range shapes { fmt.Println(\"Shape details: \", shapes[n]) fmt.Println(\"Area of this shape is: \", shapes[n].Area()) } topgen := []TopologicalGenus{r, q} fmt.Println(\"Looping through topgen for rank ...\") for n, _ := range topgen { fmt.Println(\"Shape details: \", topgen[n]) fmt.Println(\"Topological Genus of this shape is: \", topgen[n].Rank()) } } 输出： Looping through shapes for area ... Shape details: {5 3} Area of this shape is: 15 Shape details: &{5} Area of this shape is: 25 Looping through topgen for rank ... Shape details: {5 3} Topological Genus of this shape is: 2 Shape details: &{5} Topological Genus of this shape is: 1 所以你不用提前设计出所有的接口；整个设计可以持续演进，而不用废弃之前的决定。类型要实现某个接口，它本身不用改变，你只需要在这个类型上实现新的方法。 11.12.4 显式地指明类型实现了某个接口 如果你希望满足某个接口的类型显式地声明它们实现了这个接口，你可以向接口的方法集中添加一个具有描述性名字的方法。例如： type Fooer interface { Foo() ImplementsFooer() } 类型 Bar 必须实现 ImplementsFooer 方法来满足 Fooer 接口，以清楚地记录这个事实。 type Bar struct{} func (b Bar) ImplementsFooer() {} func (b Bar) Foo() {} 大部分代码并不使用这样的约束，因为它限制了接口的实用性。 但是有些时候，这样的约束在大量相似的接口中被用来解决歧义。 11.12.5 空接口和函数重载 在 6.1 节中, 我们看到函数重载是不被允许的。在 Go 语言中函数重载可以用可变参数 ...T 作为函数最后一个参数来实现（参见 6.3 节）。如果我们把 T 换为空接口，那么可以知道任何类型的变量都是满足 T (空接口）类型的，这样就允许我们传递任何数量任何类型的参数给函数，即重载的实际含义。 函数 fmt.Printf 就是这样做的： fmt.Printf(format string, a ...interface{}) (n int, errno error) 这个函数通过枚举 slice 类型的实参动态确定所有参数的类型。并查看每个类型是否实现了 String() 方法，如果是就用于产生输出信息。我们可以回到 11.10 节查看这些细节。 11.12.6 接口的继承 当一个类型包含（内嵌）另一个类型（实现了一个或多个接口）的指针时，这个类型就可以使用（另一个类型）所有的接口方法。 例如： type Task struct { Command string *log.Logger } 这个类型的工厂方法像这样： func NewTask(command string, logger *log.Logger) *Task { return &Task{command, logger} } 当 log.Logger 实现了 Log() 方法后，Task 的实例 task 就可以调用该方法： task.Log() 类型可以通过继承多个接口来提供像 多重继承 一样的特性： type ReaderWriter struct { *io.Reader *io.Writer } 上面概述的原理被应用于整个 Go 包，多态用得越多，代码就相对越少（参见 12.8 节）。这被认为是 Go 编程中的重要的最佳实践。 有用的接口可以在开发的过程中被归纳出来。添加新接口非常容易，因为已有的类型不用变动（仅仅需要实现新接口的方法）。已有的函数可以扩展为使用接口类型的约束性参数：通常只有函数签名需要改变。对比基于类的 OO 类型的语言在这种情况下则需要适应整个类层次结构的变化。 练习 11.11：map_function_interface.go： 在练习 7.13 中我们定义了一个 map 函数来使用 int 切片 （map_function.go）。 通过空接口和类型断言，现在我们可以写一个可以应用于许多类型的 泛型 的 map 函数，为 int 和 string 构建一个把 int 值加倍和连接字符串值的 map 函数 mapFunc。 提示：为了可读性可以定义一个 interface{} 的别名，比如：type obj interface{} 练习 11.12：map_function_interface_var.go： 稍微改变练习 11.9，允许 mapFunc 接收不定数量的 items。 练习 11.13：main_stack.go—stack/stack_general.go： 在练习 10.10 和 10.11 中我们开发了一些栈结构类型。但是它们被限制为某种固定的内建类型。现在用一个元素类型是 interface{}（空接口）的切片开发一个通用的栈类型。 实现下面的栈方法： Len() int IsEmpty() bool Push(x interface{}) Pop() (x interface{}, error) Pop() 改变栈并返回最顶部的元素；Top() 只返回最顶部元素。 在主程序中构建一个充满不同类型元素的栈，然后弹出并打印所有元素的值。 链接 目录 上一节：Printf 和反射 下一节：总结：Go 中的面向对象 "},"Go入门指南/11.13.html":{"url":"Go入门指南/11.13.html","title":"13","keywords":"","body":"总结：Go 中的面向对象 我们总结一下前面看到的：Go 没有类，而是松耦合的类型、方法对接口的实现。 OO 语言最重要的三个方面分别是：封装，继承和多态，在 Go 中它们是怎样表现的呢？ 封装（数据隐藏）：和别的 OO 语言有 4 个或更多的访问层次相比，Go 把它简化为了 2 层（参见 4.2 节的可见性规则）: 1）包范围内的：通过标识符首字母小写，对象 只在它所在的包内可见 2）可导出的：通过标识符首字母大写，对象 对所在包以外也可见 类型只拥有自己所在包中定义的方法。 继承：用组合实现：内嵌一个（或多个）包含想要的行为（字段和方法）的类型；多重继承可以通过内嵌多个类型实现 多态：用接口实现：某个类型的实例可以赋给它所实现的任意接口类型的变量。类型和接口是松耦合的，并且多重继承可以通过实现多个接口实现。Go 接口不是 Java 和 C# 接口的变体，而且接口间是不相关的，并且是大规模编程和可适应的演进型设计的关键。 链接 目录 上一节：接口与动态类型 下一节：结构体，集合和高阶函数 "},"Go入门指南/11.14.html":{"url":"Go入门指南/11.14.html","title":"14","keywords":"","body":"结构体、集合和高阶函数 通常你在应用中定义了一个结构体，那么你也可能需要这个结构体的（指针）对象集合，比如： type Any interface{} type Car struct { Model string Manufacturer string BuildYear int // ... } type Cars []*Car 在定义所需功能时我们可以利用函数可以作为（其它函数的）参数的事实来使用高阶函数，例如： 1）定义一个通用的 Process() 函数，它接收一个作用于每一辆 car 的 f 函数作参数： // Process all cars with the given function f: func (cs Cars) Process(f func(car *Car)) { for _, c := range cs { f(c) } } 2）在上面的基础上，实现一个查找函数来获取子集合，并在 Process() 中传入一个闭包执行（这样就可以访问局部切片 cars）： // Find all cars matching a given criteria. func (cs Cars) FindAll(f func(car *Car) bool) Cars { cars := make([]*Car, 0) cs.Process(func(c *Car) { if f(c) { cars = append(cars, c) } }) return cars } 3）实现 Map 功能，产出除 car 对象以外的东西： // Process cars and create new data. func (cs Cars) Map(f func(car *Car) Any) []Any { result := make([]Any, 0) ix := 0 cs.Process(func(c *Car) { result[ix] = f(c) ix++ }) return result } 现在我们可以定义下面这样的具体查询： allNewBMWs := allCars.FindAll(func(car *Car) bool { return (car.Manufacturer == \"BMW\") && (car.BuildYear > 2010) }) 4）我们也可以根据入参返回不同的函数。也许我们想根据不同的厂商添加汽车到不同的集合，但是这可能会是多变的。所以我们可以定义一个函数来产生特定的添加函数和 map 集： func MakeSortedAppender(manufacturers[]string)(func(car*Car),map[string]Cars) { // Prepare maps of sorted cars. sortedCars := make(map[string]Cars) for _, m := range manufacturers { sortedCars[m] = make([]*Car, 0) } sortedCars[\"Default\"] = make([]*Car, 0) // Prepare appender function: appender := func(c *Car) { if _, ok := sortedCars[c.Manufacturer]; ok { sortedCars[c.Manufacturer] = append(sortedCars[c.Manufacturer], c) } else { sortedCars[\"Default\"] = append(sortedCars[\"Default\"], c) } } return appender, sortedCars } 现在我们可以用它把汽车分类为独立的集合，像这样： manufacturers := []string{\"Ford\", \"Aston Martin\", \"Land Rover\", \"BMW\", \"Jaguar\"} sortedAppender, sortedCars := MakeSortedAppender(manufacturers) allUnsortedCars.Process(sortedAppender) BMWCount := len(sortedCars[\"BMW\"]) 我们让这些代码在下面的程序 cars.go 中执行： 示例 11.18 cars.go： // cars.go package main import ( \"fmt\" ) type Any interface{} type Car struct { Model string Manufacturer string BuildYear int // ... } type Cars []*Car func main() { // make some cars: ford := &Car{\"Fiesta\",\"Ford\", 2008} bmw := &Car{\"XL 450\", \"BMW\", 2011} merc := &Car{\"D600\", \"Mercedes\", 2009} bmw2 := &Car{\"X 800\", \"BMW\", 2008} // query: allCars := Cars([]*Car{ford, bmw, merc, bmw2}) allNewBMWs := allCars.FindAll(func(car *Car) bool { return (car.Manufacturer == \"BMW\") && (car.BuildYear > 2010) }) fmt.Println(\"AllCars: \", allCars) fmt.Println(\"New BMWs: \", allNewBMWs) // manufacturers := []string{\"Ford\", \"Aston Martin\", \"Land Rover\", \"BMW\", \"Jaguar\"} sortedAppender, sortedCars := MakeSortedAppender(manufacturers) allCars.Process(sortedAppender) fmt.Println(\"Map sortedCars: \", sortedCars) BMWCount := len(sortedCars[\"BMW\"]) fmt.Println(\"We have \", BMWCount, \" BMWs\") } // Process all cars with the given function f: func (cs Cars) Process(f func(car *Car)) { for _, c := range cs { f(c) } } // Find all cars matching a given criteria. func (cs Cars) FindAll(f func(car *Car) bool) Cars { cars := make([]*Car, 0) cs.Process(func(c *Car) { if f(c) { cars = append(cars, c) } }) return cars } // Process cars and create new data. func (cs Cars) Map(f func(car *Car) Any) []Any { result := make([]Any, len(cs)) ix := 0 cs.Process(func(c *Car) { result[ix] = f(c) ix++ }) return result } func MakeSortedAppender(manufacturers []string) (func(car *Car), map[string]Cars) { // Prepare maps of sorted cars. sortedCars := make(map[string]Cars) for _, m := range manufacturers { sortedCars[m] = make([]*Car, 0) } sortedCars[\"Default\"] = make([]*Car, 0) // Prepare appender function: appender := func(c *Car) { if _, ok := sortedCars[c.Manufacturer]; ok { sortedCars[c.Manufacturer] = append(sortedCars[c.Manufacturer], c) } else { sortedCars[\"Default\"] = append(sortedCars[\"Default\"], c) } } return appender, sortedCars } 输出： AllCars: [0xf8400038a0 0xf840003bd0 0xf840003ba0 0xf840003b70] New BMWs: [0xf840003bd0] Map sortedCars: map[Default:[0xf840003ba0] Jaguar:[] Land Rover:[] BMW:[0xf840003bd0 0xf840003b70] Aston Martin:[] Ford:[0xf8400038a0]] We have 2 BMWs 链接 目录 上一节：Go 中的面向对象 下一章：读写数据 "},"Go入门指南/11.1.html":{"url":"Go入门指南/11.1.html","title":"1","keywords":"","body":"﻿# 11.1 接口是什么 Go 语言不是一种 “传统” 的面向对象编程语言：它里面没有类和继承的概念。 但是 Go 语言里有非常灵活的 接口 概念，通过它可以实现很多面向对象的特性。接口提供了一种方式来 说明 对象的行为：如果谁能搞定这件事，它就可以用在这儿。 接口定义了一组方法（方法集），但是这些方法不包含（实现）代码：它们没有被实现（它们是抽象的）。接口里也不能包含变量。 通过如下格式定义接口： type Namer interface { Method1(param_list) return_type Method2(param_list) return_type ... } 上面的 Namer 是一个 接口类型。 （按照约定，只包含一个方法的）接口的名字由方法名加 [e]r 后缀组成，例如 Printer、Reader、Writer、Logger、Converter 等等。还有一些不常用的方式（当后缀 er 不合适时），比如 Recoverable，此时接口名以 able 结尾，或者以 I 开头（像 .NET 或 Java 中那样）。 Go 语言中的接口都很简短，通常它们会包含 0 个、最多 3 个方法。 不像大多数面向对象编程语言，在 Go 语言中接口可以有值，一个接口类型的变量或一个 接口值 ：var ai Namer，ai 是一个多字（multiword）数据结构，它的值是 nil。它本质上是一个指针，虽然不完全是一回事。指向接口值的指针是非法的，它们不仅一点用也没有，还会导致代码错误。 此处的方法指针表是通过运行时反射能力构建的。 类型（比如结构体）实现接口方法集中的方法，每一个方法的实现说明了此方法是如何作用于该类型的：即实现接口，同时方法集也构成了该类型的接口。实现了 Namer 接口类型的变量可以赋值给 ai （接收者值），此时方法表中的指针会指向被实现的接口方法。当然如果另一个类型（也实现了该接口）的变量被赋值给 ai，这二者（译者注：指针和方法实现）也会随之改变。 类型不需要显式声明它实现了某个接口：接口被隐式地实现。多个类型可以实现同一个接口。 实现某个接口的类型（除了实现接口方法外）可以有其他的方法。 一个类型可以实现多个接口。 接口类型可以包含一个实例的引用， 该实例的类型实现了此接口（接口是动态类型）。 即使接口在类型之后才定义，二者处于不同的包中，被单独编译：只要类型实现了接口中的方法，它就实现了此接口。 所有这些特性使得接口具有很大的灵活性。 第一个例子： 示例 11.1 interfaces.go： package main import \"fmt\" type Shaper interface { Area() float32 } type Square struct { side float32 } func (sq *Square) Area() float32 { return sq.side * sq.side } func main() { sq1 := new(Square) sq1.side = 5 var areaIntf Shaper areaIntf = sq1 // shorter,without separate declaration: // areaIntf := Shaper(sq1) // or even: // areaIntf := sq1 fmt.Printf(\"The square has area: %f\\n\", areaIntf.Area()) } 输出： The square has area: 25.000000 上面的程序定义了一个结构体 Square 和一个接口 Shaper，接口有一个方法 Area()。 在 main() 方法中创建了一个 Square 的实例。在主程序外边定义了一个接收者类型是 Square 方法的 Area()，用来计算正方形的面积：结构体 Square 实现了接口 Shaper 。 所以可以将一个 Square 类型的变量赋值给一个接口类型的变量：areaIntf = sq1 。 现在接口变量包含一个指向 Square 变量的引用，通过它可以调用 Square 上的方法 Area()。当然也可以直接在 Square 的实例上调用此方法，但是在接口实例上调用此方法更令人兴奋，它使此方法更具有一般性。接口变量里包含了接收者实例的值和指向对应方法表的指针。 这是 多态 的 Go 版本，多态是面向对象编程中一个广为人知的概念：根据当前的类型选择正确的方法，或者说：同一种类型在不同的实例上似乎表现出不同的行为。 如果 Square 没有实现 Area() 方法，编译器将会给出清晰的错误信息： cannot use sq1 (type *Square) as type Shaper in assignment: *Square does not implement Shaper (missing Area method) 如果 Shaper 有另外一个方法 Perimeter()，但是Square 没有实现它，即使没有人在 Square 实例上调用这个方法，编译器也会给出上面同样的错误。 扩展一下上面的例子，类型 Rectangle 也实现了 Shaper 接口。接着创建一个 Shaper 类型的数组，迭代它的每一个元素并在上面调用 Area() 方法，以此来展示多态行为： 示例 11.2 interfaces_poly.go： package main import \"fmt\" type Shaper interface { Area() float32 } type Square struct { side float32 } func (sq *Square) Area() float32 { return sq.side * sq.side } type Rectangle struct { length, width float32 } func (r Rectangle) Area() float32 { return r.length * r.width } func main() { r := Rectangle{5, 3} // Area() of Rectangle needs a value q := &Square{5} // Area() of Square needs a pointer // shapes := []Shaper{Shaper(r), Shaper(q)} // or shorter shapes := []Shaper{r, q} fmt.Println(\"Looping through shapes for area ...\") for n, _ := range shapes { fmt.Println(\"Shape details: \", shapes[n]) fmt.Println(\"Area of this shape is: \", shapes[n].Area()) } } 输出： Looping through shapes for area ... Shape details: {5 3} Area of this shape is: 15 Shape details: &{5} Area of this shape is: 25 在调用 shapes[n].Area() 这个时，只知道 shapes[n] 是一个 Shaper 对象，最后它摇身一变成为了一个 Square 或 Rectangle 对象，并且表现出了相对应的行为。 也许从现在开始你将看到通过接口如何产生 更干净、更简单 及 更具有扩展性 的代码。在 11.12.3 中将看到在开发中为类型添加新的接口是多么的容易。 下面是一个更具体的例子：有两个类型 stockPosition 和 car，它们都有一个 getValue() 方法，我们可以定义一个具有此方法的接口 valuable。接着定义一个使用 valuable 类型作为参数的函数 showValue()，所有实现了 valuable 接口的类型都可以用这个函数。 示例 11.3 valuable.go： package main import \"fmt\" type stockPosition struct { ticker string sharePrice float32 count float32 } /* method to determine the value of a stock position */ func (s stockPosition) getValue() float32 { return s.sharePrice * s.count } type car struct { make string model string price float32 } /* method to determine the value of a car */ func (c car) getValue() float32 { return c.price } /* contract that defines different things that have value */ type valuable interface { getValue() float32 } func showValue(asset valuable) { fmt.Printf(\"Value of the asset is %f\\n\", asset.getValue()) } func main() { var o valuable = stockPosition{\"GOOG\", 577.20, 4} showValue(o) o = car{\"BMW\", \"M3\", 66500} showValue(o) } 输出： Value of the asset is 2308.800049 Value of the asset is 66500.000000 一个标准库的例子 io 包里有一个接口类型 Reader: type Reader interface { Read(p []byte) (n int, err error) } 定义变量 r：var r io.Reader 那么就可以写如下的代码： var r io.Reader r = os.Stdin // see 12.1 r = bufio.NewReader(r) r = new(bytes.Buffer) f,_ := os.Open(\"test.txt\") r = bufio.NewReader(f) 上面 r 右边的类型都实现了 Read() 方法，并且有相同的方法签名，r 的静态类型是 io.Reader。 备注 有的时候，也会以一种稍微不同的方式来使用接口这个词：从某个类型的角度来看，它的接口指的是：它的所有导出方法，只不过没有显式地为这些导出方法额外定一个接口而已。 练习 11.1 simple_interface.go： 定义一个接口 Simpler，它有一个 Get() 方法和一个 Set()，Get()返回一个整型值，Set() 有一个整型参数。创建一个结构体类型 Simple 实现这个接口。 接着定一个函数，它有一个 Simpler 类型的参数，调用参数的 Get() 和 Set() 方法。在 main 函数里调用这个函数，看看它是否可以正确运行。 练习 11.2 interfaces_poly2.go： a) 扩展 interfaces_poly.go 中的例子，添加一个 Circle 类型 b) 使用一个抽象类型 Shape（没有字段） 实现同样的功能，它实现接口 Shaper，然后在其他类型里内嵌此类型。扩展 10.6.5 中的例子来说明覆写。 链接 目录 上一节：接口（Interfaces）与反射（reflection） 下一节：接口嵌套接口 "},"Go入门指南/11.2.html":{"url":"Go入门指南/11.2.html","title":"2","keywords":"","body":"﻿# 11.2 接口嵌套接口 一个接口可以包含一个或多个其他的接口，这相当于直接将这些内嵌接口的方法列举在外层接口中一样。 比如接口 File 包含了 ReadWrite 和 Lock 的所有方法，它还额外有一个 Close() 方法。 type ReadWrite interface { Read(b Buffer) bool Write(b Buffer) bool } type Lock interface { Lock() Unlock() } type File interface { ReadWrite Lock Close() } 链接 目录 上一节：接口是什么 下一节：如何检测和转换接口变量的类型：类型断言 "},"Go入门指南/11.3.html":{"url":"Go入门指南/11.3.html","title":"3","keywords":"","body":"﻿# 11.3 类型断言：如何检测和转换接口变量的类型 一个接口类型的变量 varI 中可以包含任何类型的值，必须有一种方式来检测它的 动态 类型，即运行时在变量中存储的值的实际类型。在执行过程中动态类型可能会有所不同，但是它总是可以分配给接口变量本身的类型。通常我们可以使用 类型断言 来测试在某个时刻 varI 是否包含类型 T 的值： v := varI.(T) // unchecked type assertion varI 必须是一个接口变量，否则编译器会报错：invalid type assertion: varI.(T) (non-interface type (type of varI) on left) 。 类型断言可能是无效的，虽然编译器会尽力检查转换是否有效，但是它不可能预见所有的可能性。如果转换在程序运行时失败会导致错误发生。更安全的方式是使用以下形式来进行类型断言： if v, ok := varI.(T); ok { // checked type assertion Process(v) return } // varI is not of type T 如果转换合法，v 是 varI 转换到类型 T 的值，ok 会是 true；否则 v 是类型 T 的零值，ok 是 false，也没有运行时错误发生。 应该总是使用上面的方式来进行类型断言。 多数情况下，我们可能只是想在 if 中测试一下 ok 的值，此时使用以下的方法会是最方便的： if _, ok := varI.(T); ok { // ... } 示例 11.4 type_interfaces.go： package main import ( \"fmt\" \"math\" ) type Square struct { side float32 } type Circle struct { radius float32 } type Shaper interface { Area() float32 } func main() { var areaIntf Shaper sq1 := new(Square) sq1.side = 5 areaIntf = sq1 // Is Square the type of areaIntf? if t, ok := areaIntf.(*Square); ok { fmt.Printf(\"The type of areaIntf is: %T\\n\", t) } if u, ok := areaIntf.(*Circle); ok { fmt.Printf(\"The type of areaIntf is: %T\\n\", u) } else { fmt.Println(\"areaIntf does not contain a variable of type Circle\") } } func (sq *Square) Area() float32 { return sq.side * sq.side } func (ci *Circle) Area() float32 { return ci.radius * ci.radius * math.Pi } 输出： The type of areaIntf is: *main.Square areaIntf does not contain a variable of type Circle 程序中定义了一个新类型 Circle，它也实现了 Shaper 接口。 if t, ok := areaIntf.(*Square); ok 测试 areaIntf 里是否有一个包含 *Square 类型的变量，结果是确定的；然后我们测试它是否包含一个 *Circle 类型的变量，结果是否定的。 备注 如果忽略 areaIntf.(*Square) 中的 * 号，会导致编译错误：impossible type assertion: Square does not implement Shaper (Area method has pointer receiver)。 链接 目录 上一节：接口嵌套接口 下一节：类型判断：type-switch "},"Go入门指南/11.4.html":{"url":"Go入门指南/11.4.html","title":"4","keywords":"","body":"﻿# 11.4 类型判断：type-switch 接口变量的类型也可以使用一种特殊形式的 switch 来检测：type-switch （下面是示例 11.4 的第二部分）： switch t := areaIntf.(type) { case *Square: fmt.Printf(\"Type Square %T with value %v\\n\", t, t) case *Circle: fmt.Printf(\"Type Circle %T with value %v\\n\", t, t) case nil: fmt.Printf(\"nil value: nothing to check?\\n\") default: fmt.Printf(\"Unexpected type %T\\n\", t) } 输出： Type Square *main.Square with value &{5} 变量 t 得到了 areaIntf 的值和类型， 所有 case 语句中列举的类型（nil 除外）都必须实现对应的接口（在上例中即 Shaper），如果被检测类型没有在 case 语句列举的类型中，就会执行 default 语句。 可以用 type-switch 进行运行时类型分析，但是在 type-switch 不允许有 fallthrough 。 如果仅仅是测试变量的类型，不用它的值，那么就可以不需要赋值语句，比如： switch areaIntf.(type) { case *Square: // TODO case *Circle: // TODO ... default: // TODO } 下面的代码片段展示了一个类型分类函数，它有一个可变长度参数，可以是任意类型的数组，它会根据数组元素的实际类型执行不同的动作： func classifier(items ...interface{}) { for i, x := range items { switch x.(type) { case bool: fmt.Printf(\"Param #%d is a bool\\n\", i) case float64: fmt.Printf(\"Param #%d is a float64\\n\", i) case int, int64: fmt.Printf(\"Param #%d is a int\\n\", i) case nil: fmt.Printf(\"Param #%d is a nil\\n\", i) case string: fmt.Printf(\"Param #%d is a string\\n\", i) default: fmt.Printf(\"Param #%d is unknown\\n\", i) } } } 可以这样调用此方法：classifier(13, -14.3, \"BELGIUM\", complex(1, 2), nil, false) 。 在处理来自于外部的、类型未知的数据时，比如解析诸如 JSON 或 XML 编码的数据，类型测试和转换会非常有用。 在示例 12.17（xml.go）中解析 XML 文档时，我们就会用到 type-switch。 练习 11.4 simple_interface2.go： 接着练习 11.1 中的内容，创建第二个类型 RSimple，它也实现了接口 Simpler，写一个函数 fi，使它可以区分 Simple 和 RSimple 类型的变量。 链接 目录 上一节：类型断言：如何检测和转换接口变量的类型 下一节：测试一个值是否实现了某个接口 "},"Go入门指南/11.5.html":{"url":"Go入门指南/11.5.html","title":"5","keywords":"","body":"﻿# 11.5 测试一个值是否实现了某个接口 这是 11.3 类型断言中的一个特例：假定 v 是一个值，然后我们想测试它是否实现了 Stringer 接口，可以这样做： type Stringer interface { String() string } if sv, ok := v.(Stringer); ok { fmt.Printf(\"v implements String(): %s\\n\", sv.String()) // note: sv, not v } Print 函数就是如此检测类型是否可以打印自身的。 接口是一种契约，实现类型必须满足它，它描述了类型的行为，规定类型可以做什么。接口彻底将类型能做什么，以及如何做分离开来，使得相同接口的变量在不同的时刻表现出不同的行为，这就是多态的本质。 编写参数是接口变量的函数，这使得它们更具有一般性。 使用接口使代码更具有普适性。 标准库里到处都使用了这个原则，如果对接口概念没有良好的把握，是不可能理解它是如何构建的。 在接下来的章节中，我们会讨论两个重要的例子，试着去深入理解它们，这样你就可以更好的应用上面的原则。 链接 目录 上一节：类型判断：type-switch 下一节：使用方法集与接口 "},"Go入门指南/11.6.html":{"url":"Go入门指南/11.6.html","title":"6","keywords":"","body":"﻿# 11.6 使用方法集与接口 在第 10.6.3 节及例子 methodset1.go 中我们看到，作用于变量上的方法实际上是不区分变量到底是指针还是值的。当碰到接口类型值时，这会变得有点复杂，原因是接口变量中存储的具体值是不可寻址的，幸运的是，如果使用不当编译器会给出错误。考虑下面的程序： 示例 11.5 methodset2.go： package main import ( \"fmt\" ) type List []int func (l List) Len() int { return len(l) } func (l *List) Append(val int) { *l = append(*l, val) } type Appender interface { Append(int) } func CountInto(a Appender, start, end int) { for i := start; i 42 } func main() { // A bare value var lst List // compiler error: // cannot use lst (type List) as type Appender in argument to CountInto: // List does not implement Appender (Append method has pointer receiver) // CountInto(lst, 1, 10) if LongEnough(lst) { // VALID:Identical receiver type fmt.Printf(\"- lst is long enough\\n\") } // A pointer value plst := new(List) CountInto(plst, 1, 10) //VALID:Identical receiver type if LongEnough(plst) { // VALID: a *List can be dereferenced for the receiver fmt.Printf(\"- plst is long enough\\n\") } } 讨论 在 lst 上调用 CountInto 时会导致一个编译器错误，因为 CountInto 需要一个 Appender，而它的方法 Append 只定义在指针上。 在 lst 上调用 LongEnough 是可以的，因为 Len 定义在值上。 在 plst 上调用 CountInto 是可以的，因为 CountInto 需要一个 Appender，并且它的方法 Append 定义在指针上。 在 plst 上调用 LongEnough 也是可以的，因为指针会被自动解引用。 总结 在接口上调用方法时，必须有和方法定义时相同的接收者类型或者是可以从具体类型 P 直接可以辨识的： 指针方法可以通过指针调用 值方法可以通过值调用 接收者是值的方法可以通过指针调用，因为指针会首先被解引用 接收者是指针的方法不可以通过值调用，因为存储在接口中的值没有地址 将一个值赋值给一个接口时，编译器会确保所有可能的接口方法都可以在此值上被调用，因此不正确的赋值在编译期就会失败。 译注 Go 语言规范定义了接口方法集的调用规则： 类型 T 的可调用方法集包含接受者为 T 或 T 的所有方法集 类型 T 的可调用方法集包含接受者为 T 的所有方法 类型 T 的可调用方法集不包含接受者为 *T 的方法 链接 目录 上一节：测试一个值是否实现了某个接口 下一节：第一个例子：使用 Sorter 接口排序 "},"Go入门指南/11.7.html":{"url":"Go入门指南/11.7.html","title":"7","keywords":"","body":"﻿# 11.7 第一个例子：使用 Sorter 接口排序 一个很好的例子是来自标准库的 sort 包，要对一组数字或字符串排序，只需要实现三个方法：反映元素个数的 Len()方法、比较第 i 和 j 个元素的 Less(i, j) 方法以及交换第 i 和 j 个元素的 Swap(i, j) 方法。 排序函数的算法只会使用到这三个方法（可以使用任何排序算法来实现，此处我们使用冒泡排序）： func Sort(data Sorter) { for pass := 1; pass Sort 函数接收一个接口类型的参数：Sorter ，它声明了这些方法： type Sorter interface { Len() int Less(i, j int) bool Swap(i, j int) } 参数中的 int 是待排序序列长度的类型，而不是说要排序的对象一定要是一组 int。i 和 j 表示元素的整型索引，长度也是整型的。 现在如果我们想对一个 int 数组进行排序，所有必须做的事情就是：为数组定一个类型并在它上面实现 Sorter 接口的方法： type IntArray []int func (p IntArray) Len() int { return len(p) } func (p IntArray) Less(i, j int) bool { return p[i] 下面是调用排序函数的一个具体例子： data := []int{74, 59, 238, -784, 9845, 959, 905, 0, 0, 42, 7586, -5467984, 7586} a := sort.IntArray(data) //conversion to type IntArray from package sort sort.Sort(a) 完整的、可运行的代码可以在 sort.go 和 sortmain.go 里找到。 同样的原理，排序函数可以用于一个浮点型数组，一个字符串数组，或者一个表示每周各天的结构体 dayArray。 示例 11.6 sort.go： package sort type Sorter interface { Len() int Less(i, j int) bool Swap(i, j int) } func Sort(data Sorter) { for pass := 1; pass 0; i-- { if data.Less(i, i-1) { return false } } return true } // Convenience types for common cases type IntArray []int func (p IntArray) Len() int { return len(p) } func (p IntArray) Less(i, j int) bool { return p[i] 示例 11.7 sortmain.go： package main import ( \"./sort\" \"fmt\" ) func ints() { data := []int{74, 59, 238, -784, 9845, 959, 905, 0, 0, 42, 7586, -5467984, 7586} a := sort.IntArray(data) //conversion to type IntArray sort.Sort(a) if !sort.IsSorted(a) { panic(\"fails\") } fmt.Printf(\"The sorted array is: %v\\n\", a) } func strings() { data := []string{\"monday\", \"friday\", \"tuesday\", \"wednesday\", \"sunday\", \"thursday\", \"\", \"saturday\"} a := sort.StringArray(data) sort.Sort(a) if !sort.IsSorted(a) { panic(\"fail\") } fmt.Printf(\"The sorted array is: %v\\n\", a) } type day struct { num int shortName string longName string } type dayArray struct { data []*day } func (p *dayArray) Len() int { return len(p.data) } func (p *dayArray) Less(i, j int) bool { return p.data[i].num 输出： The sorted array is: [-5467984 -784 0 0 42 59 74 238 905 959 7586 7586 9845] The sorted array is: [ friday monday saturday sunday thursday tuesday wednesday] Sunday Monday Tuesday Wednesday Thursday Friday Saturday 备注： panic(\"fail\") 用于停止处于在非正常情况下的程序（详细请参考 第13章），当然也可以先打印一条信息，然后调用 os.Exit(1) 来停止程序。 上面的例子帮助我们进一步了解了接口的意义和使用方式。对于基本类型的排序，标准库已经提供了相关的排序函数，所以不需要我们再重复造轮子了。对于一般性的排序，sort 包定义了一个接口： type Interface interface { Len() int Less(i, j int) bool Swap(i, j int) } 这个接口总结了需要用于排序的抽象方法，函数 Sort(data Interface) 用来对此类对象进行排序，可以用它们来实现对其他类型的数据（非基本类型）进行排序。在上面的例子中，我们也是这么做的，不仅可以对 int 和 string 序列进行排序，也可以对用户自定义类型 dayArray 进行排序。 练习 11.5 interfaces_ext.go： a). 继续扩展程序，定义类型 Triangle，让它实现 AreaInterface 接口。通过计算一个特定三角形的面积来进行测试（三角形面积=0.5 (底 高)） b). 定义一个新接口 PeriInterface，它有一个 Perimeter 方法。让 Square 实现这个接口，并通过一个 Square 示例来测试它。 练习 11.6 point_interfaces.go： 继续 10.3 中的练习 point_methods.go，定义接口 Magnitude，它有一个方法 Abs()。让 Point、Point3 及Polar 实现此接口。通过接口类型变量使用方法做point.go中同样的事情。 练习 11.7 float_sort.go / float_sortmain.go： 类似11.7和示例11.3/4，定义一个包 float64，并在包里定义类型 Float64Array，然后让它实现 Sorter 接口用来对 float64 数组进行排序。 另外提供如下方法： NewFloat64Array()：创建一个包含25个元素的数组变量（参考10.2） List()：返回数组格式化后的字符串，并在 String() 方法中调用它，这样就不用显式地调用 List() 来打印数组（参考10.7） Fill()：创建一个包含10个随机浮点数的数组（参考4.5.2.6） 在主程序中新建一个此类型的变量，然后对它排序并进行测试。 练习 11.8 sort.go/sort_persons.go： 定义一个结构体 Person，它有两个字段：firstName 和 lastName，为 []Person 定义类型 Persons 。让 Persons 实现 Sorter 接口并进行测试。 链接 目录 上一节：使用方法集与接口 下一节：第二个例子：读和写 "},"Go入门指南/11.8.html":{"url":"Go入门指南/11.8.html","title":"8","keywords":"","body":"﻿# 11.8 第二个例子：读和写 读和写是软件中很普遍的行为，提起它们会立即想到读写文件、缓存（比如字节或字符串切片）、标准输入输出、标准错误以及网络连接、管道等等，或者读写我们的自定义类型。为了让代码尽可能通用，Go 采取了一致的方式来读写数据。 io 包提供了用于读和写的接口 io.Reader 和 io.Writer： type Reader interface { Read(p []byte) (n int, err error) } type Writer interface { Write(p []byte) (n int, err error) } 只要类型实现了读写接口，提供 Read() 和 Write 方法，就可以从它读取数据，或向它写入数据。一个对象要是可读的，它必须实现 io.Reader 接口，这个接口只有一个签名是 Read(p []byte) (n int, err error) 的方法，它从调用它的对象上读取数据，并把读到的数据放入参数中的字节切片中，然后返回读取的字节数和一个 error 对象，如果没有错误发生返回 nil，如果已经到达输入的尾端，会返回 io.EOF(\"EOF\")，如果读取的过程中发生了错误，就会返回具体的错误信息。类似地，一个对象要是可写的，它必须实现 io.Writer 接口，这个接口也只有一个签名是 Write(p []byte) (n int, err error) 的方法，它将指定字节切片中的数据写入调用它的对象里，然后返回实际写入的字节数和一个 error 对象（如果没有错误发生就是 nil）。 io 包里的 Readers 和 Writers 都是不带缓冲的，bufio 包里提供了对应的带缓冲的操作，在读写 UTF-8 编码的文本文件时它们尤其有用。在 第12章 我们会看到很多在实战中使用它们的例子。 在实际编程中尽可能的使用这些接口，会使程序变得更通用，可以在任何实现了这些接口的类型上使用读写方法。 例如一个 JPEG 图形解码器，通过一个 Reader 参数，它可以解码来自磁盘、网络连接或以 gzip 压缩的 HTTP 流中的 JPEG 图形数据，或者其他任何实现了 Reader 接口的对象。 链接 目录 上一节：第一个例子：使用Sorter接口排序 下一节：空接口 "},"Go入门指南/11.9.html":{"url":"Go入门指南/11.9.html","title":"9","keywords":"","body":"11.9 空接口 11.9.1 概念 空接口或者最小接口 不包含任何方法，它对实现不做任何要求： type Any interface {} 任何其他类型都实现了空接口（它不仅仅像 Java/C# 中 Object 引用类型），any 或 Any 是空接口一个很好的别名或缩写。 空接口类似 Java/C# 中所有类的基类： Object 类，二者的目标也很相近。 可以给一个空接口类型的变量 var val interface {} 赋任何类型的值。 示例 11.8 empty_interface.go： package main import \"fmt\" var i = 5 var str = \"ABC\" type Person struct { name string age int } type Any interface{} func main() { var val Any val = 5 fmt.Printf(\"val has the value: %v\\n\", val) val = str fmt.Printf(\"val has the value: %v\\n\", val) pers1 := new(Person) pers1.name = \"Rob Pike\" pers1.age = 55 val = pers1 fmt.Printf(\"val has the value: %v\\n\", val) switch t := val.(type) { case int: fmt.Printf(\"Type int %T\\n\", t) case string: fmt.Printf(\"Type string %T\\n\", t) case bool: fmt.Printf(\"Type boolean %T\\n\", t) case *Person: fmt.Printf(\"Type pointer to Person %T\\n\", t) default: fmt.Printf(\"Unexpected type %T\", t) } } 输出： val has the value: 5 val has the value: ABC val has the value: &{Rob Pike 55} Type pointer to Person *main.Person 在上面的例子中，接口变量 val 被依次赋予一个 int，string 和 Person 实例的值，然后使用 type-switch 来测试它的实际类型。每个 interface {} 变量在内存中占据两个字长：一个用来存储它包含的类型，另一个用来存储它包含的数据或者指向数据的指针。 示例 emptyint_switch.go 说明了空接口在 type-switch 中联合 lambda 函数的用法： package main import \"fmt\" type specialString string var whatIsThis specialString = \"hello\" func TypeSwitch() { testFunc := func(any interface{}) { switch v := any.(type) { case bool: fmt.Printf(\"any %v is a bool type\", v) case int: fmt.Printf(\"any %v is an int type\", v) case float32: fmt.Printf(\"any %v is a float32 type\", v) case string: fmt.Printf(\"any %v is a string type\", v) case specialString: fmt.Printf(\"any %v is a special String!\", v) default: fmt.Println(\"unknown type!\") } } testFunc(whatIsThis) } func main() { TypeSwitch() } 输出： any hello is a special String! 练习 11.9 simple_interface3.go： 继续 练习11.2，在它中添加一个 gI 函数，它不再接受 Simpler 类型的参数，而是接受一个空接口参数。然后通过类型断言判断参数是否是 Simpler 类型。最后在 main 使用 gI 取代 fI 函数并调用它。确保你的代码足够安全。 11.9.2 构建通用类型或包含不同类型变量的数组 在 7.6.6 中我们看到了能被搜索和排序的 int 数组、float 数组以及 string 数组，那么对于其他类型的数组呢，是不是我们必须得自己编程实现它们？ 现在我们知道该怎么做了，就是通过使用空接口。让我们给空接口定一个别名类型 Element：type Element interface{} 然后定义一个容器类型的结构体 Vector，它包含一个 Element 类型元素的切片： type Vector struct { a []Element } Vector 里能放任何类型的变量，因为任何类型都实现了空接口，实际上 Vector 里放的每个元素可以是不同类型的变量。我们为它定义一个 At() 方法用于返回第 i 个元素： func (p *Vector) At(i int) Element { return p.a[i] } 再定一个 Set() 方法用于设置第 i 个元素的值： func (p *Vector) Set(i int, e Element) { p.a[i] = e } Vector 中存储的所有元素都是 Element 类型，要得到它们的原始类型（unboxing：拆箱）需要用到类型断言。TODO：The compiler rejects assertions guaranteed to fail，类型断言总是在运行时才执行，因此它会产生运行时错误。 练习 11.10 min_interface.go / minmain.go： 仿照11.7中开发的 Sorter 接口，创建一个 Miner 接口并实现一些必要的操作。函数 Min 接受一个 Miner 类型变量的集合，然后计算并返回集合中最小的元素。 11.9.3 复制数据切片至空接口切片 假设你有一个 myType 类型的数据切片，你想将切片中的数据复制到一个空接口切片中，类似： var dataSlice []myType = FuncReturnSlice() var interfaceSlice []interface{} = dataSlice 可惜不能这么做，编译时会出错：cannot use dataSlice (type []myType) as type []interface { } in assignment。 原因是它们俩在内存中的布局是不一样的（参考 官方说明）。 必须使用 for-range 语句来一个一个显式地复制： var dataSlice []myType = FuncReturnSlice() var interfaceSlice []interface{} = make([]interface{}, len(dataSlice)) for i, d := range dataSlice { interfaceSlice[i] = d } 11.9.4 通用类型的节点数据结构 在10.1中我们遇到了诸如列表和树这样的数据结构，在它们的定义中使用了一种叫节点的递归结构体类型，节点包含一个某种类型的数据字段。现在可以使用空接口作为数据字段的类型，这样我们就能写出通用的代码。下面是实现一个二叉树的部分代码：通用定义、用于创建空节点的 NewNode 方法，及设置数据的 SetData 方法。 示例 11.10 node_structures.go： package main import \"fmt\" type Node struct { le *Node data interface{} ri *Node } func NewNode(left, right *Node) *Node { return &Node{left, nil, right} } func (n *Node) SetData(data interface{}) { n.data = data } func main() { root := NewNode(nil, nil) root.SetData(\"root node\") // make child (leaf) nodes: a := NewNode(nil, nil) a.SetData(\"left node\") b := NewNode(nil, nil) b.SetData(\"right node\") root.le = a root.ri = b fmt.Printf(\"%v\\n\", root) // Output: &{0x125275f0 root node 0x125275e0} } 11.9.5 接口到接口 一个接口的值可以赋值给另一个接口变量，只要底层类型实现了必要的方法。这个转换是在运行时进行检查的，转换失败会导致一个运行时错误：这是 Go 语言动态的一面，可以拿它和 Ruby 和 Python 这些动态语言相比较。 假定： var ai AbsInterface // declares method Abs() type SqrInterface interface { Sqr() float } var si SqrInterface pp := new(Point) // say *Point implements Abs, Sqr var empty interface{} 那么下面的语句和类型断言是合法的： empty = pp // everything satisfies empty ai = empty.(AbsInterface) // underlying value pp implements Abs() // (runtime failure otherwise) si = ai.(SqrInterface) // *Point has Sqr() even though AbsInterface doesn’t empty = si // *Point implements empty set // Note: statically checkable so type assertion not necessary. 下面是函数调用的一个例子： type myPrintInterface interface { print() } func f3(x myInterface) { x.(myPrintInterface).print() // type assertion to myPrintInterface } x 转换为 myPrintInterface 类型是完全动态的：只要 x 的底层类型（动态类型）定义了 print 方法这个调用就可以正常运行。 链接 目录 上一节：第二个例子：读和写 下一节：对结构进行反射 "},"Go入门指南/12.0.html":{"url":"Go入门指南/12.0.html","title":"0","keywords":"","body":"12 读写数据 除了 fmt 和 os 包，我们还需要用到 bufio 包来处理缓冲的输入和输出。 链接 目录 上一章：结构体、集合和高阶函数 下一节：读取用户的输入 "},"Go入门指南/12.10.html":{"url":"Go入门指南/12.10.html","title":"10","keywords":"","body":"12.10 XML 数据格式 下面是与 12.9 节 JSON 例子等价的 XML 版本： Laura Lynn 如同 json 包一样，也有 Marshal() 和 UnMarshal() 从 XML 中编码和解码数据；但这个更通用，可以从文件中读取和写入（或者任何实现了 io.Reader 和 io.Writer 接口的类型） 和 JSON 的方式一样，XML 数据可以序列化为结构，或者从结构反序列化为 XML 数据；这些可以在例子 15.8（twitter_status.go）中看到。 encoding/xml 包实现了一个简单的 XML 解析器（SAX），用来解析 XML 数据内容。下面的例子说明如何使用解析器： 示例 12.17 xml.go： // xml.go package main import ( \"encoding/xml\" \"fmt\" \"strings\" ) var t, token xml.Token var err error func main() { input := \"LauraLynn\" inputReader := strings.NewReader(input) p := xml.NewDecoder(inputReader) for t, err = p.Token(); err == nil; t, err = p.Token() { switch token := t.(type) { case xml.StartElement: name := token.Name.Local fmt.Printf(\"Token name: %s\\n\", name) for _, attr := range token.Attr { attrName := attr.Name.Local attrValue := attr.Value fmt.Printf(\"An attribute is: %s %s\\n\", attrName, attrValue) // ... } case xml.EndElement: fmt.Println(\"End of token\") case xml.CharData: content := string([]byte(token)) fmt.Printf(\"This is the content: %v\\n\", content) // ... default: // ... } } } 输出： Token name: Person Token name: FirstName This is the content: Laura End of token Token name: LastName This is the content: Lynn End of token End of token 包中定义了若干 XML 标签类型：StartElement，Chardata（这是从开始标签到结束标签之间的实际文本），EndElement，Comment，Directive 或 ProcInst。 包中同样定义了一个结构解析器：NewParser 方法持有一个 io.Reader（这里具体类型是 strings.NewReader）并生成一个解析器类型的对象。还有一个 Token() 方法返回输入流里的下一个 XML token。在输入流的结尾处，会返回（nil，io.EOF） XML 文本被循环处理直到 Token() 返回一个错误，因为已经到达文件尾部，再没有内容可供处理了。通过一个 type-switch 可以根据一些 XML 标签进一步处理。Chardata 中的内容只是一个 []byte，通过字符串转换让其变得可读性强一些。 链接 目录 上一节：Json 数据格式 下一节：用 Gob 传输数据 "},"Go入门指南/12.11.html":{"url":"Go入门指南/12.11.html","title":"11","keywords":"","body":"12.11 用 Gob 传输数据 Gob 是 Go 自己的以二进制形式序列化和反序列化程序数据的格式；可以在 encoding 包中找到。这种格式的数据简称为 Gob （即 Go binary 的缩写）。类似于 Python 的 \"pickle\" 和 Java 的 \"Serialization\"。 Gob 通常用于远程方法调用（RPCs，参见 15.9 的 rpc 包）参数和结果的传输，以及应用程序和机器之间的数据传输。 它和 JSON 或 XML 有什么不同呢？Gob 特定地用于纯 Go 的环境中，例如，两个用 Go 写的服务之间的通信。这样的话服务可以被实现得更加高效和优化。 Gob 不是可外部定义，语言无关的编码方式。因此它的首选格式是二进制，而不是像 JSON 和 XML 那样的文本格式。 Gob 并不是一种不同于 Go 的语言，而是在编码和解码过程中用到了 Go 的反射。 Gob 文件或流是完全自描述的：里面包含的所有类型都有一个对应的描述，并且总是可以用 Go 解码，而不需要了解文件的内容。 只有可导出的字段会被编码，零值会被忽略。在解码结构体的时候，只有同时匹配名称和可兼容类型的字段才会被解码。当源数据类型增加新字段后，Gob 解码客户端仍然可以以这种方式正常工作：解码客户端会继续识别以前存在的字段。并且还提供了很大的灵活性，比如在发送者看来，整数被编码成没有固定长度的可变长度，而忽略具体的 Go 类型。 假如在发送者这边有一个有结构 T： type T struct { X, Y, Z int } var t = T{X: 7, Y: 0, Z: 8} 而在接收者这边可以用一个结构体 U 类型的变量 u 来接收这个值： type U struct { X, Y *int8 } var u U 在接收者中，X 的值是7，Y 的值是0（Y的值并没有从 t 中传递过来，因为它是零值） 和 JSON 的使用方式一样，Gob 使用通用的 io.Writer 接口，通过 NewEncoder() 函数创建 Encoder 对象并调用 Encode()；相反的过程使用通用的 io.Reader 接口，通过 NewDecoder() 函数创建 Decoder 对象并调用 Decode。 我们把示例 12.12 的信息写进名为 vcard.gob 的文件作为例子。这会产生一个文本可读数据和二进制数据的混合，当你试着在文本编辑中打开的时候会看到。 在示例 12.18 中你会看到一个编解码，并且以字节缓冲模拟网络传输的简单例子： 示例 12.18 gob1.go： // gob1.go package main import ( \"bytes\" \"fmt\" \"encoding/gob\" \"log\" ) type P struct { X, Y, Z int Name string } type Q struct { X, Y *int32 Name string } func main() { // Initialize the encoder and decoder. Normally enc and dec would be // bound to network connections and the encoder and decoder would // run in different processes. var network bytes.Buffer // Stand-in for a network connection enc := gob.NewEncoder(&network) // Will write to network. dec := gob.NewDecoder(&network) // Will read from network. // Encode (send) the value. err := enc.Encode(P{3, 4, 5, \"Pythagoras\"}) if err != nil { log.Fatal(\"encode error:\", err) } // Decode (receive) the value. var q Q err = dec.Decode(&q) if err != nil { log.Fatal(\"decode error:\", err) } fmt.Printf(\"%q: {%d,%d}\\n\", q.Name, *q.X, *q.Y) } // Output: \"Pythagoras\": {3,4} 示例 12.19 gob2.go 编码到文件： // gob2.go package main import ( \"encoding/gob\" \"log\" \"os\" ) type Address struct { Type string City string Country string } type VCard struct { FirstName string LastName string Addresses []*Address Remark string } var content string func main() { pa := &Address{\"private\", \"Aartselaar\",\"Belgium\"} wa := &Address{\"work\", \"Boom\", \"Belgium\"} vc := VCard{\"Jan\", \"Kersschot\", []*Address{pa,wa}, \"none\"} // fmt.Printf(\"%v: \\n\", vc) // {Jan Kersschot [0x126d2b80 0x126d2be0] none}: // using an encoder: file, _ := os.OpenFile(\"vcard.gob\", os.O_CREATE|os.O_WRONLY, 0666) defer file.Close() enc := gob.NewEncoder(file) err := enc.Encode(vc) if err != nil { log.Println(\"Error in encoding gob\") } } 练习 12.8：degob.go： 写一个程序读取 vcard.gob 文件，解码并打印它的内容。 链接 目录 上一节：XML 数据格式 下一节：Go 中的密码学 "},"Go入门指南/12.12.html":{"url":"Go入门指南/12.12.html","title":"12","keywords":"","body":"12.12 Go 中的密码学 通过网络传输的数据必须加密，以防止被 hacker（黑客）读取或篡改，并且保证发出的数据和收到的数据检验和一致。 鉴于 Go 母公司的业务，我们毫不惊讶地看到 Go 的标准库为该领域提供了超过 30 个的包： hash 包：实现了 adler32、crc32、crc64 和 fnv 校验； crypto 包：实现了其它的 hash 算法，比如 md4、md5、sha1 等。以及完整地实现了 aes、blowfish、rc4、rsa、xtea 等加密算法。 下面的示例用 sha1 和 md5 计算并输出了一些校验值。 示例 12.20 hash_sha1.go： // hash_sha1.go package main import ( \"fmt\" \"crypto/sha1\" \"io\" \"log\" ) func main() { hasher := sha1.New() io.WriteString(hasher, \"test\") b := []byte{} fmt.Printf(\"Result: %x\\n\", hasher.Sum(b)) fmt.Printf(\"Result: %d\\n\", hasher.Sum(b)) // hasher.Reset() data := []byte(\"We shall overcome!\") n, err := hasher.Write(data) if n!=len(data) || err!=nil { log.Printf(\"Hash write error: %v / %v\", n, err) } checksum := hasher.Sum(b) fmt.Printf(\"Result: %x\\n\", checksum) } 输出： Result: a94a8fe5ccb19ba61c4c0873d391e987982fbbd3 Result: [169 74 143 229 204 177 155 166 28 76 8 115 211 145 233 135 152 47 187 211] Result: e2222bfc59850bbb00a722e764a555603bb59b2a 通过调用 sha1.New() 创建了一个新的 hash.Hash 对象，用来计算 SHA1 校验值。Hash 类型实际上是一个接口，它实现了 io.Writer 接口： type Hash interface { // Write (via the embedded io.Writer interface) adds more data to the running hash. // It never returns an error. io.Writer // Sum appends the current hash to b and returns the resulting slice. // It does not change the underlying hash state. Sum(b []byte) []byte // Reset resets the Hash to its initial state. Reset() // Size returns the number of bytes Sum will return. Size() int // BlockSize returns the hash's underlying block size. // The Write method must be able to accept any amount // of data, but it may operate more efficiently if all writes // are a multiple of the block size. BlockSize() int } 通过 io.WriteString 或 hasher.Write 将给定的 []byte 附加到当前的 hash.Hash 对象中。 练习 12.9：hash_md5.go： 在示例 12.20 中检验 md5 算法。 链接 目录 上一节：用 Gob 传输数据 下一章：错误处理与测试 "},"Go入门指南/12.1.html":{"url":"Go入门指南/12.1.html","title":"1","keywords":"","body":"12.1 读取用户的输入 我们如何读取用户的键盘（控制台）输入呢？从键盘和标准输入 os.Stdin 读取输入，最简单的办法是使用 fmt 包提供的 Scan 和 Sscan 开头的函数。请看以下程序： 示例 12.1 readinput1.go： // 从控制台读取输入: package main import \"fmt\" var ( firstName, lastName, s string i int f float32 input = \"56.12 / 5212 / Go\" format = \"%f / %d / %s\" ) func main() { fmt.Println(\"Please enter your full name: \") fmt.Scanln(&firstName, &lastName) // fmt.Scanf(\"%s %s\", &firstName, &lastName) fmt.Printf(\"Hi %s %s!\\n\", firstName, lastName) // Hi Chris Naegels fmt.Sscanf(input, format, &f, &i, &s) fmt.Println(\"From the string we read: \", f, i, s) // 输出结果: From the string we read: 56.12 5212 Go } Scanln 扫描来自标准输入的文本，将空格分隔的值依次存放到后续的参数内，直到碰到换行。Scanf 与其类似，除了 Scanf 的第一个参数用作格式字符串，用来决定如何读取。Sscan 和以 Sscan 开头的函数则是从字符串读取，除此之外，与 Scanf 相同。如果这些函数读取到的结果与您预想的不同，您可以检查成功读入数据的个数和返回的错误。 您也可以使用 bufio 包提供的缓冲读取（buffered reader）来读取数据，正如以下例子所示： 示例 12.2 readinput2.go： package main import ( \"fmt\" \"bufio\" \"os\" ) var inputReader *bufio.Reader var input string var err error func main() { inputReader = bufio.NewReader(os.Stdin) fmt.Println(\"Please enter some input: \") input, err = inputReader.ReadString('\\n') if err == nil { fmt.Printf(\"The input was: %s\\n\", input) } } inputReader 是一个指向 bufio.Reader 的指针。inputReader := bufio.NewReader(os.Stdin) 这行代码，将会创建一个读取器，并将其与标准输入绑定。 bufio.NewReader() 构造函数的签名为：func NewReader(rd io.Reader) *Reader 该函数的实参可以是满足 io.Reader 接口的任意对象（任意包含有适当的 Read() 方法的对象，请参考章节11.8），函数返回一个新的带缓冲的 io.Reader 对象，它将从指定读取器（例如 os.Stdin）读取内容。 返回的读取器对象提供一个方法 ReadString(delim byte)，该方法从输入中读取内容，直到碰到 delim 指定的字符，然后将读取到的内容连同 delim 字符一起放到缓冲区。 ReadString 返回读取到的字符串，如果碰到错误则返回 nil。如果它一直读到文件结束，则返回读取到的字符串和 io.EOF。如果读取过程中没有碰到 delim 字符，将返回错误 err != nil。 在上面的例子中，我们会读取键盘输入，直到回车键（\\n）被按下。 屏幕是标准输出 os.Stdout；os.Stderr 用于显示错误信息，大多数情况下等同于 os.Stdout。 一般情况下，我们会省略变量声明，而使用 :=，例如： inputReader := bufio.NewReader(os.Stdin) input, err := inputReader.ReadString('\\n') 我们将从现在开始使用这种写法。 第二个例子从键盘读取输入，使用了 switch 语句： 示例 12.3 switch_input.go： package main import ( \"fmt\" \"os\" \"bufio\" ) func main() { inputReader := bufio.NewReader(os.Stdin) fmt.Println(\"Please enter your name:\") input, err := inputReader.ReadString('\\n') if err != nil { fmt.Println(\"There were errors reading, exiting program.\") return } fmt.Printf(\"Your name is %s\", input) // For Unix: test with delimiter \"\\n\", for Windows: test with \"\\r\\n\" switch input { case \"Philip\\r\\n\": fmt.Println(\"Welcome Philip!\") case \"Chris\\r\\n\": fmt.Println(\"Welcome Chris!\") case \"Ivo\\r\\n\": fmt.Println(\"Welcome Ivo!\") default: fmt.Printf(\"You are not welcome here! Goodbye!\") } // version 2: switch input { case \"Philip\\r\\n\": fallthrough case \"Ivo\\r\\n\": fallthrough case \"Chris\\r\\n\": fmt.Printf(\"Welcome %s\\n\", input) default: fmt.Printf(\"You are not welcome here! Goodbye!\\n\") } // version 3: switch input { case \"Philip\\r\\n\", \"Ivo\\r\\n\": fmt.Printf(\"Welcome %s\\n\", input) default: fmt.Printf(\"You are not welcome here! Goodbye!\\n\") } } 注意：Unix和Windows的行结束符是不同的！ 练习 练习 12.1: word_letter_count.go 编写一个程序，从键盘读取输入。当用户输入 'S' 的时候表示输入结束，这时程序输出 3 个数字：i) 输入的字符的个数，包括空格，但不包括 '\\r' 和 '\\n'ii) 输入的单词的个数iii) 输入的行数 练习 12.2: calculator.go 编写一个简单的逆波兰式计算器，它接受用户输入的整型数（最大值 999999）和运算符 +、-、*、/。输入的格式为：number1 ENTER number2 ENTER operator ENTER --> 显示结果当用户输入字符 'q' 时，程序结束。请使用您在练习11.3中开发的 stack 包。 链接 目录 上一节：读写数据 下一节：文件读写 "},"Go入门指南/12.2.html":{"url":"Go入门指南/12.2.html","title":"2","keywords":"","body":"12.2 文件读写 12.2.1 读文件 在 Go 语言中，文件使用指向 os.File 类型的指针来表示的，也叫做文件句柄。我们在前面章节使用到过标准输入 os.Stdin 和标准输出 os.Stdout，他们的类型都是 *os.File。让我们来看看下面这个程序： 示例 12.4 fileinput.go： package main import ( \"bufio\" \"fmt\" \"io\" \"os\" ) func main() { inputFile, inputError := os.Open(\"input.dat\") if inputError != nil { fmt.Printf(\"An error occurred on opening the inputfile\\n\" + \"Does the file exist?\\n\" + \"Have you got acces to it?\\n\") return // exit the function on error } defer inputFile.Close() inputReader := bufio.NewReader(inputFile) for { inputString, readerError := inputReader.ReadString('\\n') fmt.Printf(\"The input was: %s\", inputString) if readerError == io.EOF { return } } } 变量 inputFile 是 *os.File 类型的。该类型是一个结构，表示一个打开文件的描述符（文件句柄）。然后，使用 os 包里的 Open 函数来打开一个文件。该函数的参数是文件名，类型为 string。在上面的程序中，我们以只读模式打开 input.dat 文件。 如果文件不存在或者程序没有足够的权限打开这个文件，Open函数会返回一个错误：inputFile, inputError = os.Open(\"input.dat\")。如果文件打开正常，我们就使用 defer inputFile.Close() 语句确保在程序退出前关闭该文件。然后，我们使用 bufio.NewReader 来获得一个读取器变量。 通过使用 bufio 包提供的读取器（写入器也类似），如上面程序所示，我们可以很方便的操作相对高层的 string 对象，而避免了去操作比较底层的字节。 接着，我们在一个无限循环中使用 ReadString('\\n') 或 ReadBytes('\\n') 将文件的内容逐行（行结束符 '\\n'）读取出来。 注意： 在之前的例子中，我们看到，Unix和Linux的行结束符是 \\n，而Windows的行结束符是 \\r\\n。在使用 ReadString 和 ReadBytes 方法的时候，我们不需要关心操作系统的类型，直接使用 \\n 就可以了。另外，我们也可以使用 ReadLine() 方法来实现相同的功能。 一旦读取到文件末尾，变量 readerError 的值将变成非空（事实上，常量 io.EOF 的值是 true），我们就会执行 return 语句从而退出循环。 其他类似函数： 1) 将整个文件的内容读到一个字符串里： 如果您想这么做，可以使用 io/ioutil 包里的 ioutil.ReadFile() 方法，该方法第一个返回值的类型是 []byte，里面存放读取到的内容，第二个返回值是错误，如果没有错误发生，第二个返回值为 nil。请看示例 12.5。类似的，函数 WriteFile() 可以将 []byte 的值写入文件。 示例 12.5 read_write_file1.go： package main import ( \"fmt\" \"io/ioutil\" \"os\" ) func main() { inputFile := \"products.txt\" outputFile := \"products_copy.txt\" buf, err := ioutil.ReadFile(inputFile) if err != nil { fmt.Fprintf(os.Stderr, \"File Error: %s\\n\", err) // panic(err.Error()) } fmt.Printf(\"%s\\n\", string(buf)) err = ioutil.WriteFile(outputFile, buf, 0644) // oct, not hex if err != nil { panic(err.Error()) } } 2) 带缓冲的读取 在很多情况下，文件的内容是不按行划分的，或者干脆就是一个二进制文件。在这种情况下，ReadString()就无法使用了，我们可以使用 bufio.Reader 的 Read()，它只接收一个参数： buf := make([]byte, 1024) ... n, err := inputReader.Read(buf) if (n == 0) { break} 变量 n 的值表示读取到的字节数. 3) 按列读取文件中的数据 如果数据是按列排列并用空格分隔的，你可以使用 fmt 包提供的以 FScan 开头的一系列函数来读取他们。请看以下程序，我们将 3 列的数据分别读入变量 v1、v2 和 v3 内，然后分别把他们添加到切片的尾部。 示例 12.6 read_file2.go： package main import ( \"fmt\" \"os\" ) func main() { file, err := os.Open(\"products2.txt\") if err != nil { panic(err) } defer file.Close() var col1, col2, col3 []string for { var v1, v2, v3 string _, err := fmt.Fscanln(file, &v1, &v2, &v3) // scans until newline if err != nil { break } col1 = append(col1, v1) col2 = append(col2, v2) col3 = append(col3, v3) } fmt.Println(col1) fmt.Println(col2) fmt.Println(col3) } 输出结果： [ABC FUNC GO] [40 56 45] [150 280 356] 注意： path 包里包含一个子包叫 filepath，这个子包提供了跨平台的函数，用于处理文件名和路径。例如 Base() 函数用于获得路径中的最后一个元素（不包含后面的分隔符）： import \"path/filepath\" filename := filepath.Base(path) 练习 12.3：read_csv.go 文件 products.txt 的内容如下： \"The ABC of Go\";25.5;1500 \"Functional Programming with Go\";56;280 \"Go for It\";45.9;356 \"The Go Way\";55;500 每行的第一个字段为 title，第二个字段为 price，第三个字段为 quantity。内容的格式基本与 示例 12.3c 的相同，除了分隔符改成了分号。请读取出文件的内容，创建一个结构用于存取一行的数据，然后使用结构的切片，并把数据打印出来。 关于解析 CSV 文件，encoding/csv 包提供了相应的功能。具体请参考 http://golang.org/pkg/encoding/csv/ 12.2.2 compress包：读取压缩文件 compress包提供了读取压缩文件的功能，支持的压缩文件格式为：bzip2、flate、gzip、lzw 和 zlib。 下面的程序展示了如何读取一个 gzip 文件。 示例 12.7 gzipped.go： package main import ( \"fmt\" \"bufio\" \"os\" \"compress/gzip\" ) func main() { fName := \"MyFile.gz\" var r *bufio.Reader fi, err := os.Open(fName) if err != nil { fmt.Fprintf(os.Stderr, \"%v, Can't open %s: error: %s\\n\", os.Args[0], fName, err) os.Exit(1) } fz, err := gzip.NewReader(fi) if err != nil { r = bufio.NewReader(fi) } else { r = bufio.NewReader(fz) } for { line, err := r.ReadString('\\n') if err != nil { fmt.Println(\"Done reading file\") os.Exit(0) } fmt.Println(line) } } 12.2.3 写文件 请看以下程序： 示例 12.8 fileoutput.go： package main import ( \"os\" \"bufio\" \"fmt\" ) func main () { // var outputWriter *bufio.Writer // var outputFile *os.File // var outputError os.Error // var outputString string outputFile, outputError := os.OpenFile(\"output.dat\", os.O_WRONLY|os.O_CREATE, 0666) if outputError != nil { fmt.Printf(\"An error occurred with file opening or creation\\n\") return } defer outputFile.Close() outputWriter := bufio.NewWriter(outputFile) outputString := \"hello world!\\n\" for i:=0; i 除了文件句柄，我们还需要 bufio 的 Writer。我们以只写模式打开文件 output.dat，如果文件不存在则自动创建： outputFile, outputError := os.OpenFile(“output.dat”, os.O_WRONLY|os.O_CREATE, 0666) 可以看到，OpenFile 函数有三个参数：文件名、一个或多个标志（使用逻辑运算符“|”连接），使用的文件权限。 我们通常会用到以下标志： os.O_RDONLY：只读 os.O_WRONLY：只写 os.O_CREATE：创建：如果指定文件不存在，就创建该文件。 os.O_TRUNC：截断：如果指定文件已存在，就将该文件的长度截为0。 在读文件的时候，文件的权限是被忽略的，所以在使用 OpenFile 时传入的第三个参数可以用0。而在写文件时，不管是 Unix 还是 Windows，都需要使用 0666。 然后，我们创建一个写入器（缓冲区）对象： outputWriter := bufio.NewWriter(outputFile) 接着，使用一个 for 循环，将字符串写入缓冲区，写 10 次：outputWriter.WriteString(outputString) 缓冲区的内容紧接着被完全写入文件：outputWriter.Flush() 如果写入的东西很简单，我们可以使用 fmt.Fprintf(outputFile, “Some test data.\\n”) 直接将内容写入文件。fmt 包里的 F 开头的 Print 函数可以直接写入任何 io.Writer，包括文件（请参考章节12.8). 程序 filewrite.go 展示了不使用 fmt.FPrintf 函数，使用其他函数如何写文件： 示例 12.8 filewrite.go： package main import \"os\" func main() { os.Stdout.WriteString(\"hello, world\\n\") f, _ := os.OpenFile(\"test\", os.O_CREATE|os.O_WRONLY, 0) defer f.Close() f.WriteString(\"hello, world in a file\\n\") } 使用 os.Stdout.WriteString(“hello, world\\n”)，我们可以输出到屏幕。 我们以只写模式创建或打开文件“test”，并且忽略了可能发生的错误：f, _ := os.OpenFile(“test”, os.O_CREATE|os.O_WRONLY, 0) 我们不使用缓冲区，直接将内容写入文件：f.WriteString( ) 练习 12.4：wiki_part1.go （这是一个独立的练习，但是同时也是为章节15.4做准备） 程序中的数据结构如下，是一个包含以下字段的结构: type Page struct { Title string Body []byte } 请给这个结构编写一个 save 方法，将 Title 作为文件名、Body作为文件内容，写入到文本文件中。 再编写一个 load 函数，接收的参数是字符串 title，该函数读取出与 title 对应的文本文件。请使用 *Page 做为参数，因为这个结构可能相当巨大，我们不想在内存中拷贝它。请使用 ioutil 包里的函数（参考章节12.2.1）。 链接 目录 上一节：读取用户的输入 下一节：文件拷贝 "},"Go入门指南/12.3.html":{"url":"Go入门指南/12.3.html","title":"3","keywords":"","body":"12.3 文件拷贝 如何拷贝一个文件到另一个文件？最简单的方式就是使用 io 包： 示例 12.10 filecopy.go： // filecopy.go package main import ( \"fmt\" \"io\" \"os\" ) func main() { CopyFile(\"target.txt\", \"source.txt\") fmt.Println(\"Copy done!\") } func CopyFile(dstName, srcName string) (written int64, err error) { src, err := os.Open(srcName) if err != nil { return } defer src.Close() dst, err := os.OpenFile(dstName, os.O_WRONLY|os.O_CREATE, 0644) if err != nil { return } defer dst.Close() return io.Copy(dst, src) } 注意 defer 的使用：当打开目标文件时发生了错误，那么 defer 仍然能够确保 src.Close() 执行。如果不这么做，文件会一直保持打开状态并占用资源。 链接 目录 上一节：文件读写 下一节：从命令行读取参数 "},"Go入门指南/12.4.html":{"url":"Go入门指南/12.4.html","title":"4","keywords":"","body":"12.4 从命令行读取参数 12.4.1 os 包 os 包中有一个 string 类型的切片变量 os.Args，用来处理一些基本的命令行参数，它在程序启动后读取命令行输入的参数。来看下面的打招呼程序： 示例 12.11 os_args.go： // os_args.go package main import ( \"fmt\" \"os\" \"strings\" ) func main() { who := \"Alice \" if len(os.Args) > 1 { who += strings.Join(os.Args[1:], \" \") } fmt.Println(\"Good Morning\", who) } 我们在 IDE 或编辑器中直接运行这个程序输出：Good Morning Alice 我们在命令行运行 os_args or ./os_args 会得到同样的结果。 但是我们在命令行加入参数，像这样：os_args John Bill Marc Luke，将得到这样的输出：Good Morning Alice John Bill Marc Luke 这个命令行参数会放置在切片 os.Args[] 中（以空格分隔），从索引1开始（os.Args[0] 放的是程序本身的名字，在本例中是 os_args）。函数 strings.Join 以空格为间隔连接这些参数。 练习 12.5：hello_who.go 写一个\"Hello World\"的变种程序：把人的名字作为程序命令行执行的一个参数，比如： hello_who Evan Michael Laura 那么会输出Hello Evan Michael Laura! 12.4.2 flag 包 flag 包有一个扩展功能用来解析命令行选项。但是通常被用来替换基本常量，例如，在某些情况下我们希望在命令行给常量一些不一样的值。（参看 19 章的项目） 在 flag 包中一个 Flag 被定义成一个含有如下字段的结构体： type Flag struct { Name string // name as it appears on command line Usage string // help message Value Value // value as set DefValue string // default value (as text); for usage message } 下面的程序 echo.go 模拟了 Unix 的 echo 功能： package main import ( \"flag\" // command line option parser \"os\" ) var NewLine = flag.Bool(\"n\", false, \"print newline\") // echo -n flag, of type *bool const ( Space = \" \" Newline = \"\\n\" ) func main() { flag.PrintDefaults() flag.Parse() // Scans the arg list and sets up flags var s string = \"\" for i := 0; i 0 { s += \" \" if *NewLine { // -n is parsed, flag becomes true s += Newline } } s += flag.Arg(i) } os.Stdout.WriteString(s) } flag.Parse() 扫描参数列表（或者常量列表）并设置 flag, flag.Arg(i) 表示第i个参数。Parse() 之后 flag.Arg(i) 全部可用，flag.Arg(0) 就是第一个真实的 flag，而不是像 os.Args(0) 放置程序的名字。 flag.Narg() 返回参数的数量。解析后 flag 或常量就可用了。 flag.Bool() 定义了一个默认值是 false 的 flag：当在命令行出现了第一个参数（这里是 \"n\"），flag 被设置成 true（NewLine 是 *bool 类型）。flag 被解引用到 *NewLine，所以当值是 true 时将添加一个 newline（\"\\n\"）。 flag.PrintDefaults() 打印 flag 的使用帮助信息，本例中打印的是： -n=false: print newline flag.VisitAll(fn func(*Flag)) 是另一个有用的功能：按照字典顺序遍历 flag，并且对每个标签调用 fn （参考 15.8 章的例子） 当在命令行（Windows）中执行：echo.exe A B C，将输出：A B C；执行 echo.exe -n A B C，将输出： A B C 每个字符的输出都新起一行，每次都在输出的数据前面打印使用帮助信息：-n=false: print newline。 对于 flag.Bool 你可以设置布尔型 flag 来测试你的代码，例如定义一个 flag processedFlag: var processedFlag = flag.Bool(“proc”, false, “nothing processed yet”) 在后面用如下代码来测试： if *processedFlag { // found flag -proc r = process() } 要给 flag 定义其它类型，可以使用 flag.Int()，flag.Float64，flag.String()。 在第 15.8 章你将找到一个具体的例子。 链接 目录 上一节：文件拷贝 下一节：用buffer读取文件 "},"Go入门指南/12.5.html":{"url":"Go入门指南/12.5.html","title":"5","keywords":"","body":"12.5 用 buffer 读取文件 在下面的例子中，我们结合使用了缓冲读取文件和命令行 flag 解析这两项技术。如果不加参数，那么你输入什么屏幕就打印什么。 参数被认为是文件名，如果文件存在的话就打印文件内容到屏幕。命令行执行 cat test 测试输出。 示例 12.11 cat.go： package main import ( \"bufio\" \"flag\" \"fmt\" \"io\" \"os\" ) func cat(r *bufio.Reader) { for { buf, err := r.ReadBytes('\\n') if err == io.EOF { break } fmt.Fprintf(os.Stdout, \"%s\", buf) } return } func main() { flag.Parse() if flag.NArg() == 0 { cat(bufio.NewReader(os.Stdin)) } for i := 0; i 在 12.6 章节，我们将看到如何使用缓冲写入。 练习 12.5：cat_numbered.go 扩展 cat.go 例子，使用 flag 添加一个选项，目的是为每一行头部加入一个行号。使用 cat -n test 测试输出。 链接 目录 上一节：从命令行读取参数 下一节：用切片读写文件 "},"Go入门指南/12.6.html":{"url":"Go入门指南/12.6.html","title":"6","keywords":"","body":"12.6 用切片读写文件 切片提供了 Go 中处理 I/O 缓冲的标准方式，下面 cat 函数的第二版中，在一个切片缓冲内使用无限 for 循环（直到文件尾部 EOF）读取文件，并写入到标准输出（os.Stdout）。 func cat(f *os.File) { const NBUF = 512 var buf [NBUF]byte for { switch nr, err := f.Read(buf[:]); true { case nr 0: if nw, ew := os.Stdout.Write(buf[0:nr]); nw != nr { fmt.Fprintf(os.Stderr, \"cat: error writing: %s\\n\", ew.Error()) } } } } 上面的代码来自于 cat2.go，使用了 os 包中的 os.file 和 Read 方法；cat2.go 与 cat.go 具有同样的功能。 示例 12.14 cat2.go： package main import ( \"flag\" \"fmt\" \"os\" ) func cat(f *os.File) { const NBUF = 512 var buf [NBUF]byte for { switch nr, err := f.Read(buf[:]); true { case nr 0: if nw, ew := os.Stdout.Write(buf[0:nr]); nw != nr { fmt.Fprintf(os.Stderr, \"cat: error writing: %s\\n\", ew.Error()) } } } } func main() { flag.Parse() // Scans the arg list and sets up flags if flag.NArg() == 0 { cat(os.Stdin) } for i := 0; i 链接 目录 上一节：用 buffer 读取文件 下一节：用 defer 关闭文件 "},"Go入门指南/12.7.html":{"url":"Go入门指南/12.7.html","title":"7","keywords":"","body":"12.7 用 defer 关闭文件 defer 关键字（参看 6.4）对于在函数结束时关闭打开的文件非常有用，例如下面的代码片段： func data(name string) string { f, _ := os.OpenFile(name, os.O_RDONLY, 0) defer f.Close() // idiomatic Go code! contents, _ := ioutil.ReadAll(f) return string(contents) } 在函数 return 后执行了 f.Close() 链接 目录 上一节：用切片读写文件 下一节：使用接口的实际例子：fmt.Fprintf "},"Go入门指南/12.8.html":{"url":"Go入门指南/12.8.html","title":"8","keywords":"","body":"12.8 使用接口的实际例子：fmt.Fprintf 例子程序 io_interfaces.go 很好的阐述了 io 包中的接口概念。 示例 12.15 io_interfaces.go： // interfaces being used in the GO-package fmt package main import ( \"bufio\" \"fmt\" \"os\" ) func main() { // unbuffered fmt.Fprintf(os.Stdout, \"%s\\n\", \"hello world! - unbuffered\") // buffered: os.Stdout implements io.Writer buf := bufio.NewWriter(os.Stdout) // and now so does buf. fmt.Fprintf(buf, \"%s\\n\", \"hello world! - buffered\") buf.Flush() } 输出： hello world! - unbuffered hello world! - buffered 下面是 fmt.Fprintf() 函数的实际签名 func Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error) 其不是写入一个文件，而是写入一个 io.Writer 接口类型的变量，下面是 Writer 接口在 io 包中的定义： type Writer interface { Write(p []byte) (n int, err error) } fmt.Fprintf() 依据指定的格式向第一个参数内写入字符串，第一参数必须实现了 io.Writer 接口。Fprintf() 能够写入任何类型，只要其实现了 Write 方法，包括 os.Stdout,文件（例如 os.File），管道，网络连接，通道等等，同样的也可以使用 bufio 包中缓冲写入。bufio 包中定义了 type Writer struct{...}。 bufio.Writer 实现了 Write 方法： func (b *Writer) Write(p []byte) (nn int, err error) 它还有一个工厂函数：传给它一个 io.Writer 类型的参数，它会返回一个缓冲的 bufio.Writer 类型的 io.Writer: func NewWriter(wr io.Writer) (b *Writer) 其适合任何形式的缓冲写入。 在缓冲写入的最后千万不要忘了使用 Flush()，否则最后的输出不会被写入。 在 15.2-15.8 章节，我们将使用 fmt.Fprint 函数向 http.ResponseWriter 写入，其同样实现了 io.Writer 接口。 练习 12.7：remove_3till5char.go 下面的代码有一个输入文件 goprogram，然后以每一行为单位读取，从读取的当前行中截取第 3 到第 5 的字节写入另一个文件。然而当你运行这个程序，输出的文件却是个空文件。找出程序逻辑中的 bug，修正它并测试。 package main import ( \"bufio\" \"fmt\" \"os\" \"io\" ) func main() { inputFile, _ := os.Open(\"goprogram\") outputFile, _ := os.OpenFile(\"goprogramT\", os.O_WRONLY|os.O_CREATE, 0666) defer inputFile.Close() defer outputFile.Close() inputReader := bufio.NewReader(inputFile) outputWriter := bufio.NewWriter(outputFile) for { inputString, _, readerError := inputReader.ReadLine() if readerError == io.EOF { fmt.Println(\"EOF\") return } outputString := string(inputString[2:5]) + \"\\r\\n\" _, err := outputWriter.WriteString(outputString) if err != nil { fmt.Println(err) return } } fmt.Println(\"Conversion done\") } 链接 目录 上一节：用 defer 关闭文件 下一节：格式化 Json 数据 "},"Go入门指南/12.9.html":{"url":"Go入门指南/12.9.html","title":"9","keywords":"","body":"12.9 JSON 数据格式 数据结构要在网络中传输或保存到文件，就必须对其编码和解码；目前存在很多编码格式：JSON，XML，gob，Google 缓冲协议等等。Go 语言支持所有这些编码格式；在后面的章节，我们将讨论前三种格式。 结构可能包含二进制数据，如果将其作为文本打印，那么可读性是很差的。另外结构内部可能包含匿名字段，而不清楚数据的用意。 通过把数据转换成纯文本，使用命名的字段来标注，让其具有可读性。这样的数据格式可以通过网络传输，而且是与平台无关的，任何类型的应用都能够读取和输出，不与操作系统和编程语言的类型相关。 下面是一些术语说明： 数据结构 --> 指定格式 = 序列化 或 编码（传输之前） 指定格式 --> 数据格式 = 反序列化 或 解码（传输之后） 序列化是在内存中把数据转换成指定格式（data -> string），反之亦然（string -> data structure） 编码也是一样的，只是输出一个数据流（实现了 io.Writer 接口）；解码是从一个数据流（实现了 io.Reader）输出到一个数据结构。 我们都比较熟悉 XML 格式(参阅 12.10)；但有些时候 JSON（JavaScript Object Notation，参阅 http://json.org）被作为首选，主要是由于其格式上非常简洁。通常 JSON 被用于 web 后端和浏览器之间的通讯，但是在其它场景也同样的有用。 这是一个简短的 JSON 片段： { \"Person\": { \"FirstName\": \"Laura\", \"LastName\": \"Lynn\" } } 尽管 XML 被广泛的应用，但是 JSON 更加简洁、轻量（占用更少的内存、磁盘及网络带宽）和更好的可读性，这也使它越来越受欢迎。 Go 语言的 json 包可以让你在程序中方便的读取和写入 JSON 数据。 我们将在下面的例子里使用 json 包，并使用练习 10.1 vcard.go 中一个简化版本的 Address 和 VCard 结构（为了简单起见，我们忽略了很多错误处理，不过在实际应用中你必须要合理的处理这些错误，参阅 13 章） 示例 12.16 json.go： // json.go package main import ( \"encoding/json\" \"fmt\" \"log\" \"os\" ) type Address struct { Type string City string Country string } type VCard struct { FirstName string LastName string Addresses []*Address Remark string } func main() { pa := &Address{\"private\", \"Aartselaar\", \"Belgium\"} wa := &Address{\"work\", \"Boom\", \"Belgium\"} vc := VCard{\"Jan\", \"Kersschot\", []*Address{pa, wa}, \"none\"} // fmt.Printf(\"%v: \\n\", vc) // {Jan Kersschot [0x126d2b80 0x126d2be0] none}: // JSON format: js, _ := json.Marshal(vc) fmt.Printf(\"JSON format: %s\", js) // using an encoder: file, _ := os.OpenFile(\"vcard.json\", os.O_CREATE|os.O_WRONLY, 0666) defer file.Close() enc := json.NewEncoder(file) err := enc.Encode(vc) if err != nil { log.Println(\"Error in encoding json\") } } json.Marshal() 的函数签名是 func Marshal(v interface{}) ([]byte, error)，下面是数据编码后的 JSON 文本（实际上是一个 []byte）： { \"FirstName\": \"Jan\", \"LastName\": \"Kersschot\", \"Addresses\": [{ \"Type\": \"private\", \"City\": \"Aartselaar\", \"Country\": \"Belgium\" }, { \"Type\": \"work\", \"City\": \"Boom\", \"Country\": \"Belgium\" }], \"Remark\": \"none\" } 出于安全考虑，在 web 应用中最好使用 json.MarshalforHTML() 函数，其对数据执行HTML转码，所以文本可以被安全地嵌在 HTML 标签中。 json.NewEncoder() 的函数签名是 func NewEncoder(w io.Writer) *Encoder，返回的Encoder类型的指针可调用方法 Encode(v interface{})，将数据对象 v 的json编码写入 io.Writer w 中。 JSON 与 Go 类型对应如下： bool 对应 JSON 的 booleans float64 对应 JSON 的 numbers string 对应 JSON 的 strings nil 对应 JSON 的 null 不是所有的数据都可以编码为 JSON 类型：只有验证通过的数据结构才能被编码： JSON 对象只支持字符串类型的 key；要编码一个 Go map 类型，map 必须是 map[string]T（T是 json 包中支持的任何类型） Channel，复杂类型和函数类型不能被编码 不支持循环数据结构；它将引起序列化进入一个无限循环 指针可以被编码，实际上是对指针指向的值进行编码（或者指针是 nil） 反序列化： UnMarshal() 的函数签名是 func Unmarshal(data []byte, v interface{}) error 把 JSON 解码为数据结构。 示例12.16中对 vc 编码后的数据为 js ，对其解码时，我们首先创建结构 VCard 用来保存解码的数据：var v VCard 并调用 json.Unmarshal(js, &v)，解析 []byte 中的 JSON 数据并将结果存入指针 &v 指向的值。 虽然反射能够让 JSON 字段去尝试匹配目标结构字段；但是只有真正匹配上的字段才会填充数据。字段没有匹配不会报错，而是直接忽略掉。 （练习 15.2b twitter_status_json.go 中用到了 UnMarshal） 解码任意的数据： json 包使用 map[string]interface{} 和 []interface{} 储存任意的 JSON 对象和数组；其可以被反序列化为任何的 JSON blob 存储到接口值中。 来看这个 JSON 数据，被存储在变量 b 中： b := []byte(`{\"Name\": \"Wednesday\", \"Age\": 6, \"Parents\": [\"Gomez\", \"Morticia\"]}`) 不用理解这个数据的结构，我们可以直接使用 Unmarshal 把这个数据编码并保存在接口值中： var f interface{} err := json.Unmarshal(b, &f) f 指向的值是一个 map，key 是一个字符串，value 是自身存储作为空接口类型的值： map[string]interface{} { \"Name\": \"Wednesday\", \"Age\": 6, \"Parents\": []interface{} { \"Gomez\", \"Morticia\", }, } 要访问这个数据，我们可以使用类型断言 m := f.(map[string]interface{}) 我们可以通过 for range 语法和 type switch 来访问其实际类型： for k, v := range m { switch vv := v.(type) { case string: fmt.Println(k, \"is string\", vv) case int: fmt.Println(k, \"is int\", vv) case []interface{}: fmt.Println(k, \"is an array:\") for i, u := range vv { fmt.Println(i, u) } default: fmt.Println(k, \"is of a type I don’t know how to handle\") } } 通过这种方式，你可以处理未知的 JSON 数据，同时可以确保类型安全。 解码数据到结构 如果我们事先知道 JSON 数据，我们可以定义一个适当的结构并对 JSON 数据反序列化。下面的例子中，我们将定义： type FamilyMember struct { Name string Age int Parents []string } 并对其反序列化： var m FamilyMember err := json.Unmarshal(b, &m) 程序实际上是分配了一个新的切片。这是一个典型的反序列化引用类型（指针、切片和 map）的例子。 编码和解码流 json 包提供 Decoder 和 Encoder 类型来支持常用 JSON 数据流读写。NewDecoder 和 NewEncoder 函数分别封装了 io.Reader 和 io.Writer 接口。 func NewDecoder(r io.Reader) *Decoder func NewEncoder(w io.Writer) *Encoder 要想把 JSON 直接写入文件，可以使用 json.NewEncoder 初始化文件（或者任何实现 io.Writer 的类型），并调用 Encode()；反过来与其对应的是使用 json.Decoder 和 Decode() 函数： func NewDecoder(r io.Reader) *Decoder func (dec *Decoder) Decode(v interface{}) error 来看下接口是如何对实现进行抽象的：数据结构可以是任何类型，只要其实现了某种接口，目标或源数据要能够被编码就必须实现 io.Writer 或 io.Reader 接口。由于 Go 语言中到处都实现了 Reader 和 Writer，因此 Encoder 和 Decoder 可被应用的场景非常广泛，例如读取或写入 HTTP 连接、websockets 或文件。 链接 目录 上一节：使用接口的实际例子:fmt.Fprintf 下一节：XML 数据格式 "},"Go入门指南/13.0.html":{"url":"Go入门指南/13.0.html","title":"0","keywords":"","body":"13 错误处理与测试 Go 没有像 Java 和 .NET 那样的 try/catch 异常机制：不能执行抛异常操作。但是有一套 defer-panic-and-recover 机制（参见 13.2-13.3 节）。 Go 的设计者觉得 try/catch 机制的使用太泛滥了，而且从底层向更高的层级抛异常太耗费资源。他们给 Go 设计的机制也可以 “捕捉” 异常，但是更轻量，并且只应该作为（处理错误的）最后的手段。 Go 是怎么处理普通错误的呢？通过在函数和方法中返回错误对象作为它们的唯一或最后一个返回值——如果返回 nil，则没有错误发生——并且主调（calling）函数总是应该检查收到的错误。 永远不要忽略错误，否则可能会导致程序崩溃！！ 处理错误并且在函数发生错误的地方给用户返回错误信息：照这样处理就算真的出了问题，你的程序也能继续运行并且通知给用户。panic and recover 是用来处理真正的异常（无法预测的错误）而不是普通的错误。 库函数通常必须返回某种错误提示给主调（calling）函数。 在前面的章节中我们了解了 Go 检查和报告错误条件的惯有方式： 产生错误的函数会返回两个变量，一个值和一个错误码；如果后者是 nil 就是成功，非 nil 就是发生了错误。 为了防止发生错误时正在执行的函数（如果有必要的话甚至会是整个程序）被中止，在调用函数后必须检查错误。 下面这段来自 pack1 包的代码 Func1 测试了它的返回值： if value, err := pack1.Func1(param1); err != nil { fmt.Printf(“Error %s in pack1.Func1 with parameter %v”, err.Error(), param1) return // or: return err } else { // Process(value) } 为了更清晰的代码，应该总是使用包含错误值变量的 if 复合语句 上例除了 fmt.Printf 还可以使用 log 中对应的方法（参见 13.3 节 和 15.2 节），如果程序中止也没关系的话甚至可以使用 panic（参见后面的章节）。 链接 目录 上一节：Go 中的密码学 下一节：错误处理 "},"Go入门指南/13.10.html":{"url":"Go入门指南/13.10.html","title":"10","keywords":"","body":"13.10 性能调试：分析并优化 Go 程序 13.10.1 时间和内存消耗 可以用这个便捷脚本 xtime 来测量： #!/bin/sh /usr/bin/time -f '%Uu %Ss %er %MkB %C' \"$@\" 在 Unix 命令行中像这样使用 xtime goprogexec，这里的 progexec 是一个 Go 可执行程序，这句命令行输出类似：56.63u 0.26s 56.92r 1642640kB progexec，分别对应用户时间，系统时间，实际时间和最大内存占用。 13.10.2 用 go test 调试 如果代码使用了 Go 中 testing 包的基准测试功能，我们可以用 gotest 标准的 -cpuprofile 和 -memprofile 标志向指定文件写入 CPU 或 内存使用情况报告。 使用方式：go test -x -v -cpuprofile=prof.out -file x_test.go 编译执行 x_test.go 中的测试，并向 prof.out 文件中写入 cpu 性能分析信息。 13.10.3 用 pprof 调试 你可以在单机程序 progexec 中引入 runtime/pprof 包；这个包以 pprof 可视化工具需要的格式写入运行时报告数据。对于 CPU 性能分析来说你需要添加一些代码： var cpuprofile = flag.String(\"cpuprofile\", \"\", \"write cpu profile to file\") func main() { flag.Parse() if *cpuprofile != \"\" { f, err := os.Create(*cpuprofile) if err != nil { log.Fatal(err) } pprof.StartCPUProfile(f) defer pprof.StopCPUProfile() } ... 代码定义了一个名为 cpuprofile 的 flag，调用 Go flag 库来解析命令行 flag，如果命令行设置了 cpuprofile flag，则开始 CPU 性能分析并把结果重定向到那个文件。（os.Create 用拿到的名字创建了用来写入分析数据的文件）。这个分析程序最后需要在程序退出之前调用 StopCPUProfile 来刷新挂起的写操作到文件中；我们用 defer 来保证这一切会在 main 返回时触发。 现在用这个 flag 运行程序：progexec -cpuprofile=progexec.prof 然后可以像这样用 gopprof 工具：gopprof progexec progexec.prof gopprof 程序是 Google pprofC++ 分析器的一个轻微变种；关于此工具更多的信息，参见https://github.com/gperftools/gperftools。 如果开启了 CPU 性能分析，Go 程序会以大约每秒 100 次的频率阻塞，并记录当前执行的 goroutine 栈上的程序计数器样本。 此工具一些有趣的命令： 1）topN 用来展示分析结果中最开头的 N 份样本，例如：top5 它会展示在程序运行期间调用最频繁的 5 个函数，输出如下： Total: 3099 samples 626 20.2% 20.2% 626 20.2% scanblock 309 10.0% 30.2% 2839 91.6% main.FindLoops ... 第 5 列表示函数的调用频度。 2）web 或 web 函数名 该命令生成一份 SVG 格式的分析数据图表，并在网络浏览器中打开它（还有一个 gv 命令可以生成 PostScript 格式的数据，并在 GhostView 中打开，这个命令需要安装 graphviz）。函数被表示成不同的矩形（被调用越多，矩形越大），箭头指示函数调用链。 3）list 函数名 或 weblist 函数名 展示对应函数名的代码行列表，第 2 列表示当前行执行消耗的时间，这样就很好地指出了运行过程中消耗最大的代码。 如果发现函数 runtime.mallocgc（分配内存并执行周期性的垃圾回收）调用频繁，那么是应该进行内存分析的时候了。找出垃圾回收频繁执行的原因，和内存大量分配的根源。 为了做到这一点必须在合适的地方添加下面的代码： var memprofile = flag.String(\"memprofile\", \"\", \"write memory profile to this file\") ... CallToFunctionWhichAllocatesLotsOfMemory() if *memprofile != \"\" { f, err := os.Create(*memprofile) if err != nil { log.Fatal(err) } pprof.WriteHeapProfile(f) f.Close() return } 用 -memprofile flag 运行这个程序：progexec -memprofile=progexec.mprof 然后你可以像这样再次使用 gopprof 工具：gopprof progexec progexec.mprof top5，list 函数名 等命令同样适用，只不过现在是以 Mb 为单位测量内存分配情况，这是 top 命令输出的例子： Total: 118.3 MB 66.1 55.8% 55.8% 103.7 87.7% main.FindLoops 30.5 25.8% 81.6% 30.5 25.8% main.*LSG·NewLoop ... 从第 1 列可以看出，最上面的函数占用了最多的内存。 同样有一个报告内存分配计数的有趣工具： gopprof --inuse_objects progexec progexec.mprof 对于 web 应用来说，有标准的 HTTP 接口可以分析数据。在 HTTP 服务中添加 import _ \"http/pprof\" 会为 /debug/pprof/ 下的一些 URL 安装处理器。然后你可以用一个唯一的参数——你服务中的分析数据的 URL 来执行 gopprof 命令——它会下载并执行在线分析。 gopprof http://localhost:6060/debug/pprof/profile # 30-second CPU profile gopprof http://localhost:6060/debug/pprof/heap # heap profile 在 Go-blog（引用 15）中有一篇很好的文章用具体的例子进行了分析：分析 Go 程序（2011年6月）。 链接 目录 上一节：用（测试数据）表驱动测试 下一章：协程（goroutine）与通道（channel） "},"Go入门指南/13.1.html":{"url":"Go入门指南/13.1.html","title":"1","keywords":"","body":"13.1 错误处理 Go 有一个预先定义的 error 接口类型 type error interface { Error() string } 错误值用来表示异常状态；我们可以在 5.2 节中看到它的标准用法。处理文件操作的例子可以在 12 章找到；我们将在 15 章看到网络操作的例子。errors 包中有一个 errorString 结构体实现了 error 接口。当程序处于错误状态时可以用 os.Exit(1) 来中止运行。 13.1.1 定义错误 任何时候当你需要一个新的错误类型，都可以用 errors（必须先 import）包的 errors.New 函数接收合适的错误信息来创建，像下面这样： err := errors.New(\"math - square root of negative number\") 在示例 13.1 中你可以看到一个简单的用例： 示例 13.1 errors.go： // errors.go package main import ( \"errors\" \"fmt\" ) var errNotFound error = errors.New(\"Not found error\") func main() { fmt.Printf(\"error: %v\", errNotFound) } // error: Not found error 可以把它用于计算平方根函数的参数测试： func Sqrt(f float64) (float64, error) { if f 你可以像下面这样调用 Sqrt 函数： if f, err := Sqrt(-1); err != nil { fmt.Printf(\"Error: %s\\n\", err) } 由于 fmt.Printf 会自动调用 String() 方法 （参见 10.7 节），所以错误信息 “Error: math - square root of negative number” 会打印出来。通常（错误信息）都会有像 “Error:” 这样的前缀，所以你的错误信息不要以大写字母开头。 在大部分情况下自定义错误结构类型很有意义的，可以包含除了（低层级的）错误信息以外的其它有用信息，例如，正在进行的操作（打开文件等），全路径或名字。看下面例子中 os.Open 操作触发的 PathError 错误： // PathError records an error and the operation and file path that caused it. type PathError struct { Op string // \"open\", \"unlink\", etc. Path string // The associated file. Err error // Returned by the system call. } func (e *PathError) String() string { return e.Op + \" \" + e.Path + \": \"+ e.Err.Error() } 如果有不同错误条件可能发生，那么对实际的错误使用类型断言或类型判断（type-switch）是很有用的，并且可以根据错误场景做一些补救和恢复操作。 // err != nil if e, ok := err.(*os.PathError); ok { // remedy situation } 或： switch err := err.(type) { case ParseError: PrintParseError(err) case PathError: PrintPathError(err) ... default: fmt.Printf(\"Not a special error, just %s\\n\", err) } 作为第二个例子考虑用 json 包的情况。当 json.Decode 在解析 JSON 文档发生语法错误时，指定返回一个 SyntaxError 类型的错误： type SyntaxError struct { msg string // description of error // error occurred after reading Offset bytes, from which line and columnnr can be obtained Offset int64 } func (e *SyntaxError) String() string { return e.msg } 在调用代码中你可以像这样用类型断言测试错误是不是上面的类型： if serr, ok := err.(*json.SyntaxError); ok { line, col := findLine(f, serr.Offset) return fmt.Errorf(\"%s:%d:%d: %v\", f.Name(), line, col, err) } 包也可以用额外的方法（methods）定义特定的错误，比如 net.Error： package net type Error interface { Timeout() bool // Is the error a timeout? Temporary() bool // Is the error temporary? } 在 15.1 节 我们可以看到怎么使用它。 正如你所看到的一样，所有的例子都遵循同一种命名规范：错误类型以 “Error” 结尾，错误变量以 “err” 或 “Err” 开头。 syscall 是低阶外部包，用来提供系统基本调用的原始接口。它们返回整数的错误码；类型 syscall.Errno 实现了 Error 接口。 大部分 syscall 函数都返回一个结果和可能的错误，比如： r, err := syscall.Open(name, mode, perm) if err != 0 { fmt.Println(err.Error()) } os 包也提供了一套像 os.EINAL 这样的标准错误，它们基于 syscall 错误： var ( EPERM Error = Errno(syscall.EPERM) ENOENT Error = Errno(syscall.ENOENT) ESRCH Error = Errno(syscall.ESRCH) EINTR Error = Errno(syscall.EINTR) EIO Error = Errno(syscall.EIO) ... ) 13.1.2 用 fmt 创建错误对象 通常你想要返回包含错误参数的更有信息量的字符串，例如：可以用 fmt.Errorf() 来实现：它和 fmt.Printf() 完全一样，接收有一个或多个格式占位符的格式化字符串和相应数量的占位变量。和打印信息不同的是它用信息生成错误对象。 比如在前面的平方根例子中使用： if f 第二个例子：从命令行读取输入时，如果加了 help 标志，我们可以用有用的信息产生一个错误： if len(os.Args) > 1 && (os.Args[1] == \"-h\" || os.Args[1] == \"--help\") { err = fmt.Errorf(\"usage: %s infile.txt outfile.txt\", filepath.Base(os.Args[0])) return } 链接 目录 上一节：错误处理与测试 下一节：运行时异常和 panic "},"Go入门指南/13.2.html":{"url":"Go入门指南/13.2.html","title":"2","keywords":"","body":"13.2 运行时异常和 panic 当发生像数组下标越界或类型断言失败这样的运行错误时，Go 运行时会触发运行时 panic，伴随着程序的崩溃抛出一个 runtime.Error 接口类型的值。这个错误值有个 RuntimeError() 方法用于区别普通错误。 panic 可以直接从代码初始化：当错误条件（我们所测试的代码）很严苛且不可恢复，程序不能继续运行时，可以使用 panic 函数产生一个中止程序的运行时错误。panic 接收一个做任意类型的参数，通常是字符串，在程序死亡时被打印出来。Go 运行时负责中止程序并给出调试信息。在示例 13.2 panic.go 中阐明了它的工作方式： package main import \"fmt\" func main() { fmt.Println(\"Starting the program\") panic(\"A severe error occurred: stopping the program!\") fmt.Println(\"Ending the program\") } 输出如下： Starting the program panic: A severe error occurred: stopping the program! panic PC=0x4f3038 runtime.panic+0x99 /go/src/pkg/runtime/proc.c:1032 runtime.panic(0x442938, 0x4f08e8) main.main+0xa5 E:/Go/GoBoek/code examples/chapter 13/panic.go:8 main.main() runtime.mainstart+0xf 386/asm.s:84 runtime.mainstart() runtime.goexit /go/src/pkg/runtime/proc.c:148 runtime.goexit() ---- Error run E:/Go/GoBoek/code examples/chapter 13/panic.exe with code Crashed ---- Program exited with code -1073741783 一个检查程序是否被已知用户启动的具体例子： var user = os.Getenv(\"USER\") func check() { if user == \"\" { panic(\"Unknown user: no value for $USER\") } } 可以在导入包的 init() 函数中检查这些。 当发生错误必须中止程序时，panic 可以用于错误处理模式： if err != nil { panic(\"ERROR occurred:\" + err.Error()) } Go panicking： 在多层嵌套的函数调用中调用 panic，可以马上中止当前函数的执行，所有的 defer 语句都会保证执行并把控制权交还给接收到 panic 的函数调用者。这样向上冒泡直到最顶层，并执行（每层的） defer，在栈顶处程序崩溃，并在命令行中用传给 panic 的值报告错误情况：这个终止过程就是 panicking。 标准库中有许多包含 Must 前缀的函数，像 regexp.MustComplie 和 template.Must；当正则表达式或模板中转入的转换字符串导致错误时，这些函数会 panic。 不能随意地用 panic 中止程序，必须尽力补救错误让程序能继续执行。 链接 目录 上一节：错误处理 下一节：从 panic 中恢复（Recover） "},"Go入门指南/13.3.html":{"url":"Go入门指南/13.3.html","title":"3","keywords":"","body":"13.3 从 panic 中恢复（Recover） 正如名字一样，这个（recover）内建函数被用于从 panic 或 错误场景中恢复：让程序可以从 panicking 重新获得控制权，停止终止过程进而恢复正常执行。 recover 只能在 defer 修饰的函数（参见 6.4 节）中使用：用于取得 panic 调用中传递过来的错误值，如果是正常执行，调用 recover 会返回 nil，且没有其它效果。 总结：panic 会导致栈被展开直到 defer 修饰的 recover() 被调用或者程序中止。 下面例子中的 protect 函数调用函数参数 g 来保护调用者防止从 g 中抛出的运行时 panic，并展示 panic 中的信息： func protect(g func()) { defer func() { log.Println(\"done\") // Println executes normally even if there is a panic if err := recover(); err != nil { log.Printf(\"run time panic: %v\", err) } }() log.Println(\"start\") g() // possible runtime-error } 这跟 Java 和 .NET 这样的语言中的 catch 块类似。 log 包实现了简单的日志功能：默认的 log 对象向标准错误输出中写入并打印每条日志信息的日期和时间。除了 Println 和 Printf 函数，其它的致命性函数都会在写完日志信息后调用 os.Exit(1)，那些退出函数也是如此。而 Panic 效果的函数会在写完日志信息后调用 panic；可以在程序必须中止或发生了临界错误时使用它们，就像当 web 服务器不能启动时那样（参见 15.4 节中的例子）。 log 包用那些方法（methods）定义了一个 Logger 接口类型，如果你想自定义日志系统的话可以参考（参见 http://golang.org/pkg/log/#Logger）。 这是一个展示 panic，defer 和 recover 怎么结合使用的完整例子： 示例 13.3 panic_recover.go： // panic_recover.go package main import ( \"fmt\" ) func badCall() { panic(\"bad end\") } func test() { defer func() { if e := recover(); e != nil { fmt.Printf(\"Panicing %s\\r\\n\", e) } }() badCall() fmt.Printf(\"After bad call\\r\\n\") // 输出： Calling test Panicing bad end Test completed defer-panic-recover 在某种意义上也是一种像 if，for 这样的控制流机制。 Go 标准库中许多地方都用了这个机制，例如，json 包中的解码和 regexp 包中的 Complie 函数。Go 库的原则是即使在包的内部使用了 panic，在它的对外接口（API）中也必须用 recover 处理成返回显式的错误。 链接 目录 上一节：错运行时异常和 panic 下一节：自定义包中的错误处理和 panicking "},"Go入门指南/13.4.html":{"url":"Go入门指南/13.4.html","title":"4","keywords":"","body":"13.4 自定义包中的错误处理和 panicking 这是所有自定义包实现者应该遵守的最佳实践： 1）在包内部，总是应该从 panic 中 recover：不允许显式的超出包范围的 panic() 2）向包的调用者返回错误值（而不是 panic）。 在包内部，特别是在非导出函数中有很深层次的嵌套调用时，对主调函数来说用 panic 来表示应该被翻译成错误的错误场景是很有用的（并且提高了代码可读性）。 这在下面的代码中被很好地阐述了。我们有一个简单的 parse 包（示例 13.4）用来把输入的字符串解析为整数切片；这个包有自己特殊的 ParseError。 当没有东西需要转换或者转换成整数失败时，这个包会 panic（在函数 fields2numbers 中）。但是可导出的 Parse 函数会从 panic 中 recover 并用所有这些信息返回一个错误给调用者。为了演示这个过程，在 panic_recover.go 中 调用了 parse 包（示例 13.4）；不可解析的字符串会导致错误并被打印出来。 示例 13.4 parse.go： // parse.go package parse import ( \"fmt\" \"strings\" \"strconv\" ) // A ParseError indicates an error in converting a word into an integer. type ParseError struct { Index int // The index into the space-separated list of words. Word string // The word that generated the parse error. Err error // The raw error that precipitated this error, if any. } // String returns a human-readable error message. func (e *ParseError) String() string { return fmt.Sprintf(\"pkg parse: error parsing %q as int\", e.Word) } // Parse parses the space-separated words in in put as integers. func Parse(input string) (numbers []int, err error) { defer func() { if r := recover(); r != nil { var ok bool err, ok = r.(error) if !ok { err = fmt.Errorf(\"pkg: %v\", r) } } }() fields := strings.Fields(input) numbers = fields2numbers(fields) return } func fields2numbers(fields []string) (numbers []int) { if len(fields) == 0 { panic(\"no words to parse\") } for idx, field := range fields { num, err := strconv.Atoi(field) if err != nil { panic(&ParseError{idx, field, err}) } numbers = append(numbers, num) } return } 示例 13.5 panic_package.go： // panic_package.go package main import ( \"fmt\" \"./parse/parse\" ) func main() { var examples = []string{ \"1 2 3 4 5\", \"100 50 25 12.5 6.25\", \"2 + 2 = 4\", \"1st class\", \"\", } for _, ex := range examples { fmt.Printf(\"Parsing %q:\\n \", ex) nums, err := parse.Parse(ex) if err != nil { fmt.Println(err) // here String() method from ParseError is used continue } fmt.Println(nums) } } 输出： Parsing \"1 2 3 4 5\": [1 2 3 4 5] Parsing \"100 50 25 12.5 6.25\": pkg parse: error parsing \"12.5\" as int Parsing \"2 + 2 = 4\": pkg parse: error parsing \"+\" as int Parsing \"1st class\": pkg parse: error parsing \"1st\" as int Parsing \"\": pkg: no words to parse 链接 目录 上一节：从 panic 中恢复（Recover） 下一节：一种用闭包处理错误的模式 "},"Go入门指南/13.5.html":{"url":"Go入门指南/13.5.html","title":"5","keywords":"","body":"13.5 一种用闭包处理错误的模式 每当函数返回时，我们应该检查是否有错误发生：但是这会导致重复乏味的代码。结合 defer/panic/recover 机制和闭包可以得到一个我们马上要讨论的更加优雅的模式。不过这个模式只有当所有的函数都是同一种签名时可用，这样就有相当大的限制。一个很好的使用它的例子是 web 应用，所有的处理函数都是下面这样： func handler1(w http.ResponseWriter, r *http.Request) { ... } 假设所有的函数都有这样的签名： func f(a type1, b type2) 参数的数量和类型是不相关的。 我们给这个类型一个名字： fType1 = func f(a type1, b type2) 在我们的模式中使用了两个帮助函数： 1）check：这是用来检查是否有错误和 panic 发生的函数： func check(err error) { if err != nil { panic(err) } } 2）errorhandler：这是一个包装函数。接收一个 fType1 类型的函数 fn 并返回一个调用 fn 的函数。里面就包含有 defer/recover 机制，这在 13.3 节中有相应描述。 func errorHandler(fn fType1) fType1 { return func(a type1, b type2) { defer func() { if err, ok := recover().(error); ok { log.Printf(“run time panic: %v”, err) } }() fn(a, b) } } 当错误发生时会 recover 并打印在日志中；除了简单的打印，应用也可以用 template 包（参见 15.7 节）为用户生成自定义的输出。check() 函数会在所有的被调函数中调用，像这样： func f1(a type1, b type2) { ... f, _, err := // call function/method check(err) t, err := // call function/method check(err) _, err2 := // call function/method check(err2) ... } 通过这种机制，所有的错误都会被 recover，并且调用函数后的错误检查代码也被简化为调用 check(err) 即可。在这种模式下，不同的错误处理必须对应不同的函数类型；它们（错误处理）可能被隐藏在错误处理包内部。可选的更加通用的方式是用一个空接口类型的切片作为参数和返回值。 我们会在 15.5 节的 web 应用中使用这种模式。 练习 练习 13.1：recover_dividebyzero.go 用示例 13.3 中的编码模式通过整数除以 0 触发一个运行时 panic。 练习 13.2：panic_defer.go 阅读下面的完整程序。不要执行它，写出程序的输出结果。然后编译执行并验证你的预想。 // panic_defer.go package main import \"fmt\" func main() { f() fmt.Println(\"Returned normally from f.\") } func f() { defer func() { if r := recover(); r != nil { fmt.Println(\"Recovered in f\", r) } }() fmt.Println(\"Calling g.\") g(0) fmt.Println(\"Returned normally from g.\") } func g(i int) { if i > 3 { fmt.Println(\"Panicking!\") panic(fmt.Sprintf(\"%v\", i)) } defer fmt.Println(\"Defer in g\", i) fmt.Println(\"Printing in g\", i) g(i + 1) } 输出： Calling g. Printing in g 0 Printing in g 1 Printing in g 2 Printing in g 3 Panicking! Defer in g 3 Defer in g 2 Defer in g 1 Defer in g 0 Recovered in f 4 Returned normally from f. 练习 13.3：panic_defer_convint.go 写一个 ConvertInt64ToInt 函数把 int64 值转换为 int 值，如果发生错误（提示：参见 4.5.2.1 节）就 panic。然后在函数 IntFromInt64 中调用这个函数并 recover，返回一个整数和一个错误。请测试这个函数！ 链接 目录 上一节：自定义包中的错误处理和 panicking 下一节：启动外部命令和程序 "},"Go入门指南/13.6.html":{"url":"Go入门指南/13.6.html","title":"6","keywords":"","body":"13.6 启动外部命令和程序 os 包有一个 StartProcess 函数可以调用或启动外部系统命令和二进制可执行文件；它的第一个参数是要运行的进程，第二个参数用来传递选项或参数，第三个参数是含有系统环境基本信息的结构体。 这个函数返回被启动进程的 id（pid），或者启动失败返回错误。 exec 包中也有同样功能的更简单的结构体和函数；主要是 exec.Command(name string, arg ...string) 和 Run()。首先需要用系统命令或可执行文件的名字创建一个 Command 对象，然后用这个对象作为接收者调用 Run()。下面的程序（因为是执行 Linux 命令，只能在 Linux 下面运行）演示了它们的使用： 示例 13.6 exec.go： // exec.go package main import ( \"fmt\" \"os/exec\" \"os\" ) func main() { // 1) os.StartProcess // /*********************/ /* Linux: */ env := os.Environ() procAttr := &os.ProcAttr{ Env: env, Files: []*os.File{ os.Stdin, os.Stdout, os.Stderr, }, } // 1st example: list files pid, err := os.StartProcess(\"/bin/ls\", []string{\"ls\", \"-l\"}, procAttr) if err != nil { fmt.Printf(\"Error %v starting process!\", err) // os.Exit(1) } fmt.Printf(\"The process id is %v\", pid) 输出： The process id is &{2054 0}total 2056 -rwxr-xr-x 1 ivo ivo 1157555 2011-07-04 16:48 Mieken_exec -rw-r--r-- 1 ivo ivo 2124 2011-07-04 16:48 Mieken_exec.go -rw-r--r-- 1 ivo ivo 18528 2011-07-04 16:48 Mieken_exec_go_.6 -rwxr-xr-x 1 ivo ivo 913920 2011-06-03 16:13 panic.exe -rw-r--r-- 1 ivo ivo 180 2011-04-11 20:39 panic.go // 2nd example: show all processes pid, err = os.StartProcess(\"/bin/ps\", []string{\"-e\", \"-opid,ppid,comm\"}, procAttr) if err != nil { fmt.Printf(\"Error %v starting process!\", err) // os.Exit(1) } fmt.Printf(\"The process id is %v\", pid) // 2) exec.Run // /***************/ // Linux: OK, but not for ls ? // cmd := exec.Command(\"ls\", \"-l\") // no error, but doesn't show anything ? // cmd := exec.Command(\"ls\") // no error, but doesn't show anything ? cmd := exec.Command(\"gedit\") // this opens a gedit-window err = cmd.Run() if err != nil { fmt.Printf(\"Error %v executing command!\", err) os.Exit(1) } fmt.Printf(\"The command is %v\", cmd) // The command is &{/bin/ls [ls -l] [] 0xf840000210 true [0xf84000ea50 0xf84000e9f0 0xf84000e9c0] [0xf84000ea50 0xf84000e9f0 0xf84000e9c0] [] [] 0xf8400128c0} } // in Windows: uitvoering: Error fork/exec /bin/ls: The system cannot find the path specified. starting process! 链接 目录 上一节：一种用闭包处理错误的模式 下一节：Go 中的单元测试和基准测试 "},"Go入门指南/13.7.html":{"url":"Go入门指南/13.7.html","title":"7","keywords":"","body":"13.7 Go 中的单元测试和基准测试 首先所有的包都应该有一定的必要文档，然后同样重要的是对包的测试。 在第 3 章中提到了 Go 的测试工具 gotest， 我们已经在 9.8 节中使用过了。这里我们会用更多的例子进行详细说明。 名为 testing 的包被专门用来进行自动化测试，日志和错误报告。并且还包含一些基准测试函数的功能。 备注：gotest 是 Unix bash 脚本，所以在 Windows 下你需要配置 MINGW 环境（参见 2.5 节）；在 Windows 环境下把所有的 pkg/linux_amd64 替换成 pkg/windows。 对一个包做（单元）测试，需要写一些可以频繁（每次更新后）执行的小块测试单元来检查代码的正确性。于是我们必须写一些 Go 源文件来测试代码。测试程序必须属于被测试的包，并且文件名满足这种形式 *_test.go，所以测试代码和包中的业务代码是分开的。 _test 程序不会被普通的 Go 编译器编译，所以当放应用部署到生产环境时它们不会被部署；只有 gotest 会编译所有的程序：普通程序和测试程序。 测试文件中必须导入 \"testing\" 包，并写一些名字以 TestZzz 打头的全局函数，这里的 Zzz 是被测试函数的字母描述，如 TestFmtInterface，TestPayEmployees 等。 测试函数必须有这种形式的头部： func TestAbcde(t *testing.T) T 是传给测试函数的结构类型，用来管理测试状态，支持格式化测试日志，如 t.Log，t.Error，t.ErrorF 等。在函数的结尾把输出跟想要的结果对比，如果不等就打印一个错误。成功的测试则直接返回。 用下面这些函数来通知测试失败： 1）func (t *T) Fail() 标记测试函数为失败，然后继续执行（剩下的测试）。 2）func (t *T) FailNow() 标记测试函数为失败并中止执行；文件中别的测试也被略过，继续执行下一个文件。 3）func (t *T) Log(args ...interface{}) args 被用默认的格式格式化并打印到错误日志中。 4）func (t *T) Fatal(args ...interface{}) 结合 先执行 3），然后执行 2）的效果。 运行 go test 来编译测试程序，并执行程序中所有的 TestZZZ 函数。如果所有的测试都通过会打印出 PASS。 gotest 可以接收一个或多个函数程序作为参数，并指定一些选项。 结合 --chatty 或 -v 选项，每个执行的测试函数以及测试状态会被打印。 例如： go test fmt_test.go --chatty === RUN fmt.TestFlagParser --- PASS: fmt.TestFlagParser === RUN fmt.TestArrayPrinter --- PASS: fmt.TestArrayPrinter ... testing 包中有一些类型和函数可以用来做简单的基准测试；测试代码中必须包含以 BenchmarkZzz 打头的函数并接收一个 *testing.B 类型的参数，比如： func BenchmarkReverse(b *testing.B) { ... } 命令 go test –test.bench=.* 会运行所有的基准测试函数；代码中的函数会被调用 N 次（N是非常大的数，如 N = 1000000），并展示 N 的值和函数执行的平均时间，单位为 ns（纳秒，ns/op）。如果是用 testing.Benchmark 调用这些函数，直接运行程序即可。 具体可以参见 14.16 节中用 goroutines 运行基准测试的例子以及练习 13.4：string_reverse_test.go 链接 目录 上一节：启动外部命令和程序 下一节：测试的具体例子 "},"Go入门指南/13.8.html":{"url":"Go入门指南/13.8.html","title":"8","keywords":"","body":"13.8 测试的具体例子 在练习 9.4 中你写了一个叫 main_oddeven.go 的程序用来测试前 100 个整数是否是偶数。这个函数属于 even 包。 下面是一种可能的方案： 示例 13.7 even_main.go： package main import ( \"fmt\" \"even/even\" ) func main() { for i:=0; i 上面使用了 even.go 中的 even 包： 示例 13.8 even/even.go： package even func Even(i int) bool { // Exported function return i%2 == 0 } func Odd(i int) bool { // Exported function return i%2 != 0 } 在 even 包的路径下，我们创建一个名为 oddeven_test.go 的测试程序： 示例 13.9 even/oddeven_test.go： package even import \"testing\" func TestEven(t *testing.T) { if !Even(10) { t.Log(\" 10 must be even!\") t.Fail() } if Even(7) { t.Log(\" 7 is not even!\") t.Fail() } } func TestOdd(t *testing.T) { if !Odd(11) { t.Log(\" 11 must be odd!\") t.Fail() } if Odd(10) { t.Log(\" 10 is not odd!\") t.Fail() } } 由于测试需要具体的输入用例且不可能测试到所有的用例（非常像一个无穷的数），所以我们必须对要使用的测试用例思考再三。 至少应该包括： 正常的用例 反面的用例（错误的输入，如用负数或字母代替数字，没有输入等） 边界检查用例（如果参数的取值范围是 0 到 1000，检查 0 和 1000 的情况） 可以直接执行 go install 安装 even 或者创建一个 以下内容的 Makefile： include $(GOROOT)/src/Make.inc TARG=even GOFILES=\\ even.go\\ include $(GOROOT)/src/Make.pkg 然后执行 make（或 gomake）命令来构建归档文件 even.a 测试代码不能在 GOFILES 参数中引用，因为我们不希望生成的程序中有测试代码。如果包含了测试代码，go test 会给出错误提示！go test 会生成一个单独的包含测试代码的 _test 程序。 现在我们可以用命令：go test（或 make test）来测试 even 包。 因为示例 13.5 中的测试函数不会调用 t.Log 和 t.Fail，所以会得到一个 PASS 的结果。在这个简单例子中一切都正常执行。 为了看到失败时的输出，把函数 TestEven 改为： func TestEven(t *testing.T) { if Even(10) { t.Log(“Everything OK: 10 is even, just a test to see failed output!”) t.Fail() } } 现在会调用 t.Log 和 t.Fail，得到的结果如下： --- FAIL: even.TestEven (0.00 seconds) Everything OK: 10 is even, just a test to see failed output! FAIL 练习 13.4：string_reverse_test.go 为练习 7.11 string_reverse.go 写一个单元测试。 把 string_reverse 放到自己的包 strev 中，只包含一个可导出函数 reverse。 实现并测试它。 链接 目录 上一节：Go 中的单元测试和基准测试 下一节：用（测试数据）表驱动测试 "},"Go入门指南/13.9.html":{"url":"Go入门指南/13.9.html","title":"9","keywords":"","body":"13.9 用（测试数据）表驱动测试 编写测试代码时，一个较好的办法是把测试的输入数据和期望的结果写在一起组成一个数据表：表中的每条记录都是一个含有输入和期望值的完整测试用例，有时还可以结合像测试名字这样的额外信息来让测试输出更多的信息。 实际测试时简单迭代表中的每条记录，并执行必要的测试。这在练习 13.4 中有具体的应用。 可以抽象为下面的代码段： var tests = []struct{ // Test table in string out string }{ {“in1”, “exp1”}, {“in2”, “exp2”}, {“in3”, “exp3”}, ... } func TestFunction(t *testing.T) { for i, tt := range tests { s := FuncToBeTested(tt.in) if s != tt.out { t.Errorf(“%d. %q => %q, wanted: %q”, i, tt.in, s, tt.out) } } } 如果大部分函数都可以写成这种形式，那么写一个帮助函数 verify 对实际测试会很有帮助： func verify(t *testing.T, testnum int, testcase, input, output, expected string) { if expected != output { t.Errorf(\"%d. %s with input = %s: output %s != %s\", testnum, testcase, input, output, expected) } } TestFunction 则变为： func TestFunction(t *testing.T) { for i, tt := range tests { s := FuncToBeTested(tt.in) verify(t, i, “FuncToBeTested: “, tt.in, s, tt.out) } } 链接 目录 上一节：测试的具体例子 下一节：性能调试：分析并优化 Go 程序 "},"Go入门指南/14.0.html":{"url":"Go入门指南/14.0.html","title":"0","keywords":"","body":"14 协程（goroutine）与通道（channel） 作为一门 21 世纪的语言，Go 原生支持应用之间的通信（网络，客户端和服务端，分布式计算，参见第 15 章）和程序的并发。程序可以在不同的处理器和计算机上同时执行不同的代码段。Go 语言为构建并发程序的基本代码块是 协程 (goroutine) 与通道 (channel)。他们需要语言，编译器，和runtime的支持。Go 语言提供的垃圾回收器对并发编程至关重要。 不要通过共享内存来通信，而通过通信来共享内存。 通信强制协作。 链接 目录 上一节：性能调试：分析并优化 Go 程序 下一节：并发、并行和协程 "},"Go入门指南/14.1.html":{"url":"Go入门指南/14.1.html","title":"1","keywords":"","body":"14.1 并发、并行和协程 14.1.1 什么是协程 一个应用程序是运行在机器上的一个进程；进程是一个运行在自己内存地址空间里的独立执行体。一个进程由一个或多个操作系统线程组成，这些线程其实是共享同一个内存地址空间的一起工作的执行体。几乎所有'正式'的程序都是多线程的，以便让用户或计算机不必等待，或者能够同时服务多个请求（如 Web 服务器），或增加性能和吞吐量（例如，通过对不同的数据集并行执行代码）。一个并发程序可以在一个处理器或者内核上使用多个线程来执行任务，但是只有同一个程序在某个时间点同时运行在多核或者多处理器上才是真正的并行。 并行是一种通过使用多处理器以提高速度的能力。所以并发程序可以是并行的，也可以不是。 公认的，使用多线程的应用难以做到准确，最主要的问题是内存中的数据共享，它们会被多线程以无法预知的方式进行操作，导致一些无法重现或者随机的结果（称作 竞态）。 不要使用全局变量或者共享内存，它们会给你的代码在并发运算的时候带来危险。 解决之道在于同步不同的线程，对数据加锁，这样同时就只有一个线程可以变更数据。在 Go 的标准库 sync 中有一些工具用来在低级别的代码中实现加锁；我们在第 9.3 节中讨论过这个问题。不过过去的软件开发经验告诉我们这会带来更高的复杂度，更容易使代码出错以及更低的性能，所以这个经典的方法明显不再适合现代多核/多处理器编程：thread-per-connection 模型不够有效。 Go 更倾向于其他的方式，在诸多比较合适的范式中，有个被称作 Communicating Sequential Processes（顺序通信处理）（CSP, C. Hoare 发明的）还有一个叫做 message passing-model（消息传递）（已经运用在了其他语言中，比如 Erlang）。 在 Go 中，应用程序并发处理的部分被称作 goroutines（协程），它可以进行更有效的并发运算。在协程和操作系统线程之间并无一对一的关系：协程是根据一个或多个线程的可用性，映射（多路复用，执行于）在他们之上的；协程调度器在 Go 运行时很好的完成了这个工作。 协程工作在相同的地址空间中，所以共享内存的方式一定是同步的；这个可以使用 sync 包来实现（参见第 9.3 节），不过我们很不鼓励这样做：Go 使用 channels 来同步协程（可以参见第 14.2 节等章节） 当系统调用（比如等待 I/O）阻塞协程时，其他协程会继续在其他线程上工作。协程的设计隐藏了许多线程创建和管理方面的复杂工作。 协程是轻量的，比线程更轻。它们痕迹非常不明显（使用少量的内存和资源）：使用 4K 的栈内存就可以在堆中创建它们。因为创建非常廉价，必要的时候可以轻松创建并运行大量的协程（在同一个地址空间中 100,000 个连续的协程）。并且它们对栈进行了分割，从而动态的增加（或缩减）内存的使用；栈的管理是自动的，但不是由垃圾回收器管理的，而是在协程退出后自动释放。 协程可以运行在多个操作系统线程之间，也可以运行在线程之内，让你可以很小的内存占用就可以处理大量的任务。由于操作系统线程上的协程时间片，你可以使用少量的操作系统线程就能拥有任意多个提供服务的协程，而且 Go 运行时可以聪明的意识到哪些协程被阻塞了，暂时搁置它们并处理其他协程。 存在两种并发方式：确定性的（明确定义排序）和非确定性的（加锁/互斥从而未定义排序）。Go 的协程和通道理所当然的支持确定性的并发方式（例如通道具有一个 sender 和一个 receiver）。我们会在第 14.7 节中使用一个常见的算法问题（工人问题）来对比两种处理方式。 协程是通过使用关键字 go 调用（执行）一个函数或者方法来实现的（也可以是匿名或者 lambda 函数）。这样会在当前的计算过程中开始一个同时进行的函数，在相同的地址空间中并且分配了独立的栈，比如：go sum(bigArray)，在后台计算总和。 协程的栈会根据需要进行伸缩，不出现栈溢出；开发者不需要关心栈的大小。当协程结束的时候，它会静默退出：用来启动这个协程的函数不会得到任何的返回值。 任何 Go 程序都必须有的 main() 函数也可以看做是一个协程，尽管它并没有通过 go 来启动。协程可以在程序初始化的过程中运行（在 init() 函数中）。 在一个协程中，比如它需要进行非常密集的运算，你可以在运算循环中周期的使用 runtime.Gosched()：这会让出处理器，允许运行其他协程；它并不会使当前协程挂起，所以它会自动恢复执行。使用 Gosched() 可以使计算均匀分布，使通信不至于迟迟得不到响应。 14.1.2 并发和并行的差异 Go 的并发原语提供了良好的并发设计基础：表达程序结构以便表示独立地执行的动作；所以Go的的重点不在于并行的首要位置：并发程序可能是并行的，也可能不是。并行是一种通过使用多处理器以提高速度的能力。但往往是，一个设计良好的并发程序在并行方面的表现也非常出色。 在当前的运行时（2012 年一月）实现中，Go 默认没有并行指令，只有一个独立的核心或处理器被专门用于 Go 程序，不论它启动了多少个协程；所以这些协程是并发运行的，但他们不是并行运行的：同一时间只有一个协程会处在运行状态。 这个情况在以后可能会发生改变，不过届时，为了使你的程序可以使用多个核心运行，这时协程就真正的是并行运行了，你必须使用 GOMAXPROCS 变量。 这会告诉运行时有多少个协程同时执行。 并且只有 gc 编译器真正实现了协程，适当的把协程映射到操作系统线程。使用 gccgo 编译器，会为每一个协程创建操作系统线程。 14.1.3 使用 GOMAXPROCS 在 gc 编译器下（6g 或者 8g）你必须设置 GOMAXPROCS 为一个大于默认值 1 的数值来允许运行时支持使用多于 1 个的操作系统线程，所有的协程都会共享同一个线程除非将 GOMAXPROCS 设置为一个大于 1 的数。当 GOMAXPROCS 大于 1 时，会有一个线程池管理许多的线程。通过 gccgo 编译器 GOMAXPROCS 有效的与运行中的协程数量相等。假设 n 是机器上处理器或者核心的数量。如果你设置环境变量 GOMAXPROCS>=n，或者执行 runtime.GOMAXPROCS(n)，接下来协程会被分割（分散）到 n 个处理器上。更多的处理器并不意味着性能的线性提升。有这样一个经验法则，对于 n 个核心的情况设置 GOMAXPROCS 为 n-1 以获得最佳性能，也同样需要遵守这条规则：协程的数量 > 1 + GOMAXPROCS > 1。 所以如果在某一时间只有一个协程在执行，不要设置 GOMAXPROCS！ 还有一些通过实验观察到的现象：在一台 1 颗 CPU 的笔记本电脑上，增加 GOMAXPROCS 到 9 会带来性能提升。在一台 32 核的机器上，设置 GOMAXPROCS=8 会达到最好的性能，在测试环境中，更高的数值无法提升性能。如果设置一个很大的 GOMAXPROCS 只会带来轻微的性能下降；设置 GOMAXPROCS=100，使用 top 命令和 H 选项查看到只有 7 个活动的线程。 增加 GOMAXPROCS 的数值对程序进行并发计算是有好处的； 请看 goroutine_select2.go 总结：GOMAXPROCS 等同于（并发的）线程数量，在一台核心数多于1个的机器上，会尽可能有等同于核心数的线程在并行运行。 14.1.4 如何用命令行指定使用的核心数量 使用 flags 包，如下： var numCores = flag.Int(\"n\", 2, \"number of CPU cores to use\") in main() flag.Parse() runtime.GOMAXPROCS(*numCores) 协程可以通过调用runtime.Goexit()来停止，尽管这样做几乎没有必要。 示例 14.1-goroutine1.go 介绍了概念： package main import ( \"fmt\" \"time\" ) func main() { fmt.Println(\"In main()\") go longWait() go shortWait() fmt.Println(\"About to sleep in main()\") // sleep works with a Duration in nanoseconds (ns) ! time.Sleep(10 * 1e9) fmt.Println(\"At the end of main()\") } func longWait() { fmt.Println(\"Beginning longWait()\") time.Sleep(5 * 1e9) // sleep for 5 seconds fmt.Println(\"End of longWait()\") } func shortWait() { fmt.Println(\"Beginning shortWait()\") time.Sleep(2 * 1e9) // sleep for 2 seconds fmt.Println(\"End of shortWait()\") } 输出： In main() About to sleep in main() Beginning longWait() Beginning shortWait() End of shortWait() End of longWait() At the end of main() // after 10s main()，longWait() 和 shortWait() 三个函数作为独立的处理单元按顺序启动，然后开始并行运行。每一个函数都在运行的开始和结束阶段输出了消息。为了模拟他们运算的时间消耗，我们使用了 time 包中的 Sleep 函数。Sleep() 可以按照指定的时间来暂停函数或协程的执行，这里使用了纳秒（ns，符号 1e9 表示 1 乘 10 的 9 次方，e=指数）。 他们按照我们期望的顺序打印出了消息，几乎都一样，可是我们明白这是模拟出来的，以并行的方式。我们让 main() 函数暂停 10 秒从而确定它会在另外两个协程之后结束。如果不这样（如果我们让 main() 函数停止 4 秒），main() 会提前结束，longWait() 则无法完成。如果我们不在 main() 中等待，协程会随着程序的结束而消亡。 当 main() 函数返回的时候，程序退出：它不会等待任何其他非 main 协程的结束。这就是为什么在服务器程序中，每一个请求都会启动一个协程来处理，server() 函数必须保持运行状态。通常使用一个无限循环来达到这样的目的。 另外，协程是独立的处理单元，一旦陆续启动一些协程，你无法确定他们是什么时候真正开始执行的。你的代码逻辑必须独立于协程调用的顺序。 为了对比使用一个线程，连续调用的情况，移除 go 关键字，重新运行程序。 现在输出： In main() Beginning longWait() End of longWait() Beginning shortWait() End of shortWait() About to sleep in main() At the end of main() // after 17 s 协程更有用的一个例子应该是在一个非常长的数组中查找一个元素。 将数组分割为若干个不重复的切片，然后给每一个切片启动一个协程进行查找计算。这样许多并行的协程可以用来进行查找任务，整体的查找时间会缩短（除以协程的数量）。 14.1.5 Go 协程（goroutines）和协程（coroutines） （译者注：标题中的“Go协程（goroutines）” 即是 14 章讲的协程指的是 Go 语言中的协程。而“协程（coroutines）”指的是其他语言中的协程概念，仅在本节出现。） 在其他语言中，比如 C#，Lua 或者 Python 都有协程的概念。这个名字表明它和 Go协程有些相似，不过有两点不同： Go 协程意味着并行（或者可以以并行的方式部署），协程一般来说不是这样的 Go 协程通过通道来通信；协程通过让出和恢复操作来通信 Go 协程比协程更强大，也很容易从协程的逻辑复用到 Go 协程。 链接 目录 上一节：协程（goroutine）与通道（channel） 下一节：使用通道进行协程间通信 "},"Go入门指南/14.2.html":{"url":"Go入门指南/14.2.html","title":"2","keywords":"","body":"14.2 协程间的信道 14.2.1 概念 在第一个例子中，协程是独立执行的，他们之间没有通信。他们必须通信才会变得更有用：彼此之间发送和接收信息并且协调/同步他们的工作。协程可以使用共享变量来通信，但是很不提倡这样做，因为这种方式给所有的共享内存的多线程都带来了困难。 而Go有一个特殊的类型，通道（channel），像是通道（管道），可以通过它们发送类型化的数据在协程之间通信，可以避开所有内存共享导致的坑；通道的通信方式保证了同步性。数据通过通道：同一时间只有一个协程可以访问数据：所以不会出现数据竞争，设计如此。数据的归属（可以读写数据的能力）被传递。 工厂的传送带是个很有用的例子。一个机器（生产者协程）在传送带上放置物品，另外一个机器（消费者协程）拿到物品并打包。 通道服务于通信的两个目的：值的交换，同步的，保证了两个计算（协程）任何时候都是可知状态。 通常使用这样的格式来声明通道：var identifier chan datatype 未初始化的通道的值是nil。 所以通道只能传输一种类型的数据，比如 chan int 或者 chan string，所有的类型都可以用于通道，空接口 interface{} 也可以。甚至可以（有时非常有用）创建通道的通道。 通道实际上是类型化消息的队列：使数据得以传输。它是先进先出（FIFO）的结构所以可以保证发送给他们的元素的顺序（有些人知道，通道可以比作 Unix shells 中的双向管道（two-way pipe））。通道也是引用类型，所以我们使用 make() 函数来给它分配内存。这里先声明了一个字符串通道 ch1，然后创建了它（实例化）： var ch1 chan string ch1 = make(chan string) 当然可以更短： ch1 := make(chan string)。 这里我们构建一个int通道的通道： chanOfChans := make(chan int)。 或者函数通道：funcChan := chan func()（相关示例请看第 14.17 节）。 所以通道是对象的第一类型：可以存储在变量中，作为函数的参数传递，从函数返回以及通过通道发送它们自身。另外它们是类型化的，允许类型检查，比如尝试使用整数通道发送一个指针。 14.2.2 通信操作符 这个操作符直观的标示了数据的传输：信息按照箭头的方向流动。 流向通道（发送） ch 表示：用通道 ch 发送变量 int1（双目运算符，中缀 = 发送） 从通道流出（接收），三种方式： int2 = 表示：变量 int2 从通道 ch（一元运算的前缀操作符，前缀 = 接收）接收数据（获取新值）；假设 int2 已经声明过了，如果没有的话可以写成：int2 := 。 可以单独调用获取通道的（下一个）值，当前值会被丢弃，但是可以用来验证，所以以下代码是合法的： if 操作符 ch 开头或者包含 chan。通道的发送和接收操作都是自动的：它们通常一气呵成。下面的示例展示了通信操作。 示例 14.2-goroutine2.go package main import ( \"fmt\" \"time\" ) func main() { ch := make(chan string) go sendData(ch) go getData(ch) time.Sleep(1e9) } func sendData(ch chan string) { ch 输出： Washington Tripoli London Beijing Tokio main() 函数中启动了两个协程：sendData() 通过通道 ch 发送了 5 个字符串，getData() 按顺序接收它们并打印出来。 如果 2 个协程需要通信，你必须给他们同一个通道作为参数才行。 尝试一下如果注释掉 time.Sleep(1e9) 会如何。 我们发现协程之间的同步非常重要： main() 等待了 1 秒让两个协程完成，如果不这样，sendData() 就没有机会输出。 getData() 使用了无限循环：它随着 sendData() 的发送完成和 ch 变空也结束了。 如果我们移除一个或所有 go 关键字，程序无法运行，Go 运行时会抛出 panic： ---- Error run E:/Go/Goboek/code examples/chapter 14/goroutine2.exe with code Crashed ---- Program exited with code -2147483645: panic: all goroutines are asleep-deadlock! 为什么会这样？运行时会检查所有的协程（也许只有一个是这种情况）是否在等待（可以读取或者写入某个通道），意味着程序无法处理。这是死锁（deadlock）形式，运行时可以检测到这种情况。 注意：不要使用打印状态来表明通道的发送和接收顺序：由于打印状态和通道实际发生读写的时间延迟会导致和真实发生的顺序不同。 练习 14.4：解释一下为什么如果在函数 getData() 的一开始插入 time.Sleep(2e9)，不会出现错误但也没有输出呢。 14.2.3 通道阻塞 默认情况下，通信是同步且无缓冲的：在有接受者接收数据之前，发送不会结束。可以想象一个无缓冲的通道在没有空间来保存数据的时候：必须要一个接收者准备好接收通道的数据然后发送者可以直接把数据发送给接收者。所以通道的发送/接收操作在对方准备好之前是阻塞的： 1）对于同一个通道，发送操作（协程或者函数中的），在接收者准备好之前是阻塞的：如果ch中的数据无人接收，就无法再给通道传入其他数据：新的输入无法在通道非空的情况下传入。所以发送操作会等待 ch 再次变为可用状态：就是通道值被接收时（可以传入变量）。 2）对于同一个通道，接收操作是阻塞的（协程或函数中的），直到发送者可用：如果通道中没有数据，接收者就阻塞了。 尽管这看上去是非常严格的约束，实际在大部分情况下工作的很不错。 程序 channel_block.go 验证了以上理论，一个协程在无限循环中给通道发送整数数据。不过因为没有接收者，只输出了一个数字 0。 示例 14.3-channel_block.go package main import \"fmt\" func main() { ch1 := make(chan int) go pump(ch1) // pump hangs fmt.Println( 输出： 0 pump() 函数为通道提供数值，也被叫做生产者。 为通道解除阻塞定义了 suck 函数来在无限循环中读取通道，参见示例 14.4-channel_block2.go： func suck(ch chan int) { for { fmt.Println( 在 main() 中使用协程开始它： go pump(ch1) go suck(ch1) time.Sleep(1e9) 给程序 1 秒的时间来运行：输出了上万个整数。 练习 14.1：channel_block3.go：写一个通道证明它的阻塞性，开启一个协程接收通道的数据，持续 15 秒，然后给通道放入一个值。在不同的阶段打印消息并观察输出。 14.2.4 通过一个（或多个）通道交换数据进行协程同步。 通信是一种同步形式：通过通道，两个协程在通信（协程会和）中某刻同步交换数据。无缓冲通道成为了多个协程同步的完美工具。 甚至可以在通道两端互相阻塞对方，形成了叫做死锁的状态。Go 运行时会检查并 panic，停止程序。死锁几乎完全是由糟糕的设计导致的。 无缓冲通道会被阻塞。设计无阻塞的程序可以避免这种情况，或者使用带缓冲的通道。 练习 14.2： blocking.go 解释为什么下边这个程序会导致 panic：所有的协程都休眠了 - 死锁！ package main import ( \"fmt\" ) func f1(in chan int) { fmt.Println( 14.2.5 同步通道-使用带缓冲的通道 一个无缓冲通道只能包含 1 个元素，有时显得很局限。我们给通道提供了一个缓存，可以在扩展的 make 命令中设置它的容量，如下： buf := 100 ch1 := make(chan string, buf) buf 是通道可以同时容纳的元素（这里是 string）个数 在缓冲满载（缓冲被全部使用）之前，给一个带缓冲的通道发送数据是不会阻塞的，而从通道读取数据也不会阻塞，直到缓冲空了。 缓冲容量和类型无关，所以可以（尽管可能导致危险）给一些通道设置不同的容量，只要他们拥有同样的元素类型。内置的 cap 函数可以返回缓冲区的容量。 如果容量大于 0，通道就是异步的了：缓冲满载（发送）或变空（接收）之前通信不会阻塞，元素会按照发送的顺序被接收。如果容量是0或者未设置，通信仅在收发双方准备好的情况下才可以成功。 同步：ch :=make(chan type, value) value == 0 -> synchronous, unbuffered (阻塞） value > 0 -> asynchronous, buffered（非阻塞）取决于value元素 若使用通道的缓冲，你的程序会在“请求”激增的时候表现更好：更具弹性，专业术语叫：更具有伸缩性（scalable）。要在首要位置使用无缓冲通道来设计算法，只在不确定的情况下使用缓冲。 练习 14.3：channel_buffer.go：给 channel_block3.go 的通道增加缓冲并观察输出有何不同。 14.2.6 协程中用通道输出结果 为了知道计算何时完成，可以通过信道回报。在例子 go sum(bigArray) 中，要这样写： ch := make(chan int) go sum(bigArray, ch) // bigArray puts the calculated sum on ch // .. do something else for a while sum := 也可以使用通道来达到同步的目的，这个很有效的用法在传统计算机中称为信号量（semaphore）。或者换个方式：通过通道发送信号告知处理已经完成（在协程中）。 在其他协程运行时让 main 程序无限阻塞的通常做法是在 main 函数的最后放置一个{}。 也可以使用通道让 main 程序等待协程完成，就是所谓的信号量模式，我们会在接下来的部分讨论。 14.2.7 信号量模式 下边的片段阐明：协程通过在通道 ch 中放置一个值来处理结束的信号。main 协程等待 直到从中获取到值。 我们期望从这个通道中获取返回的结果，像这样： func compute(ch chan int){ ch 这个信号也可以是其他的，不返回结果，比如下面这个协程中的匿名函数（lambda）协程： ch := make(chan int) go func(){ // doSomething ch 或者等待两个协程完成，每一个都会对切片s的一部分进行排序，片段如下： done := make(chan bool) // doSort is a lambda function, so a closure which knows the channel done: doSort := func(s []int){ sort(s) done 下边的代码，用完整的信号量模式对长度为N的 float64 切片进行了 N 个doSomething() 计算并同时完成，通道 sem 分配了相同的长度（切包含空接口类型的元素），待所有的计算都完成后，发送信号（通过放入值）。在循环中从通道 sem 不停的接收数据来等待所有的协程完成。 type Empty interface {} var empty Empty ... data := make([]float64, N) res := make([]float64, N) sem := make(chan Empty, N) ... for i, xi := range data { go func (i int, xi float64) { res[i] = doSomething(i, xi) sem 注意闭合：i、xi 都是作为参数传入闭合函数的，从外层循环中隐藏了变量 i 和 xi。让每个协程有一份 i 和 xi 的拷贝；另外，for 循环的下一次迭代会更新所有协程中 i 和 xi 的值。切片 res 没有传入闭合函数，因为协程不需要单独拷贝一份。切片 res 也在闭合函数中但并不是参数。 14.2.8 实现并行的 for 循环 在上一部分章节 14.2.7 的代码片段中：for 循环的每一个迭代是并行完成的： for i, v := range data { go func (i int, v float64) { doSomething(i, v) ... } (i, v) } 在 for 循环中并行计算迭代可能带来很好的性能提升。不过所有的迭代都必须是独立完成的。有些语言比如 Fortress 或者其他并行框架以不同的结构实现了这种方式，在 Go 中用协程实现起来非常容易： 14.2.9 用带缓冲通道实现一个信号量 信号量是实现互斥锁（排外锁）常见的同步机制，限制对资源的访问，解决读写问题，比如没有实现信号量的 sync 的 Go 包，使用带缓冲的通道可以轻松实现： 带缓冲通道的容量和要同步的资源容量相同 通道的长度（当前存放的元素个数）与当前资源被使用的数量相同 容量减去通道的长度就是未处理的资源个数（标准信号量的整数值） 不用管通道中存放的是什么，只关注长度；因此我们创建了一个长度可变但容量为0（字节）的通道： type Empty interface {} type semaphore chan Empty 将可用资源的数量N来初始化信号量 semaphore：sem = make(semaphore, N) 然后直接对信号量进行操作： // acquire n resources func (s semaphore) P(n int) { e := new(Empty) for i := 0; i 可以用来实现一个互斥的例子： /* mutexes */ func (s semaphore) Lock() { s.P(1) } func (s semaphore) Unlock(){ s.V(1) } /* signal-wait */ func (s semaphore) Wait(n int) { s.P(n) } func (s semaphore) Signal() { s.V(1) } 练习 14.5：gosum.go：用这种习惯用法写一个程序，开启一个协程来计算2个整数的合并等待计算结果并打印出来。 练习 14.6：producer_consumer.go：用这种习惯用法写一个程序，有两个协程，第一个提供数字 0，10，20，...90 并将他们放入通道，第二个协程从通道中读取并打印。main() 等待两个协程完成后再结束。 习惯用法：通道工厂模式 编程中常见的另外一种模式如下：不将通道作为参数传递给协程，而用函数来生成一个通道并返回（工厂角色）；函数内有个匿名函数被协程调用。 在 channel_block2.go 加入这种模式便有了示例 14.5-channel_idiom.go： package main import ( \"fmt\" \"time\" ) func main() { stream := pump() go suck(stream) time.Sleep(1e9) } func pump() chan int { ch := make(chan int) go func() { for i := 0; ; i++ { ch 14.2.10 给通道使用 for 循环 for 循环的 range 语句可以用在通道 ch 上，便可以从通道中获取值，像这样： for v := range ch { fmt.Printf(\"The value is %v\\n\", v) } 它从指定通道中读取数据直到通道关闭，才继续执行下边的代码。很明显，另外一个协程必须写入 ch（不然代码就阻塞在 for 循环了），而且必须在写入完成后才关闭。suck 函数可以这样写，且在协程中调用这个动作，程序变成了这样： 示例 14.6-channel_idiom2.go： package main import ( \"fmt\" \"time\" ) func main() { suck(pump()) time.Sleep(1e9) } func pump() chan int { ch := make(chan int) go func() { for i := 0; ; i++ { ch 习惯用法：通道迭代模式 这个模式用到了后边14.6章示例 producer_consumer.go 的生产者-消费者模式，通常，需要从包含了地址索引字段 items 的容器给通道填入元素。为容器的类型定义一个方法 Iter()，返回一个只读的通道（参见第 14.2.8 节）items，如下： func (c *container) Iter () 在协程里，一个 for 循环迭代容器 c 中的元素（对于树或图的算法，这种简单的 for 循环可以替换为深度优先搜索）。 调用这个方法的代码可以这样迭代容器： for x := range container.Iter() { ... } 可以运行在自己的协程中，所以上边的迭代用到了一个通道和两个协程（可能运行在两个线程上）。就有了一个特殊的生产者-消费者模式。如果程序在协程给通道写完值之前结束，协程不会被回收；设计如此。这种行为看起来是错误的，但是通道是一种线程安全的通信。在这种情况下，协程尝试写入一个通道，而这个通道永远不会被读取，这可能是个 bug 而并非期望它被静默的回收。 习惯用法：生产者消费者模式 假设你有 Produce() 函数来产生 Consume 函数需要的值。它们都可以运行在独立的协程中，生产者在通道中放入给消费者读取的值。整个处理过程可以替换为无限循环： for { Consume(Produce()) } 14.2.11 通道的方向 通道类型可以用注解来表示它只发送或者只接收： var send_only chan 只接收的通道（ var c = make(chan int) // bidirectional go source(c) go sink(c) func source(ch chan 习惯用法：管道和选择器模式 更具体的例子还有协程处理它从通道接收的数据并发送给输出通道： sendChan := make(chan int) reciveChan := make(chan string) go processChannel(sendChan, receiveChan) func processChannel(in 通过使用方向注解来限制协程对通道的操作。 这里有一个来自 Go 指导的很赞的例子，打印了输出的素数，使用选择器（‘筛’）作为它的算法。每个 prime 都有一个选择器，如下图： 版本1：示例 14.7-sieve1.go // Copyright 2009 The Go Authors. All rights reserved. // Use of this source code is governed by a BSD-style // license that can be found in the LICENSE file.package main package main import \"fmt\" // Send the sequence 2, 3, 4, ... to channel 'ch'. func generate(ch chan int) { for i := 2; ; i++ { ch 协程 filter(in, out chan int, prime int) 拷贝整数到输出通道，丢弃掉可以被 prime 整除的数字。然后每个 prime 又开启了一个新的协程，生成器和选择器并发请求。 输出： 2 3 5 7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71 73 79 83 89 97 101 103 107 109 113 127 131 137 139 149 151 157 163 167 173 179 181 191 193 197 199 211 223 227 229 233 239 241 251 257 263 269 271 277 281 283 293 307 311 313 317 331 337 347 349 353 359 367 373 379 383 389 397 401 409 419 421 431 433 439 443 449 457 461 463 467 479 487 491 499 503 509 521 523 541 547 557 563 569 571 577 587 593 599 601 607 613 617 619 631 641 643 647 653 659 661 673 677 683 691 701 709 719 727 733 739 743 751 757 761 769 773 787 797 809 811 821 823 827 829 839 853 857 859 863 877 881 883 887 907 911 919 929 937 941 947 953 967 971 977 983 991 997 1009 1013... 第二个版本引入了上边的习惯用法：函数 sieve、generate 和 filter 都是工厂；它们创建通道并返回，而且使用了协程的 lambda 函数。main 函数现在短小清晰：它调用 sieve() 返回了包含素数的通道，然后通过 fmt.Println( 打印出来。 版本2：示例 14.8-sieve2.go // Copyright 2009 The Go Authors. All rights reserved. // Use of this source code is governed by a BSD-style // license that can be found in the LICENSE file. package main import ( \"fmt\" ) // Send the sequence 2, 3, 4, ... to returned channel func generate() chan int { ch := make(chan int) go func() { for i := 2; ; i++ { ch 链接 目录 上一节：并发、并行和协程 下一节：协程同步：关闭通道-测试阻塞的通道 "},"Go入门指南/14.3.html":{"url":"Go入门指南/14.3.html","title":"3","keywords":"","body":"14.3 协程的同步：关闭通道-测试阻塞的通道 通道可以被显式的关闭；尽管它们和文件不同：不必每次都关闭。只有在当需要告诉接收者不会再提供新的值的时候，才需要关闭通道。只有发送者需要关闭通道，接收者永远不会需要。 继续看示例 goroutine2.go（示例 14.2）：我们如何在通道的 sendData() 完成的时候发送一个信号，getData() 又如何检测到通道是否关闭或阻塞？ 第一个可以通过函数 close(ch) 来完成：这个将通道标记为无法通过发送操作 接受更多的值；给已经关闭的通道发送或者再次关闭都会导致运行时的 panic。在创建一个通道后使用 defer 语句是个不错的办法（类似这种情况）： ch := make(chan float64) defer close(ch) 第二个问题可以使用逗号，ok 操作符：用来检测通道是否被关闭。 如何来检测可以收到没有被阻塞（或者通道没有被关闭）？ v, ok := 通常和 if 语句一起使用： if v, ok := 或者在 for 循环中接收的时候，当关闭或者阻塞的时候使用 break： v, ok := 在示例程序 14.2 中使用这些可以改进为版本 goroutine3.go，输出相同。 实现非阻塞通道的读取，需要使用 select（参见第 14.4 节）。 示例 14.9-goroutine3.go： package main import \"fmt\" func main() { ch := make(chan string) go sendData(ch) getData(ch) } func sendData(ch chan string) { ch 改变了以下代码： 现在只有 sendData() 是协程，getData() 和 main() 在同一个线程中： go sendData(ch) getData(ch) 在 sendData() 函数的最后，关闭了通道： func sendData(ch chan string) { ch 在 for 循环的 getData() 中，在每次接收通道的数据之前都使用 if !open 来检测： for { input, open := 使用 for-range 语句来读取通道是更好的办法，因为这会自动检测通道是否关闭： for input := range ch { process(input) } 阻塞和生产者-消费者模式： 在第 14.2.10 节的通道迭代器中，两个协程经常是一个阻塞另外一个。如果程序工作在多核心的机器上，大部分时间只用到了一个处理器。可以通过使用带缓冲（缓冲空间大于 0）的通道来改善。比如，缓冲大小为 100，迭代器在阻塞之前，至少可以从容器获得 100 个元素。如果消费者协程在独立的内核运行，就有可能让协程不会出现阻塞。 由于容器中元素的数量通常是已知的，需要让通道有足够的容量放置所有的元素。这样，迭代器就不会阻塞（尽管消费者协程仍然可能阻塞）。然后，这样有效的加倍了迭代容器所需要的内存使用量，所以通道的容量需要限制一下最大值。记录运行时间和性能测试可以帮助你找到最小的缓存容量带来最好的性能。 链接 目录 上一节：协程间的信道 下一节：使用 select 切换协程 "},"Go入门指南/14.4.html":{"url":"Go入门指南/14.4.html","title":"4","keywords":"","body":"14.4 使用 select 切换协程 从不同的并发执行的协程中获取值可以通过关键字select来完成，它和switch控制语句非常相似（章节5.3）也被称作通信开关；它的行为像是“你准备好了吗”的轮询机制；select监听进入通道的数据，也可以是用通道发送值的时候。 select { case u:= default 语句是可选的；fallthrough 行为，和普通的 switch 相似，是不允许的。在任何一个 case 中执行 break 或者 return，select 就结束了。 select 做的就是：选择处理列出的多个通信情况中的一个。 如果都阻塞了，会等待直到其中一个可以处理 如果多个可以处理，随机选择一个 如果没有通道操作可以处理并且写了 default 语句，它就会执行：default 永远是可运行的（这就是准备好了，可以执行）。 在 select 中使用发送操作并且有 default可以确保发送不被阻塞！如果没有 case，select 就会一直阻塞。 select 语句实现了一种监听模式，通常用在（无限）循环中；在某种情况下，通过 break 语句使循环退出。 在程序 goroutine_select.go 中有 2 个通道 ch1 和 ch2，三个协程 pump1()、pump2() 和 suck()。这是一个典型的生产者消费者模式。在无限循环中，ch1 和 ch2 通过 pump1() 和 pump2() 填充整数；suck() 也是在无限循环中轮询输入的，通过 select 语句获取 ch1 和 ch2 的整数并输出。选择哪一个 case 取决于哪一个通道收到了信息。程序在 main 执行 1 秒后结束。 示例 14.10-goroutine_select.go： package main import ( \"fmt\" \"time\" ) func main() { ch1 := make(chan int) ch2 := make(chan int) go pump1(ch1) go pump2(ch2) go suck(ch1, ch2) time.Sleep(1e9) } func pump1(ch chan int) { for i := 0; ; i++ { ch 输出： Received on channel 2: 5 Received on channel 2: 6 Received on channel 1: 0 Received on channel 2: 7 Received on channel 2: 8 Received on channel 2: 9 Received on channel 2: 10 Received on channel 1: 2 Received on channel 2: 11 ... Received on channel 2: 47404 Received on channel 1: 94346 Received on channel 1: 94348 一秒内的输出非常惊人，如果我们给它计数（goroutine_select2.go），得到了 90000 个左右的数字。 练习： 练习 14.7： a）在练习 5.4 的 for_loop.go 中，有一个常见的 for 循环打印数字。在函数 tel 中实现一个 for 循环，用协程开始这个函数并在其中给通道发送数字。main() 线程从通道中获取并打印。不要使用 time.Sleep() 来同步：goroutine_panic.go b）也许你的方案有效，可能会引发运行时的 panic：throw:all goroutines are asleep-deadlock! 为什么会这样？你如何解决这个问题？goroutine_close.go c）解决 a）的另外一种方式：使用一个额外的通道传递给协程，然后在结束的时候随便放点什么进去。main() 线程检查是否有数据发送给了这个通道，如果有就停止：goroutine_select.go 练习 14.8： 从示例 6.10 的斐波那契程序开始，制定解决方案，使斐波那契周期计算独立到协程中，并可以把结果发送给通道。 结束的时候关闭通道。main() 函数读取通道并打印结果：goFibonacci.go 使用练习 6.9 中的算法写一个更短的 gofibonacci2.go 使用 select 语句来写，并让通道退出（gofibonacci_select.go） 注意：当给结果计时并和 6.10 对比时，我们发现使用通道通信的性能开销有轻微削减；这个例子中的算法使用协程并非性能最好的选择；但是 gofibonacci3 方案使用了 2 个协程带来了 3 倍的提速。 练习 14.9： 做一个随机位生成器，程序可以提供无限的随机 0 或者 1 的序列：random_bitgen.go 练习 14.10：polar_to_cartesian.go （这是一种综合练习，使用到第 4、9、11 章和本章的内容。）写一个可交互的控制台程序，要求用户输入二位平面极坐标上的点（半径和角度（度））。计算对应的笛卡尔坐标系的点的 x 和 y 并输出。使用极坐标和笛卡尔坐标的结构体。 使用通道和协程： channel1 用来接收极坐标 channel2 用来接收笛卡尔坐标 转换过程需要在协程中进行，从 channel1 中读取然后发送到 channel2。实际上做这种计算不提倡使用协程和通道，但是如果运算量很大很耗时，这种方案设计就非常合适了。 练习 14.11： concurrent_pi.go / concurrent_pi2.go 使用以下序列在协程中计算 pi：开启一个协程来计算公式中的每一项并将结果放入通道，main() 函数收集并累加结果，打印出 pi 的近似值。 计算执行时间（参见第 6.11 节） 再次声明这只是为了一边练习协程的概念一边找点乐子。 如果你需要的话可使用 math.pi 中的 Pi；而且不使用协程会运算的更快。一个急速版本：使用 GOMAXPROCS，开启和 GOMAXPROCS 同样多个协程。 习惯用法：后台服务模式 服务通常是是用后台协程中的无限循环实现的，在循环中使用 select 获取并处理通道中的数据： // Backend goroutine. func backend() { for { select { case cmd := 在程序的其他地方给通道 ch1，ch2 发送数据，比如：通道 stop 用来清理结束服务程序。 另一种方式（但是不太灵活）就是（客户端）在 chRequest 上提交请求，后台协程循环这个通道，使用 switch 根据请求的行为来分别处理： func backend() { for req := range chRequest { switch req.Subjext() { case A1: // Handle case ... case A2: // Handle case ... default: // Handle illegal request .. // ... } } } 链接 目录 上一节：通道的同步：关闭通道-测试阻塞的通道 下一节：通道，超时和计时器（Ticker） "},"Go入门指南/14.5.html":{"url":"Go入门指南/14.5.html","title":"5","keywords":"","body":"14.5 通道、超时和计时器（Ticker） time 包中有一些有趣的功能可以和通道组合使用。 其中就包含了 time.Ticker 结构体，这个对象以指定的时间间隔重复的向通道 C 发送时间值： type Ticker struct { C 时间间隔的单位是 ns（纳秒，int64），在工厂函数 time.NewTicker 中以 Duration 类型的参数传入：func Newticker(dur) *Ticker。 在协程周期性的执行一些事情（打印状态日志，输出，计算等等）的时候非常有用。 调用 Stop() 使计时器停止，在 defer 语句中使用。这些都很好的适应 select 语句: ticker := time.NewTicker(updateInterval) defer ticker.Stop() ... select { case u:= time.Tick() 函数声明为 Tick(d Duration) ，当你想返回一个通道而不必关闭它的时候这个函数非常有用：它以 d 为周期给返回的通道发送时间，d是纳秒数。如果需要像下边的代码一样，限制处理频率（函数 client.Call() 是一个 RPC 调用，这里暂不赘述（参见第 15.9 节）： import \"time\" rate_per_sec := 10 var dur Duration = 1e9 / rate_per_sec chRate := time.Tick(dur) // a tick every 1/10th of a second for req := range requests { 这样只会按照指定频率处理请求：chRate 阻塞了更高的频率。每秒处理的频率可以根据机器负载（和/或）资源的情况而增加或减少。 问题 14.1：扩展上边的代码，思考如何承载周期请求数的暴增（提示：使用带缓冲通道和计时器对象）。 定时器（Timer）结构体看上去和计时器（Ticker）结构体的确很像（构造为 NewTimer(d Duration)），但是它只发送一次时间，在 Dration d 之后。 还有 time.After(d) 函数，声明如下： func After(d Duration) 在 Duration d 之后，当前时间被发到返回的通道；所以它和 NewTimer(d).C 是等价的；它类似 Tick()，但是 After() 只发送一次时间。下边有个很具体的示例，很好的阐明了 select 中 default 的作用： 示例 14.11：timer_goroutine.go： package main import ( \"fmt\" \"time\" ) func main() { tick := time.Tick(1e8) boom := time.After(5e8) for { select { case 输出： . . tick. . . tick. . . tick. . . tick. . . tick. BOOM! 习惯用法：简单超时模式 要从通道 ch 中接收数据，但是最多等待1秒。先创建一个信号通道，然后启动一个 lambda 协程，协程在给通道发送数据之前是休眠的： timeout := make(chan bool, 1) go func() { time.Sleep(1e9) // one second timeout 然后使用 select 语句接收 ch 或者 timeout 的数据：如果 ch 在 1 秒内没有收到数据，就选择到了 time 分支并放弃了 ch 的读取。 select { case 第二种形式：取消耗时很长的同步调用 也可以使用 time.After() 函数替换 timeout-channel。可以在 select 中通过 time.After() 发送的超时信号来停止协程的执行。以下代码，在 timeoutNs 纳秒后执行 select 的 timeout 分支后，执行client.Call 的协程也随之结束，不会给通道 ch 返回值： ch := make(chan error, 1) go func() { ch 注意缓冲大小设置为 1 是必要的，可以避免协程死锁以及确保超时的通道可以被垃圾回收。此外，需要注意在有多个 case 符合条件时， select 对 case 的选择是伪随机的，如果上面的代码稍作修改如下，则 select 语句可能不会在定时器超时信号到来时立刻选中 time.After(timeoutNs) 对应的 case，因此协程可能不会严格按照定时器设置的时间结束。 ch := make(chan int, 1) go func() { for { ch 第三种形式：假设程序从多个复制的数据库同时读取。只需要一个答案，需要接收首先到达的答案，Query 函数获取数据库的连接切片并请求。并行请求每一个数据库并返回收到的第一个响应： func Query(conns []conn, query string) Result { ch := make(chan Result, 1) for _, conn := range conns { go func(c Conn) { select { case ch 再次声明，结果通道 ch 必须是带缓冲的：以保证第一个发送进来的数据有地方可以存放，确保放入的首个数据总会成功，所以第一个到达的值会被获取而与执行的顺序无关。正在执行的协程可以总是可以使用 runtime.Goexit() 来停止。 在应用中缓存数据： 应用程序中用到了来自数据库（或者常见的数据存储）的数据时，经常会把数据缓存到内存中，因为从数据库中获取数据的操作代价很高；如果数据库中的值不发生变化就没有问题。但是如果值有变化，我们需要一个机制来周期性的从数据库重新读取这些值：缓存的值就不可用（过期）了，而且我们也不希望用户看到陈旧的数据。 链接 目录 上一节：使用select切换协程 下一节：协程和恢复（recover） "},"Go入门指南/14.6.html":{"url":"Go入门指南/14.6.html","title":"6","keywords":"","body":"14.6 协程和恢复（recover） 一个用到 recover 的程序（参见第 13.3 节）停掉了服务器内部一个失败的协程而不影响其他协程的工作。 func server(workChan 上边的代码，如果 do(work) 发生 panic，错误会被记录且协程会退出并释放，而其他协程不受影响。 因为 recover 总是返回 nil，除非直接在 defer 修饰的函数中调用，defer 修饰的代码可以调用那些自身可以使用 panic 和 recover 避免失败的库例程（库函数）。举例，safelyDo() 中 defer 修饰的函数可能在调用 recover 之前就调用了一个 logging 函数，panicking 状态不会影响 logging 代码的运行。因为加入了恢复模式，函数 do（以及它调用的任何东西）可以通过调用 panic 来摆脱不好的情况。但是恢复是在 panicking 的协程内部的：不能被另外一个协程恢复。 链接 目录 上一节：通道，超时和计时器 下一节：对比新旧模型：任务和工作 "},"Go入门指南/14.7.html":{"url":"Go入门指南/14.7.html","title":"7","keywords":"","body":"14.7 新旧模型对比：任务和worker 假设我们需要处理很多任务；一个worker处理一项任务。任务可以被定义为一个结构体（具体的细节在这里并不重要）： type Task struct { // some state } 旧模式：使用共享内存进行同步 由各个任务组成的任务池共享内存；为了同步各个worker以及避免资源竞争，我们需要对任务池进行加锁保护： type Pool struct { Mu sync.Mutex Tasks []Task } sync.Mutex(参见9.3是互斥锁：它用来在代码中保护临界区资源：同一时间只有一个go协程（goroutine）可以进入该临界区。如果出现了同一时间多个go协程都进入了该临界区，则会产生竞争：Pool结构就不能保证被正确更新。在传统的模式中（经典的面向对象的语言中应用得比较多，比如C++,JAVA,C#)，worker代码可能这样写： func Worker(pool *Pool) { for { pool.Mu.lock() // begin critical section: task := pool.Task[0] // take the first task pool.Tasks = pool.Task[1:] // update the pool of tasks // end critical section pool.Mu.Unlock() process(task) } } 这些worker有许多都可以并发执行；他们可以在go协程中启动。一个worker先将pool锁定，从pool获取第一项任务，再解锁和处理任务。加锁保证了同一时间只有一个go协程可以进入到pool中：一项任务有且只能被赋予一个worer。如果不加锁，则工作协程可能会在task:=pool.Task[0]发生切换，导致pool.Tasks=pool.Task[1:]结果异常：一些worker获取不到任务，而一些任务可能被多个worker得到。加锁实现同步的方式在工作协程比较少时可以工作的很好，但是当工作协程数量很大，任务量也很多时，处理效率将会因为频繁的加锁/解锁开销而降低。当工作协程数增加到一个阈值时，程序效率会急剧下降，这就成为了瓶颈。 新模式：使用通道 使用通道进行同步：使用一个通道接受需要处理的任务，一个通道接受处理完成的任务（及其结果）。worker在协程中启动，其数量N应该根据任务数量进行调整。 主线程扮演着Master节点角色，可能写成如下形式： func main() { pending, done := make(chan *Task), make(chan *Task) go sendWork(pending) // put tasks with work on the channel for i := 0; i worker的逻辑比较简单：从pending通道拿任务，处理后将其放到done通道中： func Worker(in, out chan *Task) { for { t := 这里并不使用锁：从通道得到新任务的过程没有任何竞争。随着任务数量增加，worker数量也应该相应增加，同时性能并不会像第一种方式那样下降明显。在pending通道中存在一份任务的拷贝，第一个worker从pending通道中获得第一个任务并进行处理，这里并不存在竞争（对一个通道读数据和写数据的整个过程是原子性的：参见14.2.2)。某一个任务会在哪一个worker中被执行是不可知的，反过来也是。worker数量的增多也会增加通信的开销，这会对性能有轻微的影响。 从这个简单的例子中可能很难看出第二种模式的优势，但含有复杂锁运用的程序不仅在编写上显得困难，也不容易编写正确，使用第二种模式的话，就无需考虑这么复杂的东西了。 因此，第二种模式对比第一种模式而言，不仅性能是一个主要优势，而且还有个更大的优势：代码显得更清晰、更优雅。一个更符合go语言习惯的worker写法： IDIOM: Use an in- and out-channel instead of locking func Worker(in, out chan *Task) { for { t := 对于任何可以建模为Master-Worker范例的问题，一个类似于worker使用通道进行通信和交互、Master进行整体协调的方案都能完美解决。如果系统部署在多台机器上，各个机器上执行Worker协程，Master和Worker之间使用netchan或者RPC进行通信（参见15章）。 怎么选择是该使用锁还是通道？ 通道是一个较新的概念，本节我们着重强调了在go协程里通道的使用，但这并不意味着经典的锁方法就不能使用。go语言让你可以根据实际问题进行选择：创建一个优雅、简单、可读性强、在大多数场景性能表现都能很好的方案。如果你的问题适合使用锁，也不要忌讳使用它。go语言注重实用，什么方式最能解决你的问题就用什么方式，而不是强迫你使用一种编码风格。下面列出一个普遍的经验法则： 使用锁的情景： 访问共享数据结构中的缓存信息 保存应用程序上下文和状态信息数据 使用通道的情景： 与异步操作的结果进行交互 分发任务 传递数据所有权 当你发现你的锁使用规则变得很复杂时，可以反省使用通道会不会使问题变得简单些。 链接 目录 上一节：协程和恢复（recover） 下一节：惰性生成器实现 "},"Go入门指南/14.8.html":{"url":"Go入门指南/14.8.html","title":"8","keywords":"","body":"14.8 惰性生成器的实现 生成器是指当被调用时返回一个序列中下一个值的函数，例如： generateInteger() => 0 generateInteger() => 1 generateInteger() => 2 .... 生成器每次返回的是序列中下一个值而非整个序列；这种特性也称之为惰性求值：只在你需要时进行求值，同时保留相关变量资源（内存和cpu）：这是一项在需要时对表达式进行求值的技术。例如，生成一个无限数量的偶数序列：要产生这样一个序列并且在一个一个的使用可能会很困难，而且内存会溢出！但是一个含有通道和go协程的函数能轻易实现这个需求。 在14.12的例子中，我们实现了一个使用 int 型通道来实现的生成器。通道被命名为yield和resume，这些词经常在协程代码中使用。 示例 14.12 lazy_evaluation.go： package main import ( \"fmt\" ) var resume chan int func integers() chan int { yield := make(chan int) count := 0 go func() { for { yield 0 fmt.Println(generateInteger()) //=> 1 fmt.Println(generateInteger()) //=> 2 } 有一个细微的区别是从通道读取的值可能会是稍早前产生的，并不是在程序被调用时生成的。如果确实需要这样的行为，就得实现一个请求响应机制。当生成器生成数据的过程是计算密集型且各个结果的顺序并不重要时，那么就可以将生成器放入到go协程实现并行化。但是得小心，使用大量的go协程的开销可能会超过带来的性能增益。 这些原则可以概括为：通过巧妙地使用空接口、闭包和高阶函数，我们能实现一个通用的惰性生产器的工厂函数BuildLazyEvaluator（这个应该放在一个工具包中实现）。工厂函数需要一个函数和一个初始状态作为输入参数，返回一个无参、返回值是生成序列的函数。传入的函数需要计算出下一个返回值以及下一个状态参数。在工厂函数中，创建一个通道和无限循环的go协程。返回值被放到了该通道中，返回函数稍后被调用时从该通道中取得该返回值。每当取得一个值时，下一个值即被计算。在下面的例子中，定义了一个evenFunc函数，其是一个惰性生成函数：在main函数中，我们创建了前10个偶数，每个都是通过调用even()函数取得下一个值的。为此，我们需要在BuildLazyIntEvaluator函数中具体化我们的生成函数，然后我们能够基于此做出定义。 示例 14.13 general_lazy_evalution1.go： package main import ( \"fmt\" ) type Any interface{} type EvalFunc func(Any) (Any, Any) func main() { evenFunc := func(state Any) (Any, Any) { os := state.(int) ns := os + 2 return os, ns } even := BuildLazyIntEvaluator(evenFunc, 0) for i := 0; i 输出： 0th even: 0 1th even: 2 2th even: 4 3th even: 6 4th even: 8 5th even: 10 6th even: 12 7th even: 14 8th even: 16 9th even: 18 练习14.12：general_lazy_evaluation2.go 通过使用14.12中工厂函数生成前10个斐波那契数 提示：因为斐波那契数增长很迅速，使用uint64类型。 注：这种计算通常被定义为递归函数，但是在没有尾递归的语言中，例如go语言，这可能会导致栈溢出，但随着go语言中堆栈可扩展的优化，这个问题就不那么严重。这里的诀窍是使用了惰性求值。gccgo编译器在某些情况下会实现尾递归。 链接 目录 上一节：新旧模型对比：任务和worker 下一节：Implementing Futures "},"Go入门指南/14.9.html":{"url":"Go入门指南/14.9.html","title":"9","keywords":"","body":"14.9 实现 Futures 模式 所谓Futures就是指：有时候在你使用某一个值之前需要先对其进行计算。这种情况下，你就可以在另一个处理器上进行该值的计算，到使用时，该值就已经计算完毕了。 Futures模式通过闭包和通道可以很容易实现，类似于生成器，不同地方在于Futures需要返回一个值。 参考条目文献给出了一个很精彩的例子：假设我们有一个矩阵类型，我们需要计算两个矩阵A和B乘积的逆，首先我们通过函数Inverse(M)分别对其进行求逆运算，在将结果相乘。如下函数InverseProduct()实现了如上过程： func InverseProduct(a Matrix, b Matrix) { a_inv := Inverse(a) b_inv := Inverse(b) return Product(a_inv, b_inv) } 在这个例子中，a和b的求逆矩阵需要先被计算。那么为什么在计算b的逆矩阵时，需要等待a的逆计算完成呢？显然不必要，这两个求逆运算其实可以并行执行的。换句话说，调用Product函数只需要等到a_inv和b_inv的计算完成。如下代码实现了并行计算方式： func InverseProduct(a Matrix, b Matrix) { a_inv_future := InverseFuture(a) // start as a goroutine b_inv_future := InverseFuture(b) // start as a goroutine a_inv := InverseFuture函数起了一个goroutine协程，在其执行闭包运算，该闭包会将矩阵求逆结果放入到future通道中： func InverseFuture(a Matrix) { future := make(chan Matrix) go func() { future 当开发一个计算密集型库时，使用Futures模式设计API接口是很有意义的。在你的包使用Futures模式，且能保持友好的API接口。此外，Futures可以通过一个异步的API暴露出来。这样你可以以最小的成本将包中的并行计算移到用户代码中。（参见参考文件18：http://www.golangpatterns.info/concurrency/futures） 链接 目录 上一节：惰性生成器的实现 下一节：复用 "},"Go入门指南/15.0.html":{"url":"Go入门指南/15.0.html","title":"0","keywords":"","body":"15.0 网络，模板和网页应用 go在编写web应用方面非常得力。因为目前它还没有GUI（Graphic User Interface 即图形化用户界面）的框架，通过文本或者模板展现的html界面是目前go编写应用程序的唯一方式。（**译者注：实际上在翻译的时候，已经有了一些不太成熟的GUI库例如：go ui。） 链接 目录 上一节：使用通道（channel）并发修改对象数据 下一节：一个Tcp服务器 "},"Go入门指南/15.1.html":{"url":"Go入门指南/15.1.html","title":"1","keywords":"","body":"15.1 tcp服务器 这部分我们将使用TCP协议和在14章讲到的协程范式编写一个简单的客户端-服务器应用，一个（web）服务器应用需要响应众多客户端的并发请求：go会为每一个客户端产生一个协程用来处理请求。我们需要使用net包中网络通信的功能。它包含了用于TCP/IP以及UDP协议、域名解析等方法。 服务器代码，单独的一个文件： 示例 15.1 server.go package main import ( \"fmt\" \"net\" ) func main() { fmt.Println(\"Starting the server ...\") // 创建 listener listener, err := net.Listen(\"tcp\", \"localhost:50000\") if err != nil { fmt.Println(\"Error listening\", err.Error()) return //终止程序 } // 监听并接受来自客户端的连接 for { conn, err := listener.Accept() if err != nil { fmt.Println(\"Error accepting\", err.Error()) return // 终止程序 } go doServerStuff(conn) } } func doServerStuff(conn net.Conn) { for { buf := make([]byte, 512) len, err := conn.Read(buf) if err != nil { fmt.Println(\"Error reading\", err.Error()) return //终止程序 } fmt.Printf(\"Received data: %v\", string(buf[:len])) } } 我们在main()创建了一个net.Listener的变量，他是一个服务器的基本函数：用来监听和接收来自客户端的请求（来自localhost即IP地址为127.0.0.1端口为50000基于TCP协议）。这个Listen()函数可以返回一个error类型的错误变量。用一个无限for循环的listener.Accept()来等待客户端的请求。客户端的请求将产生一个net.Conn类型的连接变量。然后一个独立的协程使用这个连接执行doServerStuff()，开始使用一个512字节的缓冲data来读取客户端发送来的数据并且把它们打印到服务器的终端，len获取客户端发送的数据字节数；当客户端发送的所有数据都被读取完成时，协程就结束了。这段程序会为每一个客户端连接创建一个独立的协程。必须先运行服务器代码，再运行客户端代码。 客户端代码写在另外一个文件client.go中： 示例 15.2 client.go package main import ( \"bufio\" \"fmt\" \"net\" \"os\" \"strings\" ) func main() { //打开连接: conn, err := net.Dial(\"tcp\", \"localhost:50000\") if err != nil { //由于目标计算机积极拒绝而无法创建连接 fmt.Println(\"Error dialing\", err.Error()) return // 终止程序 } inputReader := bufio.NewReader(os.Stdin) fmt.Println(\"First, what is your name?\") clientName, _ := inputReader.ReadString('\\n') // fmt.Printf(\"CLIENTNAME %s\", clientName) trimmedClient := strings.Trim(clientName, \"\\r\\n\") // Windows 平台下用 \"\\r\\n\"，Linux平台下使用 \"\\n\" // 给服务器发送信息直到程序退出： for { fmt.Println(\"What to send to the server? Type Q to quit.\") input, _ := inputReader.ReadString('\\n') trimmedInput := strings.Trim(input, \"\\r\\n\") // fmt.Printf(\"input:--s%--\", input) // fmt.Printf(\"trimmedInput:--s%--\", trimmedInput) if trimmedInput == \"Q\" { return } _, err = conn.Write([]byte(trimmedClient + \" says: \" + trimmedInput)) } } 客户端通过net.Dial创建了一个和服务器之间的连接 它通过无限循环中的os.Stdin接收来自键盘的输入直到输入了“Q”。注意使用\\r和\\n换行符分割字符串（在windows平台下使用\\r\\n）。接下来分割后的输入通过connection的Write方法被发送到服务器。 当然，服务器必须先启动好，如果服务器并未开始监听，客户端是无法成功连接的。 如果在服务器没有开始监听的情况下运行客户端程序，客户端会停止并打印出以下错误信息：对tcp 127.0.0.1:50000发起连接时产生错误：由于目标计算机的积极拒绝而无法创建连接。 打开控制台并转到服务器和客户端可执行程序所在的目录，Windows系统下输入server.exe（或者只输入server），Linux系统下输入./server。 接下来控制台出现以下信息：Starting the server ... 在Windows系统中，我们可以通过CTRL/C停止程序。 然后开启2个或者3个独立的控制台窗口，然后分别输入client回车启动客户端程序 以下是服务器的输出： Starting the Server ... Received data: IVO says: Hi Server, what's up ? Received data: CHRIS says: Are you busy server ? Received data: MARC says: Don't forget our appointment tomorrow ! 当客户端输入 Q 并结束程序时，服务器会输出以下信息： Error reading WSARecv tcp 127.0.0.1:50000: The specified network name is no longer available. 在网络编程中net.Dial函数是非常重要的，一旦你连接到远程系统，就会返回一个Conn类型接口，我们可以用它发送和接收数据。Dial函数巧妙的抽象了网络结构及传输。所以IPv4或者IPv6，TCP或者UDP都可以使用这个公用接口。 下边这个示例先使用TCP协议连接远程80端口，然后使用UDP协议连接，最后使用TCP协议连接IPv6类型的地址： 示例 15.3 dial.go // make a connection with www.example.org: package main import ( \"fmt\" \"net\" \"os\" ) func main() { conn, err := net.Dial(\"tcp\", \"192.0.32.10:80\") // tcp ipv4 checkConnection(conn, err) conn, err = net.Dial(\"udp\", \"192.0.32.10:80\") // udp checkConnection(conn, err) conn, err = net.Dial(\"tcp\", \"[2620:0:2d0:200::10]:80\") // tcp ipv6 checkConnection(conn, err) } func checkConnection(conn net.Conn, err error) { if err != nil { fmt.Printf(\"error %v connecting!\", err) os.Exit(1) } fmt.Printf(\"Connection is made with %v\\n\", conn) } 下边也是一个使用net包从socket中打开，写入，读取数据的例子： 示例 15.4 socket.go package main import ( \"fmt\" \"io\" \"net\" ) func main() { var ( host = \"www.apache.org\" port = \"80\" remote = host + \":\" + port msg string = \"GET / \\n\" data = make([]uint8, 4096) read = true count = 0 ) // 创建一个socket con, err := net.Dial(\"tcp\", remote) // 发送我们的消息，一个http GET请求 io.WriteString(con, msg) // 读取服务器的响应 for read { count, err = con.Read(data) read = (err == nil) fmt.Printf(string(data[0:count])) } con.Close() } 练习 15.1 编写新版本的客户端和服务器（client1.go / server1.go）： 增加一个检查错误的函数checkError(error)；讨论如下方案的利弊：为什么这个重构可能并没有那么理想？看看在示例15.14中它是如何被解决的 使客户端可以通过发送一条命令SH来关闭服务器 让服务器可以保存已经连接的客户端列表（他们的名字）；当客户端发送WHO指令的时候，服务器将显示如下列表： This is the client list: 1:active, 0=inactive User IVO is 1 User MARC is 1 User CHRIS is 1 注意：当服务器运行的时候，你无法编译/连接同一个目录下的源码来产生一个新的版本，因为server.exe正在被操作系统使用而无法被替换成新的版本。 下边这个版本的 simple_tcp_server.go 从很多方面优化了第一个tcp服务器的示例 server.go 并且拥有更好的结构，它只用了80行代码！ 示例 15.5 simple_tcp_server.go： // Simple multi-thread/multi-core TCP server. package main import ( \"flag\" \"fmt\" \"net\" \"os\" ) const maxRead = 25 func main() { flag.Parse() if flag.NArg() != 2 { panic(\"usage: host port\") } hostAndPort := fmt.Sprintf(\"%s:%s\", flag.Arg(0), flag.Arg(1)) listener := initServer(hostAndPort) for { conn, err := listener.Accept() checkError(err, \"Accept: \") go connectionHandler(conn) } } func initServer(hostAndPort string) *net.TCPListener { serverAddr, err := net.ResolveTCPAddr(\"tcp\", hostAndPort) checkError(err, \"Resolving address:port failed: '\"+hostAndPort+\"'\") listener, err := net.Listen(\"tcp\", serverAddr) checkError(err, \"ListenTCP: \") println(\"Listening to: \", listener.Addr().String()) return listener } func connectionHandler(conn net.Conn) { connFrom := conn.RemoteAddr().String() println(\"Connection from: \", connFrom) sayHello(conn) for { var ibuf []byte = make([]byte, maxRead+1) length, err := conn.Read(ibuf[0:maxRead]) ibuf[maxRead] = 0 // to prevent overflow switch err { case nil: handleMsg(length, err, ibuf) case os.EAGAIN: // try again continue default: goto DISCONNECT } } DISCONNECT: err := conn.Close() println(\"Closed connection: \", connFrom) checkError(err, \"Close: \") } func sayHello(to net.Conn) { obuf := []byte{'L', 'e', 't', '\\'', 's', ' ', 'G', 'O', '!', '\\n'} wrote, err := to.Write(obuf) checkError(err, \"Write: wrote \"+string(wrote)+\" bytes.\") } func handleMsg(length int, err error, msg []byte) { if length > 0 { print(\"\") } } func checkError(error error, info string) { if error != nil { panic(\"ERROR: \" + info + \" \" + error.Error()) // terminate program } } (译者注：应该是由于go版本的更新，会提示os.EAGAIN undefined ,修改后的代码：simple_tcp_server_v1.go) 都有哪些改进？ 服务器地址和端口不再是硬编码，而是通过命令行传入参数并通过flag包来读取这些参数。这里使用了flag.NArg()检查是否按照期望传入了2个参数： if flag.NArg() != 2{ panic(\"usage: host port\") } 传入的参数通过fmt.Sprintf函数格式化成字符串 hostAndPort := fmt.Sprintf(\"%s:%s\", flag.Arg(0), flag.Arg(1)) 在initServer函数中通过net.ResolveTCPAddr指定了服务器地址和端口，这个函数最终返回了一个*net.TCPListener 每一个连接都会以协程的方式运行connectionHandler函数。这些开始于当通过conn.RemoteAddr()获取到客户端的地址 它使用conn.Write发送改进的go-message给客户端 它使用一个25字节的缓冲读取客户端发送的数据并一一打印出来。如果读取的过程中出现错误，代码会进入switch语句的default分支关闭连接。如果是操作系统的EAGAIN错误，它会重试。 所有的错误检查都被重构在独立的函数'checkError'中，用来分发出现的上下文错误。 在命令行中输入simple_tcp_server localhost 50000来启动服务器程序，然后在独立的命令行窗口启动一些client.go的客户端。当有两个客户端连接的情况下服务器的典型输出如下，这里我们可以看到每个客户端都有自己的地址： E:\\Go\\GoBoek\\code examples\\chapter 14>simple_tcp_server localhost 50000 Listening to: 127.0.0.1:50000 Connection from: 127.0.0.1:49346 Connection from: 127.0.0.1:49347 net.Error： 这个net包返回错误的错误类型，下边是约定的写法，不过net.Error接口还定义了一些其他的错误实现，有些额外的方法。 package net type Error interface{ Timeout() bool // 错误是否超时 Temporary() bool // 是否是临时错误 } 通过类型断言，客户端代码可以用来测试net.Error，从而区分哪些临时发生的错误或者必然会出现的错误。举例来说，一个网络爬虫程序在遇到临时发生的错误时可能会休眠或者重试，如果是一个必然发生的错误，则他会放弃继续执行。 // in a loop - some function returns an error err if nerr, ok := err.(net.Error); ok && nerr.Temporary(){ time.Sleep(1e9) continue // try again } if err != nil{ log.Fatal(err) } 链接 目录 上一节：网络、模版与网页应用 下一节：一个简单的web服务器 "},"Go入门指南/15.2.html":{"url":"Go入门指南/15.2.html","title":"2","keywords":"","body":"15.2 一个简单的网页服务器 Http是一个比tcp更高级的协议，它描述了客户端浏览器如何与网页服务器进行通信。Go有自己的net/http包，我们来看看它。我们从一些简单的示例开始， 首先编写一个“Hello world!”：查看示例15.6 我们引入了http包并启动了网页服务器，和15.1的net.Listen(\"tcp\", \"localhost:50000\")函数的tcp服务器是类似的，使用http.ListenAndServe(\"localhost:8080\", nil)函数，如果成功会返回空，否则会返回一个错误（可以指定localhost为其他地址，8080是指定的端口号） http.URL描述了web服务器的地址，内含存放了url字符串的Path属性；http.Request描述了客户端请求，内含一个URL属性 如果req请求是一个POST类型的html表单，“var1”就是html表单中一个输入属性的名称，然后用户输入的值就可以通过GO代码：req.FormValue(\"var1\")获取到（请看章节15.4）。还有一种方法就是先执行request.ParseForm()然后再获取`request.Form[\"var1\"]的第一个返回参数，就像这样： var1, found := request.Form[\"var1\"] 第二个参数found就是true，如果var1并未出现在表单中，found就是false 表单属性实际上是一个map[string][]string类型。网页服务器返回了一个http.Response，它是通过http.ResponseWriter对象输出的，这个对象整合了HTTP服务器的返回结果；通过对它写入内容，我们就将数据发送给了HTTP客户端。 现在我们还需要编写网页服务器必须执行的程序，它是如何处理请求的呢。这是在http.HandleFunc函数中完成的，就是在这个例子中当根路径“/”（url地址是http://localhost:8080 ）被请求的时候（或者这个服务器上的其他地址），HelloServer函数就被执行了。这个函数是http.HandlerFunc类型的，它们通常用使用Prehandler来命名，在前边加了一个Pref前缀。 http.HandleFunc注册了一个处理函数(这里是HelloServer)来处理对应/的请求。 /可以被替换为其他特定的url比如/create，/edit等等；你可以为每一个特定的url定义一个单独的处理函数。这个函数需要两个参数：第一个是ReponseWriter类型的w；第二个是请求req。程序向w写入了Hello和r.URL.Path[1:]组成的字符串后边的[1:]表示“创建一个从第一个字符到结尾的子切片”，用来丢弃掉路径开头的“/”，fmt.Fprintf()函数完成了本次写入（请看章节12.8）；另外一种写法是io.WriteString(w, \"hello, world!\\n\") 总结：第一个参数是请求的路径，第二个参数是处理这个路径请求的函数的引用。 示例 15.6 hello_world_webserver.go： package main import ( \"fmt\" \"log\" \"net/http\" ) func HelloServer(w http.ResponseWriter, req *http.Request) { fmt.Println(\"Inside HelloServer handler\") fmt.Fprintf(w, \"Hello,\"+req.URL.Path[1:]) } func main() { http.HandleFunc(\"/\", HelloServer) err := http.ListenAndServe(\"localhost:8080\", nil) if err != nil { log.Fatal(\"ListenAndServe: \", err.Error()) } } 使用命令行启动程序，会打开一个命令窗口显示如下文字： Starting Process E:/Go/GoBoek/code_examples/chapter_14/hello_world_webserver.exe ... 然后打开你的浏览器并输入url地址：http://localhost:8080/world，浏览器就会出现文字：Hello, world，网页服务器会响应你在:8080/后边输入的内容 使用fmt.Println在控制台打印状态，在每个handler被请求的时候，在他们内部打印日志会很有帮助 注： 1）前两行（没有错误处理代码）可以替换成以下写法： http.ListenAndServe(\":8080\", http.HandlerFunc(HelloServer)) 2）fmt.Fprint和fmt.Fprintf都是用来写入http.ResponseWriter的不错的函数（他们实现了io.Writer）。 比如我们可以使用 fmt.Fprintf(w, \"%s%s\", title, body) 来构建一个非常简单的网页并插入title和body的值 如果你需要更多复杂的替换，使用模板包（请看章节15.7） 3）如果你需要使用安全的https连接，使用http.ListenAndServeTLS()代替http.ListenAndServe() 4）http.HandleFunc(\"/\", Hfunc)中的HFunc是一个处理函数，如下： func HFunc(w http.ResponseWriter, req *http.Request) { ... } 也可以使用这种方式：http.Handle(\"/\", http.HandlerFunc(HFunc)) 上边的HandlerFunc只是一个类型名称，它定义如下： type HandlerFunc func(ResponseWriter, *Request) 它是一个可以把普通的函数当做HTTP处理器的适配器。如果f函数声明的合适，HandlerFunc(f)就是一个执行了f函数的处理器对象。 http.Handle的第二个参数也可以是T的一个obj对象：http.Handle(\"/\", obj)给T提供了ServeHTTP方法，实现了http的Handler接口： func (obj *Typ) ServeHTTP(w http.ResponseWriter, req *http.Request) { ... } 这个用法在章节15.8类型Counter和Chan上使用过。只要实现了http.Handler，http包就可以处理任何HTTP请求。 练习 15.2：webhello2.go 编写一个网页服务器监听端口9999，有如下处理函数： 当请求http://localhost:9999/hello/Name时，响应：hello Name(Name需是一个合法的姓，比如Chris或者Madeleine) 当请求http://localhost:9999/shouthello/Name时，响应：hello NAME 练习 15.3：hello_server.go 创建一个空结构hello并使它实现http.Handler。运行并测试。 链接 目录 上一章：tcp服务器 下一节：访问并读取页面数据 "},"Go入门指南/15.3.html":{"url":"Go入门指南/15.3.html","title":"3","keywords":"","body":"15.3 访问并读取页面 在下边这个程序中，数组中的url都将被访问：会发送一个简单的http.Head()请求查看返回值；它的声明如下：func Head(url string) (r *Response, err error) 返回状态码会被打印出来。 示例 15.7 poll_url.go： package main import ( \"fmt\" \"net/http\" ) var urls = []string{ \"http://www.google.com/\", \"http://golang.org/\", \"http://blog.golang.org/\", } func main() { // Execute an HTTP HEAD request for all url's // and returns the HTTP status string or an error string. for _, url := range urls { resp, err := http.Head(url) if err != nil { fmt.Println(\"Error:\", url, err) } fmt.Println(url, \": \", resp.Status) } } 输出为： http://www.google.com/ : 302 Found http://golang.org/ : 200 OK http://blog.golang.org/ : 200 OK 译者注 由于国内的网络环境现状，很有可能见到如下超时错误提示： Error: http://www.google.com/ Head http://www.google.com/: dial tcp 216.58.221.100:80: connectex: A connection attempt failed because the connected pa rty did not properly respond after a period of time, or established connection failed because connected host has failed to respond. 在下边的程序中我们使用http.Get()获取网页内容； Get的返回值res中的Body属性包含了网页内容，然后我们用ioutil.ReadAll把它读出来： 示例 15.8 http_fetch.go： package main import ( \"fmt\" \"io/ioutil\" \"log\" \"net/http\" ) func main() { res, err := http.Get(\"http://www.google.com\") checkError(err) data, err := ioutil.ReadAll(res.Body) checkError(err) fmt.Printf(\"Got: %q\", string(data)) } func checkError(err error) { if err != nil { log.Fatalf(\"Get : %v\", err) } } 当访问不存在的网站时，这里有一个CheckError输出错误的例子： 2011/09/30 11:24:15 Get: Get http://www.google.bex: dial tcp www.google.bex:80:GetHostByName: No such host is known. 译者注 和上一个例子相似，你可以把google.com更换为一个国内可以顺畅访问的网址进行测试 在下边的程序中，我们获取一个twitter用户的状态，通过xml包将这个状态解析成为一个结构： 示例 15.9 twitter_status.go package main import ( \"encoding/xml\" \"fmt\" \"net/http\" ) /*这个结构会保存解析后的返回数据。 他们会形成有层级的XML，可以忽略一些无用的数据*/ type Status struct { Text string } type User struct { XMLName xml.Name Status Status } func main() { // 发起请求查询推特Goodland用户的状态 response, _ := http.Get(\"http://twitter.com/users/Googland.xml\") // 初始化XML返回值的结构 user := User{xml.Name{\"\", \"user\"}, Status{\"\"}} // 将XML解析为我们的结构 xml.Unmarshal(response.Body, &user) fmt.Printf(\"status: %s\", user.Status.Text) } 输出： status: Robot cars invade California, on orders from Google: Google has been testing self-driving cars ... http://bit.ly/cbtpUN http://retwt.me/97p 译者注 和上边的示例相似，你可能无法获取到xml数据，另外由于go版本的更新，xml.Unmarshal函数的第一个参数需是[]byte类型，而无法传入Body。 我们会在章节15.4中用到http包中的其他重要的函数： http.Redirect(w ResponseWriter, r *Request, url string, code int)：这个函数会让浏览器重定向到url（是请求的url的相对路径）以及状态码。 http.NotFound(w ResponseWriter, r *Request)：这个函数将返回网页没有找到，HTTP 404错误。 http.Error(w ResponseWriter, error string, code int)：这个函数返回特定的错误信息和HTTP代码。 另http.Request对象的一个重要属性req：req.Method，这是一个包含GET或POST字符串，用来描述网页是以何种方式被请求的。 go为所有的HTTP状态码定义了常量，比如： http.StatusContinue = 100 http.StatusOK = 200 http.StatusFound = 302 http.StatusBadRequest = 400 http.StatusUnauthorized = 401 http.StatusForbidden = 403 http.StatusNotFound = 404 http.StatusInternalServerError = 500 你可以使用`w.header().Set(\"Content-Type\", \"../..\")设置头信息 比如在网页应用发送html字符串的时候，在输出之前执行w.Header().Set(\"Content-Type\", \"text/html\")。 练习 15.4：扩展 http_fetch.go 使之可以从控制台读取url，使用章节12.1学到的接收控制台输入的方法 （http_fetch2.go） 练习 15.5：获取json格式的推特状态，就像示例 15.9（twitter_status_json.go） 链接 目录 上一章：一个简单的网页服务器 下一节：写一个简单的网页应用 "},"Go入门指南/15.4.html":{"url":"Go入门指南/15.4.html","title":"4","keywords":"","body":"15.4 写一个简单的网页应用 下边的程序在端口8088上启动了一个网页服务器；SimpleServer会处理/test1url使它在浏览器输出hello world。FormServer会处理/test2url：如果url最初由浏览器请求，那么它就是一个GET请求，并且返回一个form常量，包含了简单的input表单，这个表单里有一个文本框和一个提交按钮。当在文本框输入一些东西并点击提交按钮的时候，会发起一个POST请求。FormServer中的代码用到了switch来区分两种情况。在POST情况下，使用request.FormValue(\"inp\")通过文本框的name属性inp来获取内容，并写回浏览器页面。在控制台启动程序并在浏览器中打开urlhttp://localhost:8088/test2来测试这个程序： 示例 15.10 simple_webserver.go package main import ( \"io\" \"net/http\" ) const form = ` ` /* handle a simple get request */ func SimpleServer(w http.ResponseWriter, request *http.Request) { io.WriteString(w, \"hello, world\") } func FormServer(w http.ResponseWriter, request *http.Request) { w.Header().Set(\"Content-Type\", \"text/html\") switch request.Method { case \"GET\": /* display the form to the user */ io.WriteString(w, form) case \"POST\": /* handle the form data, note that ParseForm must be called before we can extract form data */ //request.ParseForm(); //io.WriteString(w, request.Form[\"in\"][0]) io.WriteString(w, request.FormValue(\"in\")) } } func main() { http.HandleFunc(\"/test1\", SimpleServer) http.HandleFunc(\"/test2\", FormServer) if err := http.ListenAndServe(\":8088\", nil); err != nil { panic(err) } } 注：当使用字符串常量表示html文本的时候，包含对于让浏览器识别它收到了一个html非常重要。 更安全的做法是在处理器中使用w.Header().Set(\"Content-Type\", \"text/html\")在写入返回之前将header的content-type设置为text/html content-type会让浏览器认为它可以使用函数http.DetectContentType([]byte(form))来处理收到的数据 练习 15.6 [statistics.go] 编写一个网页程序，可以让用户输入一连串的数字，然后将它们打印出来，计算出这些数字的均值和中值，就像下边这张截图一样： 目录 上一章：访问并读取页面 下一节：常见的陷阱与错误 "},"Go入门指南/16.0.html":{"url":"Go入门指南/16.0.html","title":"0","keywords":"","body":"16 常见的陷阱与错误 在之前的内容中，有时候使用!!...!!标记警告go语言中的一些错误使用方式。当你在编程时候遇到的一个困难，可以确定本书特定的章节能找到类似的主题。为了方便起见，这里列出了一些常见陷进，以便于你能发现更多的解释和例子： 永远不要使用形如 var p*a 声明变量，这会混淆指针声明和乘法运算（参考4.9小节） 永远不要在for循环自身中改变计数器变量（参考5.4小节） 永远不要在for-range循环中使用一个值去改变自身的值（参考5.4.4小节） 永远不要将goto和前置标签一起使用（参考5.6小节） 永远不要忘记在函数名（参考第6章）后加括号()，尤其调用一个对象的方法或者使用匿名函数启动一个协程时 永远不要使用new()一个map，一直使用make（参考第8章） 当为一个类型定义一个String()方法时，不要使用fmt.Print或者类似的代码（参考10.7小节） 永远不要忘记当终止缓存写入时，使用Flush函数（参考12.2.3小节） 永远不要忽略错误提示，忽略错误会导致程序奔溃（参考13.1小节） 不要使用全局变量或者共享内存，这会使并发执行的代码变得不安全（参考14.1小节） println函数仅仅是用于调试的目的 最佳实践：对比以下使用方式： 使用正确的方式初始化一个元素是切片的映射，例如map[type]slice（参考8.1.3小节） 一直使用逗号，ok或者checked形式作为类型断言（参考11.3小节） 使用一个工厂函数创建并初始化自己定义类型（参考10.2小节-18.4小节） 仅当一个结构体的方法想改变结构体时，使用结构体指针作为方法的接受者，否则使用一个结构体值类型10.6.3小节 本章主要汇总了go语言使用过程中最常见的错误和注意事项。在之前的章节已经涉及到了完整的示例和解释，你应该做的不仅仅是阅读这段的标题。 链接 目录 上一章：使用SMTP（简单邮件传输协议）发送邮件 下一节：误用短声明导致变量覆盖 "},"Go入门指南/16.10.html":{"url":"Go入门指南/16.10.html","title":"10","keywords":"","body":"16.10 糟糕的错误处理 依附于第13章模式的描述和第17.1小节与第17.2.4小节的总结。 16.10.1 不要使用布尔值： 像下面代码一样，创建一个布尔型变量用于测试错误条件是多余的： var good bool // 测试一个错误，`good`被赋为`true`或者`false` if !good { return errors.New(\"things aren’t good\") } 立即检测一个错误： ... err1 := api.Func1() if err1 != nil { … } 16.10.2 避免错误检测使代码变得混乱： 避免写出这样的代码： ... err1 := api.Func1() if err1 != nil { fmt.Println(\"err: \" + err.Error()) return } err2 := api.Func2() if err2 != nil { ... return } 首先，包括在一个初始化的if语句中对函数的调用。但即使代码中到处都是以if语句的形式通知错误（通过打印错误信息）。通过这种方式，很难分辨什么是正常的程序逻辑，什么是错误检测或错误通知。还需注意的是，大部分代码都是致力于错误的检测。通常解决此问题的好办法是尽可能以闭包的形式封装你的错误检测，例如下面的代码： func httpRequestHandler(w http.ResponseWriter, req *http.Request) { err := func () error { if req.Method != \"GET\" { return errors.New(\"expected GET\") } if input := parseInput(req); input != \"command\" { return errors.New(\"malformed command\") } // 可以在此进行其他的错误检测 } () if err != nil { w.WriteHeader(400) io.WriteString(w, err) return } doSomething() ... 这种方法可以很容易分辨出错误检测、错误通知和正常的程序逻辑（更详细的方式参考第13.5小节）。 在开始阅读第17章前，先回答下列2个问题： 问题 16.1：总结你能记住的所有关于,ok模式的情况。 问题 16.2：总结你能记住的所有关于defer模式的情况。 链接 目录 上一节：闭包和协程的使用 下一章：模式 "},"Go入门指南/16.1.html":{"url":"Go入门指南/16.1.html","title":"1","keywords":"","body":"16.1 误用短声明导致变量覆盖 var remember bool = false if something { remember := true //错误 } // 使用remember 在此代码段中，remember变量永远不会在if语句外面变成true，如果something为true，由于使用了短声明:=，if语句内部的新变量remember将覆盖外面的remember变量，并且该变量的值为true，但是在if语句外面，变量remember的值变成了false，所以正确的写法应该是： if something { remember = true } 此类错误也容易在for循环中出现，尤其当函数返回一个具名变量时难于察觉 ，例如以下的代码段： func shadow() (err error) { x, err := check1() // x是新创建变量，err是被赋值 if err != nil { return // 正确返回err } if y, err := check2(x); err != nil { // y和if语句中err被创建 return // if语句中的err覆盖外面的err，所以错误的返回nil！ } else { fmt.Println(y) } return } 链接 目录 上一节：常见的陷阱与错误 下一节：误用字符串 "},"Go入门指南/16.2.html":{"url":"Go入门指南/16.2.html","title":"2","keywords":"","body":"16.2 误用字符串 当需要对一个字符串进行频繁的操作时，谨记在go语言中字符串是不可变的（类似java和c#）。使用诸如a += b形式连接字符串效率低下，尤其在一个循环内部使用这种形式。这会导致大量的内存开销和拷贝。应该使用一个字符数组代替字符串，将字符串内容写入一个缓存中。 例如以下的代码示例： var b bytes.Buffer ... for condition { b.WriteString(str) // 将字符串str写入缓存buffer } return b.String() 注意：由于编译优化和依赖于使用缓存操作的字符串大小，当循环次数大于15时，效率才会更佳。 链接 目录 上一节：误用短声明导致变量覆盖 下一节：发生错误时使用defer关闭一个文件 "},"Go入门指南/16.3.html":{"url":"Go入门指南/16.3.html","title":"3","keywords":"","body":"16.3 发生错误时使用defer关闭一个文件 如果你在一个for循环内部处理一系列文件，你需要使用defer确保文件在处理完毕后被关闭，例如： for _, file := range files { if f, err = os.Open(file); err != nil { return } // 这是错误的方式，当循环结束时文件没有关闭 defer f.Close() // 对文件进行操作 f.Process(data) } 但是在循环结尾处的defer没有执行，所以文件一直没有关闭！垃圾回收机制可能会自动关闭文件，但是这会产生一个错误，更好的做法是： for _, file := range files { if f, err = os.Open(file); err != nil { return } // 对文件进行操作 f.Process(data) // 关闭文件 f.Close() } defer仅在函数返回时才会执行，在循环的结尾或其他一些有限范围的代码内不会执行。 链接 目录 上一节：误用字符串 下一节：何时使用new()和make() "},"Go入门指南/16.4.html":{"url":"Go入门指南/16.4.html","title":"4","keywords":"","body":"16.4 何时使用new()和make() 在第7.2.1小节和第10.2.2小节，我们已经讨论过此问题，并使用代码进行详细说明，观点如下： - 切片、映射和通道，使用make - 数组、结构体和所有的值类型，使用new 链接 目录 上一节：发生错误时使用defer关闭一个文件 下一节：不需要将一个指向切片的指针传递给函数 "},"Go入门指南/16.5.html":{"url":"Go入门指南/16.5.html","title":"5","keywords":"","body":"16.5 不需要将一个指向切片的指针传递给函数 在第4.9小节，我们已经知道，切片实际是一个指向潜在数组的指针。我们常常需要把切片作为一个参数传递给函数是因为：实际就是传递一个指向变量的指针，在函数内可以改变这个变量，而不是传递数据的拷贝。 因此应该这样做： func findBiggest( listOfNumbers []int ) int {} 而不是： func findBiggest( listOfNumbers *[]int ) int {} 当切片作为参数传递时，切记不要解引用切片。 链接 目录 上一节：何时使用new()和make() 下一节：使用指针指向接口类型 "},"Go入门指南/16.6.html":{"url":"Go入门指南/16.6.html","title":"6","keywords":"","body":"16.6 使用指针指向接口类型 查看如下程序：nexter是一个接口类型，并且定义了一个next()方法读取下一字节。函数nextFew将nexter接口作为参数并读取接下来的num个字节，并返回一个切片：这是正确做法。但是nextFew2使用一个指向nexter接口类型的指针作为参数传递给函数：当使用next()函数时，系统会给出一个编译错误：n.next undefined (type *nexter has no field or method next) （译者注：n.next未定义（*nexter类型没有next成员或next方法）） 例 16.1 pointer_interface.go (不能通过编译): package main import ( “fmt” ) type nexter interface { next() byte } func nextFew1(n nexter, num int) []byte { var b []byte for i:=0; i 永远不要使用一个指针指向一个接口类型，因为它已经是一个指针。 链接 目录 上一节：不需要将一个指向切片的指针传递给函数 下一节：使用值类型时误用指针 "},"Go入门指南/16.7.html":{"url":"Go入门指南/16.7.html","title":"7","keywords":"","body":"16.7 使用值类型时误用指针 将一个值类型作为一个参数传递给函数或者作为一个方法的接收者，似乎是对内存的滥用，因为值类型一直是传递拷贝。但是另一方面，值类型的内存是在栈上分配，内存分配快速且开销不大。如果你传递一个指针，而不是一个值类型，go编译器大多数情况下会认为需要创建一个对象，并将对象移动到堆上，所以会导致额外的内存分配：因此当使用指针代替值类型作为参数传递时，我们没有任何收获。 链接 目录 上一节：使用指针指向接口类型 下一节：误用协程和通道 "},"Go入门指南/16.8.html":{"url":"Go入门指南/16.8.html","title":"8","keywords":"","body":"16.8 误用协程和通道 由于教学需要和对协程的工作原理有一个直观的了解，在第14章使用了一些简单的算法，举例说明了协程和通道的使用，例如生产者或者迭代器。在实际应用中，你不需要并发执行，或者你不需要关注协程和通道的开销，在大多数情况下，通过栈传递参数会更有效率。 但是，如果你使用break、return或者panic去跳出一个循环，很有可能会导致内存溢出，因为协程正处理某些事情而被阻塞。在实际代码中，通常仅需写一个简单的过程式循环即可。当且仅当代码中并发执行非常重要，才使用协程和通道。 链接 目录 上一节：使用值类型时误用指针 下一节：闭包和协程的使用 "},"Go入门指南/16.9.html":{"url":"Go入门指南/16.9.html","title":"9","keywords":"","body":"16.9 闭包和协程的使用 请看下面代码： package main import ( \"fmt\" \"time\" ) var values = [5]int{10, 11, 12, 13, 14} func main() { // 版本A: for ix := range values { // ix是索引值 func() { fmt.Print(ix, \" \") }() // 调用闭包打印每个索引值 } fmt.Println() // 版本B: 和A版本类似，但是通过调用闭包作为一个协程 for ix := range values { go func() { fmt.Print(ix, \" \") }() } fmt.Println() time.Sleep(5e9) // 版本C: 正确的处理方式 for ix := range values { go func(ix interface{}) { fmt.Print(ix, \" \") }(ix) } fmt.Println() time.Sleep(5e9) // 版本D: 输出值: for ix := range values { val := values[ix] go func() { fmt.Print(val, \" \") }() } time.Sleep(1e9) } 输出： 0 1 2 3 4 4 4 4 4 4 1 0 3 4 2 10 11 12 13 14 版本A调用闭包5次打印每个索引值，版本B也做相同的事，但是通过协程调用每个闭包。按理说这将执行得更快，因为闭包是并发执行的。如果我们阻塞足够多的时间，让所有协程执行完毕，版本B的输出是：4 4 4 4 4。为什么会这样？在版本B的循环中，ix变量实际是一个单变量，表示每个数组元素的索引值。因为这些闭包都只绑定到一个变量，这是一个比较好的方式，当你运行这段代码时，你将看见每次循环都打印最后一个索引值4，而不是每个元素的索引值。因为协程可能在循环结束后还没有开始执行，而此时ix值是4。 版本C的循环写法才是正确的：调用每个闭包时将ix作为参数传递给闭包。ix在每次循环时都被重新赋值，并将每个协程的ix放置在栈中，所以当协程最终被执行时，每个索引值对协程都是可用的。注意这里的输出可能是0 2 1 3 4或者0 3 1 2 4或者其他类似的序列，这主要取决于每个协程何时开始被执行。 在版本D中，我们输出这个数组的值，为什么版本B不能而版本D可以呢？ 因为版本D中的变量声明是在循环体内部，所以在每次循环时，这些变量相互之间是不共享的，所以这些变量可以单独的被每个闭包使用。 链接 目录 上一节：误用协程和通道 下一节：糟糕的错误处理 "},"Go入门指南/17.0.html":{"url":"Go入门指南/17.0.html","title":"0","keywords":"","body":"17 模式 链接 目录 上一章：糟糕的错误处理 下一节：关于逗号ok模式 "},"Go入门指南/17.1.html":{"url":"Go入门指南/17.1.html","title":"1","keywords":"","body":"17.1 关于逗号ok模式 在学习本书第二部分和第三部分时，我们经常在一个表达式返回2个参数时使用这种模式：，ok，第一个参数是一个值或者nil，第二个参数是true/false或者一个错误error。在一个需要赋值的if条件语句中，使用这种模式去检测第二个参数值会让代码显得优雅简洁。这种模式在go语言编码规范中非常重要。下面总结了所有使用这种模式的例子： （1）在函数返回时检测错误（参考第5.2小节）: value, err := pack1.Func1(param1) if err != nil { fmt.Printf(“Error %s in pack1.Func1 with parameter %v”, err.Error(), param1) return err } // 函数Func1没有错误: Process(value) e.g.: os.Open(file) strconv.Atoi(str) 这段代码中的函数将错误返回给它的调用者，当函数执行成功时，返回的错误是nil，所以使用这种写法： func SomeFunc() error { … if value, err := pack1.Func1(param1); err != nil { … return err } … return nil } 这种模式也常用于通过defer使程序从panic中恢复执行（参考第17.2（4）小节）。 要实现简洁的错误检测代码，更好的方式是使用闭包，参考第16.10.2小节 （2）检测映射中是否存在一个键值（参考第8.2小节）：key1在映射map1中是否有值？ if value, isPresent = map1[key1]; isPresent { Process(value) } // key1不存在 … （3）检测一个接口类型变量varI是否包含了类型T：类型断言（参考第11.3小节）： if value, ok := varI.(T); ok { Process(value) } // 接口类型varI没有包含类型T （4）检测一个通道ch是否关闭（参考第14.3小节）： for input := range ch { Process(input) } 或者: for { if input, open := 链接 目录 上一节：模式 下一节：关于defer模式 "},"Go入门指南/18.0.html":{"url":"Go入门指南/18.0.html","title":"0","keywords":"","body":"18 出于性能考虑的实用代码片段 链接 目录 上一章：运算符模板和接口 下一节：字符串 "},"Go入门指南/18.10.html":{"url":"Go入门指南/18.10.html","title":"10","keywords":"","body":"18.10 其他 如何在程序出错时终止程序： if err != nil { fmt.Printf(“Program stopping with error %v”, err) os.Exit(1) } 或者： if err != nil { panic(“ERROR occurred: “ + err.Error()) } 链接 目录 上一节：网络和网页应用 下一节：出于性能考虑的最佳实践和建议 "},"Go入门指南/18.11.html":{"url":"Go入门指南/18.11.html","title":"11","keywords":"","body":"18.11 出于性能考虑的最佳实践和建议 （1）尽可能的使用:=去初始化声明一个变量（在函数内部）； （2）尽可能的使用字符代替字符串； （3）尽可能的使用切片代替数组； （4）尽可能的使用数组和切片代替映射（详见参考文献15）； （5）如果只想获取切片中某项值，不需要值的索引，尽可能的使用for range去遍历切片，这比必须查询切片中的每个元素要快一些； （6）当数组元素是稀疏的（例如有很多0值或者空值nil），使用映射会降低内存消耗； （7）初始化映射时指定其容量； （8）当定义一个方法时，使用指针类型作为方法的接受者； （9）在代码中使用常量或者标志提取常量的值； （10）尽可能在需要分配大量内存时使用缓存； （11）使用缓存模板（参考章节15.7）。 链接 目录 上一节：其他 下一章：构建一个完整的应用程序 "},"Go入门指南/18.1.html":{"url":"Go入门指南/18.1.html","title":"1","keywords":"","body":"18.1 字符串 （1）如何修改字符串中的一个字符： str:=\"hello\" c:=[]byte(str) c[0]='c' s2:= string(c) // s2 == \"cello\" （2）如何获取字符串的子串： substr := str[n:m] （3）如何使用for或者for-range遍历一个字符串： // gives only the bytes: for i:=0; i （4）如何获取一个字符串的字节数：len(str) 如何获取一个字符串的字符数： 最快速：utf8.RuneCountInString(str) len([]int(str)) （5）如何连接字符串： 最快速： with a bytes.Buffer（参考章节7.2） Strings.Join()（参考章节4.7） 使用+=： str1 := \"Hello \" str2 := \"World!\" str1 += str2 //str1 == \"Hello World!\" （6）如何解析命令行参数：使用os或者flag包 （参考例12.4） 链接 目录 上一节：出于性能考虑的实用代码片段 下一节：数组和切片 "},"Go入门指南/18.2.html":{"url":"Go入门指南/18.2.html","title":"2","keywords":"","body":"18.2 数组和切片 创建： arr1 := new([len]type) slice1 := make([]type, len) 初始化： arr1 := [...]type{i1, i2, i3, i4, i5} arrKeyValue := [len]type{i1: val1, i2: val2} var slice1 []type = arr1[start:end] （1）如何截断数组或者切片的最后一个元素： line = line[:len(line)-1] （2）如何使用for或者for-range遍历一个数组（或者切片）： for i:=0; i （3）如何在一个二维数组或者切片arr2Dim中查找一个指定值V： found := false Found: for row := range arr2Dim { for column := range arr2Dim[row] { if arr2Dim[row][column] == V{ found = true break Found } } } 链接 目录 上一节：字符串 下一节：映射 "},"Go入门指南/18.3.html":{"url":"Go入门指南/18.3.html","title":"3","keywords":"","body":"18.3 映射 创建： map1 := make(map[keytype]valuetype) 初始化： map1 := map[string]int{\"one\": 1, \"two\": 2} （1）如何使用for或者for-range遍历一个映射： for key, value := range map1 { … } （2）如何在一个映射中检测键key1是否存在： val1, isPresent = map1[key1] 返回值：键key1对应的值或者0, true或者false （3）如何在映射中删除一个键： delete(map1, key1) 链接 目录 上一节：数组和切片 下一节：结构体 "},"Go入门指南/18.4.html":{"url":"Go入门指南/18.4.html","title":"4","keywords":"","body":"18.4 结构体 创建： type struct1 struct { field1 type1 field2 type2 … } ms := new(struct1) 初始化： ms := &struct1{10, 15.5, \"Chris\"} 当结构体的命名以大写字母开头时，该结构体在包外可见。 通常情况下，为每个结构体定义一个构建函数，并推荐使用构建函数初始化结构体（参考例10.2）： ms := Newstruct1{10, 15.5, \"Chris\"} func Newstruct1(n int, f float32, name string) *struct1 { return &struct1{n, f, name} } 链接 目录 上一节：映射 下一节：接口 "},"Go入门指南/18.5.html":{"url":"Go入门指南/18.5.html","title":"5","keywords":"","body":"18.5 接口 （1）如何检测一个值v是否实现了接口Stringer： if v, ok := v.(Stringer); ok { fmt.Printf(\"implements String(): %s\\n\", v.String()) } （2）如何使用接口实现一个类型分类函数： func classifier(items ...interface{}) { for i, x := range items { switch x.(type) { case bool: fmt.Printf(\"param #%d is a bool\\n\", i) case float64: fmt.Printf(\"param #%d is a float64\\n\", i) case int, int64: fmt.Printf(\"param #%d is an int\\n\", i) case nil: fmt.Printf(\"param #%d is nil\\n\", i) case string: fmt.Printf(\"param #%d is a string\\n\", i) default: fmt.Printf(\"param #%d’s type is unknown\\n\", i) } } } 链接 目录 上一节：结构体 下一节：函数 "},"Go入门指南/18.6.html":{"url":"Go入门指南/18.6.html","title":"6","keywords":"","body":"18.6 函数 如何使用内建函数recover终止panic过程（参考章节13.3）： func protect(g func()) { defer func() { log.Println(\"done\") // Println executes normally even if there is a panic if x := recover(); x != nil { log.Printf(\"run time panic: %v\", x) } }() log.Println(\"start\") g() } 链接 目录 上一节：接口 下一节：文件 "},"Go入门指南/18.7.html":{"url":"Go入门指南/18.7.html","title":"7","keywords":"","body":"18.7 文件 （1）如何打开一个文件并读取： file, err := os.Open(\"input.dat\") if err != nil { fmt.Printf(\"An error occurred on opening the inputfile\\n\" + \"Does the file exist?\\n\" + \"Have you got acces to it?\\n\") return } defer file.Close() iReader := bufio.NewReader(file) for { str, err := iReader.ReadString('\\n') if err != nil { return // error or EOF } fmt.Printf(\"The input was: %s\", str) } （2）如何通过切片读写文件： func cat(f *file.File) { const NBUF = 512 var buf [NBUF]byte for { switch nr, er := f.Read(buf[:]); true { case nr 0: if nw, ew := file.Stdout.Write(buf[0:nr]); nw != nr { fmt.Fprintf(os.Stderr, \"cat: error writing from %s: %s\\n\", f.String(), ew.String()) } } } } 链接 目录 上一节：函数 下一节：协程（goroutine）与通道（channel） "},"Go入门指南/18.8.html":{"url":"Go入门指南/18.8.html","title":"8","keywords":"","body":"18.8 协程（goroutine）与通道（channel） 出于性能考虑的建议： 实践经验表明，如果你使用并行运算获得高于串行运算的效率：在协程内部已经完成的大部分工作，其开销比创建协程和协程间通信还高。 1 出于性能考虑建议使用带缓存的通道： 使用带缓存的通道可以很轻易成倍提高它的吞吐量，某些场景其性能可以提高至10倍甚至更多。通过调整通道的容量，甚至可以尝试着更进一步的优化其性能。 2 限制一个通道的数据数量并将它们封装成一个数组： 如果使用通道传递大量单独的数据，那么通道将变成性能瓶颈。然而，将数据块打包封装成数组，在接收端解压数据时，性能可以提高至10倍。 创建：ch := make(chan type,buf) （1）如何使用for或者for-range遍历一个通道： for v := range ch { // do something with v } （2）如何检测一个通道ch是否关闭： //read channel until it closes or error-condition for { if input, open := 或者使用（1）自动检测。 （3）如何通过一个通道让主程序等待直到协程完成： （信号量模式）： ch := make(chan int) // Allocate a channel. // Start something in a goroutine; when it completes, signal on the channel. go func() { // doSomething ch 如果希望程序一直阻塞，在匿名函数中省略 ch 即可。 （4）通道的工厂模板：以下函数是一个通道工厂，启动一个匿名函数作为协程以生产通道： func pump() chan int { ch := make(chan int) go func() { for i := 0; ; i++ { ch （5）通道迭代器模板： （6）如何限制并发处理请求的数量：参考章节14.11 （7）如何在多核CPU上实现并行计算：参考章节14.13 （8）如何终止一个协程：runtime.Goexit() （9）简单的超时模板： timeout := make(chan bool, 1) go func() { time.Sleep(1e9) // one second timeout （10）如何使用输入通道和输出通道代替锁： func Worker(in, out chan *Task) { for { t := （11）如何在同步调用运行时间过长时将之丢弃：参考章节14.5 第二个变体 （12）如何在通道中使用计时器和定时器：参考章节14.5 （13）典型的服务器后端模型：参考章节14.4 链接 目录 上一节：文件 下一节：网络和网页应用 "},"Go入门指南/18.9.html":{"url":"Go入门指南/18.9.html","title":"9","keywords":"","body":"18.9 网络和网页应用 18.9.1 模板： 制作、解析并使模板生效： var strTempl = template.Must(template.New(\"TName\").Parse(strTemplateHTML)) 在网页应用中使用HTML过滤器过滤HTML特殊字符： {{html .}} 或者通过一个字段 FieldName {{ .FieldName |html }} 使用缓存模板（参考章节15.7） 链接 目录 上一节：协程（goroutine）与通道（channel） 下一节：其他 "},"Go入门指南/directory.html":{"url":"Go入门指南/directory.html","title":"directory","keywords":"","body":"目录 前言 第一部分：学习 Go 语言 第1章：Go 语言的起源，发展与普及 1.1 起源与发展 1.2 语言的主要特性与发展的环境和影响因素 第2章：安装与运行环境 2.1 平台与架构 2.2 Go 环境变量 2.3 在 Linux 上安装 Go 2.4 在 Mac OS X 上安装 Go 2.5 在 Windows 上安装 Go 2.6 安装目录清单 2.7 Go 运行时（runtime） 2.8 Go 解释器 第3章：编辑器、集成开发环境与其它工具 3.1 Go 开发环境的基本要求 3.2 编辑器和集成开发环境 3.3 调试器 3.4 构建并运行 Go 程序 3.5 格式化代码 3.6 生成代码文档 3.7 其它工具 3.8 Go 性能说明 3.9 与其它语言进行交互 第二部分：语言的核心结构与技术 第4章：基本结构和基本数据类型 4.1 文件名、关键字与标识符 4.2 Go 程序的基本结构和要素 4.3 常量 4.4 变量 4.5 基本类型和运算符 4.6 字符串 4.7 strings 和 strconv 包 4.8 时间和日期 4.9 指针 第5章：控制结构 5.1 if-else 结构 5.2 测试多返回值函数的错误 5.3 switch 结构 5.4 for 结构 5.5 Break 与 continue 5.6 标签与 goto 第6章：函数（function） 6.1 介绍 6.2 函数参数与返回值 6.3 传递变长参数 6.4 defer 和追踪 6.5 内置函数 6.6 递归函数 6.7 将函数作为参数 6.8 闭包 6.9 应用闭包：将函数作为返回值 6.10 使用闭包调试 6.11 计算函数执行时间 6.12 通过内存缓存来提升性能 第7章：数组与切片 7.1 声明和初始化 7.2 切片 7.3 For-range 结构 7.4 切片重组（reslice） 7.5 切片的复制与追加 7.6 字符串、数组和切片的应用 第8章：Map 8.1 声明、初始化和 make 8.2 测试键值对是否存在及删除元素 8.3 for-range 的配套用法 8.4 map 类型的切片 8.5 map 的排序 8.6 将 map 的键值对调 第9章：包（package） 9.1 标准库概述 9.2 regexp 包 9.3 锁和 sync 包 9.4 精密计算和 big 包 9.5 自定义包和可见性 9.6 为自定义包使用 godoc 9.7 使用 go install 安装自定义包 9.8 自定义包的目录结构、go install 和 go test 9.9 通过 Git 打包和安装 9.10 Go 的外部包和项目 9.11 在 Go 程序中使用外部库 第10章：结构（struct）与方法（method） 10.1 结构体定义 10.2 使用工厂方法创建结构体实例 10.3 使用自定义包中的结构体 10.4 带标签的结构体 10.5 匿名字段和内嵌结构体 10.6 方法 10.7 类型的 String() 方法和格式化描述符 10.8 垃圾回收和 SetFinalizer 第11章：接口（interface）与反射（reflection） 11.1 接口是什么 11.2 接口嵌套接口 11.3 类型断言：如何检测和转换接口变量的类型 11.4 类型判断：type-switch 11.5 测试一个值是否实现了某个接口 11.6 使用方法集与接口 11.7 第一个例子：使用 Sorter 接口排序 11.8 第二个例子：读和写 11.9 空接口 11.10 反射包 11.11 Printf 和反射 11.12 接口与动态类型 11.13 总结：Go 中的面向对象 11.14 结构体、集合和高阶函数 第三部分：Go 高级编程 第12章：读写数据 12.1 读取用户的输入 12.2 文件读写 12.3 文件拷贝 12.4 从命令行读取参数 12.5 用 buffer 读取文件 12.6 用切片读写文件 12.7 用 defer 关闭文件 12.8 使用接口的实际例子：fmt.Fprintf 12.9 格式化 JSON 数据 12.10 XML 数据格式 12.11 用 Gob 传输数据 12.12 Go 中的密码学 第13章：错误处理与测试 13.1 错误处理 13.2 运行时异常和 panic 13.3 从 panic 中恢复（Recover） 13.4 自定义包中的错误处理和 panicking 13.5 一种用闭包处理错误的模式 13.6 启动外部命令和程序 13.7 Go 中的单元测试和基准测试 13.8 测试的具体例子 13.9 用（测试数据）表驱动测试 13.10 性能调试：分析并优化 Go 程序 第14章：协程（goroutine）与通道（channel） 14.1 并发、并行和协程 14.2 使用通道进行协程间通信 14.3 协程同步：关闭通道-对阻塞的通道进行测试 14.4 使用 select 切换协程 14.5 通道，超时和计时器（Ticker） 14.6 协程和恢复（recover） 14.7 新旧模型对比：任务和worker 14.8 惰性生成器的实现 14.9 实现 Futures 模式 第15章：网络、模版与网页应用 15.1 tcp服务器 15.2 一个简单的web服务器 15.3 访问并读取页面数据 15.4 写一个简单的网页应用 第四部分：实际应用 第16章：常见的陷阱与错误 16.1 误用短声明导致变量覆盖 16.2 误用字符串 16.3 发生错误时使用defer关闭一个文件 16.4 何时使用new()和make() 16.5 不需要将一个指向切片的指针传递给函数 16.6 使用指针指向接口类型 16.7 使用值类型时误用指针 16.8 误用协程和通道 16.9 闭包和协程的使用 16.10 糟糕的错误处理 第17章：模式 17.1 关于逗号ok模式 第18章：出于性能考虑的实用代码片段 18.1 字符串 18.2 数组和切片 18.3 映射 18.4 结构体 18.5 接口 18.6 函数 18.7 文件 18.8 协程（goroutine）与通道（channel） 18.9 网络和网页应用 18.10 其他 18.11 出于性能考虑的最佳实践和建议 第19章：构建一个完整的应用程序 第20章：Go 语言在 Google App Engine 的使用 第21章：实际部署案例 附录 A 代码引用 B 有趣的 Go 引用 C 代码示例列表 D 书中的包引用 E 书中的工具引用 F 常见问题解答 G 习题答案 H 参考文献 索引 "},"Go入门指南/preface.html":{"url":"Go入门指南/preface.html","title":"preface","keywords":"","body":"前言 用更少的代码，更短的编译时间，创建运行更快的程序，享受更多的乐趣 对于学习 Go 编程语言的爱好者来说，这本书无疑是最适合你的一本书籍，这里包含了当前最全面的学习资源。本书通过对官方的在线文档、名人博客、书籍、相关文章以及演讲的资料收集和整理，并结合我自身在软件工程、编程语言和数据库开发的授课经验，将这些零碎的知识点组织成系统化的概念和技术分类来进行讲解。 随着软件规模的不断扩大，诸多的学者和谷歌的开发者们在公司内部的软件开发过程中开始经历大量的挫折，在诸多问题上都不能给出令人满意的解决方案，尤其是在使用 C++ 来开发大型的服务端软件时，情况更是不容乐观。由于二进制文件一般都是非常巨大的，因此需要耗费大量的时间在编译这些文件上，同时编程语言的设计思想也已经非常陈旧，这些情况都充分证明了现有的编程语言已不符合时下的生产环境。尽管硬件在过去的几十年中有了飞速的发展，但人们依旧没有找到机会去改变 C++ 在软件开发的重要地位，并在实际开发过程中忍受着它所带来的令人头疼的一些问题。因此学者们坐下来总结出了现在生产环境与软件开发之间的主要矛盾，并尝试设计一门全新的编程语言来解决这些问题。 以下就是他们讨论得出的对编程语言的设计要求： 能够以更快的速度开发软件 开发出的软件能够很好地在现代的多核计算机上工作 开发出的软件能够很好地在网络环境下工作 使人们能够享受软件开发的过程 Go 语言就在这样的环境下诞生了，它让人感觉像是 Python 或 Ruby 这样的动态语言，但却又拥有像 C 或者 Java 这类语言的高性能和安全性。 Go 语言出现的目的是希望在编程领域创造最实用的方式来进行软件开发。它并不是要用奇怪的语法和晦涩难懂的概念来从根本上推翻已有的编程语言，而是建立并改善了 C、Java、C# 中的许多语法风格。它提倡通过接口来针对面向对象编程，通过 goroutine 和 channel 来支持并发和并行编程。 这本书是为那些想要学习 Go 这门全新的，迷人的和充满希望的编程语言的开发者量身定做的。当然，你在学习 Go 语言之前需要具备一些关于编程的基础知识和经验，并且拥有合适的学习环境，但你并不需要对 C 或者 Java 或其它类似的语言有非常深入的了解。 对于那些熟悉 C 或者面向对象编程语言的开发者，我们将会在本书中用 Go 和一些编程语言的相关概念进行比较（书中会使用大家所熟知的缩写 “OO” 来表示面向对象）。 本书将会从最基础的概念讲起，同时也会讨论一些类似在应用 goroutine 和 channel 时有多少种不同的模式，如何在 Go 语言中使用谷歌 API，如何操作内存，如何在 Go 语言中进行程序测试和如何使用模板来开发 Web 应用这些高级概念和技巧。 在本书的第一部分，我们将会讨论 Go 语言的起源（第 1 章），以及如何安装 Go 语言（第 2 章）和开发环境（第 3 章）。 在本书的第二部分，我们将会带领你贯穿 Go 语言的核心思想，譬如简单与复杂类型（第 4、7、8 章），控制结构（第 5 章），函数（第 6 章），结构与方法（第 10 章）和接口（第 11 章）。我们会对 Go 语言的函数式和面向对象编程进行透彻的讲解，包括如何使用 Go 语言来构造大型项目（第 9 章）。 在本书的第三部分，你将会学习到如何处理不同格式的文件（第 12 章）和如何在 Go 语言中巧妙地使用错误处理机制（第 13 章）。然后我们会对 Go 语言中最值得称赞的设计 goroutine 和 channel 进行并发和多核应用的基本技巧的讲解（第 14 章）。最后，我们会讨论如何将 Go 语言应用到分布式和 Web 应用中的相关网络技巧（第 15 章）。 我们会在本书的第四部分向你展示许多 Go 语言的开发模式和一些编码规范，以及一些非常有用的代码片段（第 18 章）。在前面章节完成对所有的 Go 语言技巧的学习之后，你将会学习如何构造一个完整 Go 语言项目（第 19 章），然后我们会介绍一些关于 Go 语言在云（Google App Engine）方面的应用（第 20 章）。在本书的最后一章（第 21 章），我们会讨论一些在全世界范围内已经将 Go 语言投入实际开发的公司和组织。本书将会在最后给出一些对 Go 语言爱好者的引用，Go 相关包和工具的参考，以及章节练习的答案和所有参考资源和文献的清单。 Go 语言有一个被称之为 “没有废物” 的宗旨，就是将一切没有必要的东西都去掉，不能去掉的就无底线地简化，同时追求最大程度的自动化。他完美地诠释了敏捷编程的 KISS 秘诀：短小精悍！ Go 语言通过改善或去除在 C、C++ 或 Java 中的一些所谓“开放”特性来让开发者们的工作更加便利。这里只举例其中的几个，比如对于变量的默认初始化，内存分配与自动回收，以及更简洁却不失健壮的控制结构。同时我们也会发现 Go 语言旨在减少不必要的编码工作，这使得 Go 语言的代码更加简洁，从而比传统的面向对象语言更容易阅读和理解。 与 C++ 或 Java 这些有着庞大体系的语言相比，Go 语言简洁到可以将它整个的装入你的大脑中，而且比学习 Scala（Java 的并发语言）有更低的门槛，真可谓是 21 世纪的 C 语言！ 作为一门系统编程语言，你不应该为 Go 语言的大多数代码示例和练习都和控制台有着密不可分的关系而感到惊奇，因为提供平台依赖性的 GUI（用户界面）框架并不是一个简单的任务。有许多由第三方发起的 GUI 框架项目正在如火如荼地进行中，或许我们会在不久的将来看到一些可用的 Go 语言 GUI 框架。不过现阶段的 Go 语言已经提供了大量有关 Web 方面的功能，我们可以通过它强大的 http 和 template 包来达到 Web 应用的 GUI 实现。 我们会经常涉及到一些关于 Go 语言的编码规范，了解和使用这些已经被广泛认同的规范应该是你学习阶段最重要的实践。我会在书中尽量使用已经讲解的概念或者技巧来解释相关的代码示例，以避免你在不了解某些高级概念的情况下而感到迷茫。 我们通过 227 个完整的代码示例和书中的解释说明来对所有涉及到的概念和技巧进行彻底的讲解，你可以下载这些代码到你的电脑上运行，从而加深对概念的理解。 本书会尽可能地将前后章节的内容联系起来，当然这也同时要求你通过学习不同的知识来对一个问题提出尽可能多的解决方案。记住，学习一门新语言的最佳方式就是实践，运行它的代码，修改并尝试更多的方案。因此，你绝对不可以忽略书中的 130 个代码练习，这将对你学习好 Go 语言有很大的帮助。比如，我们就为斐波那契算法提供了 13 个不同的版本，而这些版本都使用了不同的概念和技巧。 你可以通过访问本书的 官方网站 下载书中的代码（译者注：所有代码文件已经包括在 GitHub 仓库中），并获得有关本书的勘误情况和内容更新。 为了让你在成为 Go 语言大师的道路上更加顺利，我们会专注于一些特别的章节以提供 Go 语言开发模式的最佳实践，同时也会帮助初学者逃离一些语言的陷阱。第 18 章可以作为你在开发时的一个参考手册，因为当中包含了众多的有价值的代码片段以及相关的解释说明。 最后要说明的是，你可以通过完整的索引来快速定位你需要阅读的章节。书中所有的代码都在 Go1.4 版本下测试通过。 这里有一段来自在 C++、Java 和 Python 领域众所周知的专家 Bruce Eckel 的评论： “作为一个有着 C/C++ 背景的开发者，我在使用 Go 语言时仿佛呼吸到了新鲜空气一般，令人心旷神怡。我认为使用 Go 语言进行系统编程开发比使用 C++ 有着更显著的优势，因为它在解决一些很难用 C++ 解决的问题的同时，让我的工作变得更加高效。我并不是说 C++ 的存在是一个错误，相反地，我认为这是历史发展的必然结果。当我深陷在 C 语言这门略微比汇编语言好一点的泥潭时，我坚信任何语言的构造都不可能支持大型项目的开发。像垃圾回收或并发语言支持这类东西，在当时都是极其荒谬的主意，根本没有人在乎。C++ 向大型项目开发迈出了重要的第一步，带领我们走进这个广袤无垠的世界。很庆幸 Stroustrup 做了让 C++ 兼容 C 语言以能够让其编译 C 程序这个正确的决定。我们当时需要 C++ 的出现。” “之后我们学到了更多。我们毫无疑问地接受了垃圾回收，异常处理和虚拟机这些当年人们认为只有疯子才会想的东西。C++ 的复杂程度（新版的 C++ 甚至更加复杂）极大的影响了软件开发的高效性，这使得它再也不再适合这个时代。人们不再像过往那样认同在 C++ 中兼容使用 C 语言的方法，认为这些工作只是在浪费时间，牺牲人们的努力。就在此时，Go 语言已经成功地解决了 C++ 中那些本打算解决却未能解决的关键问题。” 我非常想要向发明这门精湛的语言的 Go 开发团队表示真挚的感谢，尤其是团队的领导者 Rob Pike、Russ Cox 和 Andrew Gerrand，他们阐述的例子和说明都非常的完美。同时，我还要感谢 Miek Gieben、Frank Muller、Ryanne Dolan 和 Satish V.J. 给予我巨大的帮助，还有那些 golang-nuts 邮件列表里的所有的成员。 欢迎来到 Go 语言开发的奇妙世界！ 链接 目录 下一部分: Go 语言的起源，发展与普及 "},"RabbitMQ/":{"url":"RabbitMQ/","title":"RabbitMQ","keywords":"","body":"RabbitMQ 简介 RabbitMQ 是一套开源的消息队列服务软件 "},"Read/":{"url":"Read/","title":"Read","keywords":"","body":"读书 "}}